timestamp,message
1760334628860,"Preparing ...
"
1760334628864,"Mon Oct 13 05:50:28 UTC 2025
"
1760334628868,"/etc/alternatives/jre/bin/java --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions -Djavax.net.ssl.trustStore=/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -Djavax.net.ssl.trustStoreType=JKS -Djavax.net.ssl.trustStorePassword=amazon -DRDS_ROOT_CERT_PATH=/opt/amazon/certs/rds-combined-ca-bundle.pem -DREDSHIFT_ROOT_CERT_PATH=/opt/amazon/certs/redshift-ssl-ca-cert.pem -DRDS_TRUSTSTORE_URL=file:/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -cp /usr/share/aws/aws-glue-shuffle/*:/usr/share/aws/emr-glue-bootstrap/*:/usr/lib/spark/jars/*:/usr/lib/spark/conf:/usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/aws/hmclient/lib/*:/usr/share/aws/iceberg/lib/*:/usr/share/aws/delta/lib/*:/usr/lib/hudi/*:/usr/share/aws/redshift/jdbc/*:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/glue-connectors/lib/*:/usr/share/aws/glue-pii-dependencies/lib/*:/usr/share/aws/datazone-openlineage-spark/lib/*:/usr/lib/hadoop/lib/*::/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/cloudwatch-sink/lib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/lib/hadoop/*:/etc/hadoop/conf:/usr/share/java/Hive-JSON-Serde/* -Dlog4j2.configurationFile=/etc/spark/conf.dist/log4j2.properties com.amazonaws.services.glue.GlueBootstrap --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.maxExecutors=9 --conf spark.executor.memory=20g --conf spark.driver.memory=20g --conf spark.network.timeout=600 --app_name maximo_dq_matusetrans    --glue-di-packages-correlation-ids 20250828-143656_,20250828-143656_,6378082053,6378082053 --TempDir s3://aws-glue-assets-331875467123-us-gov-west-1/entergy-gov-data-core-code/temporary/ --internal-lib-urls https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/002/Glue5.0/aws-glue-dataplane-python/java17/5.0.704/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip?X-Amz-Security-Token=FwoDYXdzEDwaDAsHj%2BABAtykqHM7PCKuAQ%2BPlA1bYcjz40P4DvHrc6IrWeSrozbo5u8Jgj8gYlV6zipI3TPrs1XpyPbGPM9Z3W5hyMQFbGQcnt9VQg4KQCm1h8s6%2BifUiuXSV%2F4jVlwOuWRJ1p9J9c1hgLuxMxV%2BZ1CU5JknaYv0Kf8CYyKInnF5gn5rHcAkegtVfXuICE9oYuN2u2VzKnEND3sXDTyDaMMdCzOVyfKiBkdzIqjRQIwPRjRovzH2p8SyuneJgiicprLHBjIffBLTdz5ZfSDgLxSfFptbb9G4YcX52oM1XvA%2FA3xtVg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055020Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3H7JZ4CXI%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=12274cad0250e4130037aded804c436b21dc17bf340032faed4c614cf94bff2d,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/002/Glue5.0/aws-glue-di-libs/java17/5.0.704/odvJng-aws-glue-di-package-5.0.704.jar?X-Amz-Security-Token=FwoDYXdzEDwaDAsHj%2BABAtykqHM7PCKuAQ%2BPlA1bYcjz40P4DvHrc6IrWeSrozbo5u8Jgj8gYlV6zipI3TPrs1XpyPbGPM9Z3W5hyMQFbGQcnt9VQg4KQCm1h8s6%2BifUiuXSV%2F4jVlwOuWRJ1p9J9c1hgLuxMxV%2BZ1CU5JknaYv0Kf8CYyKInnF5gn5rHcAkegtVfXuICE9oYuN2u2VzKnEND3sXDTyDaMMdCzOVyfKiBkdzIqjRQIwPRjRovzH2p8SyuneJgiicprLHBjIffBLTdz5ZfSDgLxSfFptbb9G4YcX52oM1XvA%2FA3xtVg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055020Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3H7JZ4CXI%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=56d07ebeab5d188b780291522db711061870b6962463e803d46bb4dee5f3e82d,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/002/Glue5.0/AwsGlueMLLibsPython/java17/5.0.382/yzED3c-AwsGlueMLLibs.py.zip?X-Amz-Security-Token=FwoDYXdzEDwaDAsHj%2BABAtykqHM7PCKuAQ%2BPlA1bYcjz40P4DvHrc6IrWeSrozbo5u8Jgj8gYlV6zipI3TPrs1XpyPbGPM9Z3W5hyMQFbGQcnt9VQg4KQCm1h8s6%2BifUiuXSV%2F4jVlwOuWRJ1p9J9c1hgLuxMxV%2BZ1CU5JknaYv0Kf8CYyKInnF5gn5rHcAkegtVfXuICE9oYuN2u2VzKnEND3sXDTyDaMMdCzOVyfKiBkdzIqjRQIwPRjRovzH2p8SyuneJgiicprLHBjIffBLTdz5ZfSDgLxSfFptbb9G4YcX52oM1XvA%2FA3xtVg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055020Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3H7JZ4CXI%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=fc254803174fd1d6020b0b75b9636cf7759f173f5a02fa3f6a67e84016e1bbae,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/002/Glue5.0/AwsGlueMLLibs/java17/5.0.382/ImuwKQ-AwsGlueMLLibs.jar?X-Amz-Security-Token=FwoDYXdzEDwaDAsHj%2BABAtykqHM7PCKuAQ%2BPlA1bYcjz40P4DvHrc6IrWeSrozbo5u8Jgj8gYlV6zipI3TPrs1XpyPbGPM9Z3W5hyMQFbGQcnt9VQg4KQCm1h8s6%2BifUiuXSV%2F4jVlwOuWRJ1p9J9c1hgLuxMxV%2BZ1CU5JknaYv0Kf8CYyKInnF5gn5rHcAkegtVfXuICE9oYuN2u2VzKnEND3sXDTyDaMMdCzOVyfKiBkdzIqjRQIwPRjRovzH2p8SyuneJgiicprLHBjIffBLTdz5ZfSDgLxSfFptbb9G4YcX52oM1XvA%2FA3xtVg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055020Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3H7JZ4CXI%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=0df7ad96330544c37d6c39a05e2dc31a71a3221fb2ec194efa1d3e7a5406d5a4 --config s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/config/maximo/dq/matusetrans.yaml  --job_type data_quality --JOB_ID j_22c5407bf054c34250ae9ec0077e138d3d1797154983c269253d648df2dd2941 --extra-py-files s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/mosaic.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/sqlglot.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/yaml.zip   --JOB_RUN_ID jr_151101c2a251f9e7980ed02c5d7cde460eb28f2c6e667536e31860fea21042ef_attempt_3 --scriptLocation s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py  --tenant-internal glue --enable-auto-scaling true --JOB_NAME maximo_dq_matusetrans
"
1760334628897,"openjdk version ""17.0.16"" 2025-07-15 LTS
OpenJDK Runtime Environment Corretto-17.0.16.8.1 (build 17.0.16+8-LTS)
"
1760334628897,"OpenJDK 64-Bit Server VM Corretto-17.0.16.8.1 (build 17.0.16+8-LTS, mixed mode, sharing)
"
1760334629872,"25/10/13 05:50:29 INFO GlueBootstrap: Glue Bootstrapping...
"
1760334629875,"25/10/13 05:50:29 INFO GlueBootstrap: Glue Bootstrapping the driver...
"
1760334629892,"25/10/13 05:50:29 INFO GlueBootstrap: Downloading Glue libs...
"
1760334629895,"25/10/13 05:50:29 INFO GlueBootstrap: Downloading customer supplied extra files...
"
1760334629986,"25/10/13 05:50:29 WARN VersionInfoUtils: The AWS SDK for Java 1.x entered maintenance mode starting July 31, 2024 and will reach end of support on December 31, 2025. For more information, see https://aws.amazon.com/blogs/developer/the-aws-sdk-for-java-1-x-is-in-maintenance-mode-effective-july-31-2024/
You can print where on the file system the AWS SDK for Java 1.x core runtime is located by setting the AWS_JAVA_V1_PRINT_LOCATION environment variable or aws.java.v1.printLocation system property to 'true'.
This message can be disabled by setting the AWS_JAVA_V1_DISABLE_DEPRECATION_ANNOUNCEMENT environment variable or aws.java.v1.disableDeprecationAnnouncement system property to 'true'.
The AWS SDK for Java 1.x is being used here:
at java.base/java.lang.Thread.getStackTrace(Thread.java:1619)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.printDeprecationAnnouncement(VersionInfoUtils.java:81)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.<clinit>(VersionInfoUtils.java:59)
at glue.shaded.com.amazonaws.internal.EC2ResourceFetcher.<clinit>(EC2ResourceFetcher.java:44)
at glue.shaded.com.amazonaws.auth.InstanceMetadataServiceCredentialsFetcher.<init>(InstanceMetadataServiceCredentialsFetcher.java:38)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:111)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:91)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:75)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<clinit>(InstanceProfileCredentialsProvider.java:58)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.initializeProvider(EC2ContainerCredentialsProviderWrapper.java:66)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.<init>(EC2ContainerCredentialsProviderWrapper.java:55)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<init>(DefaultAWSCredentialsProviderChain.java:60)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<clinit>(DefaultAWSCredentialsProviderChain.java:54)
at glue.shaded.com.amazonaws.services.s3.AmazonS3ClientBuilder.standard(AmazonS3ClientBuilder.java:46)
at glue.shaded.com.amazonaws.services.s3.AmazonS3Client.builder(AmazonS3Client.java:740)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.getS3Client(GlueLibsDownloader.java:289)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.build(GlueLibsDownloader.java:281)
at com.amazonaws.services.glue.GlueBootstrap.downloadUserLibs(GlueBootstrap.java:409)
at com.amazonaws.services.glue.GlueBootstrap.lambda$setUpGlueAndUserLibs$2(GlueBootstrap.java:134)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
at java.base/java.lang.Thread.run(Thread.java:840)
"
1760334631357,"25/10/13 05:50:31 INFO GlueLibsDownloader: Elapsed time: 694 millis
"
1760334631598,"25/10/13 05:50:31 INFO GlueLibsDownloader: Elapsed time: 941 millis
"
1760334631808,"1760334631804
"
1760334632714,"INFO	2025-10-13T05:50:32,713	3786	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	25	Setting Up Virtual Env and Application/Customer Provided Python Modules started in async mode
"
1760334632717,"INFO	2025-10-13T05:50:32,717	3790	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute python3.11 -m venv --clear /tmp/glue_venv
"
1760334632725,"INFO	2025-10-13T05:50:32,724	3797	com.amazonaws.services.glue.launch.helpers.PrepareLaunchProperties	[main]	89	Get job script: raw_dq_load.py.
"
1760334632764,"INFO	2025-10-13T05:50:32,763	3836	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	99	
proxy {
  host = null
  port = -1
}
"
1760334632768,"INFO	2025-10-13T05:50:32,768	3841	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
"
1760334632968,"INFO	2025-10-13T05:50:32,968	4041	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
"
1760334632994,"INFO	2025-10-13T05:50:32,994	4067	com.amazonaws.services.glue.utils.AWSClientUtils$	[main]	98	AWSClientUtils: create aws sts client with conf: proxy hostnull, proxy port 0
"
1760334633582,"INFO	2025-10-13T05:50:33,582	4655	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	113	optimizeParallelismConfigs started 
"
1760334633588,"INFO	2025-10-13T05:50:33,588	4661	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	59	glue.etl.telemetry.runtimeImproveFeature.autoscaling, jr_151101c2a251f9e7980ed02c5d7cde460eb28f2c6e667536e31860fea21042ef_attempt_3
"
1760334633589,"INFO	2025-10-13T05:50:33,589	4662	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	31	setupLoggerProperties...
"
1760334633591,"WARN	2025-10-13T05:50:33,591	4664	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	60	Logger setup failed for exception analysis: Cannot invoke ""java.net.URL.toURI()"" because the return value of ""java.lang.Class.getResource(String)"" is null
"
1760334633594,"INFO	2025-10-13T05:50:33,594	4667	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading /tmp/glue-13001690390314342337log4j2.properties file to destination location: /tmp/glue-job-2406964502469336387/glue-13001690390314342337log4j2.properties
"
1760334633892,"INFO	2025-10-13T05:50:33,892	4965	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	78	setting up the log4j.configurationFile=/tmp/glue-job-2406964502469336387/glue-13001690390314342337log4j2.properties
"
1760334633909,"INFO	2025-10-13T05:50:33,909	4982	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/aws_glue_connectors
"
1760334633909,"INFO	2025-10-13T05:50:33,909	4982	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/aws_glue_connectors/selected
"
1760334633909,"INFO	2025-10-13T05:50:33,909	4982	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/exception_catch
"
1760334633910,"INFO	2025-10-13T05:50:33,909	4982	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/amazon
"
1760334633910,"INFO	2025-10-13T05:50:33,910	4983	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/amazon/certs
"
1760334633910,"INFO	2025-10-13T05:50:33,910	4983	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/aws_glue_connectors/selected/native
"
1760334633910,"INFO	2025-10-13T05:50:33,910	4983	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-2406964502469336387/aws_glue_connectors/marketplace
"
1760334633988,"INFO	2025-10-13T05:50:33,988	5061	com.amazonaws.services.glue.launch.helpers.ConnectionsManager	[main]	78	GLUE_CONNECTIVITY: attached connection types: ListBuffer()
"
1760334634249,"INFO	2025-10-13T05:50:34,249	5322	com.amazonaws.services.glue.PrepareLaunch	[main]	194	list of connectors to be added in classpath: List()
"
1760334634251,"INFO	2025-10-13T05:50:34,251	5324	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py file to destination location: /tmp/glue-job-2406964502469336387/raw_dq_load.py
"
1760334634435,"INFO	2025-10-13T05:50:34,435	5508	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	32	Encoding S3 URI s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
"
1760334634436,"INFO	2025-10-13T05:50:34,435	5508	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	37	Encoded S3 URI to s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
"
1760334634443,"INFO	2025-10-13T05:50:34,443	5516	com.amazonaws.services.glue.FileDownloader	[main]	138	Download bucket: entergy-govdatacore-dataeng-code-repo-dev key: entergy-gov-data-core-code/scripts/raw_dq_load.py to /tmp/glue-job-2406964502469336387/raw_dq_load.py with usingProxy: false and isProxyDisabled: true
"
1760334635242,"INFO	2025-10-13T05:50:35,242	6315	com.amazonaws.services.glue.FileDownloader	[sdk-async-response-2-0]	145	Object downloaded. Details: GetObjectResponse(AcceptRanges=bytes, LastModified=2025-10-10T16:51:03Z, ContentLength=453, ETag=""3f516bac98ff6f23cf7791a839a72cc0"", ContentType=binary/octet-stream, ServerSideEncryption=AES256, Metadata={})
INFO	2025-10-13T05:50:35,242	6315	com.amazonaws.services.glue.launch.helpers.FileManager	[main]	119	Script should be downloaded at /tmp/glue-job-2406964502469336387/raw_dq_load.py 
"
1760334639560,"INFO	2025-10-13T05:50:39,560	10633	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-2406964502469336387/python/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip -d /tmp/glue-job-2406964502469336387/python/ufak9W-AWSGlueDataplanePython-5.0.704
"
1760334639612,"INFO	2025-10-13T05:50:39,612	10685	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-2406964502469336387/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-2406964502469336387/python/ufak9W-AWSGlueDataplanePython-5.0.704/amzn_awsgluelibs-5.0.704-py3-none-any.whl
"
1760334641626,"INFO	2025-10-13T05:50:41,626	12699	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-2406964502469336387/python/yzED3c-AwsGlueMLLibs.py.zip -d /tmp/glue-job-2406964502469336387/python/yzED3c-AwsGlueMLLibs
"
1760334641631,"INFO	2025-10-13T05:50:41,631	12704	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-2406964502469336387/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-2406964502469336387/python/yzED3c-AwsGlueMLLibs/amzn_awsgluemlpythonlibs-1.0-py3-none-any.whl
"
1760334646934,"INFO	2025-10-13T05:50:46,934	18007	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-2406964502469336387/pythonmodules/createvenvzip.sh /tmp/glue_venv /tmp/glue-job-2406964502469336387_glue_venv.zip
"
1760334647083,"INFO	2025-10-13T05:50:47,082	18155	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	39	Setting Up Virtual Env and Application Python Modules has been completed in async mode
"
1760334647091,"INFO	2025-10-13T05:50:47,091	18164	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	50	shutdownAsyncProcessing has been Started
"
1760334647091,"INFO	2025-10-13T05:50:47,091	18164	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	76	shutdownAsyncProcessing has been completed
"
1760334647458,"Launching ...
"
1760334647460,"Mon Oct 13 05:50:47 UTC 2025
"
1760334649261,"INFO	2025-10-13T05:50:49,258	1743	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
"
1760334649518,"INFO	2025-10-13T05:50:49,518	2003	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
"
1760334649660,"INFO	2025-10-13T05:50:49,660	2145	com.amazonaws.services.glue.SafeLogging	[main]	60	Initializing logging subsystem
"
1760334654688,"INFO	2025-10-13T05:50:54,687	7172	org.apache.spark.emr.EMRParamSideChannel	[Thread-7]	177	Setting FGAC mode to false
"
1760334654700,"INFO	2025-10-13T05:50:54,699	7184	org.apache.spark.SparkContext	[Thread-7]	60	Running Spark version 3.5.4-amzn-0
"
1760334654700,"INFO	2025-10-13T05:50:54,700	7185	org.apache.spark.SparkContext	[Thread-7]	60	OS info Linux, 5.10.240-238.966.amzn2.x86_64, amd64
"
1760334654701,"INFO	2025-10-13T05:50:54,701	7186	org.apache.spark.SparkContext	[Thread-7]	60	Java version 17.0.16
"
1760334654850,"INFO	2025-10-13T05:50:54,850	7335	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
"
1760334654851,"INFO	2025-10-13T05:50:54,851	7336	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	No custom resources configured for spark.driver.
"
1760334654851,"INFO	2025-10-13T05:50:54,851	7336	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
"
1760334654852,"INFO	2025-10-13T05:50:54,852	7337	org.apache.spark.SparkContext	[Thread-7]	60	Submitted application: maximo_dq_matusetrans
"
1760334654877,"INFO	2025-10-13T05:50:54,877	7362	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Default ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
"
1760334654884,"INFO	2025-10-13T05:50:54,883	7368	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
"
1760334654885,"INFO	2025-10-13T05:50:54,885	7370	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 0
"
1760334654889,"INFO	2025-10-13T05:50:54,888	7373	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	User executor ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
"
1760334654889,"INFO	2025-10-13T05:50:54,889	7374	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
"
1760334654889,"INFO	2025-10-13T05:50:54,889	7374	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 1
"
1760334654974,"INFO	2025-10-13T05:50:54,973	7458	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls to: hadoop
"
1760334654974,"INFO	2025-10-13T05:50:54,974	7459	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls to: hadoop
"
1760334654975,"INFO	2025-10-13T05:50:54,974	7459	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls groups to: 
"
1760334654975,"INFO	2025-10-13T05:50:54,975	7460	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls groups to: 
"
1760334654975,"INFO	2025-10-13T05:50:54,975	7460	org.apache.spark.SecurityManager	[Thread-7]	60	SecurityManager: authentication enabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
"
1760334655245,"INFO	2025-10-13T05:50:55,244	7729	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'sparkDriver' on port 41669.
"
1760334655285,"INFO	2025-10-13T05:50:55,284	7769	org.apache.spark.SparkEnv	[Thread-7]	60	Registering MapOutputTracker
"
1760334655332,"INFO	2025-10-13T05:50:55,331	7816	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMaster
"
1760334655354,"INFO	2025-10-13T05:50:55,354	7839	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
"
1760334655355,"INFO	2025-10-13T05:50:55,354	7839	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	BlockManagerMasterEndpoint up
"
1760334655359,"INFO	2025-10-13T05:50:55,359	7844	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMasterHeartbeat
"
1760334655393,"INFO	2025-10-13T05:50:55,393	7878	org.apache.spark.storage.DiskBlockManager	[Thread-7]	60	Created local directory at /tmp/blockmgr-9478508d-3730-47a7-b82b-2e36e97a8b00
"
1760334655408,"INFO	2025-10-13T05:50:55,408	7893	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	MemoryStore started with capacity 11.8 GiB
"
1760334655424,"INFO	2025-10-13T05:50:55,423	7908	org.apache.spark.SparkEnv	[Thread-7]	60	Registering OutputCommitCoordinator
"
1760334655429,"INFO	2025-10-13T05:50:55,429	7914	org.apache.spark.subresultcache.SubResultCacheManager	[Thread-7]	60	Sub-result caches are disabled.
"
1760334655480,"INFO	2025-10-13T05:50:55,479	7964	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-2406964502469336387/jars/ImuwKQ-AwsGlueMLLibs.jar at spark://172.35.178.85:41669/jars/ImuwKQ-AwsGlueMLLibs.jar with timestamp 1760334654689
"
1760334655481,"INFO	2025-10-13T05:50:55,481	7966	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-2406964502469336387/jars/odvJng-aws-glue-di-package-5.0.704.jar at spark://172.35.178.85:41669/jars/odvJng-aws-glue-di-package-5.0.704.jar with timestamp 1760334654689
"
1760334655629,"INFO	2025-10-13T05:50:55,628	8113	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-2406964502469336387/extra-py-files/mosaic.zip at spark://172.35.178.85:41669/files/mosaic.zip with timestamp 1760334654689
"
1760334655630,"INFO	2025-10-13T05:50:55,630	8115	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-2406964502469336387/extra-py-files/mosaic.zip to /tmp/spark-d21a81a0-6545-4b3d-a2d6-92b0b0c09f2c/userFiles-48e59c55-348a-411a-af71-f93f871e68f2/mosaic.zip
"
1760334655641,"INFO	2025-10-13T05:50:55,641	8126	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-2406964502469336387/extra-py-files/sqlglot.zip at spark://172.35.178.85:41669/files/sqlglot.zip with timestamp 1760334654689
"
1760334655641,"INFO	2025-10-13T05:50:55,641	8126	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-2406964502469336387/extra-py-files/sqlglot.zip to /tmp/spark-d21a81a0-6545-4b3d-a2d6-92b0b0c09f2c/userFiles-48e59c55-348a-411a-af71-f93f871e68f2/sqlglot.zip
"
1760334655647,"INFO	2025-10-13T05:50:55,647	8132	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-2406964502469336387/extra-py-files/yaml.zip at spark://172.35.178.85:41669/files/yaml.zip with timestamp 1760334654689
"
1760334655647,"INFO	2025-10-13T05:50:55,647	8132	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-2406964502469336387/extra-py-files/yaml.zip to /tmp/spark-d21a81a0-6545-4b3d-a2d6-92b0b0c09f2c/userFiles-48e59c55-348a-411a-af71-f93f871e68f2/yaml.zip
"
1760334655691,"INFO	2025-10-13T05:50:55,690	8175	org.apache.spark.SparkContext	[Thread-7]	60	Added archive /tmp/glue-job-2406964502469336387_glue_venv.zip#python_environment at spark://172.35.178.85:41669/files/glue-job-2406964502469336387_glue_venv.zip with timestamp 1760334654689
"
1760334655691,"INFO	2025-10-13T05:50:55,691	8176	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-2406964502469336387_glue_venv.zip to /tmp/spark-641549d6-aed8-490f-b924-cfe87dea7a93/glue-job-2406964502469336387_glue_venv.zip
"
1760334655705,"INFO	2025-10-13T05:50:55,704	8189	org.apache.spark.SparkContext	[Thread-7]	60	Unpacking an archive /tmp/glue-job-2406964502469336387_glue_venv.zip#python_environment from /tmp/spark-641549d6-aed8-490f-b924-cfe87dea7a93/glue-job-2406964502469336387_glue_venv.zip to /tmp/spark-d21a81a0-6545-4b3d-a2d6-92b0b0c09f2c/userFiles-48e59c55-348a-411a-af71-f93f871e68f2/python_environment
"
1760334656123,"INFO	2025-10-13T05:50:56,122	8607	org.apache.spark.scheduler.cluster.glue.JESClusterManager	[Thread-7]	121	Python path for executors: mosaic.zip:sqlglot.zip:yaml.zip:python_environment
"
1760334656125,"INFO	2025-10-13T05:50:56,125	8610	org.apache.spark.deploy.glue.client.GlueRMClientFactory	[Thread-7]	60	JESClusterManager: Initializing JES client with endpoint: https://glue-jes.us-gov-west-1.amazonaws.com
"
1760334656749,"INFO	2025-10-13T05:50:56,749	9234	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	JESSchedulerBackend
"
1760334656751,"INFO	2025-10-13T05:50:56,751	9236	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
"
1760334656784,"INFO	2025-10-13T05:50:56,784	9269	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Starting JES Scheduler Backend.
"
1760334656785,"INFO	2025-10-13T05:50:56,785	9270	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760334656786,"INFO	2025-10-13T05:50:56,786	9271	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Initial executors are 1
"
1760334656791,"INFO	2025-10-13T05:50:56,791	9276	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334656793,"INFO	2025-10-13T05:50:56,793	9278	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 1, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334656795,"INFO	2025-10-13T05:50:56,795	9280	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42395.
"
1760334656795,"INFO	2025-10-13T05:50:56,795	9280	org.apache.spark.network.netty.NettyBlockTransferService	[Thread-7]	88	Server created on 172.35.178.85:42395
"
1760334656795,"INFO	2025-10-13T05:50:56,795	9280	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 1; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_1_a_spark-application-1760334656744_p_1
"
1760334656797,"INFO	2025-10-13T05:50:56,797	9282	org.apache.spark.storage.BlockManager	[Thread-7]	60	Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
"
1760334656805,"INFO	2025-10-13T05:50:56,805	9290	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registering BlockManager BlockManagerId(driver, 172.35.178.85, 42395, None)
"
1760334656808,"INFO	2025-10-13T05:50:56,808	9293	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.178.85:42395 with 11.8 GiB RAM, BlockManagerId(driver, 172.35.178.85, 42395, None)
"
1760334656810,"INFO	2025-10-13T05:50:56,810	9295	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registered BlockManager BlockManagerId(driver, 172.35.178.85, 42395, None)
"
1760334656811,"INFO	2025-10-13T05:50:56,811	9296	org.apache.spark.storage.BlockManager	[Thread-7]	60	Initialized BlockManager: BlockManagerId(driver, 172.35.178.85, 42395, None)
"
1760334656812,"INFO	2025-10-13T05:50:56,812	9297	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334656982,"INFO	2025-10-13T05:50:56,981	9466	org.apache.spark.deploy.history.SingleEventLogFileWriter	[Thread-7]	60	Logging events to file:/var/log/spark/apps/spark-application-1760334656744.inprogress
"
1760334657083,"INFO	2025-10-13T05:50:57,083	9568	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
"
1760334657084,"INFO	2025-10-13T05:50:57,084	9569	org.apache.spark.ExecutorAllocationManager	[Thread-7]	60	Dynamic allocation is enabled without a shuffle service.
"
1760334657111,"INFO	2025-10-13T05:50:57,110	9595	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760334657111,"INFO	2025-10-13T05:50:57,111	9596	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Requested total executors are 1
"
1760334657159,"INFO	2025-10-13T05:50:57,159	9644	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[Thread-7]	51	Started file writer for com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter
"
1760334657167,"INFO	2025-10-13T05:50:57,167	9652	org.apache.spark.SparkContext	[Thread-7]	60	Registered listener com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener
"
1760334657188,"INFO	2025-10-13T05:50:57,187	9672	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	getDriverLogUrls Map()
"
1760334657193,"INFO	2025-10-13T05:50:57,192	9677	org.apache.spark.executor.ExecutorLogUrlHandler	[Thread-7]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
"
1760334657195,"INFO	2025-10-13T05:50:57,195	9680	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
"
1760334657536,"INFO	2025-10-13T05:50:57,536	10021	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334657537,"INFO	2025-10-13T05:50:57,537	10022	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-3d5c562f7f0fcf34315dd6e8c6a97be6018c28ef created for executor 1 in resource profile 0
"
1760334657729,"INFO	2025-10-13T05:50:57,729	10214	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Setting hive.metastore.warehouse.dir ('/tmp/spark-warehouse') to the value of spark.sql.warehouse.dir.
"
1760334657733,"INFO	2025-10-13T05:50:57,732	10217	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Warehouse path is 'file:/home/hadoop/spark-warehouse'.
"
1760334660133,"INFO	2025-10-13T05:51:00,133	12618	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
"
1760334660849,"WARN	2025-10-13T05:51:00,848	13333	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
"
1760334660849,"INFO	2025-10-13T05:51:00,849	13334	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
"
1760334660964,"INFO	2025-10-13T05:51:00,963	13448	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-raw-dev/maximo_raw.db/matusetrans/metadata/00040-0ac13173-58a7-4bfe-b1c0-78d6ce82c99f.metadata.json
"
1760334661346,"INFO	2025-10-13T05:51:01,346	13831	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_raw.matusetrans
"
1760334661368,"INFO	2025-10-13T05:51:01,367	13852	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_raw.matusetrans loaded Spark schema: StructType(StructField(itemnum,StringType,true),StructField(storeloc,StringType,true),StructField(transdate,TimestampType,true),StructField(actualdate,TimestampType,true),StructField(quantity,DecimalType(15,2),true),StructField(curbal,DecimalType(15,2),true),StructField(physcnt,DecimalType(15,2),true),StructField(unitcost,DecimalType(18,6),true),StructField(actualcost,DecimalType(18,6),true),StructField(ponum,StringType,true),StructField(conversion,DecimalType(19,6),true),StructField(assetnum,StringType,true),StructField(enterby,StringType,true),StructField(it1,StringType,true),StructField(it2,StringType,true),StructField(it3,StringType,true),StructField(it4,DecimalType(15,2),true),StructField(it5,StringType,true),StructField(memo,StringType,true),StructField(outside,DecimalType(38,10),true),StructField(issueto,StringType,true),StructField(packingslipnum,StringType,true),StructField(polinenum,DecimalType(38,10),true),StructField(rollup,DecimalType(38,10),true),StructField(itin1,StringType,true),StructField(itin2,StringType,true),StructField(itin3,StringType,true),StructField(binnum,StringType,true),StructField(lotnum,StringType,true),StructField(issuetype,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(linecost,DecimalType(18,6),true),StructField(financialperiod,StringType,true),StructField(currencycode,StringType,true),StructField(currencyunitcost,DecimalType(18,6),true),StructField(rotassetnum,StringType,true),StructField(currencylinecost,DecimalType(18,6),true),StructField(location,StringType,true),StructField(description,StringType,true),StructField(exchangerate,DecimalType(14,7),true),StructField(sparepartadded,DecimalType(38,10),true),StructField(qtyrequested,DecimalType(15,2),true),StructField(exchangerate2,DecimalType(14,7),true),StructField(linecost2,DecimalType(18,6),true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(matusetransid,DecimalType(38,10),true),StructField(matrectransid,DecimalType(38,10),true),StructField(it6,StringType,true),StructField(it7,StringType,true),StructField(it8,StringType,true),StructField(it9,StringType,true),StructField(it10,StringType,true),StructField(itin4,StringType,true),StructField(itin5,StringType,true),StructField(itin6,StringType,true),StructField(itin7,StringType,true),StructField(sourcesysid,StringType,true),StructField(ownersysid,StringType,true),StructField(externalrefid,StringType,true),StructField(sendersysid,StringType,true),StructField(fincntrlid,StringType,true),StructField(issueid,DecimalType(38,10),true),StructField(qtyreturned,DecimalType(15,2),true),StructField(orgid,StringType,true),StructField(siteid,StringType,true),StructField(refwo,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(linetype,StringType,true),StructField(itemsetid,StringType,true),StructField(conditioncode,StringType,true),StructField(condrate,DecimalType(38,10),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(tositeid,StringType,true),StructField(langcode,StringType,true),StructField(hasld,DecimalType(38,10),true),StructField(porevisionnum,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(invuseid,DecimalType(38,10),true),StructField(consignment,DecimalType(38,10),true),StructField(consinvoicenum,StringType,true),StructField(consvendor,StringType,true),StructField(issueunit,StringType,true),StructField(wpitemid,DecimalType(38,10),true),StructField(invpicklistid,DecimalType(38,10),true),StructField(invuselinesplitid,DecimalType(38,10),true),StructField(etraimmwrnum,DecimalType(38,10),true),StructField(etrcapitalized,DecimalType(38,10),true),StructField(etronesourcetax,DecimalType(16,2),true),StructField(etrplusproc,StringType,true),StructField(etrsendendbal,DecimalType(15,2),true),StructField(etrtdwonum,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(rowstamp,StringType,true),StructField(etrmaterialupgrade,DecimalType(38,10),true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760334662068,"INFO	2025-10-13T05:51:02,068	14553	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
"
1760334662212,"WARN	2025-10-13T05:51:02,211	14696	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
"
1760334662212,"INFO	2025-10-13T05:51:02,212	14697	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
"
1760334662344,"INFO	2025-10-13T05:51:02,344	14829	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-dq-dev/maximo_dq.db/matusetrans/metadata/00013-a426c371-0102-4dff-a9e7-afc67c1203e6.metadata.json
"
1760334662498,"INFO	2025-10-13T05:51:02,498	14983	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_dq.matusetrans
"
1760334662501,"INFO	2025-10-13T05:51:02,501	14986	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.matusetrans loaded Spark schema: StructType(StructField(itemnum,StringType,true),StructField(storeloc,StringType,true),StructField(transdate,TimestampType,true),StructField(actualdate,TimestampType,true),StructField(quantity,DecimalType(15,2),true),StructField(curbal,DecimalType(15,2),true),StructField(physcnt,DecimalType(15,2),true),StructField(unitcost,DecimalType(18,6),true),StructField(actualcost,DecimalType(18,6),true),StructField(ponum,StringType,true),StructField(conversion,DecimalType(19,6),true),StructField(assetnum,StringType,true),StructField(enterby,StringType,true),StructField(it1,StringType,true),StructField(it2,StringType,true),StructField(it3,StringType,true),StructField(it4,DecimalType(15,2),true),StructField(it5,StringType,true),StructField(memo,StringType,true),StructField(outside,DecimalType(38,10),true),StructField(issueto,StringType,true),StructField(packingslipnum,StringType,true),StructField(polinenum,DecimalType(38,10),true),StructField(rollup,DecimalType(38,10),true),StructField(itin1,StringType,true),StructField(itin2,StringType,true),StructField(itin3,StringType,true),StructField(binnum,StringType,true),StructField(lotnum,StringType,true),StructField(issuetype,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(linecost,DecimalType(18,6),true),StructField(financialperiod,StringType,true),StructField(currencycode,StringType,true),StructField(currencyunitcost,DecimalType(18,6),true),StructField(rotassetnum,StringType,true),StructField(currencylinecost,DecimalType(18,6),true),StructField(location,StringType,true),StructField(description,StringType,true),StructField(exchangerate,DecimalType(14,7),true),StructField(sparepartadded,DecimalType(38,10),true),StructField(qtyrequested,DecimalType(15,2),true),StructField(exchangerate2,DecimalType(14,7),true),StructField(linecost2,DecimalType(18,6),true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(matusetransid,DecimalType(38,10),true),StructField(matrectransid,DecimalType(38,10),true),StructField(it6,StringType,true),StructField(it7,StringType,true),StructField(it8,StringType,true),StructField(it9,StringType,true),StructField(it10,StringType,true),StructField(itin4,StringType,true),StructField(itin5,StringType,true),StructField(itin6,StringType,true),StructField(itin7,StringType,true),StructField(sourcesysid,StringType,true),StructField(ownersysid,StringType,true),StructField(externalrefid,StringType,true),StructField(sendersysid,StringType,true),StructField(fincntrlid,StringType,true),StructField(issueid,DecimalType(38,10),true),StructField(qtyreturned,DecimalType(15,2),true),StructField(orgid,StringType,true),StructField(siteid,StringType,true),StructField(refwo,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(linetype,StringType,true),StructField(itemsetid,StringType,true),StructField(conditioncode,StringType,true),StructField(condrate,DecimalType(38,10),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(tositeid,StringType,true),StructField(langcode,StringType,true),StructField(hasld,DecimalType(38,10),true),StructField(porevisionnum,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(invuseid,DecimalType(38,10),true),StructField(consignment,DecimalType(38,10),true),StructField(consinvoicenum,StringType,true),StructField(consvendor,StringType,true),StructField(issueunit,StringType,true),StructField(wpitemid,DecimalType(38,10),true),StructField(invpicklistid,DecimalType(38,10),true),StructField(invuselinesplitid,DecimalType(38,10),true),StructField(etraimmwrnum,DecimalType(38,10),true),StructField(etrcapitalized,DecimalType(38,10),true),StructField(etronesourcetax,DecimalType(16,2),true),StructField(etrplusproc,StringType,true),StructField(etrsendendbal,DecimalType(15,2),true),StructField(etrtdwonum,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(rowstamp,StringType,true),StructField(etrmaterialupgrade,DecimalType(38,10),true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760334664099,"INFO	2025-10-13T05:51:04,098	16583	org.opensearch.hadoop.util.Version	[Thread-7]	143	OpenSearch Hadoop v1.2.0 [2a4148055f]
"
1760334664422,"INFO	2025-10-13T05:51:04,421	16906	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.matusetrans loaded Spark schema: StructType(StructField(itemnum,StringType,true),StructField(storeloc,StringType,true),StructField(transdate,TimestampType,true),StructField(actualdate,TimestampType,true),StructField(quantity,DecimalType(15,2),true),StructField(curbal,DecimalType(15,2),true),StructField(physcnt,DecimalType(15,2),true),StructField(unitcost,DecimalType(18,6),true),StructField(actualcost,DecimalType(18,6),true),StructField(ponum,StringType,true),StructField(conversion,DecimalType(19,6),true),StructField(assetnum,StringType,true),StructField(enterby,StringType,true),StructField(it1,StringType,true),StructField(it2,StringType,true),StructField(it3,StringType,true),StructField(it4,DecimalType(15,2),true),StructField(it5,StringType,true),StructField(memo,StringType,true),StructField(outside,DecimalType(38,10),true),StructField(issueto,StringType,true),StructField(packingslipnum,StringType,true),StructField(polinenum,DecimalType(38,10),true),StructField(rollup,DecimalType(38,10),true),StructField(itin1,StringType,true),StructField(itin2,StringType,true),StructField(itin3,StringType,true),StructField(binnum,StringType,true),StructField(lotnum,StringType,true),StructField(issuetype,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(linecost,DecimalType(18,6),true),StructField(financialperiod,StringType,true),StructField(currencycode,StringType,true),StructField(currencyunitcost,DecimalType(18,6),true),StructField(rotassetnum,StringType,true),StructField(currencylinecost,DecimalType(18,6),true),StructField(location,StringType,true),StructField(description,StringType,true),StructField(exchangerate,DecimalType(14,7),true),StructField(sparepartadded,DecimalType(38,10),true),StructField(qtyrequested,DecimalType(15,2),true),StructField(exchangerate2,DecimalType(14,7),true),StructField(linecost2,DecimalType(18,6),true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(matusetransid,DecimalType(38,10),true),StructField(matrectransid,DecimalType(38,10),true),StructField(it6,StringType,true),StructField(it7,StringType,true),StructField(it8,StringType,true),StructField(it9,StringType,true),StructField(it10,StringType,true),StructField(itin4,StringType,true),StructField(itin5,StringType,true),StructField(itin6,StringType,true),StructField(itin7,StringType,true),StructField(sourcesysid,StringType,true),StructField(ownersysid,StringType,true),StructField(externalrefid,StringType,true),StructField(sendersysid,StringType,true),StructField(fincntrlid,StringType,true),StructField(issueid,DecimalType(38,10),true),StructField(qtyreturned,DecimalType(15,2),true),StructField(orgid,StringType,true),StructField(siteid,StringType,true),StructField(refwo,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(linetype,StringType,true),StructField(itemsetid,StringType,true),StructField(conditioncode,StringType,true),StructField(condrate,DecimalType(38,10),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(tositeid,StringType,true),StructField(langcode,StringType,true),StructField(hasld,DecimalType(38,10),true),StructField(porevisionnum,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(invuseid,DecimalType(38,10),true),StructField(consignment,DecimalType(38,10),true),StructField(consinvoicenum,StringType,true),StructField(consvendor,StringType,true),StructField(issueunit,StringType,true),StructField(wpitemid,DecimalType(38,10),true),StructField(invpicklistid,DecimalType(38,10),true),StructField(invuselinesplitid,DecimalType(38,10),true),StructField(etraimmwrnum,DecimalType(38,10),true),StructField(etrcapitalized,DecimalType(38,10),true),StructField(etronesourcetax,DecimalType(16,2),true),StructField(etrplusproc,StringType,true),StructField(etrsendendbal,DecimalType(15,2),true),StructField(etrtdwonum,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(rowstamp,StringType,true),StructField(etrmaterialupgrade,DecimalType(38,10),true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760334664454,"WARN	2025-10-13T05:51:04,454	16939	org.apache.spark.sql.catalyst.util.SparkStringUtils	[Thread-7]	72	Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
"
1760334664884,"INFO	2025-10-13T05:51:04,883	17368	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.115.192:43930) with ID 1,  ResourceProfileId 0
"
1760334664885,"INFO	2025-10-13T05:51:04,885	17370	org.apache.spark.executor.ExecutorLogUrlHandler	[dispatcher-CoarseGrainedScheduler]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
"
1760334664887,"INFO	2025-10-13T05:51:04,887	17372	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 1 @ 1760334664885
"
1760334664888,"INFO	2025-10-13T05:51:04,887	17372	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 1
"
1760334664893,"INFO	2025-10-13T05:51:04,893	17378	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 1 has registered (new total is 1)
"
1760334664934,"INFO	2025-10-13T05:51:04,933	17418	org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown	[Thread-7]	60	
Output: itemnum#0, storeloc#1, transdate#2, actualdate#3, quantity#4, curbal#5, physcnt#6, unitcost#7, actualcost#8, ponum#9, conversion#10, assetnum#11, enterby#12, it1#13, it2#14, it3#15, it4#16, it5#17, memo#18, outside#19, issueto#20, packingslipnum#21, polinenum#22, rollup#23, itin1#24, itin2#25, itin3#26, binnum#27, lotnum#28, issuetype#29, gldebitacct#30, glcreditacct#31, linecost#32, financialperiod#33, currencycode#34, currencyunitcost#35, rotassetnum#36, currencylinecost#37, location#38, description#39, exchangerate#40, sparepartadded#41, qtyrequested#42, exchangerate2#43, linecost2#44, mrnum#45, mrlinenum#46, matusetransid#47, matrectransid#48, it6#49, it7#50, it8#51, it9#52, it10#53, itin4#54, itin5#55, itin6#56, itin7#57, sourcesysid#58, ownersysid#59, externalrefid#60, sendersysid#61, fincntrlid#62, issueid#63, qtyreturned#64, orgid#65, siteid#66, refwo#67, enteredastask#68, linetype#69, itemsetid#70, conditioncode#71, condrate#72, commoditygroup#73, commodity#74, tositeid#75, langcode#76, hasld#77, porevisionnum#78, invuselineid#79, invuseid#80, consignment#81, consinvoicenum#82, consvendor#83, issueunit#84, wpitemid#85, invpicklistid#86, invuselinesplitid#87, etraimmwrnum#88, etrcapitalized#89, etronesourcetax#90, etrplusproc#91, etrsendendbal#92, etrtdwonum#93, etrusetaxcode#94, rowstamp#95, etrmaterialupgrade#96, pk_hash#97, edl_load_date#98
        
"
1760334664946,"INFO	2025-10-13T05:51:04,945	17430	org.apache.iceberg.SnapshotScan	[Thread-7]	124	Scanning table glue_catalog.maximo_raw.matusetrans snapshot 1907307971737240053 created at 2025-10-13T05:16:06.524+00:00 with filter true
"
1760334664953,"INFO	2025-10-13T05:51:04,953	17438	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.115.192:46317 with 11.8 GiB RAM, BlockManagerId(1, 172.35.115.192, 46317, None)
"
1760334665213,"INFO	2025-10-13T05:51:05,212	17697	org.apache.iceberg.BaseDistributedDataScan	[Thread-7]	278	Planning file tasks locally for table glue_catalog.maximo_raw.matusetrans
"
1760334665513,"INFO	2025-10-13T05:51:05,513	17998	org.apache.iceberg.spark.source.SparkPartitioningAwareScan	[Thread-7]	119	Reporting UnknownPartitioning with 471 partition(s) for table glue_catalog.maximo_raw.matusetrans
"
1760334665551,"INFO	2025-10-13T05:51:05,551	18036	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	157	Requesting 0 bytes advisory partition size for table glue_catalog.maximo_dq.matusetrans
"
1760334665552,"INFO	2025-10-13T05:51:05,551	18036	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	138	Requesting UnspecifiedDistribution as write distribution for table glue_catalog.maximo_dq.matusetrans
"
1760334665554,"INFO	2025-10-13T05:51:05,554	18039	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	150	Requesting [] as write ordering for table glue_catalog.maximo_dq.matusetrans
"
1760334665805,"INFO	2025-10-13T05:51:05,805	18290	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665828,"INFO	2025-10-13T05:51:05,828	18313	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665833,"INFO	2025-10-13T05:51:05,832	18317	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665847,"INFO	2025-10-13T05:51:05,846	18331	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665854,"INFO	2025-10-13T05:51:05,854	18339	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665860,"INFO	2025-10-13T05:51:05,860	18345	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665861,"INFO	2025-10-13T05:51:05,861	18346	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334665948,"INFO	2025-10-13T05:51:05,948	18433	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 11.8 GiB)
"
1760334666012,"INFO	2025-10-13T05:51:06,012	18497	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KiB, actual size: 4.6 KiB, free 11.8 GiB)
"
1760334666014,"INFO	2025-10-13T05:51:06,014	18499	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_0_piece0 in memory on 172.35.178.85:42395 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334666018,"INFO	2025-10-13T05:51:06,018	18503	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 0 from broadcast at SparkBatch.java:85
"
1760334666346,"INFO	2025-10-13T05:51:06,346	18831	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1 stored as values in memory (estimated size 32.0 KiB, free 11.8 GiB)
"
1760334666351,"INFO	2025-10-13T05:51:06,351	18836	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KiB, actual size: 4.6 KiB, free 11.8 GiB)
"
1760334666351,"INFO	2025-10-13T05:51:06,351	18836	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.178.85:42395 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334666353,"INFO	2025-10-13T05:51:06,353	18838	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 1 from broadcast at SparkBatch.java:85
"
1760334666520,"INFO	2025-10-13T05:51:06,519	19004	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Registering RDD 5 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
"
1760334666525,"INFO	2025-10-13T05:51:06,525	19010	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Got map stage job 0 (save at NativeMethodAccessorImpl.java:0) with 471 output partitions
"
1760334666526,"INFO	2025-10-13T05:51:06,525	19010	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Final stage: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0)
"
1760334666526,"INFO	2025-10-13T05:51:06,526	19011	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Parents of final stage: List()
"
1760334666528,"INFO	2025-10-13T05:51:06,528	19013	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Missing parents: List()
"
1760334666531,"INFO	2025-10-13T05:51:06,531	19016	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
"
1760334666669,"INFO	2025-10-13T05:51:06,669	19154	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2 stored as values in memory (estimated size 37.9 KiB, free 11.8 GiB)
"
1760334666673,"INFO	2025-10-13T05:51:06,672	19157	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.2 KiB, actual size: 16.2 KiB, free 11.8 GiB)
"
1760334666673,"INFO	2025-10-13T05:51:06,673	19158	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.178.85:42395 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334666674,"INFO	2025-10-13T05:51:06,674	19159	org.apache.spark.SparkContext	[dag-scheduler-event-loop]	60	Created broadcast 2 from broadcast at DAGScheduler.scala:1664
"
1760334666696,"INFO	2025-10-13T05:51:06,696	19181	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting 471 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
"
1760334666698,"INFO	2025-10-13T05:51:06,697	19182	org.apache.spark.scheduler.TaskSchedulerImpl	[dag-scheduler-event-loop]	60	Adding task set 0.0 with 471 tasks resource profile 0
"
1760334666742,"INFO	2025-10-13T05:51:06,742	19227	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 0.0 in stage 0.0 (TID 0) (172.35.115.192, executor 1, partition 0, PROCESS_LOCAL, 40502 bytes) 
"
1760334666746,"INFO	2025-10-13T05:51:06,746	19231	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 1.0 in stage 0.0 (TID 1) (172.35.115.192, executor 1, partition 1, PROCESS_LOCAL, 37453 bytes) 
"
1760334667468,"INFO	2025-10-13T05:51:07,468	19953	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.115.192:46317 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334668854,"INFO	2025-10-13T05:51:08,853	21338	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.115.192:46317 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334684849,"INFO	2025-10-13T05:51:24,848	37333	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 2.0 in stage 0.0 (TID 2) (172.35.115.192, executor 1, partition 2, PROCESS_LOCAL, 28318 bytes) 
"
1760334684857,"INFO	2025-10-13T05:51:24,857	37342	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 1.0 in stage 0.0 (TID 1) in 18111 ms on 172.35.115.192 (executor 1) (1/471)
"
1760334685945,"INFO	2025-10-13T05:51:25,945	38430	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 3.0 in stage 0.0 (TID 3) (172.35.115.192, executor 1, partition 3, PROCESS_LOCAL, 28318 bytes) 
"
1760334685947,"INFO	2025-10-13T05:51:25,946	38431	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 0.0 in stage 0.0 (TID 0) in 19231 ms on 172.35.115.192 (executor 1) (2/471)
"
1760334696575,"INFO	2025-10-13T05:51:36,575	49060	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
"
1760334696575,"INFO	2025-10-13T05:51:36,575	49060	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
"
1760334696576,"INFO	2025-10-13T05:51:36,576	49061	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 1 new executor because tasks are backlogged (new desired total will be 2 for resource profile id: 0)
"
1760334696823,"INFO	2025-10-13T05:51:36,823	49308	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 4.0 in stage 0.0 (TID 4) (172.35.115.192, executor 1, partition 4, PROCESS_LOCAL, 28318 bytes) 
"
1760334696824,"INFO	2025-10-13T05:51:36,823	49308	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 2.0 in stage 0.0 (TID 2) in 11976 ms on 172.35.115.192 (executor 1) (3/471)
"
1760334697546,"INFO	2025-10-13T05:51:37,546	50031	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334697547,"INFO	2025-10-13T05:51:37,546	50031	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 2, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334697547,"INFO	2025-10-13T05:51:37,547	50032	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 2; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_2_a_spark-application-1760334656744_p_1
"
1760334697547,"INFO	2025-10-13T05:51:37,547	50032	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334697706,"INFO	2025-10-13T05:51:37,706	50191	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334697706,"INFO	2025-10-13T05:51:37,706	50191	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-3a45a422686ed1474e584b48701cfe7ab31b15ce created for executor 2 in resource profile 0
"
1760334698080,"INFO	2025-10-13T05:51:38,080	50565	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 5.0 in stage 0.0 (TID 5) (172.35.115.192, executor 1, partition 5, PROCESS_LOCAL, 28309 bytes) 
"
1760334698081,"INFO	2025-10-13T05:51:38,081	50566	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 3.0 in stage 0.0 (TID 3) in 12137 ms on 172.35.115.192 (executor 1) (4/471)
"
1760334706593,"INFO	2025-10-13T05:51:46,592	59077	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 4
"
1760334706593,"INFO	2025-10-13T05:51:46,592	59077	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 4
"
1760334706593,"INFO	2025-10-13T05:51:46,593	59078	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 2 new executors because tasks are backlogged (new desired total will be 4 for resource profile id: 0)
"
1760334706709,"INFO	2025-10-13T05:51:46,708	59193	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334706709,"INFO	2025-10-13T05:51:46,709	59194	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 3, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334706709,"INFO	2025-10-13T05:51:46,709	59194	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 3; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_3_a_spark-application-1760334656744_p_1
"
1760334706709,"INFO	2025-10-13T05:51:46,709	59194	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334706873,"INFO	2025-10-13T05:51:46,873	59358	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334706874,"INFO	2025-10-13T05:51:46,873	59358	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-7f8d69d5c9ac1e4337b0010e71a72a5e2d99699b created for executor 3 in resource profile 0
"
1760334706874,"INFO	2025-10-13T05:51:46,873	59358	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334706874,"INFO	2025-10-13T05:51:46,874	59359	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 4, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334706874,"INFO	2025-10-13T05:51:46,874	59359	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 4; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_4_a_spark-application-1760334656744_p_1
"
1760334706874,"INFO	2025-10-13T05:51:46,874	59359	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334707056,"INFO	2025-10-13T05:51:47,055	59540	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334707056,"INFO	2025-10-13T05:51:47,056	59541	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-cd8ad384c6bf678eca8ff7028a34d969d231f73d created for executor 4 in resource profile 0
"
1760334708647,"INFO	2025-10-13T05:51:48,647	61132	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 6.0 in stage 0.0 (TID 6) (172.35.115.192, executor 1, partition 6, PROCESS_LOCAL, 28318 bytes) 
"
1760334708648,"INFO	2025-10-13T05:51:48,647	61132	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 4.0 in stage 0.0 (TID 4) in 11825 ms on 172.35.115.192 (executor 1) (5/471)
"
1760334709727,"INFO	2025-10-13T05:51:49,727	62212	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 7.0 in stage 0.0 (TID 7) (172.35.115.192, executor 1, partition 7, PROCESS_LOCAL, 27718 bytes) 
"
1760334709728,"INFO	2025-10-13T05:51:49,728	62213	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 5.0 in stage 0.0 (TID 5) in 11649 ms on 172.35.115.192 (executor 1) (6/471)
"
1760334713632,"INFO	2025-10-13T05:51:53,632	66117	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.183.29:37286) with ID 4,  ResourceProfileId 0
"
1760334713633,"INFO	2025-10-13T05:51:53,632	66117	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 4 @ 1760334713632
"
1760334713633,"INFO	2025-10-13T05:51:53,633	66118	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 4
"
1760334713633,"INFO	2025-10-13T05:51:53,633	66118	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 4 has registered (new total is 2)
"
1760334713693,"INFO	2025-10-13T05:51:53,693	66178	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.183.29:37631 with 11.8 GiB RAM, BlockManagerId(4, 172.34.183.29, 37631, None)
"
1760334714612,"INFO	2025-10-13T05:51:54,612	67097	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 8.0 in stage 0.0 (TID 8) (172.34.183.29, executor 4, partition 8, PROCESS_LOCAL, 27718 bytes) 
"
1760334714613,"INFO	2025-10-13T05:51:54,613	67098	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 9.0 in stage 0.0 (TID 9) (172.34.183.29, executor 4, partition 9, PROCESS_LOCAL, 27718 bytes) 
"
1760334715406,"INFO	2025-10-13T05:51:55,405	67890	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.183.29:37631 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334716607,"INFO	2025-10-13T05:51:56,606	69091	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 8
"
1760334716607,"INFO	2025-10-13T05:51:56,607	69092	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 8
"
1760334716607,"INFO	2025-10-13T05:51:56,607	69092	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 4 new executors because tasks are backlogged (new desired total will be 8 for resource profile id: 0)
"
1760334716727,"INFO	2025-10-13T05:51:56,727	69212	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.183.29:37631 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334716787,"INFO	2025-10-13T05:51:56,786	69271	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334716787,"INFO	2025-10-13T05:51:56,787	69272	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 4 executor task status
"
1760334716788,"INFO	2025-10-13T05:51:56,788	69273	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling 2 pending JES executor tasks for status
"
1760334716789,"INFO	2025-10-13T05:51:56,789	69274	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-3a45a422686ed1474e584b48701cfe7ab31b15ce
"
1760334716826,"INFO	2025-10-13T05:51:56,825	69310	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 2 g-3a45a422686ed1474e584b48701cfe7ab31b15ce status is RUNNING
"
1760334716826,"INFO	2025-10-13T05:51:56,826	69311	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-7f8d69d5c9ac1e4337b0010e71a72a5e2d99699b
"
1760334716850,"INFO	2025-10-13T05:51:56,849	69334	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 3 g-7f8d69d5c9ac1e4337b0010e71a72a5e2d99699b status is RECEIVED_BY_TASKRUNNER
"
1760334717058,"INFO	2025-10-13T05:51:57,058	69543	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334717059,"INFO	2025-10-13T05:51:57,058	69543	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 5, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334717059,"INFO	2025-10-13T05:51:57,059	69544	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 5; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_5_a_spark-application-1760334656744_p_1
"
1760334717059,"INFO	2025-10-13T05:51:57,059	69544	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334717234,"INFO	2025-10-13T05:51:57,234	69719	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334717234,"INFO	2025-10-13T05:51:57,234	69719	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-37a7344b950d4a7c6b88d91b7c67c7f802bc4836 created for executor 5 in resource profile 0
"
1760334717235,"INFO	2025-10-13T05:51:57,235	69720	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334717235,"INFO	2025-10-13T05:51:57,235	69720	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 6, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334717235,"INFO	2025-10-13T05:51:57,235	69720	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 6; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_6_a_spark-application-1760334656744_p_1
"
1760334717236,"INFO	2025-10-13T05:51:57,235	69720	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334717405,"INFO	2025-10-13T05:51:57,405	69890	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334717405,"INFO	2025-10-13T05:51:57,405	69890	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-0357a2f94a6282fe8e9ff70f74abb6dd2d93309f created for executor 6 in resource profile 0
"
1760334717405,"INFO	2025-10-13T05:51:57,405	69890	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334717405,"INFO	2025-10-13T05:51:57,405	69890	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 7, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334717406,"INFO	2025-10-13T05:51:57,405	69890	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 7; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_7_a_spark-application-1760334656744_p_1
"
1760334717406,"INFO	2025-10-13T05:51:57,406	69891	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334717568,"INFO	2025-10-13T05:51:57,567	70052	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334717568,"INFO	2025-10-13T05:51:57,568	70053	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-ed45d8ace24b15a648becec4595e93c55f60c893 created for executor 7 in resource profile 0
"
1760334717568,"INFO	2025-10-13T05:51:57,568	70053	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334717569,"INFO	2025-10-13T05:51:57,568	70053	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 8, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334717569,"INFO	2025-10-13T05:51:57,569	70054	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 8; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_8_a_spark-application-1760334656744_p_1
"
1760334717569,"INFO	2025-10-13T05:51:57,569	70054	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334717750,"INFO	2025-10-13T05:51:57,750	70235	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334717750,"INFO	2025-10-13T05:51:57,750	70235	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-5ae730c72038f9a23c46fdce956915efa9487c91 created for executor 8 in resource profile 0
"
1760334718900,"INFO	2025-10-13T05:51:58,900	71385	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 10.0 in stage 0.0 (TID 10) (172.35.115.192, executor 1, partition 10, PROCESS_LOCAL, 27718 bytes) 
"
1760334718901,"INFO	2025-10-13T05:51:58,901	71386	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 7.0 in stage 0.0 (TID 7) in 9175 ms on 172.35.115.192 (executor 1) (7/471)
"
1760334719026,"INFO	2025-10-13T05:51:59,025	71510	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.42.110:50366) with ID 2,  ResourceProfileId 0
"
1760334719026,"INFO	2025-10-13T05:51:59,026	71511	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 2 @ 1760334719026
"
1760334719026,"INFO	2025-10-13T05:51:59,026	71511	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 2
"
1760334719027,"INFO	2025-10-13T05:51:59,026	71511	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 2 has registered (new total is 3)
"
1760334719088,"INFO	2025-10-13T05:51:59,087	71572	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.42.110:39813 with 11.8 GiB RAM, BlockManagerId(2, 172.35.42.110, 39813, None)
"
1760334720004,"INFO	2025-10-13T05:52:00,003	72488	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 11.0 in stage 0.0 (TID 11) (172.35.42.110, executor 2, partition 11, PROCESS_LOCAL, 27718 bytes) 
"
1760334720006,"INFO	2025-10-13T05:52:00,004	72489	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 12.0 in stage 0.0 (TID 12) (172.35.42.110, executor 2, partition 12, PROCESS_LOCAL, 27718 bytes) 
"
1760334720454,"INFO	2025-10-13T05:52:00,453	72938	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 13.0 in stage 0.0 (TID 13) (172.35.115.192, executor 1, partition 13, PROCESS_LOCAL, 27718 bytes) 
"
1760334720454,"INFO	2025-10-13T05:52:00,454	72939	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 6.0 in stage 0.0 (TID 6) in 11808 ms on 172.35.115.192 (executor 1) (8/471)
"
1760334720848,"INFO	2025-10-13T05:52:00,848	73333	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.42.110:39813 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334721463,"INFO	2025-10-13T05:52:01,462	73947	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.102.6:45112) with ID 3,  ResourceProfileId 0
"
1760334721463,"INFO	2025-10-13T05:52:01,463	73948	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 3 @ 1760334721463
"
1760334721463,"INFO	2025-10-13T05:52:01,463	73948	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 3
INFO	2025-10-13T05:52:01,463	73948	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 3 has registered (new total is 4)
"
1760334721521,"INFO	2025-10-13T05:52:01,520	74005	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.102.6:40029 with 11.8 GiB RAM, BlockManagerId(3, 172.35.102.6, 40029, None)
"
1760334722226,"INFO	2025-10-13T05:52:02,225	74710	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.42.110:39813 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334722416,"INFO	2025-10-13T05:52:02,416	74901	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 14.0 in stage 0.0 (TID 14) (172.35.102.6, executor 3, partition 14, PROCESS_LOCAL, 27718 bytes) 
"
1760334722417,"INFO	2025-10-13T05:52:02,417	74902	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 15.0 in stage 0.0 (TID 15) (172.35.102.6, executor 3, partition 15, PROCESS_LOCAL, 27718 bytes) 
"
1760334723197,"INFO	2025-10-13T05:52:03,197	75682	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.102.6:40029 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334723985,"INFO	2025-10-13T05:52:03,985	76470	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.235.173:46598) with ID 5,  ResourceProfileId 0
"
1760334723986,"INFO	2025-10-13T05:52:03,985	76470	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 5 @ 1760334723985
"
1760334723986,"INFO	2025-10-13T05:52:03,986	76471	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 5
"
1760334723986,"INFO	2025-10-13T05:52:03,986	76471	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 5 has registered (new total is 5)
"
1760334724050,"INFO	2025-10-13T05:52:04,050	76535	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.235.173:45219 with 11.8 GiB RAM, BlockManagerId(5, 172.35.235.173, 45219, None)
"
1760334724560,"INFO	2025-10-13T05:52:04,560	77045	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.102.6:40029 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334724685,"INFO	2025-10-13T05:52:04,685	77170	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.52.98:35638) with ID 6,  ResourceProfileId 0
"
1760334724686,"INFO	2025-10-13T05:52:04,686	77171	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 6 @ 1760334724685
"
1760334724686,"INFO	2025-10-13T05:52:04,686	77171	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 6
INFO	2025-10-13T05:52:04,686	77171	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 6 has registered (new total is 6)
"
1760334724752,"INFO	2025-10-13T05:52:04,752	77237	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.52.98:34261 with 11.8 GiB RAM, BlockManagerId(6, 172.35.52.98, 34261, None)
"
1760334724925,"INFO	2025-10-13T05:52:04,925	77410	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 16.0 in stage 0.0 (TID 16) (172.35.235.173, executor 5, partition 16, PROCESS_LOCAL, 27718 bytes) 
"
1760334724926,"INFO	2025-10-13T05:52:04,925	77410	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 17.0 in stage 0.0 (TID 17) (172.35.235.173, executor 5, partition 17, PROCESS_LOCAL, 27718 bytes) 
"
1760334725603,"INFO	2025-10-13T05:52:05,603	78088	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 18.0 in stage 0.0 (TID 18) (172.35.52.98, executor 6, partition 18, PROCESS_LOCAL, 27718 bytes) 
"
1760334725604,"INFO	2025-10-13T05:52:05,604	78089	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 19.0 in stage 0.0 (TID 19) (172.35.52.98, executor 6, partition 19, PROCESS_LOCAL, 27718 bytes) 
"
1760334725674,"INFO	2025-10-13T05:52:05,673	78158	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.235.173:45219 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334725902,"INFO	2025-10-13T05:52:05,902	78387	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.25.103:58944) with ID 7,  ResourceProfileId 0
"
1760334725902,"INFO	2025-10-13T05:52:05,902	78387	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 7 @ 1760334725902
"
1760334725903,"INFO	2025-10-13T05:52:05,902	78387	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 7
"
1760334725903,"INFO	2025-10-13T05:52:05,902	78387	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 7 has registered (new total is 7)
"
1760334725967,"INFO	2025-10-13T05:52:05,966	78451	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.25.103:33793 with 11.8 GiB RAM, BlockManagerId(7, 172.35.25.103, 33793, None)
"
1760334726411,"INFO	2025-10-13T05:52:06,411	78896	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.52.98:34261 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334726621,"INFO	2025-10-13T05:52:06,621	79106	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 16
"
1760334726621,"INFO	2025-10-13T05:52:06,621	79106	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 16
"
1760334726621,"INFO	2025-10-13T05:52:06,621	79106	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 8 new executors because tasks are backlogged (new desired total will be 16 for resource profile id: 0)
"
1760334726752,"INFO	2025-10-13T05:52:06,752	79237	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334726753,"INFO	2025-10-13T05:52:06,752	79237	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 9, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-13T05:52:06,752	79237	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 9; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_9_a_spark-application-1760334656744_p_1
"
1760334726753,"INFO	2025-10-13T05:52:06,753	79238	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334726850,"INFO	2025-10-13T05:52:06,849	79334	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 20.0 in stage 0.0 (TID 20) (172.35.25.103, executor 7, partition 20, PROCESS_LOCAL, 27118 bytes) 
"
1760334726850,"INFO	2025-10-13T05:52:06,850	79335	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 21.0 in stage 0.0 (TID 21) (172.35.25.103, executor 7, partition 21, PROCESS_LOCAL, 27118 bytes) 
"
1760334726931,"INFO	2025-10-13T05:52:06,930	79415	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334726931,"INFO	2025-10-13T05:52:06,931	79416	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-a390ba1fc4ad5944c89a6f75e5811f8826c07c23 created for executor 9 in resource profile 0
"
1760334726931,"INFO	2025-10-13T05:52:06,931	79416	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334726931,"INFO	2025-10-13T05:52:06,931	79416	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 10, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334726931,"INFO	2025-10-13T05:52:06,931	79416	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 10; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_10_a_spark-application-1760334656744_p_1
"
1760334726932,"INFO	2025-10-13T05:52:06,932	79417	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334726972,"INFO	2025-10-13T05:52:06,972	79457	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334726974,"INFO	2025-10-13T05:52:06,974	79459	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: c766151d-e168-4718-83ff-5a76efd09362)
"
1760334726975,"INFO	2025-10-13T05:52:06,974	79459	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 10 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334727015,"INFO	2025-10-13T05:52:07,015	79500	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.235.173:45219 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334727647,"INFO	2025-10-13T05:52:07,647	80132	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.25.103:33793 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334727856,"INFO	2025-10-13T05:52:07,856	80341	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.52.98:34261 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334728457,"INFO	2025-10-13T05:52:08,457	80942	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 22.0 in stage 0.0 (TID 22) (172.35.115.192, executor 1, partition 22, PROCESS_LOCAL, 27118 bytes) 
"
1760334728458,"INFO	2025-10-13T05:52:08,458	80943	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 10.0 in stage 0.0 (TID 10) in 9559 ms on 172.35.115.192 (executor 1) (9/471)
"
1760334729005,"INFO	2025-10-13T05:52:09,005	81490	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.25.103:33793 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334729415,"INFO	2025-10-13T05:52:09,415	81900	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.54.41:34652) with ID 8,  ResourceProfileId 0
"
1760334729416,"INFO	2025-10-13T05:52:09,416	81901	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 8 @ 1760334729416
"
1760334729416,"INFO	2025-10-13T05:52:09,416	81901	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 8
"
1760334729416,"INFO	2025-10-13T05:52:09,416	81901	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 8 has registered (new total is 8)
"
1760334729471,"INFO	2025-10-13T05:52:09,470	81955	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.54.41:36641 with 11.8 GiB RAM, BlockManagerId(8, 172.35.54.41, 36641, None)
"
1760334730129,"INFO	2025-10-13T05:52:10,129	82614	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 23.0 in stage 0.0 (TID 23) (172.35.115.192, executor 1, partition 23, PROCESS_LOCAL, 27118 bytes) 
"
1760334730130,"INFO	2025-10-13T05:52:10,130	82615	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 13.0 in stage 0.0 (TID 13) in 9676 ms on 172.35.115.192 (executor 1) (10/471)
"
1760334730312,"INFO	2025-10-13T05:52:10,312	82797	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 24.0 in stage 0.0 (TID 24) (172.35.54.41, executor 8, partition 24, PROCESS_LOCAL, 27118 bytes) 
"
1760334730313,"INFO	2025-10-13T05:52:10,313	82798	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 25.0 in stage 0.0 (TID 25) (172.35.54.41, executor 8, partition 25, PROCESS_LOCAL, 27118 bytes) 
"
1760334731039,"INFO	2025-10-13T05:52:11,039	83524	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.54.41:36641 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334732041,"INFO	2025-10-13T05:52:12,041	84526	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 26.0 in stage 0.0 (TID 26) (172.34.183.29, executor 4, partition 26, PROCESS_LOCAL, 27118 bytes) 
"
1760334732042,"INFO	2025-10-13T05:52:12,042	84527	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 9.0 in stage 0.0 (TID 9) in 17430 ms on 172.34.183.29 (executor 4) (11/471)
"
1760334732183,"INFO	2025-10-13T05:52:12,183	84668	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 27.0 in stage 0.0 (TID 27) (172.34.183.29, executor 4, partition 27, PROCESS_LOCAL, 27118 bytes) 
"
1760334732184,"INFO	2025-10-13T05:52:12,183	84668	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 8.0 in stage 0.0 (TID 8) in 17572 ms on 172.34.183.29 (executor 4) (12/471)
"
1760334732345,"INFO	2025-10-13T05:52:12,345	84830	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.54.41:36641 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334733103,"INFO	2025-10-13T05:52:13,102	85587	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.154.255:51992) with ID 9,  ResourceProfileId 0
"
1760334733103,"INFO	2025-10-13T05:52:13,103	85588	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 9 @ 1760334733103
"
1760334733103,"INFO	2025-10-13T05:52:13,103	85588	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 9 has registered (new total is 9)
INFO	2025-10-13T05:52:13,103	85588	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 9
"
1760334733160,"INFO	2025-10-13T05:52:13,160	85645	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.154.255:40305 with 11.8 GiB RAM, BlockManagerId(9, 172.34.154.255, 40305, None)
"
1760334734084,"INFO	2025-10-13T05:52:14,083	86568	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 28.0 in stage 0.0 (TID 28) (172.34.154.255, executor 9, partition 28, PROCESS_LOCAL, 27118 bytes) 
"
1760334734084,"INFO	2025-10-13T05:52:14,084	86569	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 29.0 in stage 0.0 (TID 29) (172.34.154.255, executor 9, partition 29, PROCESS_LOCAL, 27118 bytes) 
"
1760334734838,"INFO	2025-10-13T05:52:14,838	87323	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.154.255:40305 (size: 16.2 KiB, free: 11.8 GiB)
"
1760334736142,"INFO	2025-10-13T05:52:16,142	88627	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.154.255:40305 (size: 4.6 KiB, free: 11.8 GiB)
"
1760334736634,"INFO	2025-10-13T05:52:16,634	89119	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 20
"
1760334736634,"INFO	2025-10-13T05:52:16,634	89119	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 20
"
1760334736634,"INFO	2025-10-13T05:52:16,634	89119	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 4 new executors because tasks are backlogged (new desired total will be 20 for resource profile id: 0)
"
1760334737802,"INFO	2025-10-13T05:52:17,801	90286	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 30.0 in stage 0.0 (TID 30) (172.35.42.110, executor 2, partition 30, PROCESS_LOCAL, 27118 bytes) 
"
1760334737802,"INFO	2025-10-13T05:52:17,802	90287	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 12.0 in stage 0.0 (TID 12) in 17798 ms on 172.35.42.110 (executor 2) (13/471)
"
1760334738059,"INFO	2025-10-13T05:52:18,059	90544	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 31.0 in stage 0.0 (TID 31) (172.35.42.110, executor 2, partition 31, PROCESS_LOCAL, 27118 bytes) 
"
1760334738060,"INFO	2025-10-13T05:52:18,059	90544	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 11.0 in stage 0.0 (TID 11) in 18056 ms on 172.35.42.110 (executor 2) (14/471)
"
1760334739408,"INFO	2025-10-13T05:52:19,408	91893	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334739408,"INFO	2025-10-13T05:52:19,408	91893	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 11, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334739409,"INFO	2025-10-13T05:52:19,408	91893	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 11; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_11_a_spark-application-1760334656744_p_1
"
1760334739409,"INFO	2025-10-13T05:52:19,409	91894	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334739446,"INFO	2025-10-13T05:52:19,446	91931	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334739446,"INFO	2025-10-13T05:52:19,446	91931	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 8208607b-f0f0-485e-b155-b833ea4aa3c9)
"
1760334739447,"INFO	2025-10-13T05:52:19,446	91931	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 11 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334740713,"INFO	2025-10-13T05:52:20,713	93198	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 32.0 in stage 0.0 (TID 32) (172.35.102.6, executor 3, partition 32, PROCESS_LOCAL, 27118 bytes) 
"
1760334740714,"INFO	2025-10-13T05:52:20,714	93199	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 14.0 in stage 0.0 (TID 14) in 18299 ms on 172.35.102.6 (executor 3) (15/471)
"
1760334741065,"INFO	2025-10-13T05:52:21,064	93549	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 33.0 in stage 0.0 (TID 33) (172.35.102.6, executor 3, partition 33, PROCESS_LOCAL, 27118 bytes) 
"
1760334741065,"INFO	2025-10-13T05:52:21,065	93550	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 15.0 in stage 0.0 (TID 15) in 18649 ms on 172.35.102.6 (executor 3) (16/471)
"
1760334743154,"INFO	2025-10-13T05:52:23,154	95639	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 34.0 in stage 0.0 (TID 34) (172.35.235.173, executor 5, partition 34, PROCESS_LOCAL, 27118 bytes) 
"
1760334743155,"INFO	2025-10-13T05:52:23,155	95640	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 16.0 in stage 0.0 (TID 16) in 18231 ms on 172.35.235.173 (executor 5) (17/471)
"
1760334743180,"INFO	2025-10-13T05:52:23,180	95665	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 35.0 in stage 0.0 (TID 35) (172.35.115.192, executor 1, partition 35, PROCESS_LOCAL, 27118 bytes) 
"
1760334743181,"INFO	2025-10-13T05:52:23,181	95666	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 22.0 in stage 0.0 (TID 22) in 14724 ms on 172.35.115.192 (executor 1) (18/471)
"
1760334743286,"INFO	2025-10-13T05:52:23,286	95771	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 36.0 in stage 0.0 (TID 36) (172.35.235.173, executor 5, partition 36, PROCESS_LOCAL, 27118 bytes) 
"
1760334743287,"INFO	2025-10-13T05:52:23,287	95772	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 17.0 in stage 0.0 (TID 17) in 18361 ms on 172.35.235.173 (executor 5) (19/471)
"
1760334743611,"INFO	2025-10-13T05:52:23,610	96095	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 37.0 in stage 0.0 (TID 37) (172.35.52.98, executor 6, partition 37, PROCESS_LOCAL, 27118 bytes) 
"
1760334743611,"INFO	2025-10-13T05:52:23,611	96096	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 18.0 in stage 0.0 (TID 18) in 18009 ms on 172.35.52.98 (executor 6) (20/471)
"
1760334743844,"INFO	2025-10-13T05:52:23,844	96329	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 38.0 in stage 0.0 (TID 38) (172.35.52.98, executor 6, partition 38, PROCESS_LOCAL, 27118 bytes) 
"
1760334743845,"INFO	2025-10-13T05:52:23,845	96330	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 19.0 in stage 0.0 (TID 19) in 18241 ms on 172.35.52.98 (executor 6) (21/471)
"
1760334744848,"INFO	2025-10-13T05:52:24,848	97333	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 39.0 in stage 0.0 (TID 39) (172.35.115.192, executor 1, partition 39, PROCESS_LOCAL, 27118 bytes) 
"
1760334744849,"INFO	2025-10-13T05:52:24,848	97333	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 23.0 in stage 0.0 (TID 23) in 14720 ms on 172.35.115.192 (executor 1) (22/471)
"
1760334748134,"INFO	2025-10-13T05:52:28,134	100619	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 40.0 in stage 0.0 (TID 40) (172.34.183.29, executor 4, partition 40, PROCESS_LOCAL, 27118 bytes) 
"
1760334748135,"INFO	2025-10-13T05:52:28,135	100620	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 26.0 in stage 0.0 (TID 26) in 16095 ms on 172.34.183.29 (executor 4) (23/471)
"
1760334748159,"INFO	2025-10-13T05:52:28,159	100644	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 41.0 in stage 0.0 (TID 41) (172.34.183.29, executor 4, partition 41, PROCESS_LOCAL, 27118 bytes) 
"
1760334748160,"INFO	2025-10-13T05:52:28,160	100645	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 27.0 in stage 0.0 (TID 27) in 15978 ms on 172.34.183.29 (executor 4) (24/471)
"
1760334750590,"INFO	2025-10-13T05:52:30,589	103074	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 42.0 in stage 0.0 (TID 42) (172.35.25.103, executor 7, partition 42, PROCESS_LOCAL, 27118 bytes) 
"
1760334750590,"INFO	2025-10-13T05:52:30,590	103075	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 21.0 in stage 0.0 (TID 21) in 23740 ms on 172.35.25.103 (executor 7) (25/471)
"
1760334750739,"INFO	2025-10-13T05:52:30,739	103224	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 43.0 in stage 0.0 (TID 43) (172.35.25.103, executor 7, partition 43, PROCESS_LOCAL, 27118 bytes) 
"
1760334750740,"INFO	2025-10-13T05:52:30,739	103224	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 20.0 in stage 0.0 (TID 20) in 23890 ms on 172.35.25.103 (executor 7) (26/471)
"
1760334752231,"INFO	2025-10-13T05:52:32,231	104716	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 44.0 in stage 0.0 (TID 44) (172.35.54.41, executor 8, partition 44, PROCESS_LOCAL, 27118 bytes) 
"
1760334752231,"INFO	2025-10-13T05:52:32,231	104716	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 25.0 in stage 0.0 (TID 25) in 21919 ms on 172.35.54.41 (executor 8) (27/471)
"
1760334752320,"INFO	2025-10-13T05:52:32,320	104805	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 45.0 in stage 0.0 (TID 45) (172.35.54.41, executor 8, partition 45, PROCESS_LOCAL, 27118 bytes) 
"
1760334752320,"INFO	2025-10-13T05:52:32,320	104805	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 24.0 in stage 0.0 (TID 24) in 22009 ms on 172.35.54.41 (executor 8) (28/471)
"
1760334753716,"INFO	2025-10-13T05:52:33,716	106201	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334753716,"INFO	2025-10-13T05:52:33,716	106201	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 12, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334753716,"INFO	2025-10-13T05:52:33,716	106201	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 12; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_12_a_spark-application-1760334656744_p_1
"
1760334753717,"INFO	2025-10-13T05:52:33,717	106202	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334753754,"INFO	2025-10-13T05:52:33,753	106238	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334753754,"INFO	2025-10-13T05:52:33,754	106239	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: d0bf5249-e524-4cc4-9e25-d8843161c482)
"
1760334753754,"INFO	2025-10-13T05:52:33,754	106239	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 12 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334754565,"INFO	2025-10-13T05:52:34,565	107050	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 46.0 in stage 0.0 (TID 46) (172.35.42.110, executor 2, partition 46, PROCESS_LOCAL, 27118 bytes) 
"
1760334754566,"INFO	2025-10-13T05:52:34,565	107050	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 30.0 in stage 0.0 (TID 30) in 16764 ms on 172.35.42.110 (executor 2) (29/471)
"
1760334754810,"INFO	2025-10-13T05:52:34,810	107295	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 47.0 in stage 0.0 (TID 47) (172.35.42.110, executor 2, partition 47, PROCESS_LOCAL, 27118 bytes) 
"
1760334754811,"INFO	2025-10-13T05:52:34,810	107295	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 31.0 in stage 0.0 (TID 31) in 16752 ms on 172.35.42.110 (executor 2) (30/471)
"
1760334757130,"INFO	2025-10-13T05:52:37,130	109615	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 48.0 in stage 0.0 (TID 48) (172.35.102.6, executor 3, partition 48, PROCESS_LOCAL, 27118 bytes) 
"
1760334757131,"INFO	2025-10-13T05:52:37,130	109615	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 32.0 in stage 0.0 (TID 32) in 16417 ms on 172.35.102.6 (executor 3) (31/471)
"
1760334757369,"INFO	2025-10-13T05:52:37,369	109854	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 49.0 in stage 0.0 (TID 49) (172.35.102.6, executor 3, partition 49, PROCESS_LOCAL, 27118 bytes) 
"
1760334757370,"INFO	2025-10-13T05:52:37,369	109854	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 33.0 in stage 0.0 (TID 33) in 16305 ms on 172.35.102.6 (executor 3) (32/471)
"
1760334758010,"INFO	2025-10-13T05:52:38,009	110494	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 50.0 in stage 0.0 (TID 50) (172.34.154.255, executor 9, partition 50, PROCESS_LOCAL, 27118 bytes) 
"
1760334758010,"INFO	2025-10-13T05:52:38,010	110495	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 28.0 in stage 0.0 (TID 28) in 23927 ms on 172.34.154.255 (executor 9) (33/471)
"
1760334758063,"INFO	2025-10-13T05:52:38,063	110548	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 51.0 in stage 0.0 (TID 51) (172.35.115.192, executor 1, partition 51, PROCESS_LOCAL, 27118 bytes) 
"
1760334758063,"INFO	2025-10-13T05:52:38,063	110548	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 35.0 in stage 0.0 (TID 35) in 14883 ms on 172.35.115.192 (executor 1) (34/471)
"
1760334758084,"INFO	2025-10-13T05:52:38,084	110569	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 52.0 in stage 0.0 (TID 52) (172.34.154.255, executor 9, partition 52, PROCESS_LOCAL, 27118 bytes) 
"
1760334758085,"INFO	2025-10-13T05:52:38,085	110570	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 29.0 in stage 0.0 (TID 29) in 24001 ms on 172.34.154.255 (executor 9) (35/471)
"
1760334758422,"INFO	2025-10-13T05:52:38,421	110906	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 53.0 in stage 0.0 (TID 53) (172.35.235.173, executor 5, partition 53, PROCESS_LOCAL, 27118 bytes) 
"
1760334758422,"INFO	2025-10-13T05:52:38,422	110907	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 36.0 in stage 0.0 (TID 36) in 15136 ms on 172.35.235.173 (executor 5) (36/471)
"
1760334758826,"INFO	2025-10-13T05:52:38,825	111310	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 54.0 in stage 0.0 (TID 54) (172.35.52.98, executor 6, partition 54, PROCESS_LOCAL, 27118 bytes) 
"
1760334758826,"INFO	2025-10-13T05:52:38,826	111311	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 38.0 in stage 0.0 (TID 38) in 14982 ms on 172.35.52.98 (executor 6) (37/471)
"
1760334758852,"INFO	2025-10-13T05:52:38,852	111337	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 55.0 in stage 0.0 (TID 55) (172.35.52.98, executor 6, partition 55, PROCESS_LOCAL, 27118 bytes) 
"
1760334758853,"INFO	2025-10-13T05:52:38,853	111338	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 37.0 in stage 0.0 (TID 37) in 15243 ms on 172.35.52.98 (executor 6) (38/471)
"
1760334759107,"INFO	2025-10-13T05:52:39,106	111591	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 56.0 in stage 0.0 (TID 56) (172.35.235.173, executor 5, partition 56, PROCESS_LOCAL, 27118 bytes) 
"
1760334759107,"INFO	2025-10-13T05:52:39,107	111592	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 34.0 in stage 0.0 (TID 34) in 15953 ms on 172.35.235.173 (executor 5) (39/471)
"
1760334759647,"INFO	2025-10-13T05:52:39,647	112132	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 57.0 in stage 0.0 (TID 57) (172.35.115.192, executor 1, partition 57, PROCESS_LOCAL, 27118 bytes) 
"
1760334759648,"INFO	2025-10-13T05:52:39,647	112132	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 39.0 in stage 0.0 (TID 39) in 14800 ms on 172.35.115.192 (executor 1) (40/471)
"
1760334760248,"INFO	2025-10-13T05:52:40,248	112733	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334760249,"INFO	2025-10-13T05:52:40,249	112734	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 13, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334760249,"INFO	2025-10-13T05:52:40,249	112734	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 13; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_13_a_spark-application-1760334656744_p_1
"
1760334760249,"INFO	2025-10-13T05:52:40,249	112734	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334760307,"INFO	2025-10-13T05:52:40,307	112792	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334760307,"INFO	2025-10-13T05:52:40,307	112792	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: fc3d40aa-44e3-4356-83eb-c35078f6333c)
"
1760334760307,"INFO	2025-10-13T05:52:40,307	112792	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 13 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334761836,"INFO	2025-10-13T05:52:41,835	114320	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 58.0 in stage 0.0 (TID 58) (172.34.183.29, executor 4, partition 58, PROCESS_LOCAL, 27118 bytes) 
"
1760334761836,"INFO	2025-10-13T05:52:41,836	114321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 40.0 in stage 0.0 (TID 40) in 13702 ms on 172.34.183.29 (executor 4) (41/471)
"
1760334761919,"INFO	2025-10-13T05:52:41,919	114404	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 59.0 in stage 0.0 (TID 59) (172.34.183.29, executor 4, partition 59, PROCESS_LOCAL, 27118 bytes) 
"
1760334761920,"INFO	2025-10-13T05:52:41,920	114405	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 41.0 in stage 0.0 (TID 41) in 13760 ms on 172.34.183.29 (executor 4) (42/471)
"
1760334764714,"INFO	2025-10-13T05:52:44,713	117198	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 60.0 in stage 0.0 (TID 60) (172.35.25.103, executor 7, partition 60, PROCESS_LOCAL, 27118 bytes) 
"
1760334764714,"INFO	2025-10-13T05:52:44,714	117199	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 42.0 in stage 0.0 (TID 42) in 14125 ms on 172.35.25.103 (executor 7) (43/471)
"
1760334764757,"INFO	2025-10-13T05:52:44,757	117242	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 61.0 in stage 0.0 (TID 61) (172.35.25.103, executor 7, partition 61, PROCESS_LOCAL, 27118 bytes) 
"
1760334764757,"INFO	2025-10-13T05:52:44,757	117242	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 43.0 in stage 0.0 (TID 43) in 14019 ms on 172.35.25.103 (executor 7) (44/471)
"
1760334765224,"INFO	2025-10-13T05:52:45,223	117708	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 62.0 in stage 0.0 (TID 62) (172.35.54.41, executor 8, partition 62, PROCESS_LOCAL, 27109 bytes) 
"
1760334765224,"INFO	2025-10-13T05:52:45,224	117709	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 44.0 in stage 0.0 (TID 44) in 12994 ms on 172.35.54.41 (executor 8) (45/471)
"
1760334765278,"INFO	2025-10-13T05:52:45,278	117763	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 63.0 in stage 0.0 (TID 63) (172.35.54.41, executor 8, partition 63, PROCESS_LOCAL, 27118 bytes) 
"
1760334765279,"INFO	2025-10-13T05:52:45,279	117764	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 45.0 in stage 0.0 (TID 45) in 12960 ms on 172.35.54.41 (executor 8) (46/471)
"
1760334766937,"INFO	2025-10-13T05:52:46,936	119421	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334766937,"INFO	2025-10-13T05:52:46,937	119422	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 14, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334766937,"INFO	2025-10-13T05:52:46,937	119422	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 14; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_14_a_spark-application-1760334656744_p_1
"
1760334766938,"INFO	2025-10-13T05:52:46,937	119422	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334766978,"INFO	2025-10-13T05:52:46,977	119462	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334766978,"INFO	2025-10-13T05:52:46,978	119463	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 3418f47c-997f-4d5b-9464-bb1e3e8c17f7)
"
1760334766978,"INFO	2025-10-13T05:52:46,978	119463	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 14 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334769742,"INFO	2025-10-13T05:52:49,741	122226	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 64.0 in stage 0.0 (TID 64) (172.35.42.110, executor 2, partition 64, PROCESS_LOCAL, 27118 bytes) 
"
1760334769742,"INFO	2025-10-13T05:52:49,742	122227	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 46.0 in stage 0.0 (TID 46) in 15178 ms on 172.35.42.110 (executor 2) (47/471)
"
1760334770036,"INFO	2025-10-13T05:52:50,036	122521	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 65.0 in stage 0.0 (TID 65) (172.35.42.110, executor 2, partition 65, PROCESS_LOCAL, 27118 bytes) 
"
1760334770037,"INFO	2025-10-13T05:52:50,036	122521	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 47.0 in stage 0.0 (TID 47) in 15227 ms on 172.35.42.110 (executor 2) (48/471)
"
1760334771781,"INFO	2025-10-13T05:52:51,780	124265	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 66.0 in stage 0.0 (TID 66) (172.35.102.6, executor 3, partition 66, PROCESS_LOCAL, 27118 bytes) 
"
1760334771781,"INFO	2025-10-13T05:52:51,781	124266	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 48.0 in stage 0.0 (TID 48) in 14652 ms on 172.35.102.6 (executor 3) (49/471)
"
1760334772171,"INFO	2025-10-13T05:52:52,171	124656	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334772172,"INFO	2025-10-13T05:52:52,171	124656	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 15, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334772172,"INFO	2025-10-13T05:52:52,172	124657	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 15; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_15_a_spark-application-1760334656744_p_1
"
1760334772172,"INFO	2025-10-13T05:52:52,172	124657	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334772203,"INFO	2025-10-13T05:52:52,202	124687	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 67.0 in stage 0.0 (TID 67) (172.35.102.6, executor 3, partition 67, PROCESS_LOCAL, 27118 bytes) 
"
1760334772203,"INFO	2025-10-13T05:52:52,203	124688	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 49.0 in stage 0.0 (TID 49) in 14835 ms on 172.35.102.6 (executor 3) (50/471)
"
1760334772212,"INFO	2025-10-13T05:52:52,212	124697	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334772213,"INFO	2025-10-13T05:52:52,212	124697	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 07ca8e05-8d27-4c4a-a8b2-610693092ec1)
"
1760334772213,"INFO	2025-10-13T05:52:52,212	124697	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 15 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334772613,"INFO	2025-10-13T05:52:52,613	125098	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 68.0 in stage 0.0 (TID 68) (172.35.52.98, executor 6, partition 68, PROCESS_LOCAL, 27118 bytes) 
"
1760334772613,"INFO	2025-10-13T05:52:52,613	125098	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 54.0 in stage 0.0 (TID 54) in 13788 ms on 172.35.52.98 (executor 6) (51/471)
"
1760334772744,"INFO	2025-10-13T05:52:52,744	125229	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 69.0 in stage 0.0 (TID 69) (172.35.52.98, executor 6, partition 69, PROCESS_LOCAL, 27118 bytes) 
"
1760334772744,"INFO	2025-10-13T05:52:52,744	125229	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 55.0 in stage 0.0 (TID 55) in 13892 ms on 172.35.52.98 (executor 6) (52/471)
"
1760334772860,"INFO	2025-10-13T05:52:52,860	125345	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 70.0 in stage 0.0 (TID 70) (172.34.154.255, executor 9, partition 70, PROCESS_LOCAL, 27118 bytes) 
"
1760334772861,"INFO	2025-10-13T05:52:52,860	125345	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 52.0 in stage 0.0 (TID 52) in 14776 ms on 172.34.154.255 (executor 9) (53/471)
"
1760334772943,"INFO	2025-10-13T05:52:52,943	125428	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 71.0 in stage 0.0 (TID 71) (172.34.154.255, executor 9, partition 71, PROCESS_LOCAL, 27118 bytes) 
"
1760334772944,"INFO	2025-10-13T05:52:52,943	125428	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 50.0 in stage 0.0 (TID 50) in 14934 ms on 172.34.154.255 (executor 9) (54/471)
"
1760334773054,"INFO	2025-10-13T05:52:53,054	125539	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 72.0 in stage 0.0 (TID 72) (172.35.115.192, executor 1, partition 72, PROCESS_LOCAL, 27118 bytes) 
"
1760334773055,"INFO	2025-10-13T05:52:53,055	125540	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 51.0 in stage 0.0 (TID 51) in 14993 ms on 172.35.115.192 (executor 1) (55/471)
"
1760334773567,"INFO	2025-10-13T05:52:53,567	126052	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 73.0 in stage 0.0 (TID 73) (172.35.235.173, executor 5, partition 73, PROCESS_LOCAL, 27118 bytes) 
"
1760334773568,"INFO	2025-10-13T05:52:53,567	126052	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 53.0 in stage 0.0 (TID 53) in 15146 ms on 172.35.235.173 (executor 5) (56/471)
"
1760334773670,"INFO	2025-10-13T05:52:53,670	126155	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 74.0 in stage 0.0 (TID 74) (172.35.235.173, executor 5, partition 74, PROCESS_LOCAL, 27118 bytes) 
"
1760334773670,"INFO	2025-10-13T05:52:53,670	126155	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 56.0 in stage 0.0 (TID 56) in 14564 ms on 172.35.235.173 (executor 5) (57/471)
"
1760334774660,"INFO	2025-10-13T05:52:54,660	127145	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 75.0 in stage 0.0 (TID 75) (172.35.115.192, executor 1, partition 75, PROCESS_LOCAL, 27118 bytes) 
"
1760334774661,"INFO	2025-10-13T05:52:54,660	127145	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 57.0 in stage 0.0 (TID 57) in 15014 ms on 172.35.115.192 (executor 1) (58/471)
"
1760334775799,"INFO	2025-10-13T05:52:55,799	128284	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 76.0 in stage 0.0 (TID 76) (172.34.183.29, executor 4, partition 76, PROCESS_LOCAL, 27118 bytes) 
"
1760334775800,"INFO	2025-10-13T05:52:55,799	128284	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 58.0 in stage 0.0 (TID 58) in 13964 ms on 172.34.183.29 (executor 4) (59/471)
"
1760334776136,"INFO	2025-10-13T05:52:56,136	128621	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 77.0 in stage 0.0 (TID 77) (172.34.183.29, executor 4, partition 77, PROCESS_LOCAL, 27118 bytes) 
"
1760334776137,"INFO	2025-10-13T05:52:56,137	128622	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 59.0 in stage 0.0 (TID 59) in 14219 ms on 172.34.183.29 (executor 4) (60/471)
"
1760334776851,"INFO	2025-10-13T05:52:56,851	129336	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334776851,"INFO	2025-10-13T05:52:56,851	129336	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760334778098,"INFO	2025-10-13T05:52:58,097	130582	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 78.0 in stage 0.0 (TID 78) (172.35.54.41, executor 8, partition 78, PROCESS_LOCAL, 27118 bytes) 
"
1760334778098,"INFO	2025-10-13T05:52:58,098	130583	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 62.0 in stage 0.0 (TID 62) in 12875 ms on 172.35.54.41 (executor 8) (61/471)
"
1760334778155,"INFO	2025-10-13T05:52:58,155	130640	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 79.0 in stage 0.0 (TID 79) (172.35.54.41, executor 8, partition 79, PROCESS_LOCAL, 27118 bytes) 
"
1760334778156,"INFO	2025-10-13T05:52:58,155	130640	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 63.0 in stage 0.0 (TID 63) in 12877 ms on 172.35.54.41 (executor 8) (62/471)
"
1760334778689,"INFO	2025-10-13T05:52:58,689	131174	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 80.0 in stage 0.0 (TID 80) (172.35.25.103, executor 7, partition 80, PROCESS_LOCAL, 27118 bytes) 
"
1760334778690,"INFO	2025-10-13T05:52:58,689	131174	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 61.0 in stage 0.0 (TID 61) in 13933 ms on 172.35.25.103 (executor 7) (63/471)
"
1760334778705,"INFO	2025-10-13T05:52:58,704	131189	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 81.0 in stage 0.0 (TID 81) (172.35.25.103, executor 7, partition 81, PROCESS_LOCAL, 27118 bytes) 
"
1760334778705,"INFO	2025-10-13T05:52:58,705	131190	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 60.0 in stage 0.0 (TID 60) in 13992 ms on 172.35.25.103 (executor 7) (64/471)
"
1760334784607,"INFO	2025-10-13T05:53:04,606	137091	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 82.0 in stage 0.0 (TID 82) (172.35.42.110, executor 2, partition 82, PROCESS_LOCAL, 27118 bytes) 
"
1760334784607,"INFO	2025-10-13T05:53:04,607	137092	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 64.0 in stage 0.0 (TID 64) in 14866 ms on 172.35.42.110 (executor 2) (65/471)
"
1760334785165,"INFO	2025-10-13T05:53:05,165	137650	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 83.0 in stage 0.0 (TID 83) (172.35.42.110, executor 2, partition 83, PROCESS_LOCAL, 27118 bytes) 
"
1760334785166,"INFO	2025-10-13T05:53:05,165	137650	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 65.0 in stage 0.0 (TID 65) in 15130 ms on 172.35.42.110 (executor 2) (66/471)
"
1760334786305,"INFO	2025-10-13T05:53:06,304	138789	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 84.0 in stage 0.0 (TID 84) (172.35.52.98, executor 6, partition 84, PROCESS_LOCAL, 27118 bytes) 
"
1760334786305,"INFO	2025-10-13T05:53:06,305	138790	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 68.0 in stage 0.0 (TID 68) in 13693 ms on 172.35.52.98 (executor 6) (67/471)
"
1760334786338,"INFO	2025-10-13T05:53:06,338	138823	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 85.0 in stage 0.0 (TID 85) (172.35.102.6, executor 3, partition 85, PROCESS_LOCAL, 27118 bytes) 
"
1760334786339,"INFO	2025-10-13T05:53:06,338	138823	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 66.0 in stage 0.0 (TID 66) in 14558 ms on 172.35.102.6 (executor 3) (68/471)
"
1760334786588,"INFO	2025-10-13T05:53:06,587	139072	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 86.0 in stage 0.0 (TID 86) (172.35.52.98, executor 6, partition 86, PROCESS_LOCAL, 27118 bytes) 
"
1760334786588,"INFO	2025-10-13T05:53:06,588	139073	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 69.0 in stage 0.0 (TID 69) in 13845 ms on 172.35.52.98 (executor 6) (69/471)
"
1760334786808,"INFO	2025-10-13T05:53:06,808	139293	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334786808,"INFO	2025-10-13T05:53:06,808	139293	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 16, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334786808,"INFO	2025-10-13T05:53:06,808	139293	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 16; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_16_a_spark-application-1760334656744_p_1
"
1760334786809,"INFO	2025-10-13T05:53:06,808	139293	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334786846,"INFO	2025-10-13T05:53:06,846	139331	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334786846,"INFO	2025-10-13T05:53:06,846	139331	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: b4dbe047-78dc-4b39-a73b-b0306226d723)
"
1760334786846,"INFO	2025-10-13T05:53:06,846	139331	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 16 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334786924,"INFO	2025-10-13T05:53:06,924	139409	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 87.0 in stage 0.0 (TID 87) (172.35.102.6, executor 3, partition 87, PROCESS_LOCAL, 27118 bytes) 
"
1760334786925,"INFO	2025-10-13T05:53:06,925	139410	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 67.0 in stage 0.0 (TID 67) in 14723 ms on 172.35.102.6 (executor 3) (70/471)
"
1760334787389,"INFO	2025-10-13T05:53:07,389	139874	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 88.0 in stage 0.0 (TID 88) (172.34.154.255, executor 9, partition 88, PROCESS_LOCAL, 27118 bytes) 
"
1760334787390,"INFO	2025-10-13T05:53:07,389	139874	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 70.0 in stage 0.0 (TID 70) in 14530 ms on 172.34.154.255 (executor 9) (71/471)
"
1760334787403,"INFO	2025-10-13T05:53:07,403	139888	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 89.0 in stage 0.0 (TID 89) (172.34.154.255, executor 9, partition 89, PROCESS_LOCAL, 27118 bytes) 
"
1760334787403,"INFO	2025-10-13T05:53:07,403	139888	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 71.0 in stage 0.0 (TID 71) in 14461 ms on 172.34.154.255 (executor 9) (72/471)
"
1760334787856,"INFO	2025-10-13T05:53:07,856	140341	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 90.0 in stage 0.0 (TID 90) (172.35.235.173, executor 5, partition 90, PROCESS_LOCAL, 27118 bytes) 
"
1760334787856,"INFO	2025-10-13T05:53:07,856	140341	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 73.0 in stage 0.0 (TID 73) in 14290 ms on 172.35.235.173 (executor 5) (73/471)
"
1760334788461,"INFO	2025-10-13T05:53:08,460	140945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 91.0 in stage 0.0 (TID 91) (172.35.115.192, executor 1, partition 91, PROCESS_LOCAL, 27118 bytes) 
"
1760334788461,"INFO	2025-10-13T05:53:08,461	140946	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 72.0 in stage 0.0 (TID 72) in 15407 ms on 172.35.115.192 (executor 1) (74/471)
"
1760334788562,"INFO	2025-10-13T05:53:08,562	141047	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 92.0 in stage 0.0 (TID 92) (172.35.235.173, executor 5, partition 92, PROCESS_LOCAL, 27118 bytes) 
"
1760334788562,"INFO	2025-10-13T05:53:08,562	141047	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 74.0 in stage 0.0 (TID 74) in 14893 ms on 172.35.235.173 (executor 5) (75/471)
"
1760334789870,"INFO	2025-10-13T05:53:09,870	142355	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 93.0 in stage 0.0 (TID 93) (172.34.183.29, executor 4, partition 93, PROCESS_LOCAL, 27118 bytes) 
"
1760334789871,"INFO	2025-10-13T05:53:09,871	142356	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 76.0 in stage 0.0 (TID 76) in 14073 ms on 172.34.183.29 (executor 4) (76/471)
"
1760334789886,"INFO	2025-10-13T05:53:09,886	142371	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 94.0 in stage 0.0 (TID 94) (172.35.115.192, executor 1, partition 94, PROCESS_LOCAL, 27118 bytes) 
"
1760334789887,"INFO	2025-10-13T05:53:09,886	142371	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 75.0 in stage 0.0 (TID 75) in 15227 ms on 172.35.115.192 (executor 1) (77/471)
"
1760334790194,"INFO	2025-10-13T05:53:10,193	142678	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 95.0 in stage 0.0 (TID 95) (172.34.183.29, executor 4, partition 95, PROCESS_LOCAL, 27118 bytes) 
"
1760334790194,"INFO	2025-10-13T05:53:10,194	142679	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 77.0 in stage 0.0 (TID 77) in 14058 ms on 172.34.183.29 (executor 4) (78/471)
"
1760334792118,"INFO	2025-10-13T05:53:12,117	144602	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 96.0 in stage 0.0 (TID 96) (172.35.54.41, executor 8, partition 96, PROCESS_LOCAL, 27118 bytes) 
"
1760334792118,"INFO	2025-10-13T05:53:12,118	144603	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 79.0 in stage 0.0 (TID 79) in 13964 ms on 172.35.54.41 (executor 8) (79/471)
"
1760334792247,"INFO	2025-10-13T05:53:12,246	144731	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 97.0 in stage 0.0 (TID 97) (172.35.54.41, executor 8, partition 97, PROCESS_LOCAL, 27118 bytes) 
"
1760334792247,"INFO	2025-10-13T05:53:12,247	144732	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 78.0 in stage 0.0 (TID 78) in 14150 ms on 172.35.54.41 (executor 8) (80/471)
"
1760334793110,"INFO	2025-10-13T05:53:13,109	145594	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 98.0 in stage 0.0 (TID 98) (172.35.25.103, executor 7, partition 98, PROCESS_LOCAL, 27118 bytes) 
"
1760334793110,"INFO	2025-10-13T05:53:13,110	145595	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 81.0 in stage 0.0 (TID 81) in 14406 ms on 172.35.25.103 (executor 7) (81/471)
"
1760334793265,"INFO	2025-10-13T05:53:13,264	145749	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 99.0 in stage 0.0 (TID 99) (172.35.25.103, executor 7, partition 99, PROCESS_LOCAL, 27118 bytes) 
"
1760334793265,"INFO	2025-10-13T05:53:13,265	145750	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 80.0 in stage 0.0 (TID 80) in 14577 ms on 172.35.25.103 (executor 7) (82/471)
"
1760334799056,"INFO	2025-10-13T05:53:19,055	151540	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 100.0 in stage 0.0 (TID 100) (172.35.42.110, executor 2, partition 100, PROCESS_LOCAL, 27126 bytes) 
"
1760334799056,"INFO	2025-10-13T05:53:19,056	151541	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 82.0 in stage 0.0 (TID 82) in 14450 ms on 172.35.42.110 (executor 2) (83/471)
"
1760334799411,"INFO	2025-10-13T05:53:19,411	151896	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334799411,"INFO	2025-10-13T05:53:19,411	151896	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 17, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334799412,"INFO	2025-10-13T05:53:19,411	151896	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 17; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_17_a_spark-application-1760334656744_p_1
"
1760334799412,"INFO	2025-10-13T05:53:19,412	151897	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334799455,"INFO	2025-10-13T05:53:19,455	151940	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334799455,"INFO	2025-10-13T05:53:19,455	151940	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: d7ec0087-d3e4-455b-af1d-c0935b7c777d)
"
1760334799455,"INFO	2025-10-13T05:53:19,455	151940	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 17 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334799509,"INFO	2025-10-13T05:53:19,509	151994	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 101.0 in stage 0.0 (TID 101) (172.35.42.110, executor 2, partition 101, PROCESS_LOCAL, 27118 bytes) 
"
1760334799510,"INFO	2025-10-13T05:53:19,509	151994	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 83.0 in stage 0.0 (TID 83) in 14345 ms on 172.35.42.110 (executor 2) (84/471)
"
1760334799976,"INFO	2025-10-13T05:53:19,976	152461	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 102.0 in stage 0.0 (TID 102) (172.35.52.98, executor 6, partition 102, PROCESS_LOCAL, 27126 bytes) 
"
1760334799977,"INFO	2025-10-13T05:53:19,976	152461	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 84.0 in stage 0.0 (TID 84) in 13672 ms on 172.35.52.98 (executor 6) (85/471)
"
1760334800294,"INFO	2025-10-13T05:53:20,294	152779	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 103.0 in stage 0.0 (TID 103) (172.35.52.98, executor 6, partition 103, PROCESS_LOCAL, 27118 bytes) 
"
1760334800294,"INFO	2025-10-13T05:53:20,294	152779	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 86.0 in stage 0.0 (TID 86) in 13707 ms on 172.35.52.98 (executor 6) (86/471)
"
1760334801781,"INFO	2025-10-13T05:53:21,781	154266	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 104.0 in stage 0.0 (TID 104) (172.35.102.6, executor 3, partition 104, PROCESS_LOCAL, 27126 bytes) 
"
1760334801782,"INFO	2025-10-13T05:53:21,781	154266	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 85.0 in stage 0.0 (TID 85) in 15444 ms on 172.35.102.6 (executor 3) (87/471)
"
1760334802206,"INFO	2025-10-13T05:53:22,206	154691	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 105.0 in stage 0.0 (TID 105) (172.34.154.255, executor 9, partition 105, PROCESS_LOCAL, 27118 bytes) 
"
1760334802207,"INFO	2025-10-13T05:53:22,206	154691	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 88.0 in stage 0.0 (TID 88) in 14818 ms on 172.34.154.255 (executor 9) (88/471)
"
1760334802340,"INFO	2025-10-13T05:53:22,340	154825	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 106.0 in stage 0.0 (TID 106) (172.35.102.6, executor 3, partition 106, PROCESS_LOCAL, 27118 bytes) 
"
1760334802341,"INFO	2025-10-13T05:53:22,340	154825	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 87.0 in stage 0.0 (TID 87) in 15416 ms on 172.35.102.6 (executor 3) (89/471)
"
1760334802537,"INFO	2025-10-13T05:53:22,536	155021	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 107.0 in stage 0.0 (TID 107) (172.34.154.255, executor 9, partition 107, PROCESS_LOCAL, 27118 bytes) 
"
1760334802537,"INFO	2025-10-13T05:53:22,537	155022	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 89.0 in stage 0.0 (TID 89) in 15135 ms on 172.34.154.255 (executor 9) (90/471)
"
1760334802543,"INFO	2025-10-13T05:53:22,543	155028	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 108.0 in stage 0.0 (TID 108) (172.35.235.173, executor 5, partition 108, PROCESS_LOCAL, 27118 bytes) 
"
1760334802544,"INFO	2025-10-13T05:53:22,543	155028	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 90.0 in stage 0.0 (TID 90) in 14688 ms on 172.35.235.173 (executor 5) (91/471)
"
1760334803160,"INFO	2025-10-13T05:53:23,160	155645	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 109.0 in stage 0.0 (TID 109) (172.35.235.173, executor 5, partition 109, PROCESS_LOCAL, 27118 bytes) 
"
1760334803161,"INFO	2025-10-13T05:53:23,160	155645	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 92.0 in stage 0.0 (TID 92) in 14599 ms on 172.35.235.173 (executor 5) (92/471)
"
1760334803802,"INFO	2025-10-13T05:53:23,801	156286	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 110.0 in stage 0.0 (TID 110) (172.34.183.29, executor 4, partition 110, PROCESS_LOCAL, 27118 bytes) 
"
1760334803802,"INFO	2025-10-13T05:53:23,802	156287	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 93.0 in stage 0.0 (TID 93) in 13932 ms on 172.34.183.29 (executor 4) (93/471)
"
1760334804085,"INFO	2025-10-13T05:53:24,085	156570	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 111.0 in stage 0.0 (TID 111) (172.35.115.192, executor 1, partition 111, PROCESS_LOCAL, 27118 bytes) 
"
1760334804085,"INFO	2025-10-13T05:53:24,085	156570	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 91.0 in stage 0.0 (TID 91) in 15625 ms on 172.35.115.192 (executor 1) (94/471)
"
1760334804255,"INFO	2025-10-13T05:53:24,255	156740	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 112.0 in stage 0.0 (TID 112) (172.34.183.29, executor 4, partition 112, PROCESS_LOCAL, 27118 bytes) 
"
1760334804256,"INFO	2025-10-13T05:53:24,256	156741	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 95.0 in stage 0.0 (TID 95) in 14063 ms on 172.34.183.29 (executor 4) (95/471)
"
1760334805253,"INFO	2025-10-13T05:53:25,253	157738	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 113.0 in stage 0.0 (TID 113) (172.35.115.192, executor 1, partition 113, PROCESS_LOCAL, 27126 bytes) 
"
1760334805254,"INFO	2025-10-13T05:53:25,253	157738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 94.0 in stage 0.0 (TID 94) in 15367 ms on 172.35.115.192 (executor 1) (96/471)
"
1760334807143,"INFO	2025-10-13T05:53:27,142	159627	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 114.0 in stage 0.0 (TID 114) (172.35.54.41, executor 8, partition 114, PROCESS_LOCAL, 27126 bytes) 
"
1760334807143,"INFO	2025-10-13T05:53:27,143	159628	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 96.0 in stage 0.0 (TID 96) in 15026 ms on 172.35.54.41 (executor 8) (97/471)
"
1760334807206,"INFO	2025-10-13T05:53:27,205	159690	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 115.0 in stage 0.0 (TID 115) (172.35.54.41, executor 8, partition 115, PROCESS_LOCAL, 27126 bytes) 
"
1760334807206,"INFO	2025-10-13T05:53:27,206	159691	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 97.0 in stage 0.0 (TID 97) in 14960 ms on 172.35.54.41 (executor 8) (98/471)
"
1760334807803,"INFO	2025-10-13T05:53:27,803	160288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 116.0 in stage 0.0 (TID 116) (172.35.25.103, executor 7, partition 116, PROCESS_LOCAL, 27126 bytes) 
"
1760334807804,"INFO	2025-10-13T05:53:27,804	160289	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 98.0 in stage 0.0 (TID 98) in 14694 ms on 172.35.25.103 (executor 7) (99/471)
"
1760334807896,"INFO	2025-10-13T05:53:27,895	160380	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 117.0 in stage 0.0 (TID 117) (172.35.25.103, executor 7, partition 117, PROCESS_LOCAL, 27126 bytes) 
"
1760334807896,"INFO	2025-10-13T05:53:27,896	160381	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 99.0 in stage 0.0 (TID 99) in 14632 ms on 172.35.25.103 (executor 7) (100/471)
"
1760334813553,"INFO	2025-10-13T05:53:33,553	166038	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 118.0 in stage 0.0 (TID 118) (172.35.42.110, executor 2, partition 118, PROCESS_LOCAL, 27126 bytes) 
"
1760334813554,"INFO	2025-10-13T05:53:33,554	166039	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 100.0 in stage 0.0 (TID 100) in 14499 ms on 172.35.42.110 (executor 2) (101/471)
"
1760334814065,"INFO	2025-10-13T05:53:34,064	166549	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 119.0 in stage 0.0 (TID 119) (172.35.52.98, executor 6, partition 119, PROCESS_LOCAL, 27126 bytes) 
"
1760334814065,"INFO	2025-10-13T05:53:34,065	166550	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 102.0 in stage 0.0 (TID 102) in 14090 ms on 172.35.52.98 (executor 6) (102/471)
"
1760334814085,"INFO	2025-10-13T05:53:34,084	166569	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 120.0 in stage 0.0 (TID 120) (172.35.42.110, executor 2, partition 120, PROCESS_LOCAL, 27126 bytes) 
"
1760334814085,"INFO	2025-10-13T05:53:34,085	166570	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 101.0 in stage 0.0 (TID 101) in 14576 ms on 172.35.42.110 (executor 2) (103/471)
"
1760334814182,"INFO	2025-10-13T05:53:34,182	166667	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334814183,"INFO	2025-10-13T05:53:34,183	166668	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 18, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334814183,"INFO	2025-10-13T05:53:34,183	166668	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 18; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_18_a_spark-application-1760334656744_p_1
"
1760334814183,"INFO	2025-10-13T05:53:34,183	166668	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334814221,"INFO	2025-10-13T05:53:34,221	166706	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334814221,"INFO	2025-10-13T05:53:34,221	166706	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: b6ca3230-2339-4970-93f9-0e15e62894bf)
"
1760334814221,"INFO	2025-10-13T05:53:34,221	166706	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 18 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334814639,"INFO	2025-10-13T05:53:34,639	167124	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 121.0 in stage 0.0 (TID 121) (172.35.52.98, executor 6, partition 121, PROCESS_LOCAL, 27118 bytes) 
"
1760334814640,"INFO	2025-10-13T05:53:34,640	167125	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 103.0 in stage 0.0 (TID 103) in 14347 ms on 172.35.52.98 (executor 6) (104/471)
"
1760334816936,"INFO	2025-10-13T05:53:36,936	169421	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 122.0 in stage 0.0 (TID 122) (172.35.235.173, executor 5, partition 122, PROCESS_LOCAL, 27118 bytes) 
"
1760334816937,"INFO	2025-10-13T05:53:36,936	169421	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 108.0 in stage 0.0 (TID 108) in 14393 ms on 172.35.235.173 (executor 5) (105/471)
"
1760334817130,"INFO	2025-10-13T05:53:37,130	169615	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 123.0 in stage 0.0 (TID 123) (172.34.154.255, executor 9, partition 123, PROCESS_LOCAL, 27126 bytes) 
"
1760334817131,"INFO	2025-10-13T05:53:37,130	169615	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 105.0 in stage 0.0 (TID 105) in 14924 ms on 172.34.154.255 (executor 9) (106/471)
"
1760334817243,"INFO	2025-10-13T05:53:37,243	169728	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 124.0 in stage 0.0 (TID 124) (172.35.102.6, executor 3, partition 124, PROCESS_LOCAL, 27118 bytes) 
"
1760334817244,"INFO	2025-10-13T05:53:37,243	169728	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 104.0 in stage 0.0 (TID 104) in 15463 ms on 172.35.102.6 (executor 3) (107/471)
"
1760334817529,"INFO	2025-10-13T05:53:37,529	170014	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 125.0 in stage 0.0 (TID 125) (172.34.154.255, executor 9, partition 125, PROCESS_LOCAL, 27118 bytes) 
"
1760334817530,"INFO	2025-10-13T05:53:37,530	170015	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 107.0 in stage 0.0 (TID 107) in 14994 ms on 172.34.154.255 (executor 9) (108/471)
"
1760334817940,"INFO	2025-10-13T05:53:37,940	170425	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 126.0 in stage 0.0 (TID 126) (172.35.102.6, executor 3, partition 126, PROCESS_LOCAL, 27118 bytes) 
"
1760334817941,"INFO	2025-10-13T05:53:37,940	170425	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 106.0 in stage 0.0 (TID 106) in 15601 ms on 172.35.102.6 (executor 3) (109/471)
"
1760334818028,"INFO	2025-10-13T05:53:38,027	170512	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 127.0 in stage 0.0 (TID 127) (172.34.183.29, executor 4, partition 127, PROCESS_LOCAL, 27126 bytes) 
"
1760334818028,"INFO	2025-10-13T05:53:38,028	170513	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 110.0 in stage 0.0 (TID 110) in 14227 ms on 172.34.183.29 (executor 4) (110/471)
"
1760334818210,"INFO	2025-10-13T05:53:38,210	170695	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 128.0 in stage 0.0 (TID 128) (172.35.235.173, executor 5, partition 128, PROCESS_LOCAL, 27126 bytes) 
"
1760334818211,"INFO	2025-10-13T05:53:38,210	170695	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 109.0 in stage 0.0 (TID 109) in 15051 ms on 172.35.235.173 (executor 5) (111/471)
"
1760334818523,"INFO	2025-10-13T05:53:38,522	171007	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 129.0 in stage 0.0 (TID 129) (172.34.183.29, executor 4, partition 129, PROCESS_LOCAL, 27126 bytes) 
"
1760334818523,"INFO	2025-10-13T05:53:38,523	171008	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 112.0 in stage 0.0 (TID 112) in 14268 ms on 172.34.183.29 (executor 4) (112/471)
"
1760334819378,"INFO	2025-10-13T05:53:39,378	171863	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 130.0 in stage 0.0 (TID 130) (172.35.115.192, executor 1, partition 130, PROCESS_LOCAL, 27126 bytes) 
"
1760334819378,"INFO	2025-10-13T05:53:39,378	171863	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 111.0 in stage 0.0 (TID 111) in 15294 ms on 172.35.115.192 (executor 1) (113/471)
"
1760334820693,"INFO	2025-10-13T05:53:40,692	173177	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 131.0 in stage 0.0 (TID 131) (172.35.115.192, executor 1, partition 131, PROCESS_LOCAL, 27126 bytes) 
"
1760334820693,"INFO	2025-10-13T05:53:40,693	173178	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 113.0 in stage 0.0 (TID 113) in 15441 ms on 172.35.115.192 (executor 1) (114/471)
"
1760334822200,"INFO	2025-10-13T05:53:42,200	174685	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 132.0 in stage 0.0 (TID 132) (172.35.25.103, executor 7, partition 132, PROCESS_LOCAL, 27126 bytes) 
"
1760334822201,"INFO	2025-10-13T05:53:42,200	174685	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 116.0 in stage 0.0 (TID 116) in 14397 ms on 172.35.25.103 (executor 7) (115/471)
"
1760334822500,"INFO	2025-10-13T05:53:42,500	174985	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 133.0 in stage 0.0 (TID 133) (172.35.25.103, executor 7, partition 133, PROCESS_LOCAL, 27126 bytes) 
"
1760334822500,"INFO	2025-10-13T05:53:42,500	174985	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 117.0 in stage 0.0 (TID 117) in 14605 ms on 172.35.25.103 (executor 7) (116/471)
"
1760334822580,"INFO	2025-10-13T05:53:42,580	175065	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 134.0 in stage 0.0 (TID 134) (172.35.54.41, executor 8, partition 134, PROCESS_LOCAL, 27126 bytes) 
"
1760334822580,"INFO	2025-10-13T05:53:42,580	175065	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 114.0 in stage 0.0 (TID 114) in 15438 ms on 172.35.54.41 (executor 8) (117/471)
"
1760334822607,"INFO	2025-10-13T05:53:42,606	175091	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 135.0 in stage 0.0 (TID 135) (172.35.54.41, executor 8, partition 135, PROCESS_LOCAL, 27126 bytes) 
"
1760334822607,"INFO	2025-10-13T05:53:42,607	175092	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 115.0 in stage 0.0 (TID 115) in 15402 ms on 172.35.54.41 (executor 8) (118/471)
"
1760334823499,"INFO	2025-10-13T05:53:43,498	175983	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334823499,"INFO	2025-10-13T05:53:43,499	175984	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 19, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334823499,"INFO	2025-10-13T05:53:43,499	175984	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 19; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_19_a_spark-application-1760334656744_p_1
"
1760334823500,"INFO	2025-10-13T05:53:43,499	175984	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334823538,"INFO	2025-10-13T05:53:43,537	176022	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334823538,"INFO	2025-10-13T05:53:43,538	176023	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: ccbbb440-be7f-4d30-bd83-89e28dda4faa)
"
1760334823538,"INFO	2025-10-13T05:53:43,538	176023	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 19 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334828161,"INFO	2025-10-13T05:53:48,161	180646	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 136.0 in stage 0.0 (TID 136) (172.35.42.110, executor 2, partition 136, PROCESS_LOCAL, 27118 bytes) 
"
1760334828162,"INFO	2025-10-13T05:53:48,161	180646	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 118.0 in stage 0.0 (TID 118) in 14608 ms on 172.35.42.110 (executor 2) (119/471)
"
1760334828204,"INFO	2025-10-13T05:53:48,204	180689	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 137.0 in stage 0.0 (TID 137) (172.35.52.98, executor 6, partition 137, PROCESS_LOCAL, 27126 bytes) 
"
1760334828205,"INFO	2025-10-13T05:53:48,204	180689	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 119.0 in stage 0.0 (TID 119) in 14140 ms on 172.35.52.98 (executor 6) (120/471)
"
1760334828917,"INFO	2025-10-13T05:53:48,917	181402	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 138.0 in stage 0.0 (TID 138) (172.35.42.110, executor 2, partition 138, PROCESS_LOCAL, 27126 bytes) 
"
1760334828918,"INFO	2025-10-13T05:53:48,917	181402	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 120.0 in stage 0.0 (TID 120) in 14833 ms on 172.35.42.110 (executor 2) (121/471)
"
1760334829027,"INFO	2025-10-13T05:53:49,027	181512	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 139.0 in stage 0.0 (TID 139) (172.35.52.98, executor 6, partition 139, PROCESS_LOCAL, 27118 bytes) 
"
1760334829028,"INFO	2025-10-13T05:53:49,027	181512	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 121.0 in stage 0.0 (TID 121) in 14388 ms on 172.35.52.98 (executor 6) (122/471)
"
1760334831547,"INFO	2025-10-13T05:53:51,547	184032	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 140.0 in stage 0.0 (TID 140) (172.34.154.255, executor 9, partition 140, PROCESS_LOCAL, 27126 bytes) 
"
1760334831548,"INFO	2025-10-13T05:53:51,548	184033	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 123.0 in stage 0.0 (TID 123) in 14418 ms on 172.34.154.255 (executor 9) (123/471)
"
1760334831669,"INFO	2025-10-13T05:53:51,668	184153	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 141.0 in stage 0.0 (TID 141) (172.35.235.173, executor 5, partition 141, PROCESS_LOCAL, 27126 bytes) 
"
1760334831669,"INFO	2025-10-13T05:53:51,669	184154	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 122.0 in stage 0.0 (TID 122) in 14734 ms on 172.35.235.173 (executor 5) (124/471)
"
1760334832128,"INFO	2025-10-13T05:53:52,128	184613	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334832129,"INFO	2025-10-13T05:53:52,128	184613	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 20, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334832129,"INFO	2025-10-13T05:53:52,129	184614	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 20; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_20_a_spark-application-1760334656744_p_1
"
1760334832129,"INFO	2025-10-13T05:53:52,129	184614	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334832131,"INFO	2025-10-13T05:53:52,130	184615	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 142.0 in stage 0.0 (TID 142) (172.34.154.255, executor 9, partition 142, PROCESS_LOCAL, 27126 bytes) 
"
1760334832131,"INFO	2025-10-13T05:53:52,131	184616	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 125.0 in stage 0.0 (TID 125) in 14602 ms on 172.34.154.255 (executor 9) (125/471)
"
1760334832170,"INFO	2025-10-13T05:53:52,170	184655	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 143.0 in stage 0.0 (TID 143) (172.34.183.29, executor 4, partition 143, PROCESS_LOCAL, 27118 bytes) 
"
1760334832171,"INFO	2025-10-13T05:53:52,171	184656	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 127.0 in stage 0.0 (TID 127) in 14143 ms on 172.34.183.29 (executor 4) (126/471)
"
1760334832175,"INFO	2025-10-13T05:53:52,174	184659	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334832175,"INFO	2025-10-13T05:53:52,174	184659	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 2fea145a-cd23-4fc6-88ac-bf438b222187)
"
1760334832175,"INFO	2025-10-13T05:53:52,175	184660	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 20 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334832865,"INFO	2025-10-13T05:53:52,864	185349	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 144.0 in stage 0.0 (TID 144) (172.34.183.29, executor 4, partition 144, PROCESS_LOCAL, 27126 bytes) 
"
1760334832865,"INFO	2025-10-13T05:53:52,865	185350	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 129.0 in stage 0.0 (TID 129) in 14343 ms on 172.34.183.29 (executor 4) (127/471)
"
1760334833121,"INFO	2025-10-13T05:53:53,121	185606	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 145.0 in stage 0.0 (TID 145) (172.35.235.173, executor 5, partition 145, PROCESS_LOCAL, 27126 bytes) 
"
1760334833122,"INFO	2025-10-13T05:53:53,122	185607	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 128.0 in stage 0.0 (TID 128) in 14912 ms on 172.35.235.173 (executor 5) (128/471)
"
1760334833145,"INFO	2025-10-13T05:53:53,145	185630	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 146.0 in stage 0.0 (TID 146) (172.35.102.6, executor 3, partition 146, PROCESS_LOCAL, 27126 bytes) 
"
1760334833146,"INFO	2025-10-13T05:53:53,145	185630	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 124.0 in stage 0.0 (TID 124) in 15903 ms on 172.35.102.6 (executor 3) (129/471)
"
1760334833341,"INFO	2025-10-13T05:53:53,341	185826	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334833341,"INFO	2025-10-13T05:53:53,341	185826	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 21, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334833342,"INFO	2025-10-13T05:53:53,341	185826	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 21; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_21_a_spark-application-1760334656744_p_1
"
1760334833342,"INFO	2025-10-13T05:53:53,342	185827	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334833370,"INFO	2025-10-13T05:53:53,369	185854	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334833370,"INFO	2025-10-13T05:53:53,370	185855	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 1888273f-4a34-45a8-abd5-5710a14ca971)
"
1760334833370,"INFO	2025-10-13T05:53:53,370	185855	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 21 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334834043,"INFO	2025-10-13T05:53:54,042	186527	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 147.0 in stage 0.0 (TID 147) (172.35.102.6, executor 3, partition 147, PROCESS_LOCAL, 27126 bytes) 
"
1760334834043,"INFO	2025-10-13T05:53:54,043	186528	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 126.0 in stage 0.0 (TID 126) in 16104 ms on 172.35.102.6 (executor 3) (130/471)
"
1760334834987,"INFO	2025-10-13T05:53:54,986	187471	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 148.0 in stage 0.0 (TID 148) (172.35.115.192, executor 1, partition 148, PROCESS_LOCAL, 27126 bytes) 
"
1760334834987,"INFO	2025-10-13T05:53:54,987	187472	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 130.0 in stage 0.0 (TID 130) in 15610 ms on 172.35.115.192 (executor 1) (131/471)
"
1760334836218,"INFO	2025-10-13T05:53:56,218	188703	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 149.0 in stage 0.0 (TID 149) (172.35.115.192, executor 1, partition 149, PROCESS_LOCAL, 27126 bytes) 
"
1760334836219,"INFO	2025-10-13T05:53:56,219	188704	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 131.0 in stage 0.0 (TID 131) in 15527 ms on 172.35.115.192 (executor 1) (132/471)
"
1760334836638,"INFO	2025-10-13T05:53:56,637	189122	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 150.0 in stage 0.0 (TID 150) (172.35.25.103, executor 7, partition 150, PROCESS_LOCAL, 27126 bytes) 
"
1760334836638,"INFO	2025-10-13T05:53:56,638	189123	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 132.0 in stage 0.0 (TID 132) in 14439 ms on 172.35.25.103 (executor 7) (133/471)
"
1760334836852,"INFO	2025-10-13T05:53:56,852	189337	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334836852,"INFO	2025-10-13T05:53:56,852	189337	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760334837115,"INFO	2025-10-13T05:53:57,115	189600	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 151.0 in stage 0.0 (TID 151) (172.35.25.103, executor 7, partition 151, PROCESS_LOCAL, 27126 bytes) 
"
1760334837116,"INFO	2025-10-13T05:53:57,115	189600	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 133.0 in stage 0.0 (TID 133) in 14616 ms on 172.35.25.103 (executor 7) (134/471)
"
1760334837792,"INFO	2025-10-13T05:53:57,792	190277	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 152.0 in stage 0.0 (TID 152) (172.35.54.41, executor 8, partition 152, PROCESS_LOCAL, 27126 bytes) 
"
1760334837793,"INFO	2025-10-13T05:53:57,792	190277	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 134.0 in stage 0.0 (TID 134) in 15213 ms on 172.35.54.41 (executor 8) (135/471)
"
1760334838094,"INFO	2025-10-13T05:53:58,094	190579	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 153.0 in stage 0.0 (TID 153) (172.35.54.41, executor 8, partition 153, PROCESS_LOCAL, 27117 bytes) 
"
1760334838095,"INFO	2025-10-13T05:53:58,094	190579	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 135.0 in stage 0.0 (TID 135) in 15488 ms on 172.35.54.41 (executor 8) (136/471)
"
1760334841206,"INFO	2025-10-13T05:54:01,206	193691	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334841207,"INFO	2025-10-13T05:54:01,206	193691	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 22, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334841207,"INFO	2025-10-13T05:54:01,207	193692	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 22; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_22_a_spark-application-1760334656744_p_1
"
1760334841207,"INFO	2025-10-13T05:54:01,207	193692	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334841241,"INFO	2025-10-13T05:54:01,241	193726	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334841241,"INFO	2025-10-13T05:54:01,241	193726	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: ea1706d8-13bb-4d28-a225-c2d036b0f263)
"
1760334841242,"INFO	2025-10-13T05:54:01,241	193726	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 22 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334842727,"INFO	2025-10-13T05:54:02,726	195211	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 154.0 in stage 0.0 (TID 154) (172.35.42.110, executor 2, partition 154, PROCESS_LOCAL, 27126 bytes) 
"
1760334842727,"INFO	2025-10-13T05:54:02,727	195212	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 136.0 in stage 0.0 (TID 136) in 14567 ms on 172.35.42.110 (executor 2) (137/471)
"
1760334842755,"INFO	2025-10-13T05:54:02,755	195240	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 155.0 in stage 0.0 (TID 155) (172.35.52.98, executor 6, partition 155, PROCESS_LOCAL, 27118 bytes) 
"
1760334842755,"INFO	2025-10-13T05:54:02,755	195240	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 137.0 in stage 0.0 (TID 137) in 14551 ms on 172.35.52.98 (executor 6) (138/471)
"
1760334843534,"INFO	2025-10-13T05:54:03,534	196019	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 156.0 in stage 0.0 (TID 156) (172.35.42.110, executor 2, partition 156, PROCESS_LOCAL, 27118 bytes) 
"
1760334843534,"INFO	2025-10-13T05:54:03,534	196019	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 138.0 in stage 0.0 (TID 138) in 14618 ms on 172.35.42.110 (executor 2) (139/471)
"
1760334843704,"INFO	2025-10-13T05:54:03,704	196189	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 157.0 in stage 0.0 (TID 157) (172.35.52.98, executor 6, partition 157, PROCESS_LOCAL, 27118 bytes) 
"
1760334843705,"INFO	2025-10-13T05:54:03,704	196189	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 139.0 in stage 0.0 (TID 139) in 14677 ms on 172.35.52.98 (executor 6) (140/471)
"
1760334845934,"INFO	2025-10-13T05:54:05,933	198418	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 158.0 in stage 0.0 (TID 158) (172.34.154.255, executor 9, partition 158, PROCESS_LOCAL, 27118 bytes) 
"
1760334845934,"INFO	2025-10-13T05:54:05,934	198419	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 140.0 in stage 0.0 (TID 140) in 14387 ms on 172.34.154.255 (executor 9) (141/471)
"
1760334846519,"INFO	2025-10-13T05:54:06,519	199004	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 159.0 in stage 0.0 (TID 159) (172.34.183.29, executor 4, partition 159, PROCESS_LOCAL, 27126 bytes) 
"
1760334846520,"INFO	2025-10-13T05:54:06,519	199004	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 143.0 in stage 0.0 (TID 143) in 14349 ms on 172.34.183.29 (executor 4) (142/471)
"
1760334846636,"INFO	2025-10-13T05:54:06,636	199121	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 160.0 in stage 0.0 (TID 160) (172.34.154.255, executor 9, partition 160, PROCESS_LOCAL, 27126 bytes) 
"
1760334846637,"INFO	2025-10-13T05:54:06,637	199122	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 142.0 in stage 0.0 (TID 142) in 14506 ms on 172.34.154.255 (executor 9) (143/471)
"
1760334846962,"INFO	2025-10-13T05:54:06,961	199446	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 161.0 in stage 0.0 (TID 161) (172.35.235.173, executor 5, partition 161, PROCESS_LOCAL, 27118 bytes) 
"
1760334846962,"INFO	2025-10-13T05:54:06,962	199447	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 141.0 in stage 0.0 (TID 141) in 15294 ms on 172.35.235.173 (executor 5) (144/471)
"
1760334847180,"INFO	2025-10-13T05:54:07,180	199665	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 162.0 in stage 0.0 (TID 162) (172.34.183.29, executor 4, partition 162, PROCESS_LOCAL, 27118 bytes) 
"
1760334847180,"INFO	2025-10-13T05:54:07,180	199665	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 144.0 in stage 0.0 (TID 144) in 14316 ms on 172.34.183.29 (executor 4) (145/471)
"
1760334847688,"INFO	2025-10-13T05:54:07,688	200173	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 163.0 in stage 0.0 (TID 163) (172.35.235.173, executor 5, partition 163, PROCESS_LOCAL, 27118 bytes) 
"
1760334847689,"INFO	2025-10-13T05:54:07,689	200174	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 145.0 in stage 0.0 (TID 145) in 14568 ms on 172.35.235.173 (executor 5) (146/471)
"
1760334848979,"INFO	2025-10-13T05:54:08,978	201463	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 164.0 in stage 0.0 (TID 164) (172.35.102.6, executor 3, partition 164, PROCESS_LOCAL, 27118 bytes) 
"
1760334848979,"INFO	2025-10-13T05:54:08,979	201464	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 146.0 in stage 0.0 (TID 146) in 15834 ms on 172.35.102.6 (executor 3) (147/471)
"
1760334849892,"INFO	2025-10-13T05:54:09,891	202376	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 165.0 in stage 0.0 (TID 165) (172.35.102.6, executor 3, partition 165, PROCESS_LOCAL, 27118 bytes) 
"
1760334849892,"INFO	2025-10-13T05:54:09,892	202377	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 147.0 in stage 0.0 (TID 147) in 15850 ms on 172.35.102.6 (executor 3) (148/471)
"
1760334850426,"INFO	2025-10-13T05:54:10,425	202910	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 166.0 in stage 0.0 (TID 166) (172.35.115.192, executor 1, partition 166, PROCESS_LOCAL, 27126 bytes) 
"
1760334850426,"INFO	2025-10-13T05:54:10,426	202911	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 148.0 in stage 0.0 (TID 148) in 15440 ms on 172.35.115.192 (executor 1) (149/471)
"
1760334851295,"INFO	2025-10-13T05:54:11,294	203779	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 167.0 in stage 0.0 (TID 167) (172.35.25.103, executor 7, partition 167, PROCESS_LOCAL, 27126 bytes) 
"
1760334851295,"INFO	2025-10-13T05:54:11,295	203780	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 150.0 in stage 0.0 (TID 150) in 14658 ms on 172.35.25.103 (executor 7) (150/471)
"
1760334851629,"INFO	2025-10-13T05:54:11,629	204114	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 168.0 in stage 0.0 (TID 168) (172.35.115.192, executor 1, partition 168, PROCESS_LOCAL, 27118 bytes) 
"
1760334851630,"INFO	2025-10-13T05:54:11,629	204114	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 149.0 in stage 0.0 (TID 149) in 15411 ms on 172.35.115.192 (executor 1) (151/471)
"
1760334852018,"INFO	2025-10-13T05:54:12,018	204503	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 169.0 in stage 0.0 (TID 169) (172.35.25.103, executor 7, partition 169, PROCESS_LOCAL, 27109 bytes) 
"
1760334852018,"INFO	2025-10-13T05:54:12,018	204503	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 151.0 in stage 0.0 (TID 151) in 14903 ms on 172.35.25.103 (executor 7) (152/471)
"
1760334852629,"INFO	2025-10-13T05:54:12,629	205114	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 170.0 in stage 0.0 (TID 170) (172.35.54.41, executor 8, partition 170, PROCESS_LOCAL, 27118 bytes) 
"
1760334852629,"INFO	2025-10-13T05:54:12,629	205114	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 152.0 in stage 0.0 (TID 152) in 14838 ms on 172.35.54.41 (executor 8) (153/471)
"
1760334852944,"INFO	2025-10-13T05:54:12,943	205428	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 171.0 in stage 0.0 (TID 171) (172.35.54.41, executor 8, partition 171, PROCESS_LOCAL, 27118 bytes) 
"
1760334852944,"INFO	2025-10-13T05:54:12,944	205429	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 153.0 in stage 0.0 (TID 153) in 14851 ms on 172.35.54.41 (executor 8) (154/471)
"
1760334855632,"INFO	2025-10-13T05:54:15,632	208117	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334855632,"INFO	2025-10-13T05:54:15,632	208117	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 23, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334855632,"INFO	2025-10-13T05:54:15,632	208117	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 23; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_23_a_spark-application-1760334656744_p_1
"
1760334855633,"INFO	2025-10-13T05:54:15,632	208117	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334855667,"INFO	2025-10-13T05:54:15,666	208151	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334855667,"INFO	2025-10-13T05:54:15,667	208152	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: fcfd4e71-ebb9-4b51-b727-cf2b11e37eb1)
"
1760334855667,"INFO	2025-10-13T05:54:15,667	208152	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 23 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334857058,"INFO	2025-10-13T05:54:17,057	209542	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 172.0 in stage 0.0 (TID 172) (172.35.52.98, executor 6, partition 172, PROCESS_LOCAL, 27118 bytes) 
"
1760334857058,"INFO	2025-10-13T05:54:17,058	209543	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 155.0 in stage 0.0 (TID 155) in 14304 ms on 172.35.52.98 (executor 6) (155/471)
"
1760334857169,"INFO	2025-10-13T05:54:17,169	209654	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 173.0 in stage 0.0 (TID 173) (172.35.42.110, executor 2, partition 173, PROCESS_LOCAL, 27118 bytes) 
"
1760334857170,"INFO	2025-10-13T05:54:17,169	209654	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 154.0 in stage 0.0 (TID 154) in 14443 ms on 172.35.42.110 (executor 2) (156/471)
"
1760334858120,"INFO	2025-10-13T05:54:18,120	210605	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 174.0 in stage 0.0 (TID 174) (172.35.52.98, executor 6, partition 174, PROCESS_LOCAL, 27118 bytes) 
"
1760334858121,"INFO	2025-10-13T05:54:18,120	210605	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 157.0 in stage 0.0 (TID 157) in 14417 ms on 172.35.52.98 (executor 6) (157/471)
"
1760334858174,"INFO	2025-10-13T05:54:18,173	210658	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 175.0 in stage 0.0 (TID 175) (172.35.42.110, executor 2, partition 175, PROCESS_LOCAL, 27118 bytes) 
"
1760334858174,"INFO	2025-10-13T05:54:18,174	210659	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 156.0 in stage 0.0 (TID 156) in 14641 ms on 172.35.42.110 (executor 2) (158/471)
"
1760334860419,"INFO	2025-10-13T05:54:20,418	212903	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 176.0 in stage 0.0 (TID 176) (172.34.154.255, executor 9, partition 176, PROCESS_LOCAL, 27118 bytes) 
"
1760334860419,"INFO	2025-10-13T05:54:20,419	212904	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 158.0 in stage 0.0 (TID 158) in 14486 ms on 172.34.154.255 (executor 9) (159/471)
"
1760334860871,"INFO	2025-10-13T05:54:20,870	213355	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 177.0 in stage 0.0 (TID 177) (172.34.183.29, executor 4, partition 177, PROCESS_LOCAL, 27118 bytes) 
"
1760334860871,"INFO	2025-10-13T05:54:20,871	213356	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 159.0 in stage 0.0 (TID 159) in 14353 ms on 172.34.183.29 (executor 4) (160/471)
"
1760334861104,"INFO	2025-10-13T05:54:21,104	213589	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 178.0 in stage 0.0 (TID 178) (172.34.154.255, executor 9, partition 178, PROCESS_LOCAL, 27118 bytes) 
"
1760334861104,"INFO	2025-10-13T05:54:21,104	213589	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 160.0 in stage 0.0 (TID 160) in 14468 ms on 172.34.154.255 (executor 9) (161/471)
"
1760334861511,"INFO	2025-10-13T05:54:21,510	213995	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 179.0 in stage 0.0 (TID 179) (172.35.235.173, executor 5, partition 179, PROCESS_LOCAL, 27118 bytes) 
"
1760334861511,"INFO	2025-10-13T05:54:21,511	213996	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 161.0 in stage 0.0 (TID 161) in 14550 ms on 172.35.235.173 (executor 5) (162/471)
"
1760334861605,"INFO	2025-10-13T05:54:21,604	214089	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 180.0 in stage 0.0 (TID 180) (172.34.183.29, executor 4, partition 180, PROCESS_LOCAL, 27126 bytes) 
"
1760334861605,"INFO	2025-10-13T05:54:21,605	214090	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 162.0 in stage 0.0 (TID 162) in 14426 ms on 172.34.183.29 (executor 4) (163/471)
"
1760334862605,"INFO	2025-10-13T05:54:22,605	215090	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 181.0 in stage 0.0 (TID 181) (172.35.235.173, executor 5, partition 181, PROCESS_LOCAL, 27126 bytes) 
"
1760334862606,"INFO	2025-10-13T05:54:22,606	215091	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 163.0 in stage 0.0 (TID 163) in 14918 ms on 172.35.235.173 (executor 5) (164/471)
"
1760334862623,"INFO	2025-10-13T05:54:22,623	215108	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334862623,"INFO	2025-10-13T05:54:22,623	215108	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 24, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334862623,"INFO	2025-10-13T05:54:22,623	215108	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 24; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_24_a_spark-application-1760334656744_p_1
"
1760334862624,"INFO	2025-10-13T05:54:22,623	215108	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334862661,"INFO	2025-10-13T05:54:22,661	215146	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334862661,"INFO	2025-10-13T05:54:22,661	215146	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: c4eeff0f-6752-4afa-9c7a-e0d4bfe5235e)
"
1760334862661,"INFO	2025-10-13T05:54:22,661	215146	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 24 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334863467,"INFO	2025-10-13T05:54:23,467	215952	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334863468,"INFO	2025-10-13T05:54:23,467	215952	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 25, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334863468,"INFO	2025-10-13T05:54:23,468	215953	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 25; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_25_a_spark-application-1760334656744_p_1
"
1760334863468,"INFO	2025-10-13T05:54:23,468	215953	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334863506,"INFO	2025-10-13T05:54:23,505	215990	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334863506,"INFO	2025-10-13T05:54:23,506	215991	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 386b4958-37fd-42a6-9957-0cbc5d25100e)
"
1760334863506,"INFO	2025-10-13T05:54:23,506	215991	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 25 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334864242,"INFO	2025-10-13T05:54:24,242	216727	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334864242,"INFO	2025-10-13T05:54:24,242	216727	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 26, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334864243,"INFO	2025-10-13T05:54:24,242	216727	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 26; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_26_a_spark-application-1760334656744_p_1
"
1760334864243,"INFO	2025-10-13T05:54:24,243	216728	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334864269,"INFO	2025-10-13T05:54:24,269	216754	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334864269,"INFO	2025-10-13T05:54:24,269	216754	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: f67cab86-a30a-4fc6-bc3e-0b741de609bf)
"
1760334864269,"INFO	2025-10-13T05:54:24,269	216754	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 26 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334864552,"INFO	2025-10-13T05:54:24,552	217037	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 182.0 in stage 0.0 (TID 182) (172.35.102.6, executor 3, partition 182, PROCESS_LOCAL, 27118 bytes) 
"
1760334864552,"INFO	2025-10-13T05:54:24,552	217037	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 164.0 in stage 0.0 (TID 164) in 15574 ms on 172.35.102.6 (executor 3) (165/471)
"
1760334865461,"INFO	2025-10-13T05:54:25,460	217945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 183.0 in stage 0.0 (TID 183) (172.35.102.6, executor 3, partition 183, PROCESS_LOCAL, 27118 bytes) 
"
1760334865461,"INFO	2025-10-13T05:54:25,461	217946	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 165.0 in stage 0.0 (TID 165) in 15570 ms on 172.35.102.6 (executor 3) (166/471)
"
1760334865559,"INFO	2025-10-13T05:54:25,559	218044	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 184.0 in stage 0.0 (TID 184) (172.35.25.103, executor 7, partition 184, PROCESS_LOCAL, 27118 bytes) 
"
1760334865559,"INFO	2025-10-13T05:54:25,559	218044	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 167.0 in stage 0.0 (TID 167) in 14265 ms on 172.35.25.103 (executor 7) (167/471)
"
1760334865761,"INFO	2025-10-13T05:54:25,761	218246	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 185.0 in stage 0.0 (TID 185) (172.35.115.192, executor 1, partition 185, PROCESS_LOCAL, 27126 bytes) 
"
1760334865762,"INFO	2025-10-13T05:54:25,761	218246	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 166.0 in stage 0.0 (TID 166) in 15336 ms on 172.35.115.192 (executor 1) (168/471)
"
1760334866293,"INFO	2025-10-13T05:54:26,293	218778	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 186.0 in stage 0.0 (TID 186) (172.35.25.103, executor 7, partition 186, PROCESS_LOCAL, 27118 bytes) 
"
1760334866294,"INFO	2025-10-13T05:54:26,293	218778	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 169.0 in stage 0.0 (TID 169) in 14276 ms on 172.35.25.103 (executor 7) (169/471)
"
1760334866516,"INFO	2025-10-13T05:54:26,515	219000	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 187.0 in stage 0.0 (TID 187) (172.35.54.41, executor 8, partition 187, PROCESS_LOCAL, 27118 bytes) 
"
1760334866516,"INFO	2025-10-13T05:54:26,516	219001	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 170.0 in stage 0.0 (TID 170) in 13888 ms on 172.35.54.41 (executor 8) (170/471)
"
1760334866998,"INFO	2025-10-13T05:54:26,998	219483	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 188.0 in stage 0.0 (TID 188) (172.35.115.192, executor 1, partition 188, PROCESS_LOCAL, 27126 bytes) 
"
1760334866999,"INFO	2025-10-13T05:54:26,999	219484	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 168.0 in stage 0.0 (TID 168) in 15371 ms on 172.35.115.192 (executor 1) (171/471)
"
1760334867016,"INFO	2025-10-13T05:54:27,016	219501	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 189.0 in stage 0.0 (TID 189) (172.35.54.41, executor 8, partition 189, PROCESS_LOCAL, 27118 bytes) 
"
1760334867017,"INFO	2025-10-13T05:54:27,016	219501	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 171.0 in stage 0.0 (TID 171) in 14073 ms on 172.35.54.41 (executor 8) (172/471)
"
1760334869521,"INFO	2025-10-13T05:54:29,521	222006	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334869522,"INFO	2025-10-13T05:54:29,521	222006	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 27, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334869522,"INFO	2025-10-13T05:54:29,522	222007	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 27; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_27_a_spark-application-1760334656744_p_1
"
1760334869522,"INFO	2025-10-13T05:54:29,522	222007	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334869567,"INFO	2025-10-13T05:54:29,567	222052	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334869567,"INFO	2025-10-13T05:54:29,567	222052	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: bcf34848-de27-4283-9eb0-329e18c777ea)
"
1760334869567,"INFO	2025-10-13T05:54:29,567	222052	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 27 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334871137,"INFO	2025-10-13T05:54:31,136	223621	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 190.0 in stage 0.0 (TID 190) (172.35.52.98, executor 6, partition 190, PROCESS_LOCAL, 27117 bytes) 
"
1760334871137,"INFO	2025-10-13T05:54:31,137	223622	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 172.0 in stage 0.0 (TID 172) in 14080 ms on 172.35.52.98 (executor 6) (173/471)
"
1760334871670,"INFO	2025-10-13T05:54:31,670	224155	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 191.0 in stage 0.0 (TID 191) (172.35.42.110, executor 2, partition 191, PROCESS_LOCAL, 27126 bytes) 
"
1760334871671,"INFO	2025-10-13T05:54:31,670	224155	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 173.0 in stage 0.0 (TID 173) in 14501 ms on 172.35.42.110 (executor 2) (174/471)
"
1760334872171,"INFO	2025-10-13T05:54:32,171	224656	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 192.0 in stage 0.0 (TID 192) (172.35.52.98, executor 6, partition 192, PROCESS_LOCAL, 27126 bytes) 
"
1760334872172,"INFO	2025-10-13T05:54:32,172	224657	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 174.0 in stage 0.0 (TID 174) in 14053 ms on 172.35.52.98 (executor 6) (175/471)
"
1760334872758,"INFO	2025-10-13T05:54:32,758	225243	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 193.0 in stage 0.0 (TID 193) (172.35.42.110, executor 2, partition 193, PROCESS_LOCAL, 27126 bytes) 
"
1760334872758,"INFO	2025-10-13T05:54:32,758	225243	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 175.0 in stage 0.0 (TID 175) in 14585 ms on 172.35.42.110 (executor 2) (176/471)
"
1760334875010,"INFO	2025-10-13T05:54:35,009	227494	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 194.0 in stage 0.0 (TID 194) (172.34.154.255, executor 9, partition 194, PROCESS_LOCAL, 27118 bytes) 
"
1760334875010,"INFO	2025-10-13T05:54:35,010	227495	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 176.0 in stage 0.0 (TID 176) in 14592 ms on 172.34.154.255 (executor 9) (177/471)
"
1760334875557,"INFO	2025-10-13T05:54:35,556	228041	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 195.0 in stage 0.0 (TID 195) (172.34.183.29, executor 4, partition 195, PROCESS_LOCAL, 27126 bytes) 
"
1760334875557,"INFO	2025-10-13T05:54:35,557	228042	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 177.0 in stage 0.0 (TID 177) in 14687 ms on 172.34.183.29 (executor 4) (178/471)
"
1760334875660,"INFO	2025-10-13T05:54:35,660	228145	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 196.0 in stage 0.0 (TID 196) (172.34.154.255, executor 9, partition 196, PROCESS_LOCAL, 27118 bytes) 
"
1760334875661,"INFO	2025-10-13T05:54:35,661	228146	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 178.0 in stage 0.0 (TID 178) in 14558 ms on 172.34.154.255 (executor 9) (179/471)
"
1760334875904,"INFO	2025-10-13T05:54:35,904	228389	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 197.0 in stage 0.0 (TID 197) (172.35.235.173, executor 5, partition 197, PROCESS_LOCAL, 27126 bytes) 
"
1760334875904,"INFO	2025-10-13T05:54:35,904	228389	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 179.0 in stage 0.0 (TID 179) in 14394 ms on 172.35.235.173 (executor 5) (180/471)
"
1760334876295,"INFO	2025-10-13T05:54:36,295	228780	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 198.0 in stage 0.0 (TID 198) (172.34.183.29, executor 4, partition 198, PROCESS_LOCAL, 27126 bytes) 
"
1760334876296,"INFO	2025-10-13T05:54:36,295	228780	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 180.0 in stage 0.0 (TID 180) in 14691 ms on 172.34.183.29 (executor 4) (181/471)
"
1760334877062,"INFO	2025-10-13T05:54:37,061	229546	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 199.0 in stage 0.0 (TID 199) (172.35.235.173, executor 5, partition 199, PROCESS_LOCAL, 27118 bytes) 
"
1760334877062,"INFO	2025-10-13T05:54:37,062	229547	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 181.0 in stage 0.0 (TID 181) in 14457 ms on 172.35.235.173 (executor 5) (182/471)
"
1760334879736,"INFO	2025-10-13T05:54:39,735	232220	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 200.0 in stage 0.0 (TID 200) (172.35.25.103, executor 7, partition 200, PROCESS_LOCAL, 27118 bytes) 
"
1760334879736,"INFO	2025-10-13T05:54:39,736	232221	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 184.0 in stage 0.0 (TID 184) in 14178 ms on 172.35.25.103 (executor 7) (183/471)
"
1760334879793,"INFO	2025-10-13T05:54:39,793	232278	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 201.0 in stage 0.0 (TID 201) (172.35.102.6, executor 3, partition 201, PROCESS_LOCAL, 27118 bytes) 
"
1760334879793,"INFO	2025-10-13T05:54:39,793	232278	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 182.0 in stage 0.0 (TID 182) in 15242 ms on 172.35.102.6 (executor 3) (184/471)
"
1760334880502,"INFO	2025-10-13T05:54:40,502	232987	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 202.0 in stage 0.0 (TID 202) (172.35.54.41, executor 8, partition 202, PROCESS_LOCAL, 27118 bytes) 
"
1760334880503,"INFO	2025-10-13T05:54:40,502	232987	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 187.0 in stage 0.0 (TID 187) in 13987 ms on 172.35.54.41 (executor 8) (185/471)
"
1760334880573,"INFO	2025-10-13T05:54:40,573	233058	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 203.0 in stage 0.0 (TID 203) (172.35.102.6, executor 3, partition 203, PROCESS_LOCAL, 27118 bytes) 
"
1760334880574,"INFO	2025-10-13T05:54:40,573	233058	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 183.0 in stage 0.0 (TID 183) in 15113 ms on 172.35.102.6 (executor 3) (186/471)
"
1760334880827,"INFO	2025-10-13T05:54:40,826	233311	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 204.0 in stage 0.0 (TID 204) (172.35.25.103, executor 7, partition 204, PROCESS_LOCAL, 27126 bytes) 
"
1760334880827,"INFO	2025-10-13T05:54:40,827	233312	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 186.0 in stage 0.0 (TID 186) in 14535 ms on 172.35.25.103 (executor 7) (187/471)
"
1760334880959,"INFO	2025-10-13T05:54:40,959	233444	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 205.0 in stage 0.0 (TID 205) (172.35.54.41, executor 8, partition 205, PROCESS_LOCAL, 27126 bytes) 
"
1760334880960,"INFO	2025-10-13T05:54:40,959	233444	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 189.0 in stage 0.0 (TID 189) in 13943 ms on 172.35.54.41 (executor 8) (188/471)
"
1760334881374,"INFO	2025-10-13T05:54:41,374	233859	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 206.0 in stage 0.0 (TID 206) (172.35.115.192, executor 1, partition 206, PROCESS_LOCAL, 27126 bytes) 
"
1760334881374,"INFO	2025-10-13T05:54:41,374	233859	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 185.0 in stage 0.0 (TID 185) in 15614 ms on 172.35.115.192 (executor 1) (189/471)
"
1760334882413,"INFO	2025-10-13T05:54:42,412	234897	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 207.0 in stage 0.0 (TID 207) (172.35.115.192, executor 1, partition 207, PROCESS_LOCAL, 27126 bytes) 
"
1760334882413,"INFO	2025-10-13T05:54:42,413	234898	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 188.0 in stage 0.0 (TID 188) in 15415 ms on 172.35.115.192 (executor 1) (190/471)
"
1760334883533,"INFO	2025-10-13T05:54:43,532	236017	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334883533,"INFO	2025-10-13T05:54:43,533	236018	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 28, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334883533,"INFO	2025-10-13T05:54:43,533	236018	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 28; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_28_a_spark-application-1760334656744_p_1
"
1760334883534,"INFO	2025-10-13T05:54:43,533	236018	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334883574,"INFO	2025-10-13T05:54:43,573	236058	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334883574,"INFO	2025-10-13T05:54:43,574	236059	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 78157528-35ae-41b0-b2ee-57e6f7d1b243)
"
1760334883574,"INFO	2025-10-13T05:54:43,574	236059	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 28 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334884883,"INFO	2025-10-13T05:54:44,883	237368	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 208.0 in stage 0.0 (TID 208) (172.35.52.98, executor 6, partition 208, PROCESS_LOCAL, 27126 bytes) 
"
1760334884884,"INFO	2025-10-13T05:54:44,883	237368	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 190.0 in stage 0.0 (TID 190) in 13747 ms on 172.35.52.98 (executor 6) (191/471)
"
1760334886071,"INFO	2025-10-13T05:54:46,070	238555	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 209.0 in stage 0.0 (TID 209) (172.35.52.98, executor 6, partition 209, PROCESS_LOCAL, 27126 bytes) 
"
1760334886071,"INFO	2025-10-13T05:54:46,071	238556	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 192.0 in stage 0.0 (TID 192) in 13900 ms on 172.35.52.98 (executor 6) (192/471)
"
1760334886293,"INFO	2025-10-13T05:54:46,293	238778	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 210.0 in stage 0.0 (TID 210) (172.35.42.110, executor 2, partition 210, PROCESS_LOCAL, 27126 bytes) 
"
1760334886294,"INFO	2025-10-13T05:54:46,293	238778	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 191.0 in stage 0.0 (TID 191) in 14624 ms on 172.35.42.110 (executor 2) (193/471)
"
1760334887352,"INFO	2025-10-13T05:54:47,352	239837	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 211.0 in stage 0.0 (TID 211) (172.35.42.110, executor 2, partition 211, PROCESS_LOCAL, 27126 bytes) 
"
1760334887352,"INFO	2025-10-13T05:54:47,352	239837	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 193.0 in stage 0.0 (TID 193) in 14595 ms on 172.35.42.110 (executor 2) (194/471)
"
1760334889605,"INFO	2025-10-13T05:54:49,604	242089	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 212.0 in stage 0.0 (TID 212) (172.34.154.255, executor 9, partition 212, PROCESS_LOCAL, 27118 bytes) 
"
1760334889605,"INFO	2025-10-13T05:54:49,605	242090	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 194.0 in stage 0.0 (TID 194) in 14596 ms on 172.34.154.255 (executor 9) (195/471)
"
1760334890383,"INFO	2025-10-13T05:54:50,383	242868	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 213.0 in stage 0.0 (TID 213) (172.35.235.173, executor 5, partition 213, PROCESS_LOCAL, 27126 bytes) 
"
1760334890383,"INFO	2025-10-13T05:54:50,383	242868	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 197.0 in stage 0.0 (TID 197) in 14480 ms on 172.35.235.173 (executor 5) (196/471)
"
1760334890595,"INFO	2025-10-13T05:54:50,595	243080	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 214.0 in stage 0.0 (TID 214) (172.34.154.255, executor 9, partition 214, PROCESS_LOCAL, 27126 bytes) 
"
1760334890595,"INFO	2025-10-13T05:54:50,595	243080	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 196.0 in stage 0.0 (TID 196) in 14935 ms on 172.34.154.255 (executor 9) (197/471)
"
1760334890814,"INFO	2025-10-13T05:54:50,814	243299	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 215.0 in stage 0.0 (TID 215) (172.34.183.29, executor 4, partition 215, PROCESS_LOCAL, 27126 bytes) 
"
1760334890815,"INFO	2025-10-13T05:54:50,815	243300	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 195.0 in stage 0.0 (TID 195) in 15259 ms on 172.34.183.29 (executor 4) (198/471)
"
1760334891454,"INFO	2025-10-13T05:54:51,454	243939	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 216.0 in stage 0.0 (TID 216) (172.34.183.29, executor 4, partition 216, PROCESS_LOCAL, 27118 bytes) 
"
1760334891455,"INFO	2025-10-13T05:54:51,455	243940	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 198.0 in stage 0.0 (TID 198) in 15161 ms on 172.34.183.29 (executor 4) (199/471)
"
1760334891585,"INFO	2025-10-13T05:54:51,585	244070	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 217.0 in stage 0.0 (TID 217) (172.35.235.173, executor 5, partition 217, PROCESS_LOCAL, 27118 bytes) 
"
1760334891585,"INFO	2025-10-13T05:54:51,585	244070	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 199.0 in stage 0.0 (TID 199) in 14524 ms on 172.35.235.173 (executor 5) (200/471)
"
1760334891617,"INFO	2025-10-13T05:54:51,617	244102	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334891617,"INFO	2025-10-13T05:54:51,617	244102	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 29, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334891617,"INFO	2025-10-13T05:54:51,617	244102	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 29; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_29_a_spark-application-1760334656744_p_1
"
1760334891618,"INFO	2025-10-13T05:54:51,617	244102	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334891646,"INFO	2025-10-13T05:54:51,646	244131	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334891646,"INFO	2025-10-13T05:54:51,646	244131	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 5be473e7-2baf-475b-b4d2-d69bc08bd24f)
"
1760334891646,"INFO	2025-10-13T05:54:51,646	244131	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 29 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334893788,"INFO	2025-10-13T05:54:53,788	246273	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 218.0 in stage 0.0 (TID 218) (172.35.54.41, executor 8, partition 218, PROCESS_LOCAL, 27118 bytes) 
"
1760334893788,"INFO	2025-10-13T05:54:53,788	246273	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 202.0 in stage 0.0 (TID 202) in 13287 ms on 172.35.54.41 (executor 8) (201/471)
"
1760334894088,"INFO	2025-10-13T05:54:54,087	246572	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 219.0 in stage 0.0 (TID 219) (172.35.25.103, executor 7, partition 219, PROCESS_LOCAL, 27126 bytes) 
"
1760334894088,"INFO	2025-10-13T05:54:54,088	246573	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 200.0 in stage 0.0 (TID 200) in 14353 ms on 172.35.25.103 (executor 7) (202/471)
"
1760334894429,"INFO	2025-10-13T05:54:54,429	246914	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 220.0 in stage 0.0 (TID 220) (172.35.54.41, executor 8, partition 220, PROCESS_LOCAL, 27126 bytes) 
"
1760334894430,"INFO	2025-10-13T05:54:54,429	246914	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 205.0 in stage 0.0 (TID 205) in 13470 ms on 172.35.54.41 (executor 8) (203/471)
"
1760334895031,"INFO	2025-10-13T05:54:55,030	247515	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 221.0 in stage 0.0 (TID 221) (172.35.25.103, executor 7, partition 221, PROCESS_LOCAL, 27126 bytes) 
"
1760334895031,"INFO	2025-10-13T05:54:55,031	247516	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 204.0 in stage 0.0 (TID 204) in 14205 ms on 172.35.25.103 (executor 7) (204/471)
"
1760334895172,"INFO	2025-10-13T05:54:55,172	247657	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 222.0 in stage 0.0 (TID 222) (172.35.102.6, executor 3, partition 222, PROCESS_LOCAL, 27118 bytes) 
"
1760334895173,"INFO	2025-10-13T05:54:55,172	247657	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 201.0 in stage 0.0 (TID 201) in 15380 ms on 172.35.102.6 (executor 3) (205/471)
"
1760334895790,"INFO	2025-10-13T05:54:55,789	248274	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 223.0 in stage 0.0 (TID 223) (172.35.102.6, executor 3, partition 223, PROCESS_LOCAL, 27126 bytes) 
"
1760334895790,"INFO	2025-10-13T05:54:55,790	248275	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 203.0 in stage 0.0 (TID 203) in 15217 ms on 172.35.102.6 (executor 3) (206/471)
"
1760334896685,"INFO	2025-10-13T05:54:56,684	249169	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 224.0 in stage 0.0 (TID 224) (172.35.115.192, executor 1, partition 224, PROCESS_LOCAL, 27118 bytes) 
"
1760334896685,"INFO	2025-10-13T05:54:56,685	249170	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 206.0 in stage 0.0 (TID 206) in 15312 ms on 172.35.115.192 (executor 1) (207/471)
"
1760334896852,"INFO	2025-10-13T05:54:56,852	249337	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334896852,"INFO	2025-10-13T05:54:56,852	249337	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760334897725,"INFO	2025-10-13T05:54:57,724	250209	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 225.0 in stage 0.0 (TID 225) (172.35.115.192, executor 1, partition 225, PROCESS_LOCAL, 27126 bytes) 
"
1760334897725,"INFO	2025-10-13T05:54:57,725	250210	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 207.0 in stage 0.0 (TID 207) in 15313 ms on 172.35.115.192 (executor 1) (208/471)
"
1760334898524,"INFO	2025-10-13T05:54:58,524	251009	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 226.0 in stage 0.0 (TID 226) (172.35.52.98, executor 6, partition 226, PROCESS_LOCAL, 27118 bytes) 
"
1760334898525,"INFO	2025-10-13T05:54:58,524	251009	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 208.0 in stage 0.0 (TID 208) in 13642 ms on 172.35.52.98 (executor 6) (209/471)
"
1760334900065,"INFO	2025-10-13T05:55:00,065	252550	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 227.0 in stage 0.0 (TID 227) (172.35.52.98, executor 6, partition 227, PROCESS_LOCAL, 27126 bytes) 
"
1760334900065,"INFO	2025-10-13T05:55:00,065	252550	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 209.0 in stage 0.0 (TID 209) in 13995 ms on 172.35.52.98 (executor 6) (210/471)
"
1760334902563,"INFO	2025-10-13T05:55:02,563	255048	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 228.0 in stage 0.0 (TID 228) (172.35.42.110, executor 2, partition 228, PROCESS_LOCAL, 27118 bytes) 
"
1760334902563,"INFO	2025-10-13T05:55:02,563	255048	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 210.0 in stage 0.0 (TID 210) in 16270 ms on 172.35.42.110 (executor 2) (211/471)
"
1760334902988,"INFO	2025-10-13T05:55:02,988	255473	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 229.0 in stage 0.0 (TID 229) (172.35.42.110, executor 2, partition 229, PROCESS_LOCAL, 27126 bytes) 
"
1760334902988,"INFO	2025-10-13T05:55:02,988	255473	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 211.0 in stage 0.0 (TID 211) in 15637 ms on 172.35.42.110 (executor 2) (212/471)
"
1760334903549,"INFO	2025-10-13T05:55:03,548	256033	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334903549,"INFO	2025-10-13T05:55:03,549	256034	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 30, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334903549,"INFO	2025-10-13T05:55:03,549	256034	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 30; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_30_a_spark-application-1760334656744_p_1
"
1760334903549,"INFO	2025-10-13T05:55:03,549	256034	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334903585,"INFO	2025-10-13T05:55:03,585	256070	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334903585,"INFO	2025-10-13T05:55:03,585	256070	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: e24dc30e-1f40-4502-bb45-97d79e458e1c)
"
1760334903585,"INFO	2025-10-13T05:55:03,585	256070	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 30 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334904194,"INFO	2025-10-13T05:55:04,194	256679	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 230.0 in stage 0.0 (TID 230) (172.34.154.255, executor 9, partition 230, PROCESS_LOCAL, 27126 bytes) 
"
1760334904195,"INFO	2025-10-13T05:55:04,195	256680	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 212.0 in stage 0.0 (TID 212) in 14591 ms on 172.34.154.255 (executor 9) (213/471)
"
1760334904702,"INFO	2025-10-13T05:55:04,701	257186	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 231.0 in stage 0.0 (TID 231) (172.35.235.173, executor 5, partition 231, PROCESS_LOCAL, 27118 bytes) 
"
1760334904702,"INFO	2025-10-13T05:55:04,702	257187	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 213.0 in stage 0.0 (TID 213) in 14320 ms on 172.35.235.173 (executor 5) (214/471)
"
1760334905079,"INFO	2025-10-13T05:55:05,079	257564	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 232.0 in stage 0.0 (TID 232) (172.34.154.255, executor 9, partition 232, PROCESS_LOCAL, 27126 bytes) 
"
1760334905080,"INFO	2025-10-13T05:55:05,079	257564	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 214.0 in stage 0.0 (TID 214) in 14485 ms on 172.34.154.255 (executor 9) (215/471)
"
1760334905543,"INFO	2025-10-13T05:55:05,543	258028	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 233.0 in stage 0.0 (TID 233) (172.34.183.29, executor 4, partition 233, PROCESS_LOCAL, 27126 bytes) 
"
1760334905543,"INFO	2025-10-13T05:55:05,543	258028	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 215.0 in stage 0.0 (TID 215) in 14729 ms on 172.34.183.29 (executor 4) (216/471)
"
1760334906402,"INFO	2025-10-13T05:55:06,402	258887	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 234.0 in stage 0.0 (TID 234) (172.35.235.173, executor 5, partition 234, PROCESS_LOCAL, 27126 bytes) 
"
1760334906403,"INFO	2025-10-13T05:55:06,403	258888	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 217.0 in stage 0.0 (TID 217) in 14818 ms on 172.35.235.173 (executor 5) (217/471)
"
1760334906612,"INFO	2025-10-13T05:55:06,612	259097	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 235.0 in stage 0.0 (TID 235) (172.34.183.29, executor 4, partition 235, PROCESS_LOCAL, 27126 bytes) 
"
1760334906613,"INFO	2025-10-13T05:55:06,612	259097	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 216.0 in stage 0.0 (TID 216) in 15158 ms on 172.34.183.29 (executor 4) (218/471)
"
1760334907065,"INFO	2025-10-13T05:55:07,064	259549	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 236.0 in stage 0.0 (TID 236) (172.35.54.41, executor 8, partition 236, PROCESS_LOCAL, 27118 bytes) 
"
1760334907065,"INFO	2025-10-13T05:55:07,065	259550	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 218.0 in stage 0.0 (TID 218) in 13278 ms on 172.35.54.41 (executor 8) (219/471)
"
1760334907592,"INFO	2025-10-13T05:55:07,592	260077	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 237.0 in stage 0.0 (TID 237) (172.35.54.41, executor 8, partition 237, PROCESS_LOCAL, 27126 bytes) 
"
1760334907593,"INFO	2025-10-13T05:55:07,592	260077	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 220.0 in stage 0.0 (TID 220) in 13163 ms on 172.35.54.41 (executor 8) (220/471)
"
1760334908372,"INFO	2025-10-13T05:55:08,372	260857	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 238.0 in stage 0.0 (TID 238) (172.35.25.103, executor 7, partition 238, PROCESS_LOCAL, 27126 bytes) 
"
1760334908372,"INFO	2025-10-13T05:55:08,372	260857	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 219.0 in stage 0.0 (TID 219) in 14285 ms on 172.35.25.103 (executor 7) (221/471)
"
1760334909540,"INFO	2025-10-13T05:55:09,539	262024	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 239.0 in stage 0.0 (TID 239) (172.35.25.103, executor 7, partition 239, PROCESS_LOCAL, 27126 bytes) 
"
1760334909540,"INFO	2025-10-13T05:55:09,540	262025	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 221.0 in stage 0.0 (TID 221) in 14510 ms on 172.35.25.103 (executor 7) (222/471)
"
1760334910591,"INFO	2025-10-13T05:55:10,590	263075	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 240.0 in stage 0.0 (TID 240) (172.35.102.6, executor 3, partition 240, PROCESS_LOCAL, 27118 bytes) 
"
1760334910591,"INFO	2025-10-13T05:55:10,591	263076	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 222.0 in stage 0.0 (TID 222) in 15419 ms on 172.35.102.6 (executor 3) (223/471)
"
1760334911121,"INFO	2025-10-13T05:55:11,121	263606	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 241.0 in stage 0.0 (TID 241) (172.35.102.6, executor 3, partition 241, PROCESS_LOCAL, 27126 bytes) 
"
1760334911122,"INFO	2025-10-13T05:55:11,121	263606	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 223.0 in stage 0.0 (TID 223) in 15332 ms on 172.35.102.6 (executor 3) (224/471)
"
1760334912088,"INFO	2025-10-13T05:55:12,087	264572	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 242.0 in stage 0.0 (TID 242) (172.35.115.192, executor 1, partition 242, PROCESS_LOCAL, 27117 bytes) 
"
1760334912088,"INFO	2025-10-13T05:55:12,088	264573	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 224.0 in stage 0.0 (TID 224) in 15404 ms on 172.35.115.192 (executor 1) (225/471)
"
1760334912255,"INFO	2025-10-13T05:55:12,255	264740	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334912256,"INFO	2025-10-13T05:55:12,256	264741	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 31, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334912256,"INFO	2025-10-13T05:55:12,256	264741	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 31; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_31_a_spark-application-1760334656744_p_1
"
1760334912256,"INFO	2025-10-13T05:55:12,256	264741	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334912292,"INFO	2025-10-13T05:55:12,292	264777	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334912293,"INFO	2025-10-13T05:55:12,292	264777	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: d276a096-fac3-4202-9dfe-bfd91ccb9153)
"
1760334912293,"INFO	2025-10-13T05:55:12,292	264777	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 31 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334912641,"INFO	2025-10-13T05:55:12,641	265126	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 243.0 in stage 0.0 (TID 243) (172.35.52.98, executor 6, partition 243, PROCESS_LOCAL, 27118 bytes) 
"
1760334912642,"INFO	2025-10-13T05:55:12,642	265127	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 226.0 in stage 0.0 (TID 226) in 14118 ms on 172.35.52.98 (executor 6) (226/471)
"
1760334913105,"INFO	2025-10-13T05:55:13,105	265590	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 244.0 in stage 0.0 (TID 244) (172.35.115.192, executor 1, partition 244, PROCESS_LOCAL, 27118 bytes) 
"
1760334913106,"INFO	2025-10-13T05:55:13,106	265591	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 225.0 in stage 0.0 (TID 225) in 15382 ms on 172.35.115.192 (executor 1) (227/471)
"
1760334914385,"INFO	2025-10-13T05:55:14,385	266870	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 245.0 in stage 0.0 (TID 245) (172.35.52.98, executor 6, partition 245, PROCESS_LOCAL, 27118 bytes) 
"
1760334914386,"INFO	2025-10-13T05:55:14,386	266871	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 227.0 in stage 0.0 (TID 227) in 14322 ms on 172.35.52.98 (executor 6) (228/471)
"
1760334917766,"INFO	2025-10-13T05:55:17,766	270251	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 246.0 in stage 0.0 (TID 246) (172.35.42.110, executor 2, partition 246, PROCESS_LOCAL, 27126 bytes) 
"
1760334917767,"INFO	2025-10-13T05:55:17,767	270252	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 228.0 in stage 0.0 (TID 228) in 15204 ms on 172.35.42.110 (executor 2) (229/471)
"
1760334918393,"INFO	2025-10-13T05:55:18,392	270877	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 247.0 in stage 0.0 (TID 247) (172.35.42.110, executor 2, partition 247, PROCESS_LOCAL, 27126 bytes) 
"
1760334918393,"INFO	2025-10-13T05:55:18,393	270878	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 229.0 in stage 0.0 (TID 229) in 15406 ms on 172.35.42.110 (executor 2) (230/471)
"
1760334918662,"INFO	2025-10-13T05:55:18,661	271146	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 248.0 in stage 0.0 (TID 248) (172.34.154.255, executor 9, partition 248, PROCESS_LOCAL, 27118 bytes) 
"
1760334918662,"INFO	2025-10-13T05:55:18,662	271147	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 230.0 in stage 0.0 (TID 230) in 14468 ms on 172.34.154.255 (executor 9) (231/471)
"
1760334919184,"INFO	2025-10-13T05:55:19,184	271669	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 249.0 in stage 0.0 (TID 249) (172.35.235.173, executor 5, partition 249, PROCESS_LOCAL, 27118 bytes) 
"
1760334919185,"INFO	2025-10-13T05:55:19,184	271669	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 231.0 in stage 0.0 (TID 231) in 14483 ms on 172.35.235.173 (executor 5) (232/471)
"
1760334919528,"INFO	2025-10-13T05:55:19,527	272012	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334919528,"INFO	2025-10-13T05:55:19,528	272013	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 32, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334919528,"INFO	2025-10-13T05:55:19,528	272013	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 32; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_32_a_spark-application-1760334656744_p_1
"
1760334919528,"INFO	2025-10-13T05:55:19,528	272013	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334919556,"INFO	2025-10-13T05:55:19,556	272041	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 250.0 in stage 0.0 (TID 250) (172.34.154.255, executor 9, partition 250, PROCESS_LOCAL, 27126 bytes) 
"
1760334919556,"INFO	2025-10-13T05:55:19,556	272041	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 232.0 in stage 0.0 (TID 232) in 14477 ms on 172.34.154.255 (executor 9) (233/471)
"
1760334919558,"INFO	2025-10-13T05:55:19,558	272043	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334919558,"INFO	2025-10-13T05:55:19,558	272043	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 35c37abc-7460-458a-8806-d03f0f8f88f4)
"
1760334919558,"INFO	2025-10-13T05:55:19,558	272043	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 32 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334919812,"INFO	2025-10-13T05:55:19,811	272296	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 251.0 in stage 0.0 (TID 251) (172.34.183.29, executor 4, partition 251, PROCESS_LOCAL, 27118 bytes) 
"
1760334919812,"INFO	2025-10-13T05:55:19,812	272297	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 233.0 in stage 0.0 (TID 233) in 14270 ms on 172.34.183.29 (executor 4) (234/471)
"
1760334920191,"INFO	2025-10-13T05:55:20,191	272676	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 252.0 in stage 0.0 (TID 252) (172.35.54.41, executor 8, partition 252, PROCESS_LOCAL, 27126 bytes) 
"
1760334920192,"INFO	2025-10-13T05:55:20,192	272677	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 236.0 in stage 0.0 (TID 236) in 13127 ms on 172.35.54.41 (executor 8) (235/471)
"
1760334920782,"INFO	2025-10-13T05:55:20,782	273267	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 253.0 in stage 0.0 (TID 253) (172.35.54.41, executor 8, partition 253, PROCESS_LOCAL, 27118 bytes) 
"
1760334920783,"INFO	2025-10-13T05:55:20,783	273268	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 237.0 in stage 0.0 (TID 237) in 13191 ms on 172.35.54.41 (executor 8) (236/471)
"
1760334920818,"INFO	2025-10-13T05:55:20,817	273302	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 254.0 in stage 0.0 (TID 254) (172.35.235.173, executor 5, partition 254, PROCESS_LOCAL, 27126 bytes) 
"
1760334920818,"INFO	2025-10-13T05:55:20,818	273303	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 234.0 in stage 0.0 (TID 234) in 14416 ms on 172.35.235.173 (executor 5) (237/471)
"
1760334921096,"INFO	2025-10-13T05:55:21,096	273581	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 255.0 in stage 0.0 (TID 255) (172.34.183.29, executor 4, partition 255, PROCESS_LOCAL, 27126 bytes) 
"
1760334921096,"INFO	2025-10-13T05:55:21,096	273581	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 235.0 in stage 0.0 (TID 235) in 14484 ms on 172.34.183.29 (executor 4) (238/471)
"
1760334922220,"INFO	2025-10-13T05:55:22,219	274704	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 256.0 in stage 0.0 (TID 256) (172.35.25.103, executor 7, partition 256, PROCESS_LOCAL, 27118 bytes) 
"
1760334922220,"INFO	2025-10-13T05:55:22,220	274705	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 238.0 in stage 0.0 (TID 238) in 13849 ms on 172.35.25.103 (executor 7) (239/471)
"
1760334923421,"INFO	2025-10-13T05:55:23,421	275906	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 257.0 in stage 0.0 (TID 257) (172.35.25.103, executor 7, partition 257, PROCESS_LOCAL, 27118 bytes) 
"
1760334923421,"INFO	2025-10-13T05:55:23,421	275906	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 239.0 in stage 0.0 (TID 239) in 13882 ms on 172.35.25.103 (executor 7) (240/471)
"
1760334925088,"INFO	2025-10-13T05:55:25,088	277573	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334925088,"INFO	2025-10-13T05:55:25,088	277573	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 33, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334925088,"INFO	2025-10-13T05:55:25,088	277573	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 33; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_33_a_spark-application-1760334656744_p_1
"
1760334925088,"INFO	2025-10-13T05:55:25,088	277573	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334925117,"INFO	2025-10-13T05:55:25,117	277602	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334925117,"INFO	2025-10-13T05:55:25,117	277602	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 4f8fea7e-0edb-4533-b75e-e4063c2f11a7)
"
1760334925117,"INFO	2025-10-13T05:55:25,117	277602	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 33 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334925887,"INFO	2025-10-13T05:55:25,886	278371	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 258.0 in stage 0.0 (TID 258) (172.35.102.6, executor 3, partition 258, PROCESS_LOCAL, 27109 bytes) 
"
1760334925887,"INFO	2025-10-13T05:55:25,887	278372	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 240.0 in stage 0.0 (TID 240) in 15297 ms on 172.35.102.6 (executor 3) (241/471)
"
1760334926296,"INFO	2025-10-13T05:55:26,295	278780	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 259.0 in stage 0.0 (TID 259) (172.35.102.6, executor 3, partition 259, PROCESS_LOCAL, 27126 bytes) 
"
1760334926296,"INFO	2025-10-13T05:55:26,296	278781	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 241.0 in stage 0.0 (TID 241) in 15176 ms on 172.35.102.6 (executor 3) (242/471)
"
1760334926395,"INFO	2025-10-13T05:55:26,395	278880	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 260.0 in stage 0.0 (TID 260) (172.35.52.98, executor 6, partition 260, PROCESS_LOCAL, 27118 bytes) 
"
1760334926396,"INFO	2025-10-13T05:55:26,396	278881	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 243.0 in stage 0.0 (TID 243) in 13755 ms on 172.35.52.98 (executor 6) (243/471)
"
1760334927208,"INFO	2025-10-13T05:55:27,208	279693	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 261.0 in stage 0.0 (TID 261) (172.35.115.192, executor 1, partition 261, PROCESS_LOCAL, 27126 bytes) 
"
1760334927209,"INFO	2025-10-13T05:55:27,208	279693	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 242.0 in stage 0.0 (TID 242) in 15121 ms on 172.35.115.192 (executor 1) (244/471)
"
1760334928129,"INFO	2025-10-13T05:55:28,129	280614	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 262.0 in stage 0.0 (TID 262) (172.35.52.98, executor 6, partition 262, PROCESS_LOCAL, 27118 bytes) 
"
1760334928129,"INFO	2025-10-13T05:55:28,129	280614	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 245.0 in stage 0.0 (TID 245) in 13744 ms on 172.35.52.98 (executor 6) (245/471)
"
1760334928376,"INFO	2025-10-13T05:55:28,376	280861	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 263.0 in stage 0.0 (TID 263) (172.35.115.192, executor 1, partition 263, PROCESS_LOCAL, 27118 bytes) 
"
1760334928376,"INFO	2025-10-13T05:55:28,376	280861	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 244.0 in stage 0.0 (TID 244) in 15271 ms on 172.35.115.192 (executor 1) (246/471)
"
1760334932266,"INFO	2025-10-13T05:55:32,266	284751	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 264.0 in stage 0.0 (TID 264) (172.35.42.110, executor 2, partition 264, PROCESS_LOCAL, 27126 bytes) 
"
1760334932267,"INFO	2025-10-13T05:55:32,267	284752	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 246.0 in stage 0.0 (TID 246) in 14501 ms on 172.35.42.110 (executor 2) (247/471)
"
1760334932915,"INFO	2025-10-13T05:55:32,915	285400	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 265.0 in stage 0.0 (TID 265) (172.35.42.110, executor 2, partition 265, PROCESS_LOCAL, 27126 bytes) 
"
1760334932916,"INFO	2025-10-13T05:55:32,916	285401	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 247.0 in stage 0.0 (TID 247) in 14524 ms on 172.35.42.110 (executor 2) (248/471)
"
1760334933024,"INFO	2025-10-13T05:55:33,024	285509	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334933025,"INFO	2025-10-13T05:55:33,024	285509	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 34, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334933025,"INFO	2025-10-13T05:55:33,024	285509	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 34; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_34_a_spark-application-1760334656744_p_1
"
1760334933025,"INFO	2025-10-13T05:55:33,025	285510	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334933061,"INFO	2025-10-13T05:55:33,061	285546	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334933061,"INFO	2025-10-13T05:55:33,061	285546	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 8cd1bf52-28a9-41ed-a97a-8747a767992c)
"
1760334933061,"INFO	2025-10-13T05:55:33,061	285546	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 34 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334933182,"INFO	2025-10-13T05:55:33,182	285667	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 266.0 in stage 0.0 (TID 266) (172.34.154.255, executor 9, partition 266, PROCESS_LOCAL, 27126 bytes) 
"
1760334933183,"INFO	2025-10-13T05:55:33,182	285667	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 248.0 in stage 0.0 (TID 248) in 14521 ms on 172.34.154.255 (executor 9) (249/471)
"
1760334933247,"INFO	2025-10-13T05:55:33,247	285732	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 267.0 in stage 0.0 (TID 267) (172.35.54.41, executor 8, partition 267, PROCESS_LOCAL, 27118 bytes) 
"
1760334933247,"INFO	2025-10-13T05:55:33,247	285732	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 252.0 in stage 0.0 (TID 252) in 13056 ms on 172.35.54.41 (executor 8) (250/471)
"
1760334933702,"INFO	2025-10-13T05:55:33,702	286187	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 268.0 in stage 0.0 (TID 268) (172.35.235.173, executor 5, partition 268, PROCESS_LOCAL, 27126 bytes) 
"
1760334933702,"INFO	2025-10-13T05:55:33,702	286187	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 249.0 in stage 0.0 (TID 249) in 14519 ms on 172.35.235.173 (executor 5) (251/471)
"
1760334934071,"INFO	2025-10-13T05:55:34,071	286556	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 269.0 in stage 0.0 (TID 269) (172.35.54.41, executor 8, partition 269, PROCESS_LOCAL, 27118 bytes) 
"
1760334934072,"INFO	2025-10-13T05:55:34,071	286556	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 253.0 in stage 0.0 (TID 253) in 13289 ms on 172.35.54.41 (executor 8) (252/471)
"
1760334934177,"INFO	2025-10-13T05:55:34,177	286662	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 270.0 in stage 0.0 (TID 270) (172.34.154.255, executor 9, partition 270, PROCESS_LOCAL, 27126 bytes) 
"
1760334934177,"INFO	2025-10-13T05:55:34,177	286662	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 250.0 in stage 0.0 (TID 250) in 14622 ms on 172.34.154.255 (executor 9) (253/471)
"
1760334934277,"INFO	2025-10-13T05:55:34,277	286762	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 271.0 in stage 0.0 (TID 271) (172.34.183.29, executor 4, partition 271, PROCESS_LOCAL, 27126 bytes) 
"
1760334934278,"INFO	2025-10-13T05:55:34,277	286762	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 251.0 in stage 0.0 (TID 251) in 14466 ms on 172.34.183.29 (executor 4) (254/471)
"
1760334934831,"INFO	2025-10-13T05:55:34,830	287315	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334934831,"INFO	2025-10-13T05:55:34,831	287316	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 35, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334934831,"INFO	2025-10-13T05:55:34,831	287316	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 35; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_35_a_spark-application-1760334656744_p_1
"
1760334934831,"INFO	2025-10-13T05:55:34,831	287316	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334934874,"INFO	2025-10-13T05:55:34,873	287358	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334934874,"INFO	2025-10-13T05:55:34,874	287359	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 828c32bc-b8e8-48dd-94d0-a74193991df7)
"
1760334934874,"INFO	2025-10-13T05:55:34,874	287359	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 35 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334935349,"INFO	2025-10-13T05:55:35,348	287833	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 272.0 in stage 0.0 (TID 272) (172.35.235.173, executor 5, partition 272, PROCESS_LOCAL, 27126 bytes) 
"
1760334935349,"INFO	2025-10-13T05:55:35,349	287834	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 254.0 in stage 0.0 (TID 254) in 14532 ms on 172.35.235.173 (executor 5) (255/471)
"
1760334935579,"INFO	2025-10-13T05:55:35,579	288064	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 273.0 in stage 0.0 (TID 273) (172.34.183.29, executor 4, partition 273, PROCESS_LOCAL, 27126 bytes) 
"
1760334935580,"INFO	2025-10-13T05:55:35,579	288064	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 255.0 in stage 0.0 (TID 255) in 14484 ms on 172.34.183.29 (executor 4) (256/471)
"
1760334936303,"INFO	2025-10-13T05:55:36,302	288787	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 274.0 in stage 0.0 (TID 274) (172.35.25.103, executor 7, partition 274, PROCESS_LOCAL, 27118 bytes) 
"
1760334936303,"INFO	2025-10-13T05:55:36,303	288788	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 256.0 in stage 0.0 (TID 256) in 14084 ms on 172.35.25.103 (executor 7) (257/471)
"
1760334937607,"INFO	2025-10-13T05:55:37,607	290092	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 275.0 in stage 0.0 (TID 275) (172.35.25.103, executor 7, partition 275, PROCESS_LOCAL, 27126 bytes) 
"
1760334937608,"INFO	2025-10-13T05:55:37,608	290093	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 257.0 in stage 0.0 (TID 257) in 14187 ms on 172.35.25.103 (executor 7) (258/471)
"
1760334940241,"INFO	2025-10-13T05:55:40,240	292725	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 276.0 in stage 0.0 (TID 276) (172.35.52.98, executor 6, partition 276, PROCESS_LOCAL, 27126 bytes) 
"
1760334940241,"INFO	2025-10-13T05:55:40,241	292726	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 260.0 in stage 0.0 (TID 260) in 13846 ms on 172.35.52.98 (executor 6) (259/471)
"
1760334941083,"INFO	2025-10-13T05:55:41,083	293568	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 277.0 in stage 0.0 (TID 277) (172.35.102.6, executor 3, partition 277, PROCESS_LOCAL, 27126 bytes) 
"
1760334941084,"INFO	2025-10-13T05:55:41,083	293568	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 258.0 in stage 0.0 (TID 258) in 15197 ms on 172.35.102.6 (executor 3) (260/471)
"
1760334941271,"INFO	2025-10-13T05:55:41,270	293755	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 278.0 in stage 0.0 (TID 278) (172.35.102.6, executor 3, partition 278, PROCESS_LOCAL, 27118 bytes) 
"
1760334941271,"INFO	2025-10-13T05:55:41,271	293756	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 259.0 in stage 0.0 (TID 259) in 14976 ms on 172.35.102.6 (executor 3) (261/471)
"
1760334941970,"INFO	2025-10-13T05:55:41,969	294454	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 279.0 in stage 0.0 (TID 279) (172.35.52.98, executor 6, partition 279, PROCESS_LOCAL, 27118 bytes) 
"
1760334941970,"INFO	2025-10-13T05:55:41,970	294455	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 262.0 in stage 0.0 (TID 262) in 13842 ms on 172.35.52.98 (executor 6) (262/471)
"
1760334942456,"INFO	2025-10-13T05:55:42,455	294940	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 280.0 in stage 0.0 (TID 280) (172.35.115.192, executor 1, partition 280, PROCESS_LOCAL, 27126 bytes) 
"
1760334942456,"INFO	2025-10-13T05:55:42,456	294941	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 261.0 in stage 0.0 (TID 261) in 15248 ms on 172.35.115.192 (executor 1) (263/471)
"
1760334943631,"INFO	2025-10-13T05:55:43,630	296115	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 281.0 in stage 0.0 (TID 281) (172.35.115.192, executor 1, partition 281, PROCESS_LOCAL, 27118 bytes) 
"
1760334943631,"INFO	2025-10-13T05:55:43,631	296116	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 263.0 in stage 0.0 (TID 263) in 15256 ms on 172.35.115.192 (executor 1) (264/471)
"
1760334943890,"INFO	2025-10-13T05:55:43,890	296375	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334943891,"INFO	2025-10-13T05:55:43,890	296375	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 36, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334943891,"INFO	2025-10-13T05:55:43,891	296376	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 36; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_36_a_spark-application-1760334656744_p_1
"
1760334943891,"INFO	2025-10-13T05:55:43,891	296376	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334943921,"INFO	2025-10-13T05:55:43,921	296406	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334943921,"INFO	2025-10-13T05:55:43,921	296406	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: b82064f8-8a8c-4c22-a2f7-faae1868fe13)
"
1760334943921,"INFO	2025-10-13T05:55:43,921	296406	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 36 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334946351,"INFO	2025-10-13T05:55:46,351	298836	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 282.0 in stage 0.0 (TID 282) (172.35.54.41, executor 8, partition 282, PROCESS_LOCAL, 27126 bytes) 
"
1760334946351,"INFO	2025-10-13T05:55:46,351	298836	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 267.0 in stage 0.0 (TID 267) in 13105 ms on 172.35.54.41 (executor 8) (265/471)
"
1760334946691,"INFO	2025-10-13T05:55:46,690	299175	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 283.0 in stage 0.0 (TID 283) (172.35.42.110, executor 2, partition 283, PROCESS_LOCAL, 27126 bytes) 
"
1760334946691,"INFO	2025-10-13T05:55:46,691	299176	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 264.0 in stage 0.0 (TID 264) in 14425 ms on 172.35.42.110 (executor 2) (266/471)
"
1760334947253,"INFO	2025-10-13T05:55:47,252	299737	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 284.0 in stage 0.0 (TID 284) (172.35.54.41, executor 8, partition 284, PROCESS_LOCAL, 27126 bytes) 
"
1760334947253,"INFO	2025-10-13T05:55:47,253	299738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 269.0 in stage 0.0 (TID 269) in 13182 ms on 172.35.54.41 (executor 8) (267/471)
"
1760334947464,"INFO	2025-10-13T05:55:47,464	299949	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 285.0 in stage 0.0 (TID 285) (172.35.42.110, executor 2, partition 285, PROCESS_LOCAL, 27126 bytes) 
"
1760334947465,"INFO	2025-10-13T05:55:47,465	299950	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 265.0 in stage 0.0 (TID 265) in 14550 ms on 172.35.42.110 (executor 2) (268/471)
"
1760334947720,"INFO	2025-10-13T05:55:47,720	300205	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 286.0 in stage 0.0 (TID 286) (172.34.154.255, executor 9, partition 286, PROCESS_LOCAL, 27118 bytes) 
"
1760334947720,"INFO	2025-10-13T05:55:47,720	300205	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 266.0 in stage 0.0 (TID 266) in 14538 ms on 172.34.154.255 (executor 9) (269/471)
"
1760334948306,"INFO	2025-10-13T05:55:48,305	300790	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 287.0 in stage 0.0 (TID 287) (172.35.235.173, executor 5, partition 287, PROCESS_LOCAL, 27118 bytes) 
"
1760334948306,"INFO	2025-10-13T05:55:48,306	300791	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 268.0 in stage 0.0 (TID 268) in 14605 ms on 172.35.235.173 (executor 5) (270/471)
"
1760334948588,"INFO	2025-10-13T05:55:48,588	301073	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 288.0 in stage 0.0 (TID 288) (172.34.183.29, executor 4, partition 288, PROCESS_LOCAL, 27126 bytes) 
"
1760334948589,"INFO	2025-10-13T05:55:48,589	301074	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 271.0 in stage 0.0 (TID 271) in 14312 ms on 172.34.183.29 (executor 4) (271/471)
"
1760334948676,"INFO	2025-10-13T05:55:48,676	301161	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 289.0 in stage 0.0 (TID 289) (172.34.154.255, executor 9, partition 289, PROCESS_LOCAL, 27118 bytes) 
"
1760334948677,"INFO	2025-10-13T05:55:48,677	301162	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 270.0 in stage 0.0 (TID 270) in 14501 ms on 172.34.154.255 (executor 9) (272/471)
"
1760334949070,"INFO	2025-10-13T05:55:49,069	301554	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334949070,"INFO	2025-10-13T05:55:49,070	301555	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 37, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334949070,"INFO	2025-10-13T05:55:49,070	301555	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 37; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_37_a_spark-application-1760334656744_p_1
"
1760334949070,"INFO	2025-10-13T05:55:49,070	301555	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334949099,"INFO	2025-10-13T05:55:49,098	301583	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334949099,"INFO	2025-10-13T05:55:49,099	301584	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: e6d837ae-796c-48be-91c9-ecfbaf3faaae)
"
1760334949099,"INFO	2025-10-13T05:55:49,099	301584	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 37 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334949634,"INFO	2025-10-13T05:55:49,633	302118	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 290.0 in stage 0.0 (TID 290) (172.35.235.173, executor 5, partition 290, PROCESS_LOCAL, 27118 bytes) 
"
1760334949634,"INFO	2025-10-13T05:55:49,634	302119	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 272.0 in stage 0.0 (TID 272) in 14286 ms on 172.35.235.173 (executor 5) (273/471)
"
1760334949836,"INFO	2025-10-13T05:55:49,836	302321	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 291.0 in stage 0.0 (TID 291) (172.34.183.29, executor 4, partition 291, PROCESS_LOCAL, 27118 bytes) 
"
1760334949837,"INFO	2025-10-13T05:55:49,836	302321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 273.0 in stage 0.0 (TID 273) in 14257 ms on 172.34.183.29 (executor 4) (274/471)
"
1760334950337,"INFO	2025-10-13T05:55:50,337	302822	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 292.0 in stage 0.0 (TID 292) (172.35.25.103, executor 7, partition 292, PROCESS_LOCAL, 27126 bytes) 
"
1760334950337,"INFO	2025-10-13T05:55:50,337	302822	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 274.0 in stage 0.0 (TID 274) in 14035 ms on 172.35.25.103 (executor 7) (275/471)
"
1760334951849,"INFO	2025-10-13T05:55:51,849	304334	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 293.0 in stage 0.0 (TID 293) (172.35.25.103, executor 7, partition 293, PROCESS_LOCAL, 27118 bytes) 
"
1760334951849,"INFO	2025-10-13T05:55:51,849	304334	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 275.0 in stage 0.0 (TID 275) in 14242 ms on 172.35.25.103 (executor 7) (276/471)
"
1760334953714,"INFO	2025-10-13T05:55:53,714	306199	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 294.0 in stage 0.0 (TID 294) (172.35.52.98, executor 6, partition 294, PROCESS_LOCAL, 27126 bytes) 
"
1760334953715,"INFO	2025-10-13T05:55:53,714	306199	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 276.0 in stage 0.0 (TID 276) in 13474 ms on 172.35.52.98 (executor 6) (277/471)
"
1760334955530,"INFO	2025-10-13T05:55:55,530	308015	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 295.0 in stage 0.0 (TID 295) (172.35.52.98, executor 6, partition 295, PROCESS_LOCAL, 27126 bytes) 
"
1760334955555,"INFO	2025-10-13T05:55:55,530	308015	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 279.0 in stage 0.0 (TID 279) in 13561 ms on 172.35.52.98 (executor 6) (278/471)
"
1760334956436,"INFO	2025-10-13T05:55:56,435	308920	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 296.0 in stage 0.0 (TID 296) (172.35.102.6, executor 3, partition 296, PROCESS_LOCAL, 27126 bytes) 
"
1760334956436,"INFO	2025-10-13T05:55:56,436	308921	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 277.0 in stage 0.0 (TID 277) in 15354 ms on 172.35.102.6 (executor 3) (279/471)
"
1760334956739,"INFO	2025-10-13T05:55:56,739	309224	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 297.0 in stage 0.0 (TID 297) (172.35.102.6, executor 3, partition 297, PROCESS_LOCAL, 27126 bytes) 
"
1760334956740,"INFO	2025-10-13T05:55:56,739	309224	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 278.0 in stage 0.0 (TID 278) in 15469 ms on 172.35.102.6 (executor 3) (280/471)
"
1760334956853,"INFO	2025-10-13T05:55:56,853	309338	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334956853,"INFO	2025-10-13T05:55:56,853	309338	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760334957918,"INFO	2025-10-13T05:55:57,917	310402	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 298.0 in stage 0.0 (TID 298) (172.35.115.192, executor 1, partition 298, PROCESS_LOCAL, 27118 bytes) 
"
1760334957918,"INFO	2025-10-13T05:55:57,918	310403	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 280.0 in stage 0.0 (TID 280) in 15463 ms on 172.35.115.192 (executor 1) (281/471)
"
1760334958895,"INFO	2025-10-13T05:55:58,895	311380	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334958895,"INFO	2025-10-13T05:55:58,895	311380	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 38, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334958896,"INFO	2025-10-13T05:55:58,895	311380	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 38; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_38_a_spark-application-1760334656744_p_1
"
1760334958896,"INFO	2025-10-13T05:55:58,896	311381	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334958933,"INFO	2025-10-13T05:55:58,933	311418	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334958934,"INFO	2025-10-13T05:55:58,933	311418	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 41a96220-6505-49e4-88ac-8eb114fd6e3f)
"
1760334958934,"INFO	2025-10-13T05:55:58,933	311418	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 38 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334959091,"INFO	2025-10-13T05:55:59,091	311576	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 299.0 in stage 0.0 (TID 299) (172.35.115.192, executor 1, partition 299, PROCESS_LOCAL, 27118 bytes) 
"
1760334959091,"INFO	2025-10-13T05:55:59,091	311576	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 281.0 in stage 0.0 (TID 281) in 15461 ms on 172.35.115.192 (executor 1) (282/471)
"
1760334959528,"INFO	2025-10-13T05:55:59,528	312013	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 300.0 in stage 0.0 (TID 300) (172.35.54.41, executor 8, partition 300, PROCESS_LOCAL, 27126 bytes) 
"
1760334959528,"INFO	2025-10-13T05:55:59,528	312013	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 282.0 in stage 0.0 (TID 282) in 13178 ms on 172.35.54.41 (executor 8) (283/471)
"
1760334960455,"INFO	2025-10-13T05:56:00,455	312940	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 301.0 in stage 0.0 (TID 301) (172.35.54.41, executor 8, partition 301, PROCESS_LOCAL, 27126 bytes) 
"
1760334960455,"INFO	2025-10-13T05:56:00,455	312940	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 284.0 in stage 0.0 (TID 284) in 13203 ms on 172.35.54.41 (executor 8) (284/471)
"
1760334960944,"INFO	2025-10-13T05:56:00,943	313428	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 302.0 in stage 0.0 (TID 302) (172.35.42.110, executor 2, partition 302, PROCESS_LOCAL, 27126 bytes) 
"
1760334960944,"INFO	2025-10-13T05:56:00,944	313429	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 283.0 in stage 0.0 (TID 283) in 14254 ms on 172.35.42.110 (executor 2) (285/471)
"
1760334961726,"INFO	2025-10-13T05:56:01,726	314211	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 303.0 in stage 0.0 (TID 303) (172.35.42.110, executor 2, partition 303, PROCESS_LOCAL, 27126 bytes) 
"
1760334961727,"INFO	2025-10-13T05:56:01,726	314211	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 285.0 in stage 0.0 (TID 285) in 14262 ms on 172.35.42.110 (executor 2) (286/471)
"
1760334962254,"INFO	2025-10-13T05:56:02,253	314738	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 304.0 in stage 0.0 (TID 304) (172.34.154.255, executor 9, partition 304, PROCESS_LOCAL, 27126 bytes) 
"
1760334962254,"INFO	2025-10-13T05:56:02,254	314739	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 286.0 in stage 0.0 (TID 286) in 14535 ms on 172.34.154.255 (executor 9) (287/471)
"
1760334962943,"INFO	2025-10-13T05:56:02,942	315427	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 305.0 in stage 0.0 (TID 305) (172.34.183.29, executor 4, partition 305, PROCESS_LOCAL, 27126 bytes) 
"
1760334962943,"INFO	2025-10-13T05:56:02,943	315428	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 288.0 in stage 0.0 (TID 288) in 14355 ms on 172.34.183.29 (executor 4) (288/471)
"
1760334963034,"INFO	2025-10-13T05:56:03,034	315519	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 306.0 in stage 0.0 (TID 306) (172.35.235.173, executor 5, partition 306, PROCESS_LOCAL, 27126 bytes) 
"
1760334963034,"INFO	2025-10-13T05:56:03,034	315519	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 287.0 in stage 0.0 (TID 287) in 14729 ms on 172.35.235.173 (executor 5) (289/471)
"
1760334963480,"INFO	2025-10-13T05:56:03,480	315965	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 307.0 in stage 0.0 (TID 307) (172.34.154.255, executor 9, partition 307, PROCESS_LOCAL, 27118 bytes) 
"
1760334963481,"INFO	2025-10-13T05:56:03,480	315965	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 289.0 in stage 0.0 (TID 289) in 14804 ms on 172.34.154.255 (executor 9) (290/471)
"
1760334964085,"INFO	2025-10-13T05:56:04,085	316570	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 308.0 in stage 0.0 (TID 308) (172.35.235.173, executor 5, partition 308, PROCESS_LOCAL, 27126 bytes) 
"
1760334964086,"INFO	2025-10-13T05:56:04,086	316571	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 290.0 in stage 0.0 (TID 290) in 14453 ms on 172.35.235.173 (executor 5) (291/471)
"
1760334964214,"INFO	2025-10-13T05:56:04,214	316699	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 309.0 in stage 0.0 (TID 309) (172.35.25.103, executor 7, partition 309, PROCESS_LOCAL, 27126 bytes) 
"
1760334964215,"INFO	2025-10-13T05:56:04,214	316699	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 292.0 in stage 0.0 (TID 292) in 13878 ms on 172.35.25.103 (executor 7) (292/471)
"
1760334964427,"INFO	2025-10-13T05:56:04,427	316912	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 310.0 in stage 0.0 (TID 310) (172.34.183.29, executor 4, partition 310, PROCESS_LOCAL, 27118 bytes) 
"
1760334964427,"INFO	2025-10-13T05:56:04,427	316912	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 291.0 in stage 0.0 (TID 291) in 14592 ms on 172.34.183.29 (executor 4) (293/471)
"
1760334965818,"INFO	2025-10-13T05:56:05,818	318303	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 311.0 in stage 0.0 (TID 311) (172.35.25.103, executor 7, partition 311, PROCESS_LOCAL, 27126 bytes) 
"
1760334965818,"INFO	2025-10-13T05:56:05,818	318303	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 293.0 in stage 0.0 (TID 293) in 13970 ms on 172.35.25.103 (executor 7) (294/471)
"
1760334966745,"INFO	2025-10-13T05:56:06,745	319230	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334966745,"INFO	2025-10-13T05:56:06,745	319230	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 39, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334966745,"INFO	2025-10-13T05:56:06,745	319230	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 39; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_39_a_spark-application-1760334656744_p_1
"
1760334966746,"INFO	2025-10-13T05:56:06,746	319231	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334966782,"INFO	2025-10-13T05:56:06,782	319267	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334966782,"INFO	2025-10-13T05:56:06,782	319267	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: e54f3ee3-19d8-46d5-b2dc-385f2f138088)
"
1760334966783,"INFO	2025-10-13T05:56:06,782	319267	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 39 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334967329,"INFO	2025-10-13T05:56:07,329	319814	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 312.0 in stage 0.0 (TID 312) (172.35.52.98, executor 6, partition 312, PROCESS_LOCAL, 27126 bytes) 
"
1760334967329,"INFO	2025-10-13T05:56:07,329	319814	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 294.0 in stage 0.0 (TID 294) in 13615 ms on 172.35.52.98 (executor 6) (295/471)
"
1760334969407,"INFO	2025-10-13T05:56:09,406	321891	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 313.0 in stage 0.0 (TID 313) (172.35.52.98, executor 6, partition 313, PROCESS_LOCAL, 27118 bytes) 
"
1760334969407,"INFO	2025-10-13T05:56:09,407	321892	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 295.0 in stage 0.0 (TID 295) in 13878 ms on 172.35.52.98 (executor 6) (296/471)
"
1760334972006,"INFO	2025-10-13T05:56:12,006	324491	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 314.0 in stage 0.0 (TID 314) (172.35.102.6, executor 3, partition 314, PROCESS_LOCAL, 27126 bytes) 
"
1760334972006,"INFO	2025-10-13T05:56:12,006	324491	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 296.0 in stage 0.0 (TID 296) in 15571 ms on 172.35.102.6 (executor 3) (297/471)
"
1760334972205,"INFO	2025-10-13T05:56:12,205	324690	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334972205,"INFO	2025-10-13T05:56:12,205	324690	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 40, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334972205,"INFO	2025-10-13T05:56:12,205	324690	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 40; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_40_a_spark-application-1760334656744_p_1
"
1760334972205,"INFO	2025-10-13T05:56:12,205	324690	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334972244,"INFO	2025-10-13T05:56:12,244	324729	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334972244,"INFO	2025-10-13T05:56:12,244	324729	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: d8150ead-7205-4e1c-a1d6-e4e9b92acc48)
"
1760334972244,"INFO	2025-10-13T05:56:12,244	324729	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 40 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334972324,"INFO	2025-10-13T05:56:12,324	324809	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 315.0 in stage 0.0 (TID 315) (172.35.102.6, executor 3, partition 315, PROCESS_LOCAL, 27126 bytes) 
"
1760334972325,"INFO	2025-10-13T05:56:12,324	324809	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 297.0 in stage 0.0 (TID 297) in 15585 ms on 172.35.102.6 (executor 3) (298/471)
"
1760334972584,"INFO	2025-10-13T05:56:12,583	325068	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 316.0 in stage 0.0 (TID 316) (172.35.54.41, executor 8, partition 316, PROCESS_LOCAL, 27126 bytes) 
"
1760334972584,"INFO	2025-10-13T05:56:12,584	325069	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 300.0 in stage 0.0 (TID 300) in 13056 ms on 172.35.54.41 (executor 8) (299/471)
"
1760334973443,"INFO	2025-10-13T05:56:13,442	325927	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 317.0 in stage 0.0 (TID 317) (172.35.54.41, executor 8, partition 317, PROCESS_LOCAL, 27118 bytes) 
"
1760334973443,"INFO	2025-10-13T05:56:13,443	325928	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 301.0 in stage 0.0 (TID 301) in 12989 ms on 172.35.54.41 (executor 8) (300/471)
"
1760334973826,"INFO	2025-10-13T05:56:13,826	326311	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 318.0 in stage 0.0 (TID 318) (172.35.115.192, executor 1, partition 318, PROCESS_LOCAL, 27118 bytes) 
"
1760334973827,"INFO	2025-10-13T05:56:13,827	326312	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 298.0 in stage 0.0 (TID 298) in 15910 ms on 172.35.115.192 (executor 1) (301/471)
"
1760334975136,"INFO	2025-10-13T05:56:15,135	327620	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 319.0 in stage 0.0 (TID 319) (172.35.115.192, executor 1, partition 319, PROCESS_LOCAL, 27126 bytes) 
"
1760334975136,"INFO	2025-10-13T05:56:15,136	327621	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 299.0 in stage 0.0 (TID 299) in 16046 ms on 172.35.115.192 (executor 1) (302/471)
"
1760334975210,"INFO	2025-10-13T05:56:15,210	327695	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 320.0 in stage 0.0 (TID 320) (172.35.42.110, executor 2, partition 320, PROCESS_LOCAL, 27118 bytes) 
"
1760334975210,"INFO	2025-10-13T05:56:15,210	327695	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 302.0 in stage 0.0 (TID 302) in 14267 ms on 172.35.42.110 (executor 2) (303/471)
"
1760334976035,"INFO	2025-10-13T05:56:16,035	328520	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 321.0 in stage 0.0 (TID 321) (172.35.42.110, executor 2, partition 321, PROCESS_LOCAL, 27118 bytes) 
"
1760334976035,"INFO	2025-10-13T05:56:16,035	328520	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 303.0 in stage 0.0 (TID 303) in 14309 ms on 172.35.42.110 (executor 2) (304/471)
"
1760334976694,"INFO	2025-10-13T05:56:16,693	329178	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 322.0 in stage 0.0 (TID 322) (172.34.154.255, executor 9, partition 322, PROCESS_LOCAL, 27126 bytes) 
"
1760334976694,"INFO	2025-10-13T05:56:16,694	329179	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 304.0 in stage 0.0 (TID 304) in 14441 ms on 172.34.154.255 (executor 9) (305/471)
"
1760334976894,"INFO	2025-10-13T05:56:16,894	329379	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334976895,"INFO	2025-10-13T05:56:16,895	329380	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 41, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334976895,"INFO	2025-10-13T05:56:16,895	329380	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 41; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_41_a_spark-application-1760334656744_p_1
"
1760334976895,"INFO	2025-10-13T05:56:16,895	329380	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334976924,"INFO	2025-10-13T05:56:16,923	329408	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334976924,"INFO	2025-10-13T05:56:16,923	329408	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 986a7138-9ec2-4aab-8655-5c46d49d2fed)
"
1760334976924,"INFO	2025-10-13T05:56:16,924	329409	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 41 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334977229,"INFO	2025-10-13T05:56:17,228	329713	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 323.0 in stage 0.0 (TID 323) (172.34.183.29, executor 4, partition 323, PROCESS_LOCAL, 27118 bytes) 
"
1760334977229,"INFO	2025-10-13T05:56:17,229	329714	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 305.0 in stage 0.0 (TID 305) in 14287 ms on 172.34.183.29 (executor 4) (306/471)
"
1760334977495,"INFO	2025-10-13T05:56:17,494	329979	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 324.0 in stage 0.0 (TID 324) (172.35.235.173, executor 5, partition 324, PROCESS_LOCAL, 27126 bytes) 
"
1760334977495,"INFO	2025-10-13T05:56:17,495	329980	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 306.0 in stage 0.0 (TID 306) in 14461 ms on 172.35.235.173 (executor 5) (307/471)
"
1760334978015,"INFO	2025-10-13T05:56:18,014	330499	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 325.0 in stage 0.0 (TID 325) (172.35.25.103, executor 7, partition 325, PROCESS_LOCAL, 27118 bytes) 
"
1760334978015,"INFO	2025-10-13T05:56:18,015	330500	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 309.0 in stage 0.0 (TID 309) in 13801 ms on 172.35.25.103 (executor 7) (308/471)
"
1760334978219,"INFO	2025-10-13T05:56:18,218	330703	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 326.0 in stage 0.0 (TID 326) (172.34.154.255, executor 9, partition 326, PROCESS_LOCAL, 27118 bytes) 
"
1760334978219,"INFO	2025-10-13T05:56:18,219	330704	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 307.0 in stage 0.0 (TID 307) in 14739 ms on 172.34.154.255 (executor 9) (309/471)
"
1760334979001,"INFO	2025-10-13T05:56:19,001	331486	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 327.0 in stage 0.0 (TID 327) (172.34.183.29, executor 4, partition 327, PROCESS_LOCAL, 27126 bytes) 
"
1760334979002,"INFO	2025-10-13T05:56:19,001	331486	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 310.0 in stage 0.0 (TID 310) in 14575 ms on 172.34.183.29 (executor 4) (310/471)
"
1760334979007,"INFO	2025-10-13T05:56:19,007	331492	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 328.0 in stage 0.0 (TID 328) (172.35.235.173, executor 5, partition 328, PROCESS_LOCAL, 27118 bytes) 
"
1760334979007,"INFO	2025-10-13T05:56:19,007	331492	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 308.0 in stage 0.0 (TID 308) in 14922 ms on 172.35.235.173 (executor 5) (311/471)
"
1760334979746,"INFO	2025-10-13T05:56:19,746	332231	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 329.0 in stage 0.0 (TID 329) (172.35.25.103, executor 7, partition 329, PROCESS_LOCAL, 27126 bytes) 
"
1760334979746,"INFO	2025-10-13T05:56:19,746	332231	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 311.0 in stage 0.0 (TID 311) in 13929 ms on 172.35.25.103 (executor 7) (312/471)
"
1760334980941,"INFO	2025-10-13T05:56:20,940	333425	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 330.0 in stage 0.0 (TID 330) (172.35.52.98, executor 6, partition 330, PROCESS_LOCAL, 27126 bytes) 
"
1760334980941,"INFO	2025-10-13T05:56:20,941	333426	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 312.0 in stage 0.0 (TID 312) in 13613 ms on 172.35.52.98 (executor 6) (313/471)
"
1760334983403,"INFO	2025-10-13T05:56:23,402	335887	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 331.0 in stage 0.0 (TID 331) (172.35.52.98, executor 6, partition 331, PROCESS_LOCAL, 27118 bytes) 
"
1760334983403,"INFO	2025-10-13T05:56:23,403	335888	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 313.0 in stage 0.0 (TID 313) in 13997 ms on 172.35.52.98 (executor 6) (314/471)
"
1760334985617,"INFO	2025-10-13T05:56:25,617	338102	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 332.0 in stage 0.0 (TID 332) (172.35.54.41, executor 8, partition 332, PROCESS_LOCAL, 27126 bytes) 
"
1760334985618,"INFO	2025-10-13T05:56:25,617	338102	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 316.0 in stage 0.0 (TID 316) in 13034 ms on 172.35.54.41 (executor 8) (315/471)
"
1760334985869,"INFO	2025-10-13T05:56:25,869	338354	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334985869,"INFO	2025-10-13T05:56:25,869	338354	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 42, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334985869,"INFO	2025-10-13T05:56:25,869	338354	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 42; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_42_a_spark-application-1760334656744_p_1
"
1760334985870,"INFO	2025-10-13T05:56:25,869	338354	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334985908,"INFO	2025-10-13T05:56:25,908	338393	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334985908,"INFO	2025-10-13T05:56:25,908	338393	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 77acb2db-26c0-4860-b8d6-6cb5186e0765)
"
1760334985908,"INFO	2025-10-13T05:56:25,908	338393	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 42 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334986460,"INFO	2025-10-13T05:56:26,459	338944	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 333.0 in stage 0.0 (TID 333) (172.35.54.41, executor 8, partition 333, PROCESS_LOCAL, 27118 bytes) 
"
1760334986460,"INFO	2025-10-13T05:56:26,459	338944	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 317.0 in stage 0.0 (TID 317) in 13017 ms on 172.35.54.41 (executor 8) (316/471)
"
1760334987726,"INFO	2025-10-13T05:56:27,726	340211	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 334.0 in stage 0.0 (TID 334) (172.35.102.6, executor 3, partition 334, PROCESS_LOCAL, 27118 bytes) 
"
1760334987727,"INFO	2025-10-13T05:56:27,726	340211	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 314.0 in stage 0.0 (TID 314) in 15721 ms on 172.35.102.6 (executor 3) (317/471)
"
1760334988265,"INFO	2025-10-13T05:56:28,265	340750	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 335.0 in stage 0.0 (TID 335) (172.35.102.6, executor 3, partition 335, PROCESS_LOCAL, 27126 bytes) 
"
1760334988266,"INFO	2025-10-13T05:56:28,265	340750	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 315.0 in stage 0.0 (TID 315) in 15941 ms on 172.35.102.6 (executor 3) (318/471)
"
1760334989473,"INFO	2025-10-13T05:56:29,473	341958	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 336.0 in stage 0.0 (TID 336) (172.35.115.192, executor 1, partition 336, PROCESS_LOCAL, 27117 bytes) 
"
1760334989474,"INFO	2025-10-13T05:56:29,473	341958	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 318.0 in stage 0.0 (TID 318) in 15647 ms on 172.35.115.192 (executor 1) (319/471)
"
1760334989674,"INFO	2025-10-13T05:56:29,674	342159	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 337.0 in stage 0.0 (TID 337) (172.35.42.110, executor 2, partition 337, PROCESS_LOCAL, 27126 bytes) 
"
1760334989675,"INFO	2025-10-13T05:56:29,674	342159	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 320.0 in stage 0.0 (TID 320) in 14465 ms on 172.35.42.110 (executor 2) (320/471)
"
1760334990629,"INFO	2025-10-13T05:56:30,628	343113	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 338.0 in stage 0.0 (TID 338) (172.35.42.110, executor 2, partition 338, PROCESS_LOCAL, 27126 bytes) 
"
1760334990629,"INFO	2025-10-13T05:56:30,629	343114	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 321.0 in stage 0.0 (TID 321) in 14595 ms on 172.35.42.110 (executor 2) (321/471)
"
1760334990848,"INFO	2025-10-13T05:56:30,847	343332	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 339.0 in stage 0.0 (TID 339) (172.35.115.192, executor 1, partition 339, PROCESS_LOCAL, 27126 bytes) 
"
1760334990848,"INFO	2025-10-13T05:56:30,848	343333	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 319.0 in stage 0.0 (TID 319) in 15713 ms on 172.35.115.192 (executor 1) (322/471)
"
1760334991388,"INFO	2025-10-13T05:56:31,387	343872	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 340.0 in stage 0.0 (TID 340) (172.34.154.255, executor 9, partition 340, PROCESS_LOCAL, 27126 bytes) 
"
1760334991388,"INFO	2025-10-13T05:56:31,388	343873	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 322.0 in stage 0.0 (TID 322) in 14695 ms on 172.34.154.255 (executor 9) (323/471)
"
1760334991802,"INFO	2025-10-13T05:56:31,801	344286	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 341.0 in stage 0.0 (TID 341) (172.34.183.29, executor 4, partition 341, PROCESS_LOCAL, 27126 bytes) 
"
1760334991802,"INFO	2025-10-13T05:56:31,802	344287	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 323.0 in stage 0.0 (TID 323) in 14574 ms on 172.34.183.29 (executor 4) (324/471)
"
1760334991876,"INFO	2025-10-13T05:56:31,875	344360	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 342.0 in stage 0.0 (TID 342) (172.35.25.103, executor 7, partition 342, PROCESS_LOCAL, 27126 bytes) 
"
1760334991876,"INFO	2025-10-13T05:56:31,876	344361	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 325.0 in stage 0.0 (TID 325) in 13862 ms on 172.35.25.103 (executor 7) (325/471)
"
1760334991968,"INFO	2025-10-13T05:56:31,968	344453	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 343.0 in stage 0.0 (TID 343) (172.35.235.173, executor 5, partition 343, PROCESS_LOCAL, 27118 bytes) 
"
1760334991969,"INFO	2025-10-13T05:56:31,969	344454	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 324.0 in stage 0.0 (TID 324) in 14475 ms on 172.35.235.173 (executor 5) (326/471)
"
1760334992776,"INFO	2025-10-13T05:56:32,775	345260	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 344.0 in stage 0.0 (TID 344) (172.34.154.255, executor 9, partition 344, PROCESS_LOCAL, 27118 bytes) 
"
1760334992776,"INFO	2025-10-13T05:56:32,776	345261	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 326.0 in stage 0.0 (TID 326) in 14558 ms on 172.34.154.255 (executor 9) (327/471)
"
1760334993682,"INFO	2025-10-13T05:56:33,681	346166	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 345.0 in stage 0.0 (TID 345) (172.34.183.29, executor 4, partition 345, PROCESS_LOCAL, 27118 bytes) 
"
1760334993682,"INFO	2025-10-13T05:56:33,682	346167	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 327.0 in stage 0.0 (TID 327) in 14681 ms on 172.34.183.29 (executor 4) (328/471)
"
1760334993892,"INFO	2025-10-13T05:56:33,892	346377	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 346.0 in stage 0.0 (TID 346) (172.35.25.103, executor 7, partition 346, PROCESS_LOCAL, 27118 bytes) 
"
1760334993893,"INFO	2025-10-13T05:56:33,892	346377	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 329.0 in stage 0.0 (TID 329) in 14147 ms on 172.35.25.103 (executor 7) (329/471)
"
1760334994097,"INFO	2025-10-13T05:56:34,096	346581	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 347.0 in stage 0.0 (TID 347) (172.35.235.173, executor 5, partition 347, PROCESS_LOCAL, 27118 bytes) 
"
1760334994097,"INFO	2025-10-13T05:56:34,097	346582	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 328.0 in stage 0.0 (TID 328) in 15090 ms on 172.35.235.173 (executor 5) (330/471)
"
1760334994431,"INFO	2025-10-13T05:56:34,431	346916	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334994431,"INFO	2025-10-13T05:56:34,431	346916	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 43, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334994432,"INFO	2025-10-13T05:56:34,431	346916	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 43; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_43_a_spark-application-1760334656744_p_1
"
1760334994432,"INFO	2025-10-13T05:56:34,432	346917	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334994470,"INFO	2025-10-13T05:56:34,470	346955	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334994471,"INFO	2025-10-13T05:56:34,470	346955	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 1742c421-9c9b-4fba-9a23-932d43bac20c)
"
1760334994471,"INFO	2025-10-13T05:56:34,470	346955	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 43 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334994760,"INFO	2025-10-13T05:56:34,760	347245	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 348.0 in stage 0.0 (TID 348) (172.35.52.98, executor 6, partition 348, PROCESS_LOCAL, 27118 bytes) 
"
1760334994760,"INFO	2025-10-13T05:56:34,760	347245	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 330.0 in stage 0.0 (TID 330) in 13820 ms on 172.35.52.98 (executor 6) (331/471)
"
1760334997547,"INFO	2025-10-13T05:56:37,547	350032	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 349.0 in stage 0.0 (TID 349) (172.35.52.98, executor 6, partition 349, PROCESS_LOCAL, 27118 bytes) 
"
1760334997548,"INFO	2025-10-13T05:56:37,547	350032	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 331.0 in stage 0.0 (TID 331) in 14145 ms on 172.35.52.98 (executor 6) (332/471)
"
1760334998788,"INFO	2025-10-13T05:56:38,787	351272	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 350.0 in stage 0.0 (TID 350) (172.35.54.41, executor 8, partition 350, PROCESS_LOCAL, 27118 bytes) 
"
1760334998788,"INFO	2025-10-13T05:56:38,788	351273	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 332.0 in stage 0.0 (TID 332) in 13172 ms on 172.35.54.41 (executor 8) (333/471)
"
1760334999584,"INFO	2025-10-13T05:56:39,584	352069	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760334999584,"INFO	2025-10-13T05:56:39,584	352069	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 44, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760334999584,"INFO	2025-10-13T05:56:39,584	352069	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 44; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_44_a_spark-application-1760334656744_p_1
"
1760334999584,"INFO	2025-10-13T05:56:39,584	352069	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334999621,"INFO	2025-10-13T05:56:39,621	352106	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334999621,"INFO	2025-10-13T05:56:39,621	352106	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 0c587e1c-b856-4f4b-af72-857f370b927e)
"
1760334999621,"INFO	2025-10-13T05:56:39,621	352106	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 44 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334999671,"INFO	2025-10-13T05:56:39,671	352156	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 351.0 in stage 0.0 (TID 351) (172.35.54.41, executor 8, partition 351, PROCESS_LOCAL, 27118 bytes) 
"
1760334999672,"INFO	2025-10-13T05:56:39,671	352156	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 333.0 in stage 0.0 (TID 333) in 13212 ms on 172.35.54.41 (executor 8) (334/471)
"
1760335003489,"INFO	2025-10-13T05:56:43,489	355974	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 352.0 in stage 0.0 (TID 352) (172.35.102.6, executor 3, partition 352, PROCESS_LOCAL, 27118 bytes) 
"
1760335003490,"INFO	2025-10-13T05:56:43,489	355974	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 334.0 in stage 0.0 (TID 334) in 15764 ms on 172.35.102.6 (executor 3) (335/471)
"
1760335003919,"INFO	2025-10-13T05:56:43,918	356403	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 353.0 in stage 0.0 (TID 353) (172.35.102.6, executor 3, partition 353, PROCESS_LOCAL, 27118 bytes) 
"
1760335003919,"INFO	2025-10-13T05:56:43,919	356404	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 335.0 in stage 0.0 (TID 335) in 15655 ms on 172.35.102.6 (executor 3) (336/471)
"
1760335004119,"INFO	2025-10-13T05:56:44,119	356604	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 354.0 in stage 0.0 (TID 354) (172.35.42.110, executor 2, partition 354, PROCESS_LOCAL, 27118 bytes) 
"
1760335004119,"INFO	2025-10-13T05:56:44,119	356604	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 337.0 in stage 0.0 (TID 337) in 14445 ms on 172.35.42.110 (executor 2) (337/471)
"
1760335004892,"INFO	2025-10-13T05:56:44,892	357377	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 355.0 in stage 0.0 (TID 355) (172.35.115.192, executor 1, partition 355, PROCESS_LOCAL, 27118 bytes) 
"
1760335004893,"INFO	2025-10-13T05:56:44,892	357377	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 336.0 in stage 0.0 (TID 336) in 15420 ms on 172.35.115.192 (executor 1) (338/471)
"
1760335005474,"INFO	2025-10-13T05:56:45,473	357958	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 356.0 in stage 0.0 (TID 356) (172.35.42.110, executor 2, partition 356, PROCESS_LOCAL, 27118 bytes) 
"
1760335005474,"INFO	2025-10-13T05:56:45,474	357959	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 338.0 in stage 0.0 (TID 338) in 14846 ms on 172.35.42.110 (executor 2) (339/471)
"
1760335005908,"INFO	2025-10-13T05:56:45,907	358392	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 357.0 in stage 0.0 (TID 357) (172.35.25.103, executor 7, partition 357, PROCESS_LOCAL, 27118 bytes) 
"
1760335005908,"INFO	2025-10-13T05:56:45,908	358393	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 342.0 in stage 0.0 (TID 342) in 14033 ms on 172.35.25.103 (executor 7) (340/471)
"
1760335006063,"INFO	2025-10-13T05:56:46,062	358547	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 358.0 in stage 0.0 (TID 358) (172.34.154.255, executor 9, partition 358, PROCESS_LOCAL, 27118 bytes) 
"
1760335006063,"INFO	2025-10-13T05:56:46,063	358548	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 340.0 in stage 0.0 (TID 340) in 14676 ms on 172.34.154.255 (executor 9) (341/471)
"
1760335006196,"INFO	2025-10-13T05:56:46,196	358681	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 359.0 in stage 0.0 (TID 359) (172.34.183.29, executor 4, partition 359, PROCESS_LOCAL, 27118 bytes) 
"
1760335006197,"INFO	2025-10-13T05:56:46,196	358681	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 341.0 in stage 0.0 (TID 341) in 14395 ms on 172.34.183.29 (executor 4) (342/471)
"
1760335006209,"INFO	2025-10-13T05:56:46,208	358693	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 360.0 in stage 0.0 (TID 360) (172.35.115.192, executor 1, partition 360, PROCESS_LOCAL, 27118 bytes) 
"
1760335006209,"INFO	2025-10-13T05:56:46,209	358694	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 339.0 in stage 0.0 (TID 339) in 15362 ms on 172.35.115.192 (executor 1) (343/471)
"
1760335006618,"INFO	2025-10-13T05:56:46,617	359102	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 361.0 in stage 0.0 (TID 361) (172.35.235.173, executor 5, partition 361, PROCESS_LOCAL, 27126 bytes) 
"
1760335006618,"INFO	2025-10-13T05:56:46,618	359103	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 343.0 in stage 0.0 (TID 343) in 14650 ms on 172.35.235.173 (executor 5) (344/471)
"
1760335007785,"INFO	2025-10-13T05:56:47,785	360270	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 362.0 in stage 0.0 (TID 362) (172.34.154.255, executor 9, partition 362, PROCESS_LOCAL, 27118 bytes) 
"
1760335007786,"INFO	2025-10-13T05:56:47,786	360271	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 344.0 in stage 0.0 (TID 344) in 15010 ms on 172.34.154.255 (executor 9) (345/471)
"
1760335007976,"INFO	2025-10-13T05:56:47,976	360461	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 363.0 in stage 0.0 (TID 363) (172.35.25.103, executor 7, partition 363, PROCESS_LOCAL, 27118 bytes) 
"
1760335007976,"INFO	2025-10-13T05:56:47,976	360461	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 346.0 in stage 0.0 (TID 346) in 14084 ms on 172.35.25.103 (executor 7) (346/471)
"
1760335008242,"INFO	2025-10-13T05:56:48,242	360727	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 364.0 in stage 0.0 (TID 364) (172.34.183.29, executor 4, partition 364, PROCESS_LOCAL, 27118 bytes) 
"
1760335008243,"INFO	2025-10-13T05:56:48,243	360728	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 345.0 in stage 0.0 (TID 345) in 14561 ms on 172.34.183.29 (executor 4) (347/471)
"
1760335008864,"INFO	2025-10-13T05:56:48,863	361348	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 365.0 in stage 0.0 (TID 365) (172.35.52.98, executor 6, partition 365, PROCESS_LOCAL, 27126 bytes) 
"
1760335008864,"INFO	2025-10-13T05:56:48,864	361349	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 348.0 in stage 0.0 (TID 348) in 14104 ms on 172.35.52.98 (executor 6) (348/471)
"
1760335009098,"INFO	2025-10-13T05:56:49,098	361583	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 366.0 in stage 0.0 (TID 366) (172.35.235.173, executor 5, partition 366, PROCESS_LOCAL, 27126 bytes) 
"
1760335009098,"INFO	2025-10-13T05:56:49,098	361583	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 347.0 in stage 0.0 (TID 347) in 15002 ms on 172.35.235.173 (executor 5) (349/471)
"
1760335011695,"INFO	2025-10-13T05:56:51,695	364180	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 367.0 in stage 0.0 (TID 367) (172.35.52.98, executor 6, partition 367, PROCESS_LOCAL, 27126 bytes) 
"
1760335011696,"INFO	2025-10-13T05:56:51,695	364180	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 349.0 in stage 0.0 (TID 349) in 14149 ms on 172.35.52.98 (executor 6) (350/471)
"
1760335012102,"INFO	2025-10-13T05:56:52,101	364586	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 368.0 in stage 0.0 (TID 368) (172.35.54.41, executor 8, partition 368, PROCESS_LOCAL, 27126 bytes) 
"
1760335012102,"INFO	2025-10-13T05:56:52,102	364587	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 350.0 in stage 0.0 (TID 350) in 13315 ms on 172.35.54.41 (executor 8) (351/471)
"
1760335013032,"INFO	2025-10-13T05:56:53,031	365516	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 369.0 in stage 0.0 (TID 369) (172.35.54.41, executor 8, partition 369, PROCESS_LOCAL, 27126 bytes) 
"
1760335013032,"INFO	2025-10-13T05:56:53,032	365517	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 351.0 in stage 0.0 (TID 351) in 13361 ms on 172.35.54.41 (executor 8) (352/471)
"
1760335013683,"INFO	2025-10-13T05:56:53,682	366167	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335013683,"INFO	2025-10-13T05:56:53,683	366168	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 45, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335013683,"INFO	2025-10-13T05:56:53,683	366168	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 45; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_45_a_spark-application-1760334656744_p_1
"
1760335013683,"INFO	2025-10-13T05:56:53,683	366168	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335013731,"INFO	2025-10-13T05:56:53,731	366216	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335013732,"INFO	2025-10-13T05:56:53,731	366216	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 726284c9-dd5d-4909-839c-bceb81dbd285)
"
1760335013732,"INFO	2025-10-13T05:56:53,731	366216	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 45 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335016853,"INFO	2025-10-13T05:56:56,853	369338	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760335016854,"INFO	2025-10-13T05:56:56,853	369338	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760335018634,"INFO	2025-10-13T05:56:58,633	371118	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 370.0 in stage 0.0 (TID 370) (172.35.42.110, executor 2, partition 370, PROCESS_LOCAL, 27126 bytes) 
"
1760335018634,"INFO	2025-10-13T05:56:58,634	371119	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 354.0 in stage 0.0 (TID 354) in 14516 ms on 172.35.42.110 (executor 2) (353/471)
"
1760335019202,"INFO	2025-10-13T05:56:59,201	371686	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 371.0 in stage 0.0 (TID 371) (172.35.102.6, executor 3, partition 371, PROCESS_LOCAL, 27126 bytes) 
"
1760335019202,"INFO	2025-10-13T05:56:59,202	371687	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 352.0 in stage 0.0 (TID 352) in 15713 ms on 172.35.102.6 (executor 3) (354/471)
"
1760335019648,"INFO	2025-10-13T05:56:59,647	372132	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 372.0 in stage 0.0 (TID 372) (172.35.102.6, executor 3, partition 372, PROCESS_LOCAL, 27126 bytes) 
"
1760335019648,"INFO	2025-10-13T05:56:59,648	372133	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 353.0 in stage 0.0 (TID 353) in 15730 ms on 172.35.102.6 (executor 3) (355/471)
"
1760335020062,"INFO	2025-10-13T05:57:00,062	372547	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 373.0 in stage 0.0 (TID 373) (172.35.42.110, executor 2, partition 373, PROCESS_LOCAL, 27126 bytes) 
"
1760335020063,"INFO	2025-10-13T05:57:00,062	372547	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 356.0 in stage 0.0 (TID 356) in 14589 ms on 172.35.42.110 (executor 2) (356/471)
"
1760335020272,"INFO	2025-10-13T05:57:00,272	372757	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 374.0 in stage 0.0 (TID 374) (172.35.25.103, executor 7, partition 374, PROCESS_LOCAL, 27126 bytes) 
"
1760335020272,"INFO	2025-10-13T05:57:00,272	372757	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 357.0 in stage 0.0 (TID 357) in 14365 ms on 172.35.25.103 (executor 7) (357/471)
"
1760335020405,"INFO	2025-10-13T05:57:00,405	372890	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 375.0 in stage 0.0 (TID 375) (172.35.115.192, executor 1, partition 375, PROCESS_LOCAL, 27126 bytes) 
"
1760335020406,"INFO	2025-10-13T05:57:00,405	372890	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 355.0 in stage 0.0 (TID 355) in 15513 ms on 172.35.115.192 (executor 1) (358/471)
"
1760335020786,"INFO	2025-10-13T05:57:00,785	373270	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 376.0 in stage 0.0 (TID 376) (172.34.183.29, executor 4, partition 376, PROCESS_LOCAL, 27126 bytes) 
"
1760335020786,"INFO	2025-10-13T05:57:00,786	373271	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 359.0 in stage 0.0 (TID 359) in 14590 ms on 172.34.183.29 (executor 4) (359/471)
"
1760335020962,"INFO	2025-10-13T05:57:00,961	373446	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 377.0 in stage 0.0 (TID 377) (172.34.154.255, executor 9, partition 377, PROCESS_LOCAL, 27126 bytes) 
"
1760335020962,"INFO	2025-10-13T05:57:00,962	373447	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 358.0 in stage 0.0 (TID 358) in 14900 ms on 172.34.154.255 (executor 9) (360/471)
"
1760335021707,"INFO	2025-10-13T05:57:01,707	374192	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 378.0 in stage 0.0 (TID 378) (172.35.115.192, executor 1, partition 378, PROCESS_LOCAL, 27126 bytes) 
"
1760335021708,"INFO	2025-10-13T05:57:01,708	374193	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 360.0 in stage 0.0 (TID 360) in 15500 ms on 172.35.115.192 (executor 1) (361/471)
"
1760335021952,"INFO	2025-10-13T05:57:01,952	374437	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 379.0 in stage 0.0 (TID 379) (172.35.235.173, executor 5, partition 379, PROCESS_LOCAL, 27126 bytes) 
"
1760335021952,"INFO	2025-10-13T05:57:01,952	374437	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 361.0 in stage 0.0 (TID 361) in 15335 ms on 172.35.235.173 (executor 5) (362/471)
"
1760335022118,"INFO	2025-10-13T05:57:02,118	374603	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 380.0 in stage 0.0 (TID 380) (172.35.25.103, executor 7, partition 380, PROCESS_LOCAL, 27126 bytes) 
"
1760335022119,"INFO	2025-10-13T05:57:02,119	374604	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 363.0 in stage 0.0 (TID 363) in 14142 ms on 172.35.25.103 (executor 7) (363/471)
"
1760335022905,"INFO	2025-10-13T05:57:02,905	375390	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 381.0 in stage 0.0 (TID 381) (172.34.183.29, executor 4, partition 381, PROCESS_LOCAL, 27126 bytes) 
"
1760335022906,"INFO	2025-10-13T05:57:02,905	375390	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 364.0 in stage 0.0 (TID 364) in 14663 ms on 172.34.183.29 (executor 4) (364/471)
"
1760335022971,"INFO	2025-10-13T05:57:02,971	375456	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 382.0 in stage 0.0 (TID 382) (172.34.154.255, executor 9, partition 382, PROCESS_LOCAL, 27126 bytes) 
"
1760335022972,"INFO	2025-10-13T05:57:02,971	375456	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 362.0 in stage 0.0 (TID 362) in 15186 ms on 172.34.154.255 (executor 9) (365/471)
"
1760335023425,"INFO	2025-10-13T05:57:03,424	375909	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 383.0 in stage 0.0 (TID 383) (172.35.52.98, executor 6, partition 383, PROCESS_LOCAL, 27126 bytes) 
"
1760335023425,"INFO	2025-10-13T05:57:03,425	375910	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 365.0 in stage 0.0 (TID 365) in 14562 ms on 172.35.52.98 (executor 6) (366/471)
"
1760335023831,"INFO	2025-10-13T05:57:03,831	376316	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 384.0 in stage 0.0 (TID 384) (172.35.235.173, executor 5, partition 384, PROCESS_LOCAL, 27126 bytes) 
"
1760335023831,"INFO	2025-10-13T05:57:03,831	376316	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 366.0 in stage 0.0 (TID 366) in 14734 ms on 172.35.235.173 (executor 5) (367/471)
"
1760335025572,"INFO	2025-10-13T05:57:05,571	378056	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 385.0 in stage 0.0 (TID 385) (172.35.54.41, executor 8, partition 385, PROCESS_LOCAL, 27126 bytes) 
"
1760335025572,"INFO	2025-10-13T05:57:05,572	378057	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 368.0 in stage 0.0 (TID 368) in 13471 ms on 172.35.54.41 (executor 8) (368/471)
"
1760335026103,"INFO	2025-10-13T05:57:06,103	378588	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335026103,"INFO	2025-10-13T05:57:06,103	378588	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 46, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335026103,"INFO	2025-10-13T05:57:06,103	378588	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 46; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_46_a_spark-application-1760334656744_p_1
"
1760335026103,"INFO	2025-10-13T05:57:06,103	378588	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335026145,"INFO	2025-10-13T05:57:06,145	378630	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335026145,"INFO	2025-10-13T05:57:06,145	378630	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: f0f865ea-e36c-498a-bd27-c72357615c33)
"
1760335026145,"INFO	2025-10-13T05:57:06,145	378630	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 46 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335026552,"INFO	2025-10-13T05:57:06,552	379037	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 386.0 in stage 0.0 (TID 386) (172.35.52.98, executor 6, partition 386, PROCESS_LOCAL, 27126 bytes) 
"
1760335026553,"INFO	2025-10-13T05:57:06,552	379037	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 367.0 in stage 0.0 (TID 367) in 14857 ms on 172.35.52.98 (executor 6) (369/471)
"
1760335026620,"INFO	2025-10-13T05:57:06,619	379104	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 387.0 in stage 0.0 (TID 387) (172.35.54.41, executor 8, partition 387, PROCESS_LOCAL, 27126 bytes) 
"
1760335026620,"INFO	2025-10-13T05:57:06,620	379105	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 369.0 in stage 0.0 (TID 369) in 13589 ms on 172.35.54.41 (executor 8) (370/471)
"
1760335030192,"INFO	2025-10-13T05:57:10,192	382677	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335030193,"INFO	2025-10-13T05:57:10,192	382677	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 47, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335030193,"INFO	2025-10-13T05:57:10,193	382678	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 47; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_47_a_spark-application-1760334656744_p_1
"
1760335030193,"INFO	2025-10-13T05:57:10,193	382678	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335030231,"INFO	2025-10-13T05:57:10,231	382716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335030231,"INFO	2025-10-13T05:57:10,231	382716	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 2edea23c-e17a-441f-8868-fa6d333c6933)
"
1760335030231,"INFO	2025-10-13T05:57:10,231	382716	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 47 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335033285,"INFO	2025-10-13T05:57:13,284	385769	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 388.0 in stage 0.0 (TID 388) (172.35.42.110, executor 2, partition 388, PROCESS_LOCAL, 27126 bytes) 
"
1760335033285,"INFO	2025-10-13T05:57:13,285	385770	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 370.0 in stage 0.0 (TID 370) in 14652 ms on 172.35.42.110 (executor 2) (371/471)
"
1760335034815,"INFO	2025-10-13T05:57:14,815	387300	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 389.0 in stage 0.0 (TID 389) (172.35.25.103, executor 7, partition 389, PROCESS_LOCAL, 27118 bytes) 
"
1760335034816,"INFO	2025-10-13T05:57:14,815	387300	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 374.0 in stage 0.0 (TID 374) in 14544 ms on 172.35.25.103 (executor 7) (372/471)
"
1760335034836,"INFO	2025-10-13T05:57:14,836	387321	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 390.0 in stage 0.0 (TID 390) (172.35.42.110, executor 2, partition 390, PROCESS_LOCAL, 27118 bytes) 
"
1760335034837,"INFO	2025-10-13T05:57:14,836	387321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 373.0 in stage 0.0 (TID 373) in 14775 ms on 172.35.42.110 (executor 2) (373/471)
"
1760335035144,"INFO	2025-10-13T05:57:15,144	387629	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 391.0 in stage 0.0 (TID 391) (172.35.102.6, executor 3, partition 391, PROCESS_LOCAL, 27118 bytes) 
"
1760335035145,"INFO	2025-10-13T05:57:15,144	387629	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 371.0 in stage 0.0 (TID 371) in 15943 ms on 172.35.102.6 (executor 3) (374/471)
"
1760335035343,"INFO	2025-10-13T05:57:15,343	387828	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 392.0 in stage 0.0 (TID 392) (172.34.183.29, executor 4, partition 392, PROCESS_LOCAL, 27118 bytes) 
"
1760335035343,"INFO	2025-10-13T05:57:15,343	387828	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 376.0 in stage 0.0 (TID 376) in 14558 ms on 172.34.183.29 (executor 4) (375/471)
"
1760335035711,"INFO	2025-10-13T05:57:15,711	388196	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 393.0 in stage 0.0 (TID 393) (172.35.102.6, executor 3, partition 393, PROCESS_LOCAL, 27118 bytes) 
"
1760335035712,"INFO	2025-10-13T05:57:15,711	388196	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 372.0 in stage 0.0 (TID 372) in 16064 ms on 172.35.102.6 (executor 3) (376/471)
"
1760335035981,"INFO	2025-10-13T05:57:15,981	388466	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 394.0 in stage 0.0 (TID 394) (172.34.154.255, executor 9, partition 394, PROCESS_LOCAL, 27118 bytes) 
"
1760335035981,"INFO	2025-10-13T05:57:15,981	388466	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 377.0 in stage 0.0 (TID 377) in 15020 ms on 172.34.154.255 (executor 9) (377/471)
"
1760335036212,"INFO	2025-10-13T05:57:16,212	388697	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 395.0 in stage 0.0 (TID 395) (172.35.115.192, executor 1, partition 395, PROCESS_LOCAL, 27118 bytes) 
"
1760335036212,"INFO	2025-10-13T05:57:16,212	388697	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 375.0 in stage 0.0 (TID 375) in 15807 ms on 172.35.115.192 (executor 1) (378/471)
"
1760335036502,"INFO	2025-10-13T05:57:16,502	388987	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 396.0 in stage 0.0 (TID 396) (172.35.25.103, executor 7, partition 396, PROCESS_LOCAL, 27118 bytes) 
"
1760335036503,"INFO	2025-10-13T05:57:16,503	388988	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 380.0 in stage 0.0 (TID 380) in 14385 ms on 172.35.25.103 (executor 7) (379/471)
"
1760335036667,"INFO	2025-10-13T05:57:16,667	389152	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 397.0 in stage 0.0 (TID 397) (172.35.235.173, executor 5, partition 397, PROCESS_LOCAL, 27118 bytes) 
"
1760335036668,"INFO	2025-10-13T05:57:16,668	389153	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 379.0 in stage 0.0 (TID 379) in 14717 ms on 172.35.235.173 (executor 5) (380/471)
"
1760335037686,"INFO	2025-10-13T05:57:17,686	390171	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 398.0 in stage 0.0 (TID 398) (172.34.183.29, executor 4, partition 398, PROCESS_LOCAL, 27118 bytes) 
"
1760335037686,"INFO	2025-10-13T05:57:17,686	390171	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 381.0 in stage 0.0 (TID 381) in 14781 ms on 172.34.183.29 (executor 4) (381/471)
"
1760335037717,"INFO	2025-10-13T05:57:17,717	390202	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 399.0 in stage 0.0 (TID 399) (172.35.52.98, executor 6, partition 399, PROCESS_LOCAL, 27118 bytes) 
"
1760335037718,"INFO	2025-10-13T05:57:17,718	390203	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 383.0 in stage 0.0 (TID 383) in 14294 ms on 172.35.52.98 (executor 6) (382/471)
"
1760335037723,"INFO	2025-10-13T05:57:17,723	390208	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 400.0 in stage 0.0 (TID 400) (172.35.115.192, executor 1, partition 400, PROCESS_LOCAL, 27118 bytes) 
"
1760335037723,"INFO	2025-10-13T05:57:17,723	390208	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 378.0 in stage 0.0 (TID 378) in 16016 ms on 172.35.115.192 (executor 1) (383/471)
"
1760335038117,"INFO	2025-10-13T05:57:18,117	390602	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 401.0 in stage 0.0 (TID 401) (172.34.154.255, executor 9, partition 401, PROCESS_LOCAL, 27118 bytes) 
"
1760335038118,"INFO	2025-10-13T05:57:18,117	390602	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 382.0 in stage 0.0 (TID 382) in 15146 ms on 172.34.154.255 (executor 9) (384/471)
"
1760335038921,"INFO	2025-10-13T05:57:18,921	391406	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 402.0 in stage 0.0 (TID 402) (172.35.54.41, executor 8, partition 402, PROCESS_LOCAL, 27118 bytes) 
"
1760335038921,"INFO	2025-10-13T05:57:18,921	391406	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 385.0 in stage 0.0 (TID 385) in 13350 ms on 172.35.54.41 (executor 8) (385/471)
"
1760335038925,"INFO	2025-10-13T05:57:18,925	391410	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 403.0 in stage 0.0 (TID 403) (172.35.235.173, executor 5, partition 403, PROCESS_LOCAL, 27118 bytes) 
"
1760335038925,"INFO	2025-10-13T05:57:18,925	391410	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 384.0 in stage 0.0 (TID 384) in 15095 ms on 172.35.235.173 (executor 5) (386/471)
"
1760335039963,"INFO	2025-10-13T05:57:19,962	392447	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 404.0 in stage 0.0 (TID 404) (172.35.54.41, executor 8, partition 404, PROCESS_LOCAL, 27118 bytes) 
"
1760335039963,"INFO	2025-10-13T05:57:19,963	392448	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 387.0 in stage 0.0 (TID 387) in 13344 ms on 172.35.54.41 (executor 8) (387/471)
"
1760335040972,"INFO	2025-10-13T05:57:20,972	393457	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 405.0 in stage 0.0 (TID 405) (172.35.52.98, executor 6, partition 405, PROCESS_LOCAL, 27118 bytes) 
"
1760335040973,"INFO	2025-10-13T05:57:20,973	393458	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 386.0 in stage 0.0 (TID 386) in 14421 ms on 172.35.52.98 (executor 6) (388/471)
"
1760335044153,"INFO	2025-10-13T05:57:24,152	396637	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335044153,"INFO	2025-10-13T05:57:24,153	396638	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 48, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335044153,"INFO	2025-10-13T05:57:24,153	396638	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 48; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_48_a_spark-application-1760334656744_p_1
"
1760335044153,"INFO	2025-10-13T05:57:24,153	396638	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335044185,"INFO	2025-10-13T05:57:24,185	396670	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335044185,"INFO	2025-10-13T05:57:24,185	396670	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 48eec948-3d9a-48c3-bbab-3f17be52a075)
"
1760335044185,"INFO	2025-10-13T05:57:24,185	396670	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 48 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335048002,"INFO	2025-10-13T05:57:28,001	400486	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 406.0 in stage 0.0 (TID 406) (172.35.42.110, executor 2, partition 406, PROCESS_LOCAL, 27118 bytes) 
"
1760335048002,"INFO	2025-10-13T05:57:28,002	400487	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 388.0 in stage 0.0 (TID 388) in 14718 ms on 172.35.42.110 (executor 2) (389/471)
"
1760335051218,"INFO	2025-10-13T05:57:31,218	403703	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335051218,"INFO	2025-10-13T05:57:31,218	403703	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 49, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335051219,"INFO	2025-10-13T05:57:31,218	403703	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 49; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_49_a_spark-application-1760334656744_p_1
"
1760335051219,"INFO	2025-10-13T05:57:31,219	403704	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335051249,"INFO	2025-10-13T05:57:31,249	403734	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335051249,"INFO	2025-10-13T05:57:31,249	403734	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: a34177e8-52ac-4bd8-b6d0-d6cd8ef5e62f)
"
1760335051249,"INFO	2025-10-13T05:57:31,249	403734	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 49 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335051483,"INFO	2025-10-13T05:57:31,483	403968	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 407.0 in stage 0.0 (TID 407) (172.35.25.103, executor 7, partition 407, PROCESS_LOCAL, 27118 bytes) 
"
1760335051484,"INFO	2025-10-13T05:57:31,484	403969	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 389.0 in stage 0.0 (TID 389) in 16669 ms on 172.35.25.103 (executor 7) (390/471)
"
1760335051588,"INFO	2025-10-13T05:57:31,587	404072	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 408.0 in stage 0.0 (TID 408) (172.35.42.110, executor 2, partition 408, PROCESS_LOCAL, 27118 bytes) 
"
1760335051588,"INFO	2025-10-13T05:57:31,588	404073	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 390.0 in stage 0.0 (TID 390) in 16752 ms on 172.35.42.110 (executor 2) (391/471)
"
1760335052440,"INFO	2025-10-13T05:57:32,440	404925	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 409.0 in stage 0.0 (TID 409) (172.34.183.29, executor 4, partition 409, PROCESS_LOCAL, 27118 bytes) 
"
1760335052440,"INFO	2025-10-13T05:57:32,440	404925	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 392.0 in stage 0.0 (TID 392) in 17098 ms on 172.34.183.29 (executor 4) (392/471)
"
1760335053054,"INFO	2025-10-13T05:57:33,053	405538	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 410.0 in stage 0.0 (TID 410) (172.35.235.173, executor 5, partition 410, PROCESS_LOCAL, 27118 bytes) 
"
1760335053054,"INFO	2025-10-13T05:57:33,054	405539	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 397.0 in stage 0.0 (TID 397) in 16387 ms on 172.35.235.173 (executor 5) (393/471)
"
1760335053118,"INFO	2025-10-13T05:57:33,118	405603	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 411.0 in stage 0.0 (TID 411) (172.35.25.103, executor 7, partition 411, PROCESS_LOCAL, 27118 bytes) 
"
1760335053119,"INFO	2025-10-13T05:57:33,118	405603	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 396.0 in stage 0.0 (TID 396) in 16616 ms on 172.35.25.103 (executor 7) (394/471)
"
1760335053266,"INFO	2025-10-13T05:57:33,266	405751	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 412.0 in stage 0.0 (TID 412) (172.34.154.255, executor 9, partition 412, PROCESS_LOCAL, 27118 bytes) 
"
1760335053267,"INFO	2025-10-13T05:57:33,267	405752	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 394.0 in stage 0.0 (TID 394) in 17287 ms on 172.34.154.255 (executor 9) (395/471)
"
1760335053282,"INFO	2025-10-13T05:57:33,282	405767	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 19
"
1760335053283,"INFO	2025-10-13T05:57:33,282	405767	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 19
"
1760335053287,"INFO	2025-10-13T05:57:33,286	405771	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 413.0 in stage 0.0 (TID 413) (172.35.102.6, executor 3, partition 413, PROCESS_LOCAL, 27118 bytes) 
"
1760335053287,"INFO	2025-10-13T05:57:33,287	405772	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 391.0 in stage 0.0 (TID 391) in 18143 ms on 172.35.102.6 (executor 3) (396/471)
"
1760335053722,"INFO	2025-10-13T05:57:33,722	406207	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 414.0 in stage 0.0 (TID 414) (172.35.102.6, executor 3, partition 414, PROCESS_LOCAL, 27118 bytes) 
"
1760335053722,"INFO	2025-10-13T05:57:33,722	406207	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 393.0 in stage 0.0 (TID 393) in 18011 ms on 172.35.102.6 (executor 3) (397/471)
"
1760335054030,"INFO	2025-10-13T05:57:34,029	406514	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 415.0 in stage 0.0 (TID 415) (172.35.115.192, executor 1, partition 415, PROCESS_LOCAL, 27118 bytes) 
"
1760335054030,"INFO	2025-10-13T05:57:34,030	406515	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 395.0 in stage 0.0 (TID 395) in 17819 ms on 172.35.115.192 (executor 1) (398/471)
"
1760335054133,"INFO	2025-10-13T05:57:34,133	406618	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 416.0 in stage 0.0 (TID 416) (172.35.52.98, executor 6, partition 416, PROCESS_LOCAL, 27118 bytes) 
"
1760335054133,"INFO	2025-10-13T05:57:34,133	406618	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 399.0 in stage 0.0 (TID 399) in 16416 ms on 172.35.52.98 (executor 6) (399/471)
"
1760335054184,"INFO	2025-10-13T05:57:34,184	406669	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 18
"
1760335054185,"INFO	2025-10-13T05:57:34,184	406669	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 18
"
1760335054315,"INFO	2025-10-13T05:57:34,315	406800	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 417.0 in stage 0.0 (TID 417) (172.35.54.41, executor 8, partition 417, PROCESS_LOCAL, 27118 bytes) 
"
1760335054316,"INFO	2025-10-13T05:57:34,316	406801	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 402.0 in stage 0.0 (TID 402) in 15395 ms on 172.35.54.41 (executor 8) (400/471)
"
1760335054829,"INFO	2025-10-13T05:57:34,829	407314	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 418.0 in stage 0.0 (TID 418) (172.34.183.29, executor 4, partition 418, PROCESS_LOCAL, 27118 bytes) 
"
1760335054830,"INFO	2025-10-13T05:57:34,829	407314	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 398.0 in stage 0.0 (TID 398) in 17144 ms on 172.34.183.29 (executor 4) (401/471)
"
1760335055263,"INFO	2025-10-13T05:57:35,263	407748	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 419.0 in stage 0.0 (TID 419) (172.35.115.192, executor 1, partition 419, PROCESS_LOCAL, 27118 bytes) 
"
1760335055264,"INFO	2025-10-13T05:57:35,263	407748	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 400.0 in stage 0.0 (TID 400) in 17540 ms on 172.35.115.192 (executor 1) (402/471)
"
1760335055505,"INFO	2025-10-13T05:57:35,505	407990	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 420.0 in stage 0.0 (TID 420) (172.35.235.173, executor 5, partition 420, PROCESS_LOCAL, 27118 bytes) 
"
1760335055506,"INFO	2025-10-13T05:57:35,505	407990	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 403.0 in stage 0.0 (TID 403) in 16580 ms on 172.35.235.173 (executor 5) (403/471)
"
1760335055506,"INFO	2025-10-13T05:57:35,506	407991	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 421.0 in stage 0.0 (TID 421) (172.34.154.255, executor 9, partition 421, PROCESS_LOCAL, 27118 bytes) 
"
1760335055507,"INFO	2025-10-13T05:57:35,506	407991	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 401.0 in stage 0.0 (TID 401) in 17389 ms on 172.34.154.255 (executor 9) (404/471)
"
1760335055584,"INFO	2025-10-13T05:57:35,584	408069	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 422.0 in stage 0.0 (TID 422) (172.35.54.41, executor 8, partition 422, PROCESS_LOCAL, 27118 bytes) 
"
1760335055585,"INFO	2025-10-13T05:57:35,585	408070	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 404.0 in stage 0.0 (TID 404) in 15622 ms on 172.35.54.41 (executor 8) (405/471)
"
1760335055586,"INFO	2025-10-13T05:57:35,586	408071	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 17
"
1760335055586,"INFO	2025-10-13T05:57:35,586	408071	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 17
"
1760335057240,"INFO	2025-10-13T05:57:37,240	409725	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 423.0 in stage 0.0 (TID 423) (172.35.52.98, executor 6, partition 423, PROCESS_LOCAL, 27118 bytes) 
"
1760335057241,"INFO	2025-10-13T05:57:37,240	409725	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 405.0 in stage 0.0 (TID 405) in 16268 ms on 172.35.52.98 (executor 6) (406/471)
"
1760335064461,"INFO	2025-10-13T05:57:44,460	416945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 424.0 in stage 0.0 (TID 424) (172.35.42.110, executor 2, partition 424, PROCESS_LOCAL, 27118 bytes) 
"
1760335064461,"INFO	2025-10-13T05:57:44,461	416946	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 406.0 in stage 0.0 (TID 406) in 16460 ms on 172.35.42.110 (executor 2) (407/471)
"
1760335064495,"INFO	2025-10-13T05:57:44,495	416980	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 16
"
1760335064495,"INFO	2025-10-13T05:57:44,495	416980	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 16
"
1760335067218,"INFO	2025-10-13T05:57:47,217	419702	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335067218,"INFO	2025-10-13T05:57:47,218	419703	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 50, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335067218,"INFO	2025-10-13T05:57:47,218	419703	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 50; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_50_a_spark-application-1760334656744_p_1
"
1760335067218,"INFO	2025-10-13T05:57:47,218	419703	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335067257,"INFO	2025-10-13T05:57:47,257	419742	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335067257,"INFO	2025-10-13T05:57:47,257	419742	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 6361e514-69dc-4c7b-b057-c03e82f43a1f)
"
1760335067257,"INFO	2025-10-13T05:57:47,257	419742	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 50 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335067793,"INFO	2025-10-13T05:57:47,793	420278	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 425.0 in stage 0.0 (TID 425) (172.35.25.103, executor 7, partition 425, PROCESS_LOCAL, 27118 bytes) 
"
1760335067794,"INFO	2025-10-13T05:57:47,794	420279	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 407.0 in stage 0.0 (TID 407) in 16311 ms on 172.35.25.103 (executor 7) (408/471)
"
1760335068082,"INFO	2025-10-13T05:57:48,082	420567	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 426.0 in stage 0.0 (TID 426) (172.35.42.110, executor 2, partition 426, PROCESS_LOCAL, 27118 bytes) 
"
1760335068082,"INFO	2025-10-13T05:57:48,082	420567	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 408.0 in stage 0.0 (TID 408) in 16495 ms on 172.35.42.110 (executor 2) (409/471)
"
1760335068873,"INFO	2025-10-13T05:57:48,873	421358	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335068874,"INFO	2025-10-13T05:57:48,874	421359	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 51, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335068874,"INFO	2025-10-13T05:57:48,874	421359	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 51; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_51_a_spark-application-1760334656744_p_1
"
1760335068874,"INFO	2025-10-13T05:57:48,874	421359	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335068911,"INFO	2025-10-13T05:57:48,911	421396	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335068911,"INFO	2025-10-13T05:57:48,911	421396	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: fcdd6ba9-7e0a-4449-af85-4105a80ceb9f)
"
1760335068911,"INFO	2025-10-13T05:57:48,911	421396	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 51 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335069254,"INFO	2025-10-13T05:57:49,253	421738	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 427.0 in stage 0.0 (TID 427) (172.35.235.173, executor 5, partition 427, PROCESS_LOCAL, 27118 bytes) 
"
1760335069254,"INFO	2025-10-13T05:57:49,254	421739	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 410.0 in stage 0.0 (TID 410) in 16201 ms on 172.35.235.173 (executor 5) (410/471)
"
1760335069462,"INFO	2025-10-13T05:57:49,461	421946	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 428.0 in stage 0.0 (TID 428) (172.35.25.103, executor 7, partition 428, PROCESS_LOCAL, 27118 bytes) 
"
1760335069462,"INFO	2025-10-13T05:57:49,462	421947	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 411.0 in stage 0.0 (TID 411) in 16344 ms on 172.35.25.103 (executor 7) (411/471)
"
1760335069497,"INFO	2025-10-13T05:57:49,496	421981	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 429.0 in stage 0.0 (TID 429) (172.34.183.29, executor 4, partition 429, PROCESS_LOCAL, 27118 bytes) 
"
1760335069497,"INFO	2025-10-13T05:57:49,497	421982	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 409.0 in stage 0.0 (TID 409) in 17058 ms on 172.34.183.29 (executor 4) (412/471)
"
1760335069500,"INFO	2025-10-13T05:57:49,500	421985	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 15
"
1760335069500,"INFO	2025-10-13T05:57:49,500	421985	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 15
"
1760335069610,"INFO	2025-10-13T05:57:49,610	422095	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 430.0 in stage 0.0 (TID 430) (172.35.54.41, executor 8, partition 430, PROCESS_LOCAL, 27118 bytes) 
"
1760335069611,"INFO	2025-10-13T05:57:49,610	422095	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 417.0 in stage 0.0 (TID 417) in 15295 ms on 172.35.54.41 (executor 8) (413/471)
"
1760335070378,"INFO	2025-10-13T05:57:50,377	422862	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 431.0 in stage 0.0 (TID 431) (172.34.154.255, executor 9, partition 431, PROCESS_LOCAL, 27118 bytes) 
"
1760335070378,"INFO	2025-10-13T05:57:50,378	422863	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 412.0 in stage 0.0 (TID 412) in 17112 ms on 172.34.154.255 (executor 9) (414/471)
"
1760335070427,"INFO	2025-10-13T05:57:50,427	422912	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 432.0 in stage 0.0 (TID 432) (172.35.52.98, executor 6, partition 432, PROCESS_LOCAL, 27118 bytes) 
"
1760335070428,"INFO	2025-10-13T05:57:50,427	422912	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 416.0 in stage 0.0 (TID 416) in 16295 ms on 172.35.52.98 (executor 6) (415/471)
"
1760335070502,"INFO	2025-10-13T05:57:50,501	422986	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 14
"
1760335070502,"INFO	2025-10-13T05:57:50,501	422986	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 14
"
1760335071144,"INFO	2025-10-13T05:57:51,143	423628	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 433.0 in stage 0.0 (TID 433) (172.35.54.41, executor 8, partition 433, PROCESS_LOCAL, 27118 bytes) 
"
1760335071144,"INFO	2025-10-13T05:57:51,144	423629	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 422.0 in stage 0.0 (TID 422) in 15560 ms on 172.35.54.41 (executor 8) (416/471)
"
1760335071295,"INFO	2025-10-13T05:57:51,295	423780	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 434.0 in stage 0.0 (TID 434) (172.35.102.6, executor 3, partition 434, PROCESS_LOCAL, 27118 bytes) 
"
1760335071296,"INFO	2025-10-13T05:57:51,295	423780	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 413.0 in stage 0.0 (TID 413) in 18009 ms on 172.35.102.6 (executor 3) (417/471)
"
1760335071634,"INFO	2025-10-13T05:57:51,634	424119	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 435.0 in stage 0.0 (TID 435) (172.35.102.6, executor 3, partition 435, PROCESS_LOCAL, 27118 bytes) 
"
1760335071635,"INFO	2025-10-13T05:57:51,634	424119	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 414.0 in stage 0.0 (TID 414) in 17913 ms on 172.35.102.6 (executor 3) (418/471)
"
1760335071784,"INFO	2025-10-13T05:57:51,783	424268	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 436.0 in stage 0.0 (TID 436) (172.35.115.192, executor 1, partition 436, PROCESS_LOCAL, 27118 bytes) 
"
1760335071784,"INFO	2025-10-13T05:57:51,784	424269	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 415.0 in stage 0.0 (TID 415) in 17755 ms on 172.35.115.192 (executor 1) (419/471)
"
1760335071803,"INFO	2025-10-13T05:57:51,803	424288	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 13
"
1760335071803,"INFO	2025-10-13T05:57:51,803	424288	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 13
"
1760335071955,"INFO	2025-10-13T05:57:51,955	424440	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 437.0 in stage 0.0 (TID 437) (172.34.183.29, executor 4, partition 437, PROCESS_LOCAL, 27118 bytes) 
"
1760335071955,"INFO	2025-10-13T05:57:51,955	424440	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 418.0 in stage 0.0 (TID 418) in 17126 ms on 172.34.183.29 (executor 4) (420/471)
"
1760335072330,"INFO	2025-10-13T05:57:52,329	424814	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 438.0 in stage 0.0 (TID 438) (172.35.235.173, executor 5, partition 438, PROCESS_LOCAL, 27118 bytes) 
"
1760335072330,"INFO	2025-10-13T05:57:52,330	424815	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 420.0 in stage 0.0 (TID 420) in 16825 ms on 172.35.235.173 (executor 5) (421/471)
"
1760335072592,"INFO	2025-10-13T05:57:52,592	425077	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 439.0 in stage 0.0 (TID 439) (172.34.154.255, executor 9, partition 439, PROCESS_LOCAL, 27118 bytes) 
"
1760335072593,"INFO	2025-10-13T05:57:52,592	425077	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 421.0 in stage 0.0 (TID 421) in 17086 ms on 172.34.154.255 (executor 9) (422/471)
"
1760335073244,"INFO	2025-10-13T05:57:53,243	425728	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 440.0 in stage 0.0 (TID 440) (172.35.115.192, executor 1, partition 440, PROCESS_LOCAL, 27118 bytes) 
"
1760335073244,"INFO	2025-10-13T05:57:53,244	425729	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 419.0 in stage 0.0 (TID 419) in 17981 ms on 172.35.115.192 (executor 1) (423/471)
"
1760335073305,"INFO	2025-10-13T05:57:53,305	425790	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 12
"
1760335073305,"INFO	2025-10-13T05:57:53,305	425790	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 12
"
1760335073579,"INFO	2025-10-13T05:57:53,579	426064	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 441.0 in stage 0.0 (TID 441) (172.35.52.98, executor 6, partition 441, PROCESS_LOCAL, 27118 bytes) 
"
1760335073579,"INFO	2025-10-13T05:57:53,579	426064	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 423.0 in stage 0.0 (TID 423) in 16339 ms on 172.35.52.98 (executor 6) (424/471)
"
1760335074228,"INFO	2025-10-13T05:57:54,227	426712	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335074228,"INFO	2025-10-13T05:57:54,228	426713	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 52, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335074228,"INFO	2025-10-13T05:57:54,228	426713	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 52; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_52_a_spark-application-1760334656744_p_1
"
1760335074228,"INFO	2025-10-13T05:57:54,228	426713	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335074258,"INFO	2025-10-13T05:57:54,258	426743	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335074258,"INFO	2025-10-13T05:57:54,258	426743	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 147d27a1-0b60-4991-aa81-4123de3a23b3)
"
1760335074258,"INFO	2025-10-13T05:57:54,258	426743	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 52 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335076854,"INFO	2025-10-13T05:57:56,854	429339	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760335076854,"INFO	2025-10-13T05:57:56,854	429339	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760335077058,"INFO	2025-10-13T05:57:57,058	429543	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335077059,"INFO	2025-10-13T05:57:57,059	429544	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 53, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335077059,"INFO	2025-10-13T05:57:57,059	429544	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 53; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_53_a_spark-application-1760334656744_p_1
"
1760335077059,"INFO	2025-10-13T05:57:57,059	429544	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335077087,"INFO	2025-10-13T05:57:57,087	429572	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335077087,"INFO	2025-10-13T05:57:57,087	429572	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 0bc76450-ea95-4cff-909d-4a81cf289f67)
"
1760335077087,"INFO	2025-10-13T05:57:57,087	429572	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 53 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335080807,"INFO	2025-10-13T05:58:00,807	433292	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335080808,"INFO	2025-10-13T05:58:00,808	433293	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 54, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335080808,"INFO	2025-10-13T05:58:00,808	433293	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 54; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_54_a_spark-application-1760334656744_p_1
"
1760335080808,"INFO	2025-10-13T05:58:00,808	433293	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335080856,"INFO	2025-10-13T05:58:00,855	433340	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335080856,"INFO	2025-10-13T05:58:00,856	433341	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 372c3bfa-f5cc-4afe-aaeb-af205455e830)
"
1760335080856,"INFO	2025-10-13T05:58:00,856	433341	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 54 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335080997,"INFO	2025-10-13T05:58:00,997	433482	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 442.0 in stage 0.0 (TID 442) (172.35.42.110, executor 2, partition 442, PROCESS_LOCAL, 27118 bytes) 
"
1760335080997,"INFO	2025-10-13T05:58:00,997	433482	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 424.0 in stage 0.0 (TID 424) in 16537 ms on 172.35.42.110 (executor 2) (425/471)
"
1760335084298,"INFO	2025-10-13T05:58:04,297	436782	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 443.0 in stage 0.0 (TID 443) (172.35.25.103, executor 7, partition 443, PROCESS_LOCAL, 27118 bytes) 
"
1760335084298,"INFO	2025-10-13T05:58:04,298	436783	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 425.0 in stage 0.0 (TID 425) in 16505 ms on 172.35.25.103 (executor 7) (426/471)
"
1760335084510,"INFO	2025-10-13T05:58:04,509	436994	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 444.0 in stage 0.0 (TID 444) (172.35.42.110, executor 2, partition 444, PROCESS_LOCAL, 27118 bytes) 
"
1760335084510,"INFO	2025-10-13T05:58:04,510	436995	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 426.0 in stage 0.0 (TID 426) in 16428 ms on 172.35.42.110 (executor 2) (427/471)
"
1760335084517,"INFO	2025-10-13T05:58:04,517	437002	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 11
"
1760335084517,"INFO	2025-10-13T05:58:04,517	437002	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 11
"
1760335084924,"INFO	2025-10-13T05:58:04,924	437409	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 445.0 in stage 0.0 (TID 445) (172.35.54.41, executor 8, partition 445, PROCESS_LOCAL, 27118 bytes) 
"
1760335084924,"INFO	2025-10-13T05:58:04,924	437409	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 430.0 in stage 0.0 (TID 430) in 15314 ms on 172.35.54.41 (executor 8) (428/471)
"
1760335085847,"INFO	2025-10-13T05:58:05,847	438332	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 446.0 in stage 0.0 (TID 446) (172.35.235.173, executor 5, partition 446, PROCESS_LOCAL, 27118 bytes) 
"
1760335085848,"INFO	2025-10-13T05:58:05,847	438332	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 427.0 in stage 0.0 (TID 427) in 16594 ms on 172.35.235.173 (executor 5) (429/471)
"
1760335086021,"INFO	2025-10-13T05:58:06,021	438506	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 447.0 in stage 0.0 (TID 447) (172.35.25.103, executor 7, partition 447, PROCESS_LOCAL, 27118 bytes) 
"
1760335086021,"INFO	2025-10-13T05:58:06,021	438506	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 428.0 in stage 0.0 (TID 428) in 16560 ms on 172.35.25.103 (executor 7) (430/471)
"
1760335086271,"INFO	2025-10-13T05:58:06,271	438756	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 448.0 in stage 0.0 (TID 448) (172.34.183.29, executor 4, partition 448, PROCESS_LOCAL, 27118 bytes) 
"
1760335086271,"INFO	2025-10-13T05:58:06,271	438756	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 429.0 in stage 0.0 (TID 429) in 16775 ms on 172.34.183.29 (executor 4) (431/471)
"
1760335086320,"INFO	2025-10-13T05:58:06,320	438805	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 10
"
1760335086320,"INFO	2025-10-13T05:58:06,320	438805	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 10
"
1760335086711,"INFO	2025-10-13T05:58:06,711	439196	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 449.0 in stage 0.0 (TID 449) (172.35.54.41, executor 8, partition 449, PROCESS_LOCAL, 27118 bytes) 
"
1760335086712,"INFO	2025-10-13T05:58:06,711	439196	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 433.0 in stage 0.0 (TID 433) in 15568 ms on 172.35.54.41 (executor 8) (432/471)
"
1760335086743,"INFO	2025-10-13T05:58:06,743	439228	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 450.0 in stage 0.0 (TID 450) (172.35.52.98, executor 6, partition 450, PROCESS_LOCAL, 27118 bytes) 
"
1760335086743,"INFO	2025-10-13T05:58:06,743	439228	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 432.0 in stage 0.0 (TID 432) in 16316 ms on 172.35.52.98 (executor 6) (433/471)
"
1760335087398,"INFO	2025-10-13T05:58:07,398	439883	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 451.0 in stage 0.0 (TID 451) (172.34.154.255, executor 9, partition 451, PROCESS_LOCAL, 27118 bytes) 
"
1760335087399,"INFO	2025-10-13T05:58:07,398	439883	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 431.0 in stage 0.0 (TID 431) in 17021 ms on 172.34.154.255 (executor 9) (434/471)
"
1760335088742,"INFO	2025-10-13T05:58:08,742	441227	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 452.0 in stage 0.0 (TID 452) (172.35.235.173, executor 5, partition 452, PROCESS_LOCAL, 27118 bytes) 
"
1760335088742,"INFO	2025-10-13T05:58:08,742	441227	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 438.0 in stage 0.0 (TID 438) in 16413 ms on 172.35.235.173 (executor 5) (435/471)
"
1760335088755,"INFO	2025-10-13T05:58:08,755	441240	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 453.0 in stage 0.0 (TID 453) (172.34.183.29, executor 4, partition 453, PROCESS_LOCAL, 27118 bytes) 
"
1760335088755,"INFO	2025-10-13T05:58:08,755	441240	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 437.0 in stage 0.0 (TID 437) in 16801 ms on 172.34.183.29 (executor 4) (436/471)
"
1760335088823,"INFO	2025-10-13T05:58:08,823	441308	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 9
"
1760335088823,"INFO	2025-10-13T05:58:08,823	441308	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 9
"
1760335089486,"INFO	2025-10-13T05:58:09,486	441971	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335089486,"INFO	2025-10-13T05:58:09,486	441971	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 55, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335089486,"INFO	2025-10-13T05:58:09,486	441971	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 55; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_55_a_spark-application-1760334656744_p_1
"
1760335089487,"INFO	2025-10-13T05:58:09,487	441972	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335089499,"INFO	2025-10-13T05:58:09,499	441984	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 454.0 in stage 0.0 (TID 454) (172.35.115.192, executor 1, partition 454, PROCESS_LOCAL, 27118 bytes) 
"
1760335089499,"INFO	2025-10-13T05:58:09,499	441984	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 436.0 in stage 0.0 (TID 436) in 17716 ms on 172.35.115.192 (executor 1) (437/471)
"
1760335089522,"INFO	2025-10-13T05:58:09,522	442007	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335089522,"INFO	2025-10-13T05:58:09,522	442007	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: 1c5d39b4-3337-4ba9-a0ab-bcfe8e82f53c)
"
1760335089522,"INFO	2025-10-13T05:58:09,522	442007	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 55 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335089529,"INFO	2025-10-13T05:58:09,529	442014	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 455.0 in stage 0.0 (TID 455) (172.35.102.6, executor 3, partition 455, PROCESS_LOCAL, 27118 bytes) 
"
1760335089529,"INFO	2025-10-13T05:58:09,529	442014	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 434.0 in stage 0.0 (TID 434) in 18234 ms on 172.35.102.6 (executor 3) (438/471)
"
1760335089578,"INFO	2025-10-13T05:58:09,577	442062	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 456.0 in stage 0.0 (TID 456) (172.34.154.255, executor 9, partition 456, PROCESS_LOCAL, 27118 bytes) 
"
1760335089578,"INFO	2025-10-13T05:58:09,578	442063	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 439.0 in stage 0.0 (TID 439) in 16986 ms on 172.34.154.255 (executor 9) (439/471)
"
1760335089624,"INFO	2025-10-13T05:58:09,624	442109	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 8
"
1760335089624,"INFO	2025-10-13T05:58:09,624	442109	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 8
"
1760335089663,"INFO	2025-10-13T05:58:09,663	442148	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 457.0 in stage 0.0 (TID 457) (172.35.52.98, executor 6, partition 457, PROCESS_LOCAL, 27118 bytes) 
INFO	2025-10-13T05:58:09,663	442148	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 441.0 in stage 0.0 (TID 441) in 16085 ms on 172.35.52.98 (executor 6) (440/471)
"
1760335089758,"INFO	2025-10-13T05:58:09,758	442243	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 458.0 in stage 0.0 (TID 458) (172.35.102.6, executor 3, partition 458, PROCESS_LOCAL, 27118 bytes) 
"
1760335089758,"INFO	2025-10-13T05:58:09,758	442243	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 435.0 in stage 0.0 (TID 435) in 18124 ms on 172.35.102.6 (executor 3) (441/471)
"
1760335090952,"INFO	2025-10-13T05:58:10,952	443437	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 459.0 in stage 0.0 (TID 459) (172.35.115.192, executor 1, partition 459, PROCESS_LOCAL, 27118 bytes) 
"
1760335090952,"INFO	2025-10-13T05:58:10,952	443437	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 440.0 in stage 0.0 (TID 440) in 17709 ms on 172.35.115.192 (executor 1) (442/471)
"
1760335095730,"INFO	2025-10-13T05:58:15,730	448215	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334656744 with resource profile 0
"
1760335095731,"INFO	2025-10-13T05:58:15,730	448215	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.178.85:41669, --executor-id, 56, --app-id, spark-application-1760334656744, --cores, 2, --resourceProfileId, 0)
"
1760335095731,"INFO	2025-10-13T05:58:15,731	448216	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 56; clientToken gr_a45e0fa4-497b-40fe-9319-174341c2723e_e_56_a_spark-application-1760334656744_p_1
"
1760335095731,"INFO	2025-10-13T05:58:15,731	448216	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335095767,"INFO	2025-10-13T05:58:15,767	448252	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335095767,"INFO	2025-10-13T05:58:15,767	448252	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId a45e0fa4-497b-40fe-9319-174341c2723e (Service: GlueJobExecutor, Status Code: 400, Request ID: f56f5669-fce2-4a4e-8e32-ed8bf629e059)
"
1760335095767,"INFO	2025-10-13T05:58:15,767	448252	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 56 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335097490,"INFO	2025-10-13T05:58:17,489	449974	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 460.0 in stage 0.0 (TID 460) (172.35.42.110, executor 2, partition 460, PROCESS_LOCAL, 27118 bytes) 
"
1760335097490,"INFO	2025-10-13T05:58:17,490	449975	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 442.0 in stage 0.0 (TID 442) in 16494 ms on 172.35.42.110 (executor 2) (443/471)
"
1760335097533,"INFO	2025-10-13T05:58:17,532	450017	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 7
"
1760335097533,"INFO	2025-10-13T05:58:17,533	450018	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 7
"
1760335100067,"INFO	2025-10-13T05:58:20,066	452551	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 461.0 in stage 0.0 (TID 461) (172.35.54.41, executor 8, partition 461, PROCESS_LOCAL, 27118 bytes) 
"
1760335100067,"INFO	2025-10-13T05:58:20,067	452552	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 445.0 in stage 0.0 (TID 445) in 15144 ms on 172.35.54.41 (executor 8) (444/471)
"
1760335100620,"INFO	2025-10-13T05:58:20,620	453105	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 462.0 in stage 0.0 (TID 462) (172.35.25.103, executor 7, partition 462, PROCESS_LOCAL, 27118 bytes) 
"
1760335100621,"INFO	2025-10-13T05:58:20,620	453105	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 443.0 in stage 0.0 (TID 443) in 16323 ms on 172.35.25.103 (executor 7) (445/471)
"
1760335101118,"INFO	2025-10-13T05:58:21,118	453603	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 463.0 in stage 0.0 (TID 463) (172.35.42.110, executor 2, partition 463, PROCESS_LOCAL, 27118 bytes) 
"
1760335101119,"INFO	2025-10-13T05:58:21,118	453603	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 444.0 in stage 0.0 (TID 444) in 16609 ms on 172.35.42.110 (executor 2) (446/471)
"
1760335101753,"INFO	2025-10-13T05:58:21,753	454238	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 464.0 in stage 0.0 (TID 464) (172.35.54.41, executor 8, partition 464, PROCESS_LOCAL, 27118 bytes) 
"
1760335101753,"INFO	2025-10-13T05:58:21,753	454238	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 449.0 in stage 0.0 (TID 449) in 15042 ms on 172.35.54.41 (executor 8) (447/471)
"
1760335101838,"INFO	2025-10-13T05:58:21,837	454322	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 6
"
1760335101838,"INFO	2025-10-13T05:58:21,838	454323	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 6
"
1760335102601,"INFO	2025-10-13T05:58:22,601	455086	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 465.0 in stage 0.0 (TID 465) (172.35.25.103, executor 7, partition 465, PROCESS_LOCAL, 27118 bytes) 
"
1760335102602,"INFO	2025-10-13T05:58:22,601	455086	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 447.0 in stage 0.0 (TID 447) in 16581 ms on 172.35.25.103 (executor 7) (448/471)
"
1760335102636,"INFO	2025-10-13T05:58:22,636	455121	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 466.0 in stage 0.0 (TID 466) (172.35.235.173, executor 5, partition 466, PROCESS_LOCAL, 27118 bytes) 
"
1760335102636,"INFO	2025-10-13T05:58:22,636	455121	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 446.0 in stage 0.0 (TID 446) in 16789 ms on 172.35.235.173 (executor 5) (449/471)
"
1760335102640,"INFO	2025-10-13T05:58:22,640	455125	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 467.0 in stage 0.0 (TID 467) (172.35.52.98, executor 6, partition 467, PROCESS_LOCAL, 27118 bytes) 
"
1760335102640,"INFO	2025-10-13T05:58:22,640	455125	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 450.0 in stage 0.0 (TID 450) in 15897 ms on 172.35.52.98 (executor 6) (450/471)
"
1760335103032,"INFO	2025-10-13T05:58:23,031	455516	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 468.0 in stage 0.0 (TID 468) (172.34.183.29, executor 4, partition 468, PROCESS_LOCAL, 27118 bytes) 
"
1760335103032,"INFO	2025-10-13T05:58:23,032	455517	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 448.0 in stage 0.0 (TID 448) in 16762 ms on 172.34.183.29 (executor 4) (451/471)
"
1760335103039,"INFO	2025-10-13T05:58:23,039	455524	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 5
"
1760335103039,"INFO	2025-10-13T05:58:23,039	455524	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 5
"
1760335104453,"INFO	2025-10-13T05:58:24,452	456937	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 469.0 in stage 0.0 (TID 469) (172.34.154.255, executor 9, partition 469, PROCESS_LOCAL, 27118 bytes) 
"
1760335104453,"INFO	2025-10-13T05:58:24,453	456938	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 451.0 in stage 0.0 (TID 451) in 17055 ms on 172.34.154.255 (executor 9) (452/471)
"
1760335105034,"INFO	2025-10-13T05:58:25,033	457518	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 470.0 in stage 0.0 (TID 470) (172.35.235.173, executor 5, partition 470, PROCESS_LOCAL, 27118 bytes) 
"
1760335105034,"INFO	2025-10-13T05:58:25,034	457519	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 452.0 in stage 0.0 (TID 452) in 16293 ms on 172.35.235.173 (executor 5) (453/471)
"
1760335105626,"INFO	2025-10-13T05:58:25,626	458111	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 453.0 in stage 0.0 (TID 453) in 16872 ms on 172.34.183.29 (executor 4) (454/471)
"
1760335105879,"INFO	2025-10-13T05:58:25,879	458364	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 457.0 in stage 0.0 (TID 457) in 16217 ms on 172.35.52.98 (executor 6) (455/471)
"
1760335105943,"INFO	2025-10-13T05:58:25,942	458427	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 4
"
1760335105943,"INFO	2025-10-13T05:58:25,942	458427	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 4
"
1760335106722,"INFO	2025-10-13T05:58:26,722	459207	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 456.0 in stage 0.0 (TID 456) in 17145 ms on 172.34.154.255 (executor 9) (456/471)
"
1760335107318,"INFO	2025-10-13T05:58:27,318	459803	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 454.0 in stage 0.0 (TID 454) in 17819 ms on 172.35.115.192 (executor 1) (457/471)
"
1760335107780,"INFO	2025-10-13T05:58:27,780	460265	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 458.0 in stage 0.0 (TID 458) in 18023 ms on 172.35.102.6 (executor 3) (458/471)
"
1760335107852,"INFO	2025-10-13T05:58:27,852	460337	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 455.0 in stage 0.0 (TID 455) in 18323 ms on 172.35.102.6 (executor 3) (459/471)
"
1760335107945,"INFO	2025-10-13T05:58:27,944	460429	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 3
"
1760335107945,"INFO	2025-10-13T05:58:27,945	460430	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 3
"
1760335108755,"INFO	2025-10-13T05:58:28,755	461240	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 459.0 in stage 0.0 (TID 459) in 17804 ms on 172.35.115.192 (executor 1) (460/471)
"
1760335113987,"INFO	2025-10-13T05:58:33,987	466472	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 460.0 in stage 0.0 (TID 460) in 16498 ms on 172.35.42.110 (executor 2) (461/471)
"
1760335115769,"INFO	2025-10-13T05:58:35,768	468253	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 461.0 in stage 0.0 (TID 461) in 15702 ms on 172.35.54.41 (executor 8) (462/471)
"
1760335117203,"INFO	2025-10-13T05:58:37,202	469687	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 464.0 in stage 0.0 (TID 464) in 15450 ms on 172.35.54.41 (executor 8) (463/471)
"
1760335117229,"INFO	2025-10-13T05:58:37,229	469714	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 462.0 in stage 0.0 (TID 462) in 16609 ms on 172.35.25.103 (executor 7) (464/471)
"
1760335117254,"INFO	2025-10-13T05:58:37,254	469739	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
"
1760335117254,"INFO	2025-10-13T05:58:37,254	469739	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
"
1760335117588,"INFO	2025-10-13T05:58:37,587	470072	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 463.0 in stage 0.0 (TID 463) in 16469 ms on 172.35.42.110 (executor 2) (465/471)
"
1760335118169,"INFO	2025-10-13T05:58:38,169	470654	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 467.0 in stage 0.0 (TID 467) in 15529 ms on 172.35.52.98 (executor 6) (466/471)
"
1760335118952,"INFO	2025-10-13T05:58:38,952	471437	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 465.0 in stage 0.0 (TID 465) in 16351 ms on 172.35.25.103 (executor 7) (467/471)
"
1760335118956,"INFO	2025-10-13T05:58:38,956	471441	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760335118956,"INFO	2025-10-13T05:58:38,956	471441	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 1
"
1760335119253,"INFO	2025-10-13T05:58:39,253	471738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 468.0 in stage 0.0 (TID 468) in 16222 ms on 172.34.183.29 (executor 4) (468/471)
"
1760335119276,"ERROR	2025-10-13T05:58:39,275	471760	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	76	threshold for consecutive executor task creation reached
"
1760335119278,"INFO	2025-10-13T05:58:39,278	471763	org.apache.spark.SparkContext	[shutdown-hook-0]	60	Invoking stop() from shutdown hook
"
1760335119278,"INFO	2025-10-13T05:58:39,278	471763	org.apache.spark.SparkContext	[shutdown-hook-0]	60	SparkContext is stopping with exitCode 0.
"
1760335119284,"INFO	2025-10-13T05:58:39,283	471768	org.apache.spark.scheduler.DAGScheduler	[shutdown-hook-0]	60	ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0) failed in 452.716 s due to Stage cancelled because SparkContext was shut down
"
1760335119286,"INFO	2025-10-13T05:58:39,285	471770	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[shutdown-hook-0]	60	Stopping JES Scheduler Backend.
"
1760335119286,"INFO	2025-10-13T05:58:39,286	471771	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[spark-listener-group-shared]	70	Logs, events processed and insights are written to file /tmp/glue-exception-analysis-logs/spark-application-1760334656744
"
1760335119287,"INFO	2025-10-13T05:58:39,287	471772	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[shutdown-hook-0]	60	Shutting down all executors
"
1760335119287,"INFO	2025-10-13T05:58:39,287	471772	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Asking each executor to shut down
"
1760335119293,"ERROR	2025-10-13T05:58:39,293	471778	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisStageFailed"",""Timestamp"":1760335119283,""Failure Reason"":""Stage cancelled because SparkContext was shut down"",""Stack Trace"":[],""Stage ID"":0,""Stage Attempt ID"":0,""Number of Tasks"":471}
"
1760335119299,"ERROR	2025-10-13T05:58:39,298	471783	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisJobFailed"",""Timestamp"":1760335119295,""Failure Reason"":""org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down"",""Stack Trace"":[{""Declaring Class"":""org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down)"",""Method Name"":""TopLevelFailedReason"",""File Name"":""TopLevelFailedReason"",""Line Number"":-1}],""Job Id"":0,""Job Result"":""JobFailed"",""Failed Stage Id"":-1}
"
1760335119300,"INFO	2025-10-13T05:58:39,300	471785	org.apache.spark.sql.execution.SQLExecution	[Thread-7]	60	Skipped SparkListenerSQLExecutionObfuscatedInfo event due to NON_EMPTY_ERROR.
"
1760335119305,"INFO	2025-10-13T05:58:39,305	471790	org.apache.spark.MapOutputTrackerMasterEndpoint	[dispatcher-event-loop-4]	60	MapOutputTrackerMasterEndpoint stopped!
"
1760335119316,"INFO	2025-10-13T05:58:39,316	471801	org.apache.spark.storage.memory.MemoryStore	[shutdown-hook-0]	60	MemoryStore cleared
"
1760335119316,"INFO	2025-10-13T05:58:39,316	471801	org.apache.spark.storage.BlockManager	[shutdown-hook-0]	60	BlockManager stopped
"
1760335119321,"INFO	2025-10-13T05:58:39,321	471806	org.apache.spark.storage.BlockManagerMaster	[shutdown-hook-0]	60	BlockManagerMaster stopped
"
1760335119323,"INFO	2025-10-13T05:58:39,322	471807	org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint	[dispatcher-event-loop-7]	60	OutputCommitCoordinator stopped!
"
1760335119378,"INFO	2025-10-13T05:58:39,378	471863	org.apache.spark.SparkContext	[shutdown-hook-0]	60	Successfully stopped SparkContext
"
1760335119393,"INFO	2025-10-13T05:58:39,379	471864	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Shutdown hook called
"
1760335119393,"INFO	2025-10-13T05:58:39,380	471865	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-641549d6-aed8-490f-b924-cfe87dea7a93
"
1760335119393,"INFO	2025-10-13T05:58:39,386	471871	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-d21a81a0-6545-4b3d-a2d6-92b0b0c09f2c
"
1760335119393,"INFO	2025-10-13T05:58:39,390	471875	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-d21a81a0-6545-4b3d-a2d6-92b0b0c09f2c/pyspark-51f10ea1-4875-40e9-8903-afad31cafd1f
"