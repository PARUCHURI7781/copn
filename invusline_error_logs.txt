timestamp,message
1760373911771,"Preparing ...
"
1760373911774,"Mon Oct 13 16:45:11 UTC 2025
"
1760373911779,"/etc/alternatives/jre/bin/java --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions -Djavax.net.ssl.trustStore=/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -Djavax.net.ssl.trustStoreType=JKS -Djavax.net.ssl.trustStorePassword=amazon -DRDS_ROOT_CERT_PATH=/opt/amazon/certs/rds-combined-ca-bundle.pem -DREDSHIFT_ROOT_CERT_PATH=/opt/amazon/certs/redshift-ssl-ca-cert.pem -DRDS_TRUSTSTORE_URL=file:/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -cp /usr/share/aws/aws-glue-shuffle/*:/usr/share/aws/emr-glue-bootstrap/*:/usr/lib/spark/jars/*:/usr/lib/spark/conf:/usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/aws/hmclient/lib/*:/usr/share/aws/iceberg/lib/*:/usr/share/aws/delta/lib/*:/usr/lib/hudi/*:/usr/share/aws/redshift/jdbc/*:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/glue-connectors/lib/*:/usr/share/aws/glue-pii-dependencies/lib/*:/usr/share/aws/datazone-openlineage-spark/lib/*:/usr/lib/hadoop/lib/*::/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/cloudwatch-sink/lib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/lib/hadoop/*:/etc/hadoop/conf:/usr/share/java/Hive-JSON-Serde/* -Dlog4j2.configurationFile=/etc/spark/conf.dist/log4j2.properties com.amazonaws.services.glue.GlueBootstrap --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.maxExecutors=9 --conf spark.executor.memory=20g --conf spark.driver.memory=20g --conf spark.network.timeout=600 --app_name maximo_dq_invuseline    --glue-di-packages-correlation-ids 20250828-143656_,20250828-143656_,6378082053,6378082053 --TempDir s3://aws-glue-assets-331875467123-us-gov-west-1/entergy-gov-data-core-code/temporary/ --internal-lib-urls https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/aws-glue-dataplane-python/java17/5.0.704/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip?X-Amz-Security-Token=FwoDYXdzEEcaDLr%2B3nBDkH%2FIm0c67iKuAXuuxFqA5v2vntx1JAXOgIJibs91eCOeXRpjJChsaq7slvclPNiG8XkE66Mjzr222mAl8qK5H2TlQn5QFf%2B5tVOPNz1yDfDe7LJjLKNnw0akTRi3oG41g5Ps4IXder3skQA%2FEr%2BiIFailNR9FiOrQQc3GLeuSyFKbne40n0UueOg6Pw265CJiHlspmsGDTjqSmwqXX1AK7%2FolgCh86KxLeOvOqCvoOUl9VALNPtnwCjg2LTHBjIfOsjKhGQ7UPxD8HG5DDSdlaDhx5KQcNYytAGVFnOc8g%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T164508Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3PT2U5M7W%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=f345d87e05aa3b89224a63c204c69b1fe4bad6ab736ee8395b485ea67ce058a6,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/aws-glue-di-libs/java17/5.0.704/odvJng-aws-glue-di-package-5.0.704.jar?X-Amz-Security-Token=FwoDYXdzEEcaDLr%2B3nBDkH%2FIm0c67iKuAXuuxFqA5v2vntx1JAXOgIJibs91eCOeXRpjJChsaq7slvclPNiG8XkE66Mjzr222mAl8qK5H2TlQn5QFf%2B5tVOPNz1yDfDe7LJjLKNnw0akTRi3oG41g5Ps4IXder3skQA%2FEr%2BiIFailNR9FiOrQQc3GLeuSyFKbne40n0UueOg6Pw265CJiHlspmsGDTjqSmwqXX1AK7%2FolgCh86KxLeOvOqCvoOUl9VALNPtnwCjg2LTHBjIfOsjKhGQ7UPxD8HG5DDSdlaDhx5KQcNYytAGVFnOc8g%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T164508Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3PT2U5M7W%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=a846f7c05f428b1c158b2664a542e9ea8f629e820d08cb917f560ed935473d88,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/AwsGlueMLLibsPython/java17/5.0.382/yzED3c-AwsGlueMLLibs.py.zip?X-Amz-Security-Token=FwoDYXdzEEcaDLr%2B3nBDkH%2FIm0c67iKuAXuuxFqA5v2vntx1JAXOgIJibs91eCOeXRpjJChsaq7slvclPNiG8XkE66Mjzr222mAl8qK5H2TlQn5QFf%2B5tVOPNz1yDfDe7LJjLKNnw0akTRi3oG41g5Ps4IXder3skQA%2FEr%2BiIFailNR9FiOrQQc3GLeuSyFKbne40n0UueOg6Pw265CJiHlspmsGDTjqSmwqXX1AK7%2FolgCh86KxLeOvOqCvoOUl9VALNPtnwCjg2LTHBjIfOsjKhGQ7UPxD8HG5DDSdlaDhx5KQcNYytAGVFnOc8g%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T164508Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3PT2U5M7W%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=6e469f0537761566165ef0ed5c49dbdf21126e0b00bed1c7ad73c93819be95ee,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/AwsGlueMLLibs/java17/5.0.382/ImuwKQ-AwsGlueMLLibs.jar?X-Amz-Security-Token=FwoDYXdzEEcaDLr%2B3nBDkH%2FIm0c67iKuAXuuxFqA5v2vntx1JAXOgIJibs91eCOeXRpjJChsaq7slvclPNiG8XkE66Mjzr222mAl8qK5H2TlQn5QFf%2B5tVOPNz1yDfDe7LJjLKNnw0akTRi3oG41g5Ps4IXder3skQA%2FEr%2BiIFailNR9FiOrQQc3GLeuSyFKbne40n0UueOg6Pw265CJiHlspmsGDTjqSmwqXX1AK7%2FolgCh86KxLeOvOqCvoOUl9VALNPtnwCjg2LTHBjIfOsjKhGQ7UPxD8HG5DDSdlaDhx5KQcNYytAGVFnOc8g%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T164508Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3PT2U5M7W%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=9ae5f937a25a7c95b06743f68f9901b07efde58809a12abb9c98bf193c6cde9e --config s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/config/maximo/dq/invuseline.yaml  --job_type data_quality --JOB_ID j_efa31fc869c8dee42e4d418a22ff814987235318d8124ea647e103b402305b1b --extra-py-files s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/mosaic.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/sqlglot.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/yaml.zip   --JOB_RUN_ID jr_2330a9406ceaf183ba380c85730bf11679262181d39bb0d820186a3f9ee5acbb --scriptLocation s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py  --tenant-internal glue --enable-auto-scaling true --JOB_NAME maximo_dq_invuseline
"
1760373911809,"openjdk version ""17.0.16"" 2025-07-15 LTS
OpenJDK Runtime Environment Corretto-17.0.16.8.1 (build 17.0.16+8-LTS)
"
1760373911809,"OpenJDK 64-Bit Server VM Corretto-17.0.16.8.1 (build 17.0.16+8-LTS, mixed mode, sharing)
"
1760373912830,"25/10/13 16:45:12 INFO GlueBootstrap: Glue Bootstrapping...
"
1760373912834,"25/10/13 16:45:12 INFO GlueBootstrap: Glue Bootstrapping the driver...
"
1760373912851,"25/10/13 16:45:12 INFO GlueBootstrap: Downloading Glue libs...
"
1760373912854,"25/10/13 16:45:12 INFO GlueBootstrap: Downloading customer supplied extra files...
"
1760373913139,"25/10/13 16:45:13 WARN VersionInfoUtils: The AWS SDK for Java 1.x entered maintenance mode starting July 31, 2024 and will reach end of support on December 31, 2025. For more information, see https://aws.amazon.com/blogs/developer/the-aws-sdk-for-java-1-x-is-in-maintenance-mode-effective-july-31-2024/
You can print where on the file system the AWS SDK for Java 1.x core runtime is located by setting the AWS_JAVA_V1_PRINT_LOCATION environment variable or aws.java.v1.printLocation system property to 'true'.
This message can be disabled by setting the AWS_JAVA_V1_DISABLE_DEPRECATION_ANNOUNCEMENT environment variable or aws.java.v1.disableDeprecationAnnouncement system property to 'true'.
The AWS SDK for Java 1.x is being used here:
at java.base/java.lang.Thread.getStackTrace(Thread.java:1619)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.printDeprecationAnnouncement(VersionInfoUtils.java:81)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.<clinit>(VersionInfoUtils.java:59)
at glue.shaded.com.amazonaws.internal.EC2ResourceFetcher.<clinit>(EC2ResourceFetcher.java:44)
at glue.shaded.com.amazonaws.auth.InstanceMetadataServiceCredentialsFetcher.<init>(InstanceMetadataServiceCredentialsFetcher.java:38)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:111)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:91)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:75)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<clinit>(InstanceProfileCredentialsProvider.java:58)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.initializeProvider(EC2ContainerCredentialsProviderWrapper.java:66)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.<init>(EC2ContainerCredentialsProviderWrapper.java:55)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<init>(DefaultAWSCredentialsProviderChain.java:60)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<clinit>(DefaultAWSCredentialsProviderChain.java:54)
at glue.shaded.com.amazonaws.services.s3.AmazonS3ClientBuilder.standard(AmazonS3ClientBuilder.java:46)
at glue.shaded.com.amazonaws.services.s3.AmazonS3Client.builder(AmazonS3Client.java:740)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.getS3Client(GlueLibsDownloader.java:289)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.build(GlueLibsDownloader.java:281)
at com.amazonaws.services.glue.GlueBootstrap.downloadUserLibs(GlueBootstrap.java:409)
at com.amazonaws.services.glue.GlueBootstrap.lambda$setUpGlueAndUserLibs$2(GlueBootstrap.java:134)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
at java.base/java.lang.Thread.run(Thread.java:840)
"
1760373915553,"25/10/13 16:45:15 INFO GlueLibsDownloader: Elapsed time: 946 millis
"
1760373915743,"25/10/13 16:45:15 INFO GlueLibsDownloader: Elapsed time: 1141 millis
"
1760373915951,"1760373915949
"
1760373919062,"INFO	2025-10-13T16:45:19,062	7222	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	25	Setting Up Virtual Env and Application/Customer Provided Python Modules started in async mode
"
1760373919066,"INFO	2025-10-13T16:45:19,066	7226	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute python3.11 -m venv --clear /tmp/glue_venv
"
1760373919072,"INFO	2025-10-13T16:45:19,072	7232	com.amazonaws.services.glue.launch.helpers.PrepareLaunchProperties	[main]	89	Get job script: raw_dq_load.py.
"
1760373919106,"INFO	2025-10-13T16:45:19,105	7265	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	99	
proxy {
  host = null
  port = -1
}
"
1760373919110,"INFO	2025-10-13T16:45:19,110	7270	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
"
1760373919292,"INFO	2025-10-13T16:45:19,292	7452	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
"
1760373919324,"INFO	2025-10-13T16:45:19,324	7484	com.amazonaws.services.glue.utils.AWSClientUtils$	[main]	98	AWSClientUtils: create aws sts client with conf: proxy hostnull, proxy port 0
"
1760373920192,"INFO	2025-10-13T16:45:20,192	8352	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	113	optimizeParallelismConfigs started 
"
1760373920197,"INFO	2025-10-13T16:45:20,197	8357	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	59	glue.etl.telemetry.runtimeImproveFeature.autoscaling, jr_2330a9406ceaf183ba380c85730bf11679262181d39bb0d820186a3f9ee5acbb
"
1760373920198,"INFO	2025-10-13T16:45:20,198	8358	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	31	setupLoggerProperties...
"
1760373920200,"WARN	2025-10-13T16:45:20,200	8360	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	60	Logger setup failed for exception analysis: Cannot invoke ""java.net.URL.toURI()"" because the return value of ""java.lang.Class.getResource(String)"" is null
"
1760373920203,"INFO	2025-10-13T16:45:20,203	8363	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading /tmp/glue-15380977344099148172log4j2.properties file to destination location: /tmp/glue-job-12877998855152647238/glue-15380977344099148172log4j2.properties
"
1760373921275,"INFO	2025-10-13T16:45:21,275	9435	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	78	setting up the log4j.configurationFile=/tmp/glue-job-12877998855152647238/glue-15380977344099148172log4j2.properties
"
1760373921288,"INFO	2025-10-13T16:45:21,287	9447	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/aws_glue_connectors
"
1760373921288,"INFO	2025-10-13T16:45:21,288	9448	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/aws_glue_connectors/selected
"
1760373921288,"INFO	2025-10-13T16:45:21,288	9448	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/exception_catch
"
1760373921288,"INFO	2025-10-13T16:45:21,288	9448	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/amazon
"
1760373921288,"INFO	2025-10-13T16:45:21,288	9448	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/amazon/certs
"
1760373921289,"INFO	2025-10-13T16:45:21,288	9448	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/aws_glue_connectors/selected/native
"
1760373921289,"INFO	2025-10-13T16:45:21,289	9449	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12877998855152647238/aws_glue_connectors/marketplace
"
1760373921352,"INFO	2025-10-13T16:45:21,352	9512	com.amazonaws.services.glue.launch.helpers.ConnectionsManager	[main]	78	GLUE_CONNECTIVITY: attached connection types: ListBuffer()
"
1760373921631,"INFO	2025-10-13T16:45:21,631	9791	com.amazonaws.services.glue.PrepareLaunch	[main]	194	list of connectors to be added in classpath: List()
"
1760373921633,"INFO	2025-10-13T16:45:21,633	9793	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py file to destination location: /tmp/glue-job-12877998855152647238/raw_dq_load.py
"
1760373922270,"INFO	2025-10-13T16:45:22,270	10430	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	32	Encoding S3 URI s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
"
1760373922270,"INFO	2025-10-13T16:45:22,270	10430	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	37	Encoded S3 URI to s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
"
1760373922277,"INFO	2025-10-13T16:45:22,277	10437	com.amazonaws.services.glue.FileDownloader	[main]	138	Download bucket: entergy-govdatacore-dataeng-code-repo-dev key: entergy-gov-data-core-code/scripts/raw_dq_load.py to /tmp/glue-job-12877998855152647238/raw_dq_load.py with usingProxy: false and isProxyDisabled: true
"
1760373923389,"INFO	2025-10-13T16:45:23,389	11549	com.amazonaws.services.glue.FileDownloader	[sdk-async-response-2-0]	145	Object downloaded. Details: GetObjectResponse(AcceptRanges=bytes, LastModified=2025-10-13T16:27:35Z, ContentLength=468, ETag=""dd7370b40168a9d31e66ac62284df745"", ContentType=binary/octet-stream, ServerSideEncryption=AES256, Metadata={})
INFO	2025-10-13T16:45:23,389	11549	com.amazonaws.services.glue.launch.helpers.FileManager	[main]	119	Script should be downloaded at /tmp/glue-job-12877998855152647238/raw_dq_load.py 
"
1760373929329,"INFO	2025-10-13T16:45:29,328	17488	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-12877998855152647238/python/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip -d /tmp/glue-job-12877998855152647238/python/ufak9W-AWSGlueDataplanePython-5.0.704
"
1760373929379,"INFO	2025-10-13T16:45:29,378	17538	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-12877998855152647238/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-12877998855152647238/python/ufak9W-AWSGlueDataplanePython-5.0.704/amzn_awsgluelibs-5.0.704-py3-none-any.whl
"
1760373933025,"INFO	2025-10-13T16:45:33,025	21185	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-12877998855152647238/python/yzED3c-AwsGlueMLLibs.py.zip -d /tmp/glue-job-12877998855152647238/python/yzED3c-AwsGlueMLLibs
"
1760373933030,"INFO	2025-10-13T16:45:33,030	21190	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-12877998855152647238/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-12877998855152647238/python/yzED3c-AwsGlueMLLibs/amzn_awsgluemlpythonlibs-1.0-py3-none-any.whl
"
1760373941866,"INFO	2025-10-13T16:45:41,865	30025	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-12877998855152647238/pythonmodules/createvenvzip.sh /tmp/glue_venv /tmp/glue-job-12877998855152647238_glue_venv.zip
"
1760373942035,"INFO	2025-10-13T16:45:42,034	30194	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	39	Setting Up Virtual Env and Application Python Modules has been completed in async mode
"
1760373942042,"INFO	2025-10-13T16:45:42,042	30202	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	50	shutdownAsyncProcessing has been Started
"
1760373942043,"INFO	2025-10-13T16:45:42,043	30203	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	76	shutdownAsyncProcessing has been completed
"
1760373942402,"Launching ...
"
1760373942404,"Mon Oct 13 16:45:42 UTC 2025
"
1760373944351,"INFO	2025-10-13T16:45:44,348	1855	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
"
1760373944601,"INFO	2025-10-13T16:45:44,600	2107	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
"
1760373944744,"INFO	2025-10-13T16:45:44,744	2251	com.amazonaws.services.glue.SafeLogging	[main]	60	Initializing logging subsystem
"
1760373952102,"INFO	2025-10-13T16:45:52,102	9609	org.apache.spark.emr.EMRParamSideChannel	[Thread-7]	177	Setting FGAC mode to false
"
1760373952114,"INFO	2025-10-13T16:45:52,113	9620	org.apache.spark.SparkContext	[Thread-7]	60	Running Spark version 3.5.4-amzn-0
"
1760373952114,"INFO	2025-10-13T16:45:52,114	9621	org.apache.spark.SparkContext	[Thread-7]	60	OS info Linux, 5.10.240-238.966.amzn2.x86_64, amd64
"
1760373952115,"INFO	2025-10-13T16:45:52,115	9622	org.apache.spark.SparkContext	[Thread-7]	60	Java version 17.0.16
"
1760373952273,"INFO	2025-10-13T16:45:52,272	9779	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
"
1760373952273,"INFO	2025-10-13T16:45:52,273	9780	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	No custom resources configured for spark.driver.
"
1760373952274,"INFO	2025-10-13T16:45:52,273	9780	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
"
1760373952274,"INFO	2025-10-13T16:45:52,274	9781	org.apache.spark.SparkContext	[Thread-7]	60	Submitted application: maximo_dq_invuseline
"
1760373952300,"INFO	2025-10-13T16:45:52,300	9807	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Default ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
"
1760373952308,"INFO	2025-10-13T16:45:52,307	9814	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
"
1760373952309,"INFO	2025-10-13T16:45:52,309	9816	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 0
"
1760373952313,"INFO	2025-10-13T16:45:52,312	9819	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	User executor ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
"
1760373952313,"INFO	2025-10-13T16:45:52,313	9820	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
"
1760373952314,"INFO	2025-10-13T16:45:52,313	9820	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 1
"
1760373952458,"INFO	2025-10-13T16:45:52,458	9965	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls to: hadoop
"
1760373952459,"INFO	2025-10-13T16:45:52,458	9965	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls to: hadoop
"
1760373952459,"INFO	2025-10-13T16:45:52,459	9966	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls groups to: 
"
1760373952460,"INFO	2025-10-13T16:45:52,459	9966	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls groups to: 
"
1760373952460,"INFO	2025-10-13T16:45:52,460	9967	org.apache.spark.SecurityManager	[Thread-7]	60	SecurityManager: authentication enabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
"
1760373952839,"INFO	2025-10-13T16:45:52,839	10346	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'sparkDriver' on port 45217.
"
1760373952884,"INFO	2025-10-13T16:45:52,883	10390	org.apache.spark.SparkEnv	[Thread-7]	60	Registering MapOutputTracker
"
1760373952924,"INFO	2025-10-13T16:45:52,924	10431	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMaster
"
1760373952956,"INFO	2025-10-13T16:45:52,955	10462	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
"
1760373952957,"INFO	2025-10-13T16:45:52,956	10463	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	BlockManagerMasterEndpoint up
"
1760373952962,"INFO	2025-10-13T16:45:52,961	10468	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMasterHeartbeat
"
1760373952986,"INFO	2025-10-13T16:45:52,986	10493	org.apache.spark.storage.DiskBlockManager	[Thread-7]	60	Created local directory at /tmp/blockmgr-15e40647-05e8-4c53-9919-2c400396c307
"
1760373953001,"INFO	2025-10-13T16:45:53,000	10507	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	MemoryStore started with capacity 11.8 GiB
"
1760373953017,"INFO	2025-10-13T16:45:53,017	10524	org.apache.spark.SparkEnv	[Thread-7]	60	Registering OutputCommitCoordinator
"
1760373953023,"INFO	2025-10-13T16:45:53,023	10530	org.apache.spark.subresultcache.SubResultCacheManager	[Thread-7]	60	Sub-result caches are disabled.
"
1760373953086,"INFO	2025-10-13T16:45:53,085	10592	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-12877998855152647238/jars/odvJng-aws-glue-di-package-5.0.704.jar at spark://172.34.216.56:45217/jars/odvJng-aws-glue-di-package-5.0.704.jar with timestamp 1760373952104
"
1760373953087,"INFO	2025-10-13T16:45:53,087	10594	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-12877998855152647238/jars/ImuwKQ-AwsGlueMLLibs.jar at spark://172.34.216.56:45217/jars/ImuwKQ-AwsGlueMLLibs.jar with timestamp 1760373952104
"
1760373953235,"INFO	2025-10-13T16:45:53,234	10741	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-12877998855152647238/extra-py-files/mosaic.zip at spark://172.34.216.56:45217/files/mosaic.zip with timestamp 1760373952104
"
1760373953236,"INFO	2025-10-13T16:45:53,236	10743	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12877998855152647238/extra-py-files/mosaic.zip to /tmp/spark-1c64ab29-0127-4caf-a731-51091bf66ccf/userFiles-a8bf8884-c7b0-4c80-8f74-753ff667ab4b/mosaic.zip
"
1760373953248,"INFO	2025-10-13T16:45:53,247	10754	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-12877998855152647238/extra-py-files/yaml.zip at spark://172.34.216.56:45217/files/yaml.zip with timestamp 1760373952104
"
1760373953248,"INFO	2025-10-13T16:45:53,248	10755	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12877998855152647238/extra-py-files/yaml.zip to /tmp/spark-1c64ab29-0127-4caf-a731-51091bf66ccf/userFiles-a8bf8884-c7b0-4c80-8f74-753ff667ab4b/yaml.zip
"
1760373953264,"INFO	2025-10-13T16:45:53,253	10760	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-12877998855152647238/extra-py-files/sqlglot.zip at spark://172.34.216.56:45217/files/sqlglot.zip with timestamp 1760373952104
"
1760373953264,"INFO	2025-10-13T16:45:53,253	10760	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12877998855152647238/extra-py-files/sqlglot.zip to /tmp/spark-1c64ab29-0127-4caf-a731-51091bf66ccf/userFiles-a8bf8884-c7b0-4c80-8f74-753ff667ab4b/sqlglot.zip
"
1760373953331,"INFO	2025-10-13T16:45:53,330	10837	org.apache.spark.SparkContext	[Thread-7]	60	Added archive /tmp/glue-job-12877998855152647238_glue_venv.zip#python_environment at spark://172.34.216.56:45217/files/glue-job-12877998855152647238_glue_venv.zip with timestamp 1760373952104
"
1760373953331,"INFO	2025-10-13T16:45:53,331	10838	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12877998855152647238_glue_venv.zip to /tmp/spark-fdce11ed-4f9f-4482-b121-c0e7162906bc/glue-job-12877998855152647238_glue_venv.zip
"
1760373953345,"INFO	2025-10-13T16:45:53,345	10852	org.apache.spark.SparkContext	[Thread-7]	60	Unpacking an archive /tmp/glue-job-12877998855152647238_glue_venv.zip#python_environment from /tmp/spark-fdce11ed-4f9f-4482-b121-c0e7162906bc/glue-job-12877998855152647238_glue_venv.zip to /tmp/spark-1c64ab29-0127-4caf-a731-51091bf66ccf/userFiles-a8bf8884-c7b0-4c80-8f74-753ff667ab4b/python_environment
"
1760373953909,"INFO	2025-10-13T16:45:53,908	11415	org.apache.spark.scheduler.cluster.glue.JESClusterManager	[Thread-7]	121	Python path for executors: mosaic.zip:yaml.zip:sqlglot.zip:python_environment
"
1760373953911,"INFO	2025-10-13T16:45:53,911	11418	org.apache.spark.deploy.glue.client.GlueRMClientFactory	[Thread-7]	60	JESClusterManager: Initializing JES client with endpoint: https://glue-jes.us-gov-west-1.amazonaws.com
"
1760373954346,"INFO	2025-10-13T16:45:54,346	11853	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	JESSchedulerBackend
"
1760373954348,"INFO	2025-10-13T16:45:54,348	11855	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
"
1760373954384,"INFO	2025-10-13T16:45:54,383	11890	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Starting JES Scheduler Backend.
"
1760373954385,"INFO	2025-10-13T16:45:54,385	11892	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760373954386,"INFO	2025-10-13T16:45:54,385	11892	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Initial executors are 1
"
1760373954391,"INFO	2025-10-13T16:45:54,391	11898	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760373954393,"INFO	2025-10-13T16:45:54,393	11900	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 1, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760373954395,"INFO	2025-10-13T16:45:54,394	11901	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35017.
"
1760373954395,"INFO	2025-10-13T16:45:54,395	11902	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 1; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_1_a_spark-application-1760373954341_p_1
"
1760373954395,"INFO	2025-10-13T16:45:54,395	11902	org.apache.spark.network.netty.NettyBlockTransferService	[Thread-7]	88	Server created on 172.34.216.56:35017
"
1760373954397,"INFO	2025-10-13T16:45:54,397	11904	org.apache.spark.storage.BlockManager	[Thread-7]	60	Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
"
1760373954405,"INFO	2025-10-13T16:45:54,405	11912	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registering BlockManager BlockManagerId(driver, 172.34.216.56, 35017, None)
"
1760373954409,"INFO	2025-10-13T16:45:54,408	11915	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.216.56:35017 with 11.8 GiB RAM, BlockManagerId(driver, 172.34.216.56, 35017, None)
"
1760373954411,"INFO	2025-10-13T16:45:54,410	11917	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registered BlockManager BlockManagerId(driver, 172.34.216.56, 35017, None)
"
1760373954411,"INFO	2025-10-13T16:45:54,411	11918	org.apache.spark.storage.BlockManager	[Thread-7]	60	Initialized BlockManager: BlockManagerId(driver, 172.34.216.56, 35017, None)
"
1760373954413,"INFO	2025-10-13T16:45:54,412	11919	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760373954597,"INFO	2025-10-13T16:45:54,596	12103	org.apache.spark.deploy.history.SingleEventLogFileWriter	[Thread-7]	60	Logging events to file:/var/log/spark/apps/spark-application-1760373954341.inprogress
"
1760373954700,"INFO	2025-10-13T16:45:54,699	12206	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
"
1760373954701,"INFO	2025-10-13T16:45:54,700	12207	org.apache.spark.ExecutorAllocationManager	[Thread-7]	60	Dynamic allocation is enabled without a shuffle service.
"
1760373954716,"INFO	2025-10-13T16:45:54,715	12222	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760373954716,"INFO	2025-10-13T16:45:54,716	12223	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Requested total executors are 1
"
1760373954779,"INFO	2025-10-13T16:45:54,779	12286	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[Thread-7]	51	Started file writer for com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter
"
1760373954791,"INFO	2025-10-13T16:45:54,791	12298	org.apache.spark.SparkContext	[Thread-7]	60	Registered listener com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener
"
1760373954810,"INFO	2025-10-13T16:45:54,807	12314	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	getDriverLogUrls Map()
"
1760373954812,"INFO	2025-10-13T16:45:54,812	12319	org.apache.spark.executor.ExecutorLogUrlHandler	[Thread-7]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
"
1760373954815,"INFO	2025-10-13T16:45:54,815	12322	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
"
1760373955438,"INFO	2025-10-13T16:45:55,438	12945	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760373955439,"INFO	2025-10-13T16:45:55,439	12946	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-0d45eb6437619f682e1908d8d30c4a58b45331d7 created for executor 1 in resource profile 0
"
1760373956224,"INFO	2025-10-13T16:45:56,224	13731	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Setting hive.metastore.warehouse.dir ('/tmp/spark-warehouse') to the value of spark.sql.warehouse.dir.
"
1760373956228,"INFO	2025-10-13T16:45:56,227	13734	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Warehouse path is 'file:/home/hadoop/spark-warehouse'.
"
1760373959612,"INFO	2025-10-13T16:45:59,611	17118	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
"
1760373960530,"WARN	2025-10-13T16:46:00,530	18037	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
"
1760373960531,"INFO	2025-10-13T16:46:00,530	18037	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
"
1760373960669,"INFO	2025-10-13T16:46:00,669	18176	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-raw-dev/maximo_raw.db/invuseline/metadata/00062-237a3a9b-faae-4f18-9d45-3d92894779fd.metadata.json
"
1760373961184,"INFO	2025-10-13T16:46:01,184	18691	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_raw.invuseline
"
1760373961208,"INFO	2025-10-13T16:46:01,207	18714	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_raw.invuseline loaded Spark schema: StructType(StructField(invusenum,StringType,true),StructField(usetype,StringType,true),StructField(itemnum,StringType,true),StructField(itemsetid,StringType,true),StructField(tostoreloc,StringType,true),StructField(tositeid,StringType,true),StructField(quantity,DecimalType(15,2),true),StructField(fromconditioncode,StringType,true),StructField(orgid,StringType,true),StructField(requestnum,StringType,true),StructField(sendersysid,StringType,true),StructField(validated,DecimalType(38,10),true),StructField(financialperiod,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(toconditioncode,StringType,true),StructField(linetype,StringType,true),StructField(remark,StringType,true),StructField(tobin,StringType,true),StructField(tolot,StringType,true),StructField(fromstoreloc,StringType,true),StructField(enterby,StringType,true),StructField(siteid,StringType,true),StructField(invuselinenum,DecimalType(38,10),true),StructField(issueid,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(issueto,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(refwo,StringType,true),StructField(actualdate,TimestampType,true),StructField(conversion,DecimalType(19,6),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(ponum,StringType,true),StructField(porevisionnum,DecimalType(38,10),true),StructField(polinenum,DecimalType(38,10),true),StructField(positeid,StringType,true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(prsiteid,StringType,true),StructField(rotassetnum,StringType,true),StructField(fromlot,StringType,true),StructField(frombin,StringType,true),StructField(physcnt,DecimalType(15,2),true),StructField(physcntdate,TimestampType,true),StructField(split,DecimalType(38,10),true),StructField(newassetnum,StringType,true),StructField(returnagainstissue,DecimalType(38,10),true),StructField(toorgid,StringType,true),StructField(receiptscomplete,DecimalType(38,10),true),StructField(receivedqty,DecimalType(15,2),true),StructField(description,StringType,true),StructField(returnedqty,DecimalType(15,2),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(hasld,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(invpicklistnum,StringType,true),StructField(openqty,DecimalType(15,2),true),StructField(pickedqty,DecimalType(15,2),true),StructField(stagedqty,DecimalType(15,2),true),StructField(issuedqty,DecimalType(15,2),true),StructField(displayname,StringType,true),StructField(etraddress1,StringType,true),StructField(etraddressee,StringType,true),StructField(etraimmwr,DecimalType(38,10),true),StructField(etrbintype,StringType,true),StructField(etrchemctrlnum,StringType,true),StructField(etrcity,StringType,true),StructField(etrcommandpickqty,DecimalType(16,2),true),StructField(etrcountry,StringType,true),StructField(etrdropship,DecimalType(38,10),true),StructField(etrgeocode,StringType,true),StructField(etrissuereason,StringType,true),StructField(etrkit,DecimalType(38,10),true),StructField(etrorigtranstic,StringType,true),StructField(etrpartnum,StringType,true),StructField(etrpostalcode,StringType,true),StructField(etrrequiredby,TimestampType,true),StructField(etrreturnreason,StringType,true),StructField(etrserialnum,StringType,true),StructField(etrshippingnotes,StringType,true),StructField(etrshipto,StringType,true),StructField(etrstateprovince,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrtotaltax,DecimalType(16,2),true),StructField(etrtp,DecimalType(38,10),true),StructField(etrtracetype,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(etrvendor,StringType,true),StructField(shiptoattn,StringType,true),StructField(etrterm,DecimalType(38,10),true),StructField(plustype,StringType,true),StructField(rowstamp,StringType,true),StructField(etrdispcannibalized,StringType,true),StructField(etrdispcapspare,StringType,true),StructField(etrdispclean,StringType,true),StructField(etrdispdamage,StringType,true),StructField(etrdisplowcontrol,StringType,true),StructField(etrdispmark,StringType,true),StructField(etrdispnewitem,StringType,true),StructField(etrdispondemand,StringType,true),StructField(etrdisprepairreq,StringType,true),StructField(etrdispstorage,StringType,true),StructField(etrdisptrace,StringType,true),StructField(etrshipvendor,StringType,true),StructField(etrstagingbin,StringType,true),StructField(etrreturninvreserve,DecimalType(38,10),true),StructField(etractualexpirationdate,TimestampType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760373961597,"INFO	2025-10-13T16:46:01,596	19103	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.46.142:43578) with ID 1,  ResourceProfileId 0
"
1760373961599,"INFO	2025-10-13T16:46:01,598	19105	org.apache.spark.executor.ExecutorLogUrlHandler	[dispatcher-CoarseGrainedScheduler]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
"
1760373961601,"INFO	2025-10-13T16:46:01,600	19107	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 1 @ 1760373961599
"
1760373961601,"INFO	2025-10-13T16:46:01,601	19108	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 1
"
1760373961604,"INFO	2025-10-13T16:46:01,603	19110	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 1 has registered (new total is 1)
"
1760373961661,"INFO	2025-10-13T16:46:01,661	19168	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.46.142:35315 with 11.8 GiB RAM, BlockManagerId(1, 172.34.46.142, 35315, None)
"
1760373962000,"INFO	2025-10-13T16:46:02,000	19507	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
"
1760373962148,"WARN	2025-10-13T16:46:02,147	19654	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
"
1760373962148,"INFO	2025-10-13T16:46:02,148	19655	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
"
1760373962249,"INFO	2025-10-13T16:46:02,248	19755	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-dq-dev/maximo_dq.db/invuseline/metadata/00010-13405169-b972-46a7-8ae2-85e5cd5fea71.metadata.json
"
1760373962355,"INFO	2025-10-13T16:46:02,355	19862	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_dq.invuseline
"
1760373962358,"INFO	2025-10-13T16:46:02,358	19865	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.invuseline loaded Spark schema: StructType(StructField(invusenum,StringType,true),StructField(usetype,StringType,true),StructField(itemnum,StringType,true),StructField(itemsetid,StringType,true),StructField(tostoreloc,StringType,true),StructField(tositeid,StringType,true),StructField(quantity,DecimalType(15,2),true),StructField(fromconditioncode,StringType,true),StructField(orgid,StringType,true),StructField(requestnum,StringType,true),StructField(sendersysid,StringType,true),StructField(validated,DecimalType(38,10),true),StructField(financialperiod,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(toconditioncode,StringType,true),StructField(linetype,StringType,true),StructField(remark,StringType,true),StructField(tobin,StringType,true),StructField(tolot,StringType,true),StructField(fromstoreloc,StringType,true),StructField(enterby,StringType,true),StructField(siteid,StringType,true),StructField(invuselinenum,DecimalType(38,10),true),StructField(issueid,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(issueto,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(refwo,StringType,true),StructField(actualdate,TimestampType,true),StructField(conversion,DecimalType(19,6),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(ponum,StringType,true),StructField(porevisionnum,DecimalType(38,10),true),StructField(polinenum,DecimalType(38,10),true),StructField(positeid,StringType,true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(prsiteid,StringType,true),StructField(rotassetnum,StringType,true),StructField(fromlot,StringType,true),StructField(frombin,StringType,true),StructField(physcnt,DecimalType(15,2),true),StructField(physcntdate,TimestampType,true),StructField(split,DecimalType(38,10),true),StructField(newassetnum,StringType,true),StructField(returnagainstissue,DecimalType(38,10),true),StructField(toorgid,StringType,true),StructField(receiptscomplete,DecimalType(38,10),true),StructField(receivedqty,DecimalType(15,2),true),StructField(description,StringType,true),StructField(returnedqty,DecimalType(15,2),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(hasld,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(invpicklistnum,StringType,true),StructField(openqty,DecimalType(15,2),true),StructField(pickedqty,DecimalType(15,2),true),StructField(stagedqty,DecimalType(15,2),true),StructField(issuedqty,DecimalType(15,2),true),StructField(displayname,StringType,true),StructField(etraddress1,StringType,true),StructField(etraddressee,StringType,true),StructField(etraimmwr,DecimalType(38,10),true),StructField(etrbintype,StringType,true),StructField(etrchemctrlnum,StringType,true),StructField(etrcity,StringType,true),StructField(etrcommandpickqty,DecimalType(16,2),true),StructField(etrcountry,StringType,true),StructField(etrdropship,DecimalType(38,10),true),StructField(etrgeocode,StringType,true),StructField(etrissuereason,StringType,true),StructField(etrkit,DecimalType(38,10),true),StructField(etrorigtranstic,StringType,true),StructField(etrpartnum,StringType,true),StructField(etrpostalcode,StringType,true),StructField(etrrequiredby,TimestampType,true),StructField(etrreturnreason,StringType,true),StructField(etrserialnum,StringType,true),StructField(etrshippingnotes,StringType,true),StructField(etrshipto,StringType,true),StructField(etrstateprovince,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrtotaltax,DecimalType(16,2),true),StructField(etrtp,DecimalType(38,10),true),StructField(etrtracetype,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(etrvendor,StringType,true),StructField(shiptoattn,StringType,true),StructField(etrterm,DecimalType(38,10),true),StructField(plustype,StringType,true),StructField(rowstamp,StringType,true),StructField(etrdispcannibalized,StringType,true),StructField(etrdispcapspare,StringType,true),StructField(etrdispclean,StringType,true),StructField(etrdispdamage,StringType,true),StructField(etrdisplowcontrol,StringType,true),StructField(etrdispmark,StringType,true),StructField(etrdispnewitem,StringType,true),StructField(etrdispondemand,StringType,true),StructField(etrdisprepairreq,StringType,true),StructField(etrdispstorage,StringType,true),StructField(etrdisptrace,StringType,true),StructField(etrshipvendor,StringType,true),StructField(etrstagingbin,StringType,true),StructField(etrreturninvreserve,DecimalType(38,10),true),StructField(etractualexpirationdate,TimestampType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760373964441,"INFO	2025-10-13T16:46:04,441	21948	org.opensearch.hadoop.util.Version	[Thread-7]	143	OpenSearch Hadoop v1.2.0 [2a4148055f]
"
1760373964869,"INFO	2025-10-13T16:46:04,869	22376	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.invuseline loaded Spark schema: StructType(StructField(invusenum,StringType,true),StructField(usetype,StringType,true),StructField(itemnum,StringType,true),StructField(itemsetid,StringType,true),StructField(tostoreloc,StringType,true),StructField(tositeid,StringType,true),StructField(quantity,DecimalType(15,2),true),StructField(fromconditioncode,StringType,true),StructField(orgid,StringType,true),StructField(requestnum,StringType,true),StructField(sendersysid,StringType,true),StructField(validated,DecimalType(38,10),true),StructField(financialperiod,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(toconditioncode,StringType,true),StructField(linetype,StringType,true),StructField(remark,StringType,true),StructField(tobin,StringType,true),StructField(tolot,StringType,true),StructField(fromstoreloc,StringType,true),StructField(enterby,StringType,true),StructField(siteid,StringType,true),StructField(invuselinenum,DecimalType(38,10),true),StructField(issueid,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(issueto,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(refwo,StringType,true),StructField(actualdate,TimestampType,true),StructField(conversion,DecimalType(19,6),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(ponum,StringType,true),StructField(porevisionnum,DecimalType(38,10),true),StructField(polinenum,DecimalType(38,10),true),StructField(positeid,StringType,true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(prsiteid,StringType,true),StructField(rotassetnum,StringType,true),StructField(fromlot,StringType,true),StructField(frombin,StringType,true),StructField(physcnt,DecimalType(15,2),true),StructField(physcntdate,TimestampType,true),StructField(split,DecimalType(38,10),true),StructField(newassetnum,StringType,true),StructField(returnagainstissue,DecimalType(38,10),true),StructField(toorgid,StringType,true),StructField(receiptscomplete,DecimalType(38,10),true),StructField(receivedqty,DecimalType(15,2),true),StructField(description,StringType,true),StructField(returnedqty,DecimalType(15,2),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(hasld,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(invpicklistnum,StringType,true),StructField(openqty,DecimalType(15,2),true),StructField(pickedqty,DecimalType(15,2),true),StructField(stagedqty,DecimalType(15,2),true),StructField(issuedqty,DecimalType(15,2),true),StructField(displayname,StringType,true),StructField(etraddress1,StringType,true),StructField(etraddressee,StringType,true),StructField(etraimmwr,DecimalType(38,10),true),StructField(etrbintype,StringType,true),StructField(etrchemctrlnum,StringType,true),StructField(etrcity,StringType,true),StructField(etrcommandpickqty,DecimalType(16,2),true),StructField(etrcountry,StringType,true),StructField(etrdropship,DecimalType(38,10),true),StructField(etrgeocode,StringType,true),StructField(etrissuereason,StringType,true),StructField(etrkit,DecimalType(38,10),true),StructField(etrorigtranstic,StringType,true),StructField(etrpartnum,StringType,true),StructField(etrpostalcode,StringType,true),StructField(etrrequiredby,TimestampType,true),StructField(etrreturnreason,StringType,true),StructField(etrserialnum,StringType,true),StructField(etrshippingnotes,StringType,true),StructField(etrshipto,StringType,true),StructField(etrstateprovince,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrtotaltax,DecimalType(16,2),true),StructField(etrtp,DecimalType(38,10),true),StructField(etrtracetype,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(etrvendor,StringType,true),StructField(shiptoattn,StringType,true),StructField(etrterm,DecimalType(38,10),true),StructField(plustype,StringType,true),StructField(rowstamp,StringType,true),StructField(etrdispcannibalized,StringType,true),StructField(etrdispcapspare,StringType,true),StructField(etrdispclean,StringType,true),StructField(etrdispdamage,StringType,true),StructField(etrdisplowcontrol,StringType,true),StructField(etrdispmark,StringType,true),StructField(etrdispnewitem,StringType,true),StructField(etrdispondemand,StringType,true),StructField(etrdisprepairreq,StringType,true),StructField(etrdispstorage,StringType,true),StructField(etrdisptrace,StringType,true),StructField(etrshipvendor,StringType,true),StructField(etrstagingbin,StringType,true),StructField(etrreturninvreserve,DecimalType(38,10),true),StructField(etractualexpirationdate,TimestampType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760373964903,"WARN	2025-10-13T16:46:04,903	22410	org.apache.spark.sql.catalyst.util.SparkStringUtils	[Thread-7]	72	Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
"
1760373965367,"INFO	2025-10-13T16:46:05,367	22874	org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown	[Thread-7]	60	
Output: invusenum#0, usetype#1, itemnum#2, itemsetid#3, tostoreloc#4, tositeid#5, quantity#6, fromconditioncode#7, orgid#8, requestnum#9, sendersysid#10, validated#11, financialperiod#12, enteredastask#13, toconditioncode#14, linetype#15, remark#16, tobin#17, tolot#18, fromstoreloc#19, enterby#20, siteid#21, invuselinenum#22, issueid#23, assetnum#24, location#25, issueto#26, gldebitacct#27, glcreditacct#28, refwo#29, actualdate#30, conversion#31, unitcost#32, linecost#33, commoditygroup#34, commodity#35, ponum#36, porevisionnum#37, polinenum#38, positeid#39, mrnum#40, mrlinenum#41, prsiteid#42, rotassetnum#43, fromlot#44, frombin#45, physcnt#46, physcntdate#47, split#48, newassetnum#49, returnagainstissue#50, toorgid#51, receiptscomplete#52, receivedqty#53, description#54, returnedqty#55, inspectionrequired#56, invuselineid#57, hasld#58, langcode#59, invpicklistnum#60, openqty#61, pickedqty#62, stagedqty#63, issuedqty#64, displayname#65, etraddress1#66, etraddressee#67, etraimmwr#68, etrbintype#69, etrchemctrlnum#70, etrcity#71, etrcommandpickqty#72, etrcountry#73, etrdropship#74, etrgeocode#75, etrissuereason#76, etrkit#77, etrorigtranstic#78, etrpartnum#79, etrpostalcode#80, etrrequiredby#81, etrreturnreason#82, etrserialnum#83, etrshippingnotes#84, etrshipto#85, etrstateprovince#86, etrtdwonum#87, etrtotaltax#88, etrtp#89, etrtracetype#90, etrusetaxcode#91, etrvendor#92, shiptoattn#93, etrterm#94, plustype#95, rowstamp#96, etrdispcannibalized#97, etrdispcapspare#98, etrdispclean#99, etrdispdamage#100, etrdisplowcontrol#101, etrdispmark#102, etrdispnewitem#103, etrdispondemand#104, etrdisprepairreq#105, etrdispstorage#106, etrdisptrace#107, etrshipvendor#108, etrstagingbin#109, etrreturninvreserve#110, etractualexpirationdate#111, pk_hash#112, edl_load_date#113
        
"
1760373965377,"INFO	2025-10-13T16:46:05,377	22884	org.apache.iceberg.SnapshotScan	[Thread-7]	124	Scanning table glue_catalog.maximo_raw.invuseline snapshot 2712825793381406464 created at 2025-10-13T05:15:07.706+00:00 with filter true
"
1760373965671,"INFO	2025-10-13T16:46:05,671	23178	org.apache.iceberg.BaseDistributedDataScan	[Thread-7]	278	Planning file tasks locally for table glue_catalog.maximo_raw.invuseline
"
1760373966135,"INFO	2025-10-13T16:46:06,135	23642	org.apache.iceberg.spark.source.SparkPartitioningAwareScan	[Thread-7]	119	Reporting UnknownPartitioning with 590 partition(s) for table glue_catalog.maximo_raw.invuseline
"
1760373966170,"INFO	2025-10-13T16:46:06,170	23677	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	157	Requesting 0 bytes advisory partition size for table glue_catalog.maximo_dq.invuseline
"
1760373966170,"INFO	2025-10-13T16:46:06,170	23677	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	138	Requesting UnspecifiedDistribution as write distribution for table glue_catalog.maximo_dq.invuseline
"
1760373966172,"INFO	2025-10-13T16:46:06,172	23679	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	150	Requesting [] as write ordering for table glue_catalog.maximo_dq.invuseline
"
1760373966443,"INFO	2025-10-13T16:46:06,443	23950	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966468,"INFO	2025-10-13T16:46:06,468	23975	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966473,"INFO	2025-10-13T16:46:06,473	23980	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966488,"INFO	2025-10-13T16:46:06,488	23995	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966495,"INFO	2025-10-13T16:46:06,495	24002	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966502,"INFO	2025-10-13T16:46:06,501	24008	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966503,"INFO	2025-10-13T16:46:06,503	24010	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760373966567,"INFO	2025-10-13T16:46:06,566	24073	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 11.8 GiB)
"
1760373966744,"INFO	2025-10-13T16:46:06,744	24251	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.8 KiB, actual size: 4.8 KiB, free 11.8 GiB)
"
1760373966747,"INFO	2025-10-13T16:46:06,747	24254	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_0_piece0 in memory on 172.34.216.56:35017 (size: 4.8 KiB, free: 11.8 GiB)
"
1760373966750,"INFO	2025-10-13T16:46:06,750	24257	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 0 from broadcast at SparkBatch.java:85
"
1760373967090,"INFO	2025-10-13T16:46:07,090	24597	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1 stored as values in memory (estimated size 32.0 KiB, free 11.8 GiB)
"
1760373967094,"INFO	2025-10-13T16:46:07,093	24600	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KiB, actual size: 4.8 KiB, free 11.8 GiB)
"
1760373967095,"INFO	2025-10-13T16:46:07,094	24601	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.216.56:35017 (size: 4.8 KiB, free: 11.8 GiB)
"
1760373967096,"INFO	2025-10-13T16:46:07,096	24603	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 1 from broadcast at SparkBatch.java:85
"
1760373967269,"INFO	2025-10-13T16:46:07,269	24776	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Registering RDD 5 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
"
1760373967275,"INFO	2025-10-13T16:46:07,274	24781	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Got map stage job 0 (save at NativeMethodAccessorImpl.java:0) with 590 output partitions
"
1760373967275,"INFO	2025-10-13T16:46:07,275	24782	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Final stage: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0)
"
1760373967275,"INFO	2025-10-13T16:46:07,275	24782	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Parents of final stage: List()
"
1760373967277,"INFO	2025-10-13T16:46:07,277	24784	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Missing parents: List()
"
1760373967281,"INFO	2025-10-13T16:46:07,281	24788	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
"
1760373967415,"INFO	2025-10-13T16:46:07,414	24921	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2 stored as values in memory (estimated size 39.4 KiB, free 11.8 GiB)
"
1760373967417,"INFO	2025-10-13T16:46:07,416	24923	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.6 KiB, actual size: 16.6 KiB, free 11.8 GiB)
"
1760373967418,"INFO	2025-10-13T16:46:07,417	24924	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.216.56:35017 (size: 16.6 KiB, free: 11.8 GiB)
"
1760373967418,"INFO	2025-10-13T16:46:07,418	24925	org.apache.spark.SparkContext	[dag-scheduler-event-loop]	60	Created broadcast 2 from broadcast at DAGScheduler.scala:1664
"
1760373967435,"INFO	2025-10-13T16:46:07,434	24941	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting 590 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
"
1760373967436,"INFO	2025-10-13T16:46:07,436	24943	org.apache.spark.scheduler.TaskSchedulerImpl	[dag-scheduler-event-loop]	60	Adding task set 0.0 with 590 tasks resource profile 0
"
1760373967473,"INFO	2025-10-13T16:46:07,472	24979	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 0.0 in stage 0.0 (TID 0) (172.34.46.142, executor 1, partition 0, PROCESS_LOCAL, 44718 bytes) 
"
1760373967476,"INFO	2025-10-13T16:46:07,476	24983	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 1.0 in stage 0.0 (TID 1) (172.34.46.142, executor 1, partition 1, PROCESS_LOCAL, 44960 bytes) 
"
1760373968080,"INFO	2025-10-13T16:46:08,080	25587	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.46.142:35315 (size: 16.6 KiB, free: 11.8 GiB)
"
1760373969407,"INFO	2025-10-13T16:46:09,406	26913	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.46.142:35315 (size: 4.8 KiB, free: 11.8 GiB)
"
1760373986480,"INFO	2025-10-13T16:46:26,479	43986	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 2.0 in stage 0.0 (TID 2) (172.34.46.142, executor 1, partition 2, PROCESS_LOCAL, 44718 bytes) 
"
1760373986483,"INFO	2025-10-13T16:46:26,483	43990	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 3.0 in stage 0.0 (TID 3) (172.34.46.142, executor 1, partition 3, PROCESS_LOCAL, 44101 bytes) 
"
1760373986488,"INFO	2025-10-13T16:46:26,488	43995	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 1.0 in stage 0.0 (TID 1) in 19012 ms on 172.34.46.142 (executor 1) (1/590)
"
1760373986490,"INFO	2025-10-13T16:46:26,489	43996	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 0.0 in stage 0.0 (TID 0) in 19038 ms on 172.34.46.142 (executor 1) (2/590)
"
1760373997398,"INFO	2025-10-13T16:46:37,398	54905	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
"
1760373997399,"INFO	2025-10-13T16:46:37,398	54905	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
"
1760373997400,"INFO	2025-10-13T16:46:37,400	54907	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 1 new executor because tasks are backlogged (new desired total will be 2 for resource profile id: 0)
"
1760373997449,"INFO	2025-10-13T16:46:37,449	54956	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760373997449,"INFO	2025-10-13T16:46:37,449	54956	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 2, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760373997450,"INFO	2025-10-13T16:46:37,449	54956	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 2; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_2_a_spark-application-1760373954341_p_1
"
1760373997450,"INFO	2025-10-13T16:46:37,450	54957	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760373997604,"INFO	2025-10-13T16:46:37,603	55110	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760373997604,"INFO	2025-10-13T16:46:37,604	55111	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-858f76a10df7a9ef597f2988e07617667fbe8f1f created for executor 2 in resource profile 0
"
1760373997824,"INFO	2025-10-13T16:46:37,824	55331	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 4.0 in stage 0.0 (TID 4) (172.34.46.142, executor 1, partition 4, PROCESS_LOCAL, 31630 bytes) 
"
1760373997825,"INFO	2025-10-13T16:46:37,824	55331	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 2.0 in stage 0.0 (TID 2) in 11346 ms on 172.34.46.142 (executor 1) (3/590)
"
1760373999084,"INFO	2025-10-13T16:46:39,084	56591	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 5.0 in stage 0.0 (TID 5) (172.34.46.142, executor 1, partition 5, PROCESS_LOCAL, 31033 bytes) 
"
1760373999085,"INFO	2025-10-13T16:46:39,084	56591	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 3.0 in stage 0.0 (TID 3) in 12602 ms on 172.34.46.142 (executor 1) (4/590)
"
1760374007417,"INFO	2025-10-13T16:46:47,416	64923	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 4
"
1760374007417,"INFO	2025-10-13T16:46:47,417	64924	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 4
"
1760374007417,"INFO	2025-10-13T16:46:47,417	64924	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 2 new executors because tasks are backlogged (new desired total will be 4 for resource profile id: 0)
"
1760374007607,"INFO	2025-10-13T16:46:47,606	65113	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374007607,"INFO	2025-10-13T16:46:47,607	65114	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 3, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374007607,"INFO	2025-10-13T16:46:47,607	65114	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 3; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_3_a_spark-application-1760373954341_p_1
"
1760374007607,"INFO	2025-10-13T16:46:47,607	65114	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374007763,"INFO	2025-10-13T16:46:47,763	65270	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374007763,"INFO	2025-10-13T16:46:47,763	65270	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-d7c50128c13d4d519d2e8d94c7e69749fbfed11a created for executor 3 in resource profile 0
"
1760374007763,"INFO	2025-10-13T16:46:47,763	65270	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374007764,"INFO	2025-10-13T16:46:47,763	65270	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 4, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374007764,"INFO	2025-10-13T16:46:47,763	65270	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 4; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_4_a_spark-application-1760373954341_p_1
"
1760374007764,"INFO	2025-10-13T16:46:47,764	65271	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374007931,"INFO	2025-10-13T16:46:47,931	65438	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374007931,"INFO	2025-10-13T16:46:47,931	65438	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-029966021c631b3da0a76ec469c12414edb39429 created for executor 4 in resource profile 0
"
1760374011687,"INFO	2025-10-13T16:46:51,686	69193	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 6.0 in stage 0.0 (TID 6) (172.34.46.142, executor 1, partition 6, PROCESS_LOCAL, 31033 bytes) 
"
1760374011687,"INFO	2025-10-13T16:46:51,687	69194	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 4.0 in stage 0.0 (TID 4) in 13864 ms on 172.34.46.142 (executor 1) (5/590)
"
1760374012340,"INFO	2025-10-13T16:46:52,340	69847	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 7.0 in stage 0.0 (TID 7) (172.34.46.142, executor 1, partition 7, PROCESS_LOCAL, 31033 bytes) 
"
1760374012341,"INFO	2025-10-13T16:46:52,341	69848	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 5.0 in stage 0.0 (TID 5) in 13257 ms on 172.34.46.142 (executor 1) (6/590)
"
1760374014387,"INFO	2025-10-13T16:46:54,386	71893	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374014387,"INFO	2025-10-13T16:46:54,387	71894	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 4 executor task status
"
1760374014388,"INFO	2025-10-13T16:46:54,388	71895	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling 3 pending JES executor tasks for status
"
1760374014389,"INFO	2025-10-13T16:46:54,389	71896	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-858f76a10df7a9ef597f2988e07617667fbe8f1f
"
1760374014419,"INFO	2025-10-13T16:46:54,418	71925	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 2 g-858f76a10df7a9ef597f2988e07617667fbe8f1f status is RUNNING
"
1760374014419,"INFO	2025-10-13T16:46:54,418	71925	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-029966021c631b3da0a76ec469c12414edb39429
"
1760374014443,"INFO	2025-10-13T16:46:54,443	71950	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 4 g-029966021c631b3da0a76ec469c12414edb39429 status is PENDING_EXECUTION
"
1760374014444,"INFO	2025-10-13T16:46:54,443	71950	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-d7c50128c13d4d519d2e8d94c7e69749fbfed11a
"
1760374014470,"INFO	2025-10-13T16:46:54,469	71976	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 3 g-d7c50128c13d4d519d2e8d94c7e69749fbfed11a status is PENDING_EXECUTION
"
1760374016271,"INFO	2025-10-13T16:46:56,270	73777	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.141.226:33204) with ID 2,  ResourceProfileId 0
"
1760374016271,"INFO	2025-10-13T16:46:56,271	73778	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 2 @ 1760374016271
"
1760374016271,"INFO	2025-10-13T16:46:56,271	73778	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 2
"
1760374016272,"INFO	2025-10-13T16:46:56,271	73778	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 2 has registered (new total is 2)
"
1760374016326,"INFO	2025-10-13T16:46:56,326	73833	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.141.226:43437 with 11.8 GiB RAM, BlockManagerId(2, 172.34.141.226, 43437, None)
"
1760374017100,"INFO	2025-10-13T16:46:57,100	74607	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 8.0 in stage 0.0 (TID 8) (172.34.141.226, executor 2, partition 8, PROCESS_LOCAL, 31033 bytes) 
"
1760374017101,"INFO	2025-10-13T16:46:57,101	74608	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 9.0 in stage 0.0 (TID 9) (172.34.141.226, executor 2, partition 9, PROCESS_LOCAL, 31033 bytes) 
"
1760374017434,"INFO	2025-10-13T16:46:57,433	74940	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 8
"
1760374017434,"INFO	2025-10-13T16:46:57,434	74941	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 8
"
1760374017434,"INFO	2025-10-13T16:46:57,434	74941	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 4 new executors because tasks are backlogged (new desired total will be 8 for resource profile id: 0)
"
1760374017903,"INFO	2025-10-13T16:46:57,903	75410	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.141.226:43437 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374017933,"INFO	2025-10-13T16:46:57,933	75440	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374017934,"INFO	2025-10-13T16:46:57,933	75440	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 5, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374017934,"INFO	2025-10-13T16:46:57,934	75441	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 5; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_5_a_spark-application-1760373954341_p_1
"
1760374017934,"INFO	2025-10-13T16:46:57,934	75441	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374018087,"INFO	2025-10-13T16:46:58,086	75593	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374018087,"INFO	2025-10-13T16:46:58,087	75594	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-a48ac4fcf075ff84022a840bc4fa8ed40f038f8a created for executor 5 in resource profile 0
"
1760374018087,"INFO	2025-10-13T16:46:58,087	75594	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374018087,"INFO	2025-10-13T16:46:58,087	75594	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 6, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374018087,"INFO	2025-10-13T16:46:58,087	75594	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 6; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_6_a_spark-application-1760373954341_p_1
"
1760374018088,"INFO	2025-10-13T16:46:58,088	75595	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374018241,"INFO	2025-10-13T16:46:58,241	75748	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374018241,"INFO	2025-10-13T16:46:58,241	75748	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-ec6aa43c6b37280f51cc9498b8d903e306ae469f created for executor 6 in resource profile 0
"
1760374018241,"INFO	2025-10-13T16:46:58,241	75748	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374018242,"INFO	2025-10-13T16:46:58,241	75748	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 7, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374018242,"INFO	2025-10-13T16:46:58,242	75749	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 7; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_7_a_spark-application-1760373954341_p_1
"
1760374018242,"INFO	2025-10-13T16:46:58,242	75749	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374018408,"INFO	2025-10-13T16:46:58,407	75914	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374018408,"INFO	2025-10-13T16:46:58,407	75914	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-f67ffe5bbff633675f1310894bc753d6013e52c5 created for executor 7 in resource profile 0
"
1760374018408,"INFO	2025-10-13T16:46:58,408	75915	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374018408,"INFO	2025-10-13T16:46:58,408	75915	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 8, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374018408,"INFO	2025-10-13T16:46:58,408	75915	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 8; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_8_a_spark-application-1760373954341_p_1
"
1760374018409,"INFO	2025-10-13T16:46:58,408	75915	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374018574,"INFO	2025-10-13T16:46:58,574	76081	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374018575,"INFO	2025-10-13T16:46:58,574	76081	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-d3bfa02aaffc25fc04bf262e833519bd46fff9b4 created for executor 8 in resource profile 0
"
1760374019079,"INFO	2025-10-13T16:46:59,078	76585	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.141.226:43437 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374020899,"INFO	2025-10-13T16:47:00,899	78406	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.141.1:47472) with ID 4,  ResourceProfileId 0
"
1760374020899,"INFO	2025-10-13T16:47:00,899	78406	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 4 @ 1760374020899
"
1760374020900,"INFO	2025-10-13T16:47:00,899	78406	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 4
"
1760374020900,"INFO	2025-10-13T16:47:00,899	78406	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 4 has registered (new total is 3)
"
1760374020958,"INFO	2025-10-13T16:47:00,957	78464	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.141.1:37349 with 11.8 GiB RAM, BlockManagerId(4, 172.34.141.1, 37349, None)
"
1760374021885,"INFO	2025-10-13T16:47:01,884	79391	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 10.0 in stage 0.0 (TID 10) (172.34.141.1, executor 4, partition 10, PROCESS_LOCAL, 31033 bytes) 
"
1760374021886,"INFO	2025-10-13T16:47:01,885	79392	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 11.0 in stage 0.0 (TID 11) (172.34.141.1, executor 4, partition 11, PROCESS_LOCAL, 31033 bytes) 
"
1760374022681,"INFO	2025-10-13T16:47:02,680	80187	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.141.1:37349 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374024039,"INFO	2025-10-13T16:47:04,038	81545	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.141.1:37349 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374024596,"INFO	2025-10-13T16:47:04,595	82102	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.107.166:37950) with ID 8,  ResourceProfileId 0
"
1760374024596,"INFO	2025-10-13T16:47:04,596	82103	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 8 @ 1760374024596
"
1760374024596,"INFO	2025-10-13T16:47:04,596	82103	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 8
INFO	2025-10-13T16:47:04,596	82103	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 8 has registered (new total is 4)
"
1760374024655,"INFO	2025-10-13T16:47:04,654	82161	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.107.166:39735 with 11.8 GiB RAM, BlockManagerId(8, 172.35.107.166, 39735, None)
"
1760374024879,"INFO	2025-10-13T16:47:04,878	82385	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 12.0 in stage 0.0 (TID 12) (172.34.46.142, executor 1, partition 12, PROCESS_LOCAL, 30451 bytes) 
"
1760374024879,"INFO	2025-10-13T16:47:04,879	82386	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 6.0 in stage 0.0 (TID 6) in 13193 ms on 172.34.46.142 (executor 1) (7/590)
"
1760374025079,"INFO	2025-10-13T16:47:05,079	82586	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.24.244:33100) with ID 3,  ResourceProfileId 0
"
1760374025080,"INFO	2025-10-13T16:47:05,080	82587	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 3 @ 1760374025080
"
1760374025080,"INFO	2025-10-13T16:47:05,080	82587	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 3
"
1760374025080,"INFO	2025-10-13T16:47:05,080	82587	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 3 has registered (new total is 5)
"
1760374025144,"INFO	2025-10-13T16:47:05,144	82651	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.24.244:38267 with 11.8 GiB RAM, BlockManagerId(3, 172.35.24.244, 38267, None)
"
1760374025564,"INFO	2025-10-13T16:47:05,564	83071	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 13.0 in stage 0.0 (TID 13) (172.35.107.166, executor 8, partition 13, PROCESS_LOCAL, 30451 bytes) 
"
1760374025565,"INFO	2025-10-13T16:47:05,565	83072	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 14.0 in stage 0.0 (TID 14) (172.35.107.166, executor 8, partition 14, PROCESS_LOCAL, 30451 bytes) 
"
1760374025753,"INFO	2025-10-13T16:47:05,753	83260	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 15.0 in stage 0.0 (TID 15) (172.34.46.142, executor 1, partition 15, PROCESS_LOCAL, 30451 bytes) 
"
1760374025754,"INFO	2025-10-13T16:47:05,754	83261	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 7.0 in stage 0.0 (TID 7) in 13415 ms on 172.34.46.142 (executor 1) (8/590)
"
1760374025939,"INFO	2025-10-13T16:47:05,938	83445	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.206.195:60516) with ID 6,  ResourceProfileId 0
"
1760374025939,"INFO	2025-10-13T16:47:05,939	83446	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 6 @ 1760374025939
"
1760374025939,"INFO	2025-10-13T16:47:05,939	83446	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 6
"
1760374025939,"INFO	2025-10-13T16:47:05,939	83446	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 6 has registered (new total is 6)
"
1760374025998,"INFO	2025-10-13T16:47:05,997	83504	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 16.0 in stage 0.0 (TID 16) (172.35.24.244, executor 3, partition 16, PROCESS_LOCAL, 30451 bytes) 
"
1760374025998,"INFO	2025-10-13T16:47:05,998	83505	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 17.0 in stage 0.0 (TID 17) (172.35.24.244, executor 3, partition 17, PROCESS_LOCAL, 30451 bytes) 
"
1760374026006,"INFO	2025-10-13T16:47:06,006	83513	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.206.195:44693 with 11.8 GiB RAM, BlockManagerId(6, 172.34.206.195, 44693, None)
"
1760374026255,"INFO	2025-10-13T16:47:06,255	83762	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.194.6:47600) with ID 7,  ResourceProfileId 0
"
1760374026256,"INFO	2025-10-13T16:47:06,255	83762	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 7 @ 1760374026255
"
1760374026256,"INFO	2025-10-13T16:47:06,256	83763	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 7 has registered (new total is 7)
"
1760374026256,"INFO	2025-10-13T16:47:06,256	83763	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 7
"
1760374026317,"INFO	2025-10-13T16:47:06,316	83823	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.194.6:36937 with 11.8 GiB RAM, BlockManagerId(7, 172.34.194.6, 36937, None)
"
1760374026326,"INFO	2025-10-13T16:47:06,326	83833	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.107.166:39735 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374026817,"INFO	2025-10-13T16:47:06,817	84324	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.24.244:38267 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374026945,"INFO	2025-10-13T16:47:06,945	84452	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 18.0 in stage 0.0 (TID 18) (172.34.206.195, executor 6, partition 18, PROCESS_LOCAL, 30451 bytes) 
"
1760374026946,"INFO	2025-10-13T16:47:06,946	84453	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 19.0 in stage 0.0 (TID 19) (172.34.206.195, executor 6, partition 19, PROCESS_LOCAL, 30451 bytes) 
"
1760374027059,"INFO	2025-10-13T16:47:07,059	84566	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.201.115:40434) with ID 5,  ResourceProfileId 0
"
1760374027060,"INFO	2025-10-13T16:47:07,059	84566	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 5 @ 1760374027059
"
1760374027060,"INFO	2025-10-13T16:47:07,060	84567	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 5
"
1760374027060,"INFO	2025-10-13T16:47:07,060	84567	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 5 has registered (new total is 8)
"
1760374027135,"INFO	2025-10-13T16:47:07,135	84642	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.201.115:41815 with 11.8 GiB RAM, BlockManagerId(5, 172.35.201.115, 41815, None)
"
1760374027155,"INFO	2025-10-13T16:47:07,155	84662	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 20.0 in stage 0.0 (TID 20) (172.34.194.6, executor 7, partition 20, PROCESS_LOCAL, 30451 bytes) 
"
1760374027156,"INFO	2025-10-13T16:47:07,156	84663	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 21.0 in stage 0.0 (TID 21) (172.34.194.6, executor 7, partition 21, PROCESS_LOCAL, 30451 bytes) 
"
1760374027451,"INFO	2025-10-13T16:47:07,450	84957	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 16
"
1760374027451,"INFO	2025-10-13T16:47:07,451	84958	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 16
"
1760374027451,"INFO	2025-10-13T16:47:07,451	84958	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 8 new executors because tasks are backlogged (new desired total will be 16 for resource profile id: 0)
"
1760374027577,"INFO	2025-10-13T16:47:07,576	85083	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374027577,"INFO	2025-10-13T16:47:07,577	85084	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 9, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374027577,"INFO	2025-10-13T16:47:07,577	85084	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 9; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_9_a_spark-application-1760373954341_p_1
"
1760374027578,"INFO	2025-10-13T16:47:07,578	85085	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374027659,"INFO	2025-10-13T16:47:07,659	85166	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.107.166:39735 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374027678,"INFO	2025-10-13T16:47:07,678	85185	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.206.195:44693 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374027743,"INFO	2025-10-13T16:47:07,743	85250	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760374027744,"INFO	2025-10-13T16:47:07,743	85250	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-5e7f4886319b17bf5f4225e6945c086ad18e91e5 created for executor 9 in resource profile 0
"
1760374027744,"INFO	2025-10-13T16:47:07,744	85251	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374027744,"INFO	2025-10-13T16:47:07,744	85251	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 10, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374027744,"INFO	2025-10-13T16:47:07,744	85251	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 10; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_10_a_spark-application-1760373954341_p_1
"
1760374027745,"INFO	2025-10-13T16:47:07,744	85251	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374027794,"INFO	2025-10-13T16:47:07,794	85301	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374027796,"INFO	2025-10-13T16:47:07,796	85303	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: aeed1609-dae4-452b-9053-c3a29db71b4b)
"
1760374027797,"INFO	2025-10-13T16:47:07,796	85303	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 10 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374027965,"INFO	2025-10-13T16:47:07,965	85472	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.194.6:36937 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374028094,"INFO	2025-10-13T16:47:08,094	85601	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 22.0 in stage 0.0 (TID 22) (172.35.201.115, executor 5, partition 22, PROCESS_LOCAL, 29287 bytes) 
"
1760374028095,"INFO	2025-10-13T16:47:08,095	85602	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 23.0 in stage 0.0 (TID 23) (172.35.201.115, executor 5, partition 23, PROCESS_LOCAL, 29311 bytes) 
"
1760374028124,"INFO	2025-10-13T16:47:08,123	85630	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.24.244:38267 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374028925,"INFO	2025-10-13T16:47:08,924	86431	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.201.115:41815 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374028996,"INFO	2025-10-13T16:47:08,996	86503	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.206.195:44693 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374029312,"INFO	2025-10-13T16:47:09,311	86818	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.194.6:36937 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374030380,"INFO	2025-10-13T16:47:10,380	87887	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.201.115:41815 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374033744,"INFO	2025-10-13T16:47:13,743	91250	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.27.84:54874) with ID 9,  ResourceProfileId 0
"
1760374033744,"INFO	2025-10-13T16:47:13,744	91251	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 9 @ 1760374033744
"
1760374033744,"INFO	2025-10-13T16:47:13,744	91251	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 9
"
1760374033744,"INFO	2025-10-13T16:47:13,744	91251	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 9 has registered (new total is 9)
"
1760374033803,"INFO	2025-10-13T16:47:13,802	91309	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.27.84:43353 with 11.8 GiB RAM, BlockManagerId(9, 172.34.27.84, 43353, None)
"
1760374034607,"INFO	2025-10-13T16:47:14,606	92113	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 24.0 in stage 0.0 (TID 24) (172.34.27.84, executor 9, partition 24, PROCESS_LOCAL, 29311 bytes) 
"
1760374034607,"INFO	2025-10-13T16:47:14,607	92114	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 25.0 in stage 0.0 (TID 25) (172.34.27.84, executor 9, partition 25, PROCESS_LOCAL, 29311 bytes) 
"
1760374035416,"INFO	2025-10-13T16:47:15,416	92923	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.27.84:43353 (size: 16.6 KiB, free: 11.8 GiB)
"
1760374036723,"INFO	2025-10-13T16:47:16,723	94230	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.27.84:43353 (size: 4.8 KiB, free: 11.8 GiB)
"
1760374037165,"INFO	2025-10-13T16:47:17,165	94672	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 26.0 in stage 0.0 (TID 26) (172.34.46.142, executor 1, partition 26, PROCESS_LOCAL, 29311 bytes) 
"
1760374037166,"INFO	2025-10-13T16:47:17,166	94673	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 12.0 in stage 0.0 (TID 12) in 12287 ms on 172.34.46.142 (executor 1) (9/590)
"
1760374037466,"INFO	2025-10-13T16:47:17,466	94973	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 20
"
1760374037466,"INFO	2025-10-13T16:47:17,466	94973	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 20
"
1760374037466,"INFO	2025-10-13T16:47:17,466	94973	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 4 new executors because tasks are backlogged (new desired total will be 20 for resource profile id: 0)
"
1760374037688,"INFO	2025-10-13T16:47:17,688	95195	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374037688,"INFO	2025-10-13T16:47:17,688	95195	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 11, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374037688,"INFO	2025-10-13T16:47:17,688	95195	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 11; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_11_a_spark-application-1760373954341_p_1
"
1760374037689,"INFO	2025-10-13T16:47:17,689	95196	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374037717,"INFO	2025-10-13T16:47:17,717	95224	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374037717,"INFO	2025-10-13T16:47:17,717	95224	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 24b46f8f-5e37-466a-8b4c-bd770e32c0bb)
"
1760374037718,"INFO	2025-10-13T16:47:17,717	95224	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 11 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374038652,"INFO	2025-10-13T16:47:18,652	96159	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 27.0 in stage 0.0 (TID 27) (172.34.46.142, executor 1, partition 27, PROCESS_LOCAL, 29311 bytes) 
"
1760374038653,"INFO	2025-10-13T16:47:18,653	96160	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 15.0 in stage 0.0 (TID 15) in 12901 ms on 172.34.46.142 (executor 1) (10/590)
"
1760374040053,"INFO	2025-10-13T16:47:20,052	97559	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374040053,"INFO	2025-10-13T16:47:20,053	97560	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 12, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374040053,"INFO	2025-10-13T16:47:20,053	97560	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 12; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_12_a_spark-application-1760373954341_p_1
"
1760374040054,"INFO	2025-10-13T16:47:20,053	97560	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374040083,"INFO	2025-10-13T16:47:20,083	97590	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374040083,"INFO	2025-10-13T16:47:20,083	97590	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 3e710f92-bc85-40bb-a4ec-9d088fa97725)
"
1760374040084,"INFO	2025-10-13T16:47:20,083	97590	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 12 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374041754,"INFO	2025-10-13T16:47:21,754	99261	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 28.0 in stage 0.0 (TID 28) (172.35.201.115, executor 5, partition 28, PROCESS_LOCAL, 29311 bytes) 
"
1760374041755,"INFO	2025-10-13T16:47:21,754	99261	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 22.0 in stage 0.0 (TID 22) in 13660 ms on 172.35.201.115 (executor 5) (11/590)
"
1760374041954,"INFO	2025-10-13T16:47:21,953	99460	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374041954,"INFO	2025-10-13T16:47:21,954	99461	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 13, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374041954,"INFO	2025-10-13T16:47:21,954	99461	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 13; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_13_a_spark-application-1760373954341_p_1
"
1760374041954,"INFO	2025-10-13T16:47:21,954	99461	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374041996,"INFO	2025-10-13T16:47:21,996	99503	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374041997,"INFO	2025-10-13T16:47:21,996	99503	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a9148958-e6ff-4195-846b-506a19474ac9)
"
1760374041997,"INFO	2025-10-13T16:47:21,997	99504	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 13 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374042272,"INFO	2025-10-13T16:47:22,272	99779	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374042273,"INFO	2025-10-13T16:47:22,272	99779	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 14, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374042273,"INFO	2025-10-13T16:47:22,273	99780	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 14; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_14_a_spark-application-1760373954341_p_1
"
1760374042273,"INFO	2025-10-13T16:47:22,273	99780	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374042305,"INFO	2025-10-13T16:47:22,304	99811	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374042305,"INFO	2025-10-13T16:47:22,305	99812	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: adecd053-69b5-481a-aff9-d622421f6019)
"
1760374042305,"INFO	2025-10-13T16:47:22,305	99812	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 14 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374043054,"INFO	2025-10-13T16:47:23,053	100560	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 29.0 in stage 0.0 (TID 29) (172.34.141.226, executor 2, partition 29, PROCESS_LOCAL, 29311 bytes) 
"
1760374043054,"INFO	2025-10-13T16:47:23,054	100561	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 8.0 in stage 0.0 (TID 8) in 25955 ms on 172.34.141.226 (executor 2) (12/590)
"
1760374043481,"INFO	2025-10-13T16:47:23,480	100987	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 30.0 in stage 0.0 (TID 30) (172.34.141.226, executor 2, partition 30, PROCESS_LOCAL, 29311 bytes) 
"
1760374043481,"INFO	2025-10-13T16:47:23,481	100988	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 9.0 in stage 0.0 (TID 9) in 26381 ms on 172.34.141.226 (executor 2) (13/590)
"
1760374048338,"INFO	2025-10-13T16:47:28,338	105845	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374048339,"INFO	2025-10-13T16:47:28,339	105846	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 15, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374048339,"INFO	2025-10-13T16:47:28,339	105846	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 15; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_15_a_spark-application-1760373954341_p_1
"
1760374048339,"INFO	2025-10-13T16:47:28,339	105846	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374048384,"INFO	2025-10-13T16:47:28,384	105891	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374048384,"INFO	2025-10-13T16:47:28,384	105891	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: c88a38a2-0bd5-4c6f-8835-056870dcab67)
"
1760374048384,"INFO	2025-10-13T16:47:28,384	105891	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 15 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374048440,"INFO	2025-10-13T16:47:28,440	105947	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 31.0 in stage 0.0 (TID 31) (172.34.141.1, executor 4, partition 31, PROCESS_LOCAL, 29311 bytes) 
"
1760374048441,"INFO	2025-10-13T16:47:28,441	105948	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 11.0 in stage 0.0 (TID 11) in 26555 ms on 172.34.141.1 (executor 4) (14/590)
"
1760374048660,"INFO	2025-10-13T16:47:28,660	106167	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 32.0 in stage 0.0 (TID 32) (172.34.141.1, executor 4, partition 32, PROCESS_LOCAL, 29311 bytes) 
"
1760374048661,"INFO	2025-10-13T16:47:28,661	106168	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 10.0 in stage 0.0 (TID 10) in 26777 ms on 172.34.141.1 (executor 4) (15/590)
"
1760374048702,"INFO	2025-10-13T16:47:28,701	106208	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 33.0 in stage 0.0 (TID 33) (172.35.107.166, executor 8, partition 33, PROCESS_LOCAL, 29311 bytes) 
"
1760374048703,"INFO	2025-10-13T16:47:28,702	106209	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 13.0 in stage 0.0 (TID 13) in 23138 ms on 172.35.107.166 (executor 8) (16/590)
"
1760374048724,"INFO	2025-10-13T16:47:28,724	106231	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 34.0 in stage 0.0 (TID 34) (172.35.107.166, executor 8, partition 34, PROCESS_LOCAL, 29311 bytes) 
"
1760374048724,"INFO	2025-10-13T16:47:28,724	106231	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 14.0 in stage 0.0 (TID 14) in 23160 ms on 172.35.107.166 (executor 8) (17/590)
"
1760374050066,"INFO	2025-10-13T16:47:30,066	107573	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 35.0 in stage 0.0 (TID 35) (172.35.24.244, executor 3, partition 35, PROCESS_LOCAL, 29311 bytes) 
"
1760374050067,"INFO	2025-10-13T16:47:30,066	107573	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 16.0 in stage 0.0 (TID 16) in 24069 ms on 172.35.24.244 (executor 3) (18/590)
"
1760374050100,"INFO	2025-10-13T16:47:30,099	107606	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 36.0 in stage 0.0 (TID 36) (172.35.24.244, executor 3, partition 36, PROCESS_LOCAL, 29311 bytes) 
"
1760374050100,"INFO	2025-10-13T16:47:30,100	107607	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 17.0 in stage 0.0 (TID 17) in 24102 ms on 172.35.24.244 (executor 3) (19/590)
"
1760374050741,"INFO	2025-10-13T16:47:30,740	108247	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 37.0 in stage 0.0 (TID 37) (172.34.194.6, executor 7, partition 37, PROCESS_LOCAL, 29311 bytes) 
"
1760374050741,"INFO	2025-10-13T16:47:30,741	108248	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 20.0 in stage 0.0 (TID 20) in 23587 ms on 172.34.194.6 (executor 7) (20/590)
"
1760374051066,"INFO	2025-10-13T16:47:31,066	108573	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 38.0 in stage 0.0 (TID 38) (172.34.206.195, executor 6, partition 38, PROCESS_LOCAL, 29311 bytes) 
"
1760374051066,"INFO	2025-10-13T16:47:31,066	108573	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 18.0 in stage 0.0 (TID 18) in 24122 ms on 172.34.206.195 (executor 6) (21/590)
"
1760374051067,"INFO	2025-10-13T16:47:31,067	108574	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 39.0 in stage 0.0 (TID 39) (172.34.206.195, executor 6, partition 39, PROCESS_LOCAL, 29311 bytes) 
"
1760374051068,"INFO	2025-10-13T16:47:31,068	108575	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 19.0 in stage 0.0 (TID 19) in 24123 ms on 172.34.206.195 (executor 6) (22/590)
"
1760374051501,"INFO	2025-10-13T16:47:31,501	109008	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 40.0 in stage 0.0 (TID 40) (172.34.194.6, executor 7, partition 40, PROCESS_LOCAL, 29311 bytes) 
"
1760374051502,"INFO	2025-10-13T16:47:31,501	109008	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 21.0 in stage 0.0 (TID 21) in 24346 ms on 172.34.194.6 (executor 7) (23/590)
"
1760374056060,"INFO	2025-10-13T16:47:36,059	113566	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374056060,"INFO	2025-10-13T16:47:36,060	113567	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 16, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374056060,"INFO	2025-10-13T16:47:36,060	113567	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 16; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_16_a_spark-application-1760373954341_p_1
"
1760374056060,"INFO	2025-10-13T16:47:36,060	113567	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374056093,"INFO	2025-10-13T16:47:36,093	113600	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374056093,"INFO	2025-10-13T16:47:36,093	113600	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 10db44c5-4122-43b7-ab04-3262962d605f)
"
1760374056093,"INFO	2025-10-13T16:47:36,093	113600	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 16 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374060315,"INFO	2025-10-13T16:47:40,314	117821	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 41.0 in stage 0.0 (TID 41) (172.34.46.142, executor 1, partition 41, PROCESS_LOCAL, 29311 bytes) 
"
1760374060315,"INFO	2025-10-13T16:47:40,315	117822	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 26.0 in stage 0.0 (TID 26) in 23151 ms on 172.34.46.142 (executor 1) (24/590)
"
1760374061338,"INFO	2025-10-13T16:47:41,337	118844	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 42.0 in stage 0.0 (TID 42) (172.35.201.115, executor 5, partition 42, PROCESS_LOCAL, 29311 bytes) 
"
1760374061338,"INFO	2025-10-13T16:47:41,338	118845	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 23.0 in stage 0.0 (TID 23) in 33244 ms on 172.35.201.115 (executor 5) (25/590)
"
1760374062295,"INFO	2025-10-13T16:47:42,294	119801	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 43.0 in stage 0.0 (TID 43) (172.34.46.142, executor 1, partition 43, PROCESS_LOCAL, 29311 bytes) 
"
1760374062295,"INFO	2025-10-13T16:47:42,295	119802	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 27.0 in stage 0.0 (TID 27) in 23643 ms on 172.34.46.142 (executor 1) (26/590)
"
1760374067427,"INFO	2025-10-13T16:47:47,426	124933	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 44.0 in stage 0.0 (TID 44) (172.34.27.84, executor 9, partition 44, PROCESS_LOCAL, 29311 bytes) 
"
1760374067427,"INFO	2025-10-13T16:47:47,427	124934	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 25.0 in stage 0.0 (TID 25) in 32820 ms on 172.34.27.84 (executor 9) (27/590)
"
1760374067428,"INFO	2025-10-13T16:47:47,428	124935	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 45.0 in stage 0.0 (TID 45) (172.34.27.84, executor 9, partition 45, PROCESS_LOCAL, 29311 bytes) 
"
1760374067429,"INFO	2025-10-13T16:47:47,429	124936	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 24.0 in stage 0.0 (TID 24) in 32823 ms on 172.34.27.84 (executor 9) (28/590)
"
1760374067725,"INFO	2025-10-13T16:47:47,725	125232	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374067725,"INFO	2025-10-13T16:47:47,725	125232	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 17, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374067725,"INFO	2025-10-13T16:47:47,725	125232	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 17; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_17_a_spark-application-1760373954341_p_1
"
1760374067726,"INFO	2025-10-13T16:47:47,725	125232	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374067761,"INFO	2025-10-13T16:47:47,760	125267	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374067761,"INFO	2025-10-13T16:47:47,761	125268	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 8040e7a7-f923-454e-a8bf-d6a2a5b516c4)
"
1760374067761,"INFO	2025-10-13T16:47:47,761	125268	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 17 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374068418,"INFO	2025-10-13T16:47:48,417	125924	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 46.0 in stage 0.0 (TID 46) (172.35.201.115, executor 5, partition 46, PROCESS_LOCAL, 29311 bytes) 
"
1760374068418,"INFO	2025-10-13T16:47:48,418	125925	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 28.0 in stage 0.0 (TID 28) in 26665 ms on 172.35.201.115 (executor 5) (29/590)
"
1760374070064,"INFO	2025-10-13T16:47:50,063	127570	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 47.0 in stage 0.0 (TID 47) (172.34.141.226, executor 2, partition 47, PROCESS_LOCAL, 29311 bytes) 
"
1760374070064,"INFO	2025-10-13T16:47:50,064	127571	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 29.0 in stage 0.0 (TID 29) in 27011 ms on 172.34.141.226 (executor 2) (30/590)
"
1760374070382,"INFO	2025-10-13T16:47:50,382	127889	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374070383,"INFO	2025-10-13T16:47:50,383	127890	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 18, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374070383,"INFO	2025-10-13T16:47:50,383	127890	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 18; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_18_a_spark-application-1760373954341_p_1
"
1760374070383,"INFO	2025-10-13T16:47:50,383	127890	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374070427,"INFO	2025-10-13T16:47:50,426	127933	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374070427,"INFO	2025-10-13T16:47:50,427	127934	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: dc450f58-f9e4-4c8f-a52f-b78e0e2264eb)
"
1760374070427,"INFO	2025-10-13T16:47:50,427	127934	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 18 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374070642,"INFO	2025-10-13T16:47:50,642	128149	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 48.0 in stage 0.0 (TID 48) (172.34.141.226, executor 2, partition 48, PROCESS_LOCAL, 29311 bytes) 
"
1760374070642,"INFO	2025-10-13T16:47:50,642	128149	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 30.0 in stage 0.0 (TID 30) in 27162 ms on 172.34.141.226 (executor 2) (31/590)
"
1760374071885,"INFO	2025-10-13T16:47:51,884	129391	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 49.0 in stage 0.0 (TID 49) (172.35.107.166, executor 8, partition 49, PROCESS_LOCAL, 29311 bytes) 
"
1760374071885,"INFO	2025-10-13T16:47:51,885	129392	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 33.0 in stage 0.0 (TID 33) in 23184 ms on 172.35.107.166 (executor 8) (32/590)
"
1760374072133,"INFO	2025-10-13T16:47:52,132	129639	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 50.0 in stage 0.0 (TID 50) (172.35.107.166, executor 8, partition 50, PROCESS_LOCAL, 29311 bytes) 
"
1760374072133,"INFO	2025-10-13T16:47:52,133	129640	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 34.0 in stage 0.0 (TID 34) in 23410 ms on 172.35.107.166 (executor 8) (33/590)
"
1760374072486,"INFO	2025-10-13T16:47:52,486	129993	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 51.0 in stage 0.0 (TID 51) (172.34.141.1, executor 4, partition 51, PROCESS_LOCAL, 29311 bytes) 
"
1760374072487,"INFO	2025-10-13T16:47:52,486	129993	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 31.0 in stage 0.0 (TID 31) in 24047 ms on 172.34.141.1 (executor 4) (34/590)
"
1760374072494,"INFO	2025-10-13T16:47:52,494	130001	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 52.0 in stage 0.0 (TID 52) (172.34.141.1, executor 4, partition 52, PROCESS_LOCAL, 29311 bytes) 
"
1760374072494,"INFO	2025-10-13T16:47:52,494	130001	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 32.0 in stage 0.0 (TID 32) in 23834 ms on 172.34.141.1 (executor 4) (35/590)
"
1760374073115,"INFO	2025-10-13T16:47:53,114	130621	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 53.0 in stage 0.0 (TID 53) (172.35.24.244, executor 3, partition 53, PROCESS_LOCAL, 29311 bytes) 
"
1760374073115,"INFO	2025-10-13T16:47:53,115	130622	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 35.0 in stage 0.0 (TID 35) in 23050 ms on 172.35.24.244 (executor 3) (36/590)
"
1760374073148,"INFO	2025-10-13T16:47:53,147	130654	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 54.0 in stage 0.0 (TID 54) (172.35.24.244, executor 3, partition 54, PROCESS_LOCAL, 29311 bytes) 
"
1760374073148,"INFO	2025-10-13T16:47:53,148	130655	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 36.0 in stage 0.0 (TID 36) in 23049 ms on 172.35.24.244 (executor 3) (37/590)
"
1760374073173,"INFO	2025-10-13T16:47:53,173	130680	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 55.0 in stage 0.0 (TID 55) (172.34.194.6, executor 7, partition 55, PROCESS_LOCAL, 29311 bytes) 
"
1760374073174,"INFO	2025-10-13T16:47:53,173	130680	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 37.0 in stage 0.0 (TID 37) in 22433 ms on 172.34.194.6 (executor 7) (38/590)
"
1760374073623,"INFO	2025-10-13T16:47:53,623	131130	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 56.0 in stage 0.0 (TID 56) (172.34.206.195, executor 6, partition 56, PROCESS_LOCAL, 29311 bytes) 
"
1760374073623,"INFO	2025-10-13T16:47:53,623	131130	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 38.0 in stage 0.0 (TID 38) in 22558 ms on 172.34.206.195 (executor 6) (39/590)
"
1760374073791,"INFO	2025-10-13T16:47:53,791	131298	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 57.0 in stage 0.0 (TID 57) (172.34.206.195, executor 6, partition 57, PROCESS_LOCAL, 29311 bytes) 
"
1760374073791,"INFO	2025-10-13T16:47:53,791	131298	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 39.0 in stage 0.0 (TID 39) in 22724 ms on 172.34.206.195 (executor 6) (40/590)
"
1760374074453,"INFO	2025-10-13T16:47:54,453	131960	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374074454,"INFO	2025-10-13T16:47:54,453	131960	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 19, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374074454,"INFO	2025-10-13T16:47:54,454	131961	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 19; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_19_a_spark-application-1760373954341_p_1
"
1760374074454,"INFO	2025-10-13T16:47:54,454	131961	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374074471,"INFO	2025-10-13T16:47:54,471	131978	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374074472,"INFO	2025-10-13T16:47:54,471	131978	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374074492,"INFO	2025-10-13T16:47:54,491	131998	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374074492,"INFO	2025-10-13T16:47:54,491	131998	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 7310bb8a-995e-4060-9559-a51ed767fbce)
"
1760374074492,"INFO	2025-10-13T16:47:54,492	131999	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 19 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374075252,"INFO	2025-10-13T16:47:55,252	132759	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 58.0 in stage 0.0 (TID 58) (172.34.194.6, executor 7, partition 58, PROCESS_LOCAL, 29311 bytes) 
"
1760374075253,"INFO	2025-10-13T16:47:55,253	132760	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 40.0 in stage 0.0 (TID 40) in 23753 ms on 172.34.194.6 (executor 7) (41/590)
"
1760374082385,"INFO	2025-10-13T16:48:02,384	139891	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 59.0 in stage 0.0 (TID 59) (172.34.46.142, executor 1, partition 59, PROCESS_LOCAL, 29311 bytes) 
"
1760374082385,"INFO	2025-10-13T16:48:02,385	139892	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 41.0 in stage 0.0 (TID 41) in 22071 ms on 172.34.46.142 (executor 1) (42/590)
"
1760374082846,"INFO	2025-10-13T16:48:02,846	140353	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374082847,"INFO	2025-10-13T16:48:02,846	140353	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 20, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374082847,"INFO	2025-10-13T16:48:02,846	140353	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 20; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_20_a_spark-application-1760373954341_p_1
"
1760374082847,"INFO	2025-10-13T16:48:02,847	140354	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374082889,"INFO	2025-10-13T16:48:02,889	140396	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374082890,"INFO	2025-10-13T16:48:02,889	140396	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5ebcb484-c8da-4789-b8dc-0c70669925c4)
"
1760374082890,"INFO	2025-10-13T16:48:02,889	140396	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 20 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374084370,"INFO	2025-10-13T16:48:04,370	141877	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374084370,"INFO	2025-10-13T16:48:04,370	141877	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 21, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374084371,"INFO	2025-10-13T16:48:04,370	141877	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 21; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_21_a_spark-application-1760373954341_p_1
"
1760374084371,"INFO	2025-10-13T16:48:04,371	141878	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374084406,"INFO	2025-10-13T16:48:04,406	141913	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 60.0 in stage 0.0 (TID 60) (172.34.46.142, executor 1, partition 60, PROCESS_LOCAL, 29311 bytes) 
"
1760374084407,"INFO	2025-10-13T16:48:04,407	141914	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 43.0 in stage 0.0 (TID 43) in 22113 ms on 172.34.46.142 (executor 1) (43/590)
"
1760374084423,"INFO	2025-10-13T16:48:04,423	141930	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374084423,"INFO	2025-10-13T16:48:04,423	141930	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: cec1b4cf-a1e0-46e3-bc2b-c0860f39e812)
"
1760374084423,"INFO	2025-10-13T16:48:04,423	141930	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 21 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374084814,"INFO	2025-10-13T16:48:04,813	142320	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 61.0 in stage 0.0 (TID 61) (172.35.201.115, executor 5, partition 61, PROCESS_LOCAL, 29311 bytes) 
"
1760374084814,"INFO	2025-10-13T16:48:04,814	142321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 42.0 in stage 0.0 (TID 42) in 23477 ms on 172.35.201.115 (executor 5) (44/590)
"
1760374090074,"INFO	2025-10-13T16:48:10,074	147581	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 62.0 in stage 0.0 (TID 62) (172.34.27.84, executor 9, partition 62, PROCESS_LOCAL, 29311 bytes) 
"
1760374090075,"INFO	2025-10-13T16:48:10,074	147581	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 45.0 in stage 0.0 (TID 45) in 22646 ms on 172.34.27.84 (executor 9) (45/590)
"
1760374090614,"INFO	2025-10-13T16:48:10,613	148120	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 63.0 in stage 0.0 (TID 63) (172.34.27.84, executor 9, partition 63, PROCESS_LOCAL, 29311 bytes) 
"
1760374090614,"INFO	2025-10-13T16:48:10,614	148121	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 44.0 in stage 0.0 (TID 44) in 23188 ms on 172.34.27.84 (executor 9) (46/590)
"
1760374091580,"INFO	2025-10-13T16:48:11,580	149087	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 64.0 in stage 0.0 (TID 64) (172.35.201.115, executor 5, partition 64, PROCESS_LOCAL, 29311 bytes) 
"
1760374091580,"INFO	2025-10-13T16:48:11,580	149087	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 46.0 in stage 0.0 (TID 46) in 23163 ms on 172.35.201.115 (executor 5) (47/590)
"
1760374092425,"INFO	2025-10-13T16:48:12,425	149932	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374092426,"INFO	2025-10-13T16:48:12,426	149933	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 22, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374092426,"INFO	2025-10-13T16:48:12,426	149933	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 22; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_22_a_spark-application-1760373954341_p_1
"
1760374092426,"INFO	2025-10-13T16:48:12,426	149933	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374092459,"INFO	2025-10-13T16:48:12,459	149966	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374092459,"INFO	2025-10-13T16:48:12,459	149966	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 9b02e3b4-6b41-44b4-ac8e-085e8435d2e7)
"
1760374092459,"INFO	2025-10-13T16:48:12,459	149966	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 22 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374094444,"INFO	2025-10-13T16:48:14,443	151950	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 65.0 in stage 0.0 (TID 65) (172.35.107.166, executor 8, partition 65, PROCESS_LOCAL, 29311 bytes) 
"
1760374094444,"INFO	2025-10-13T16:48:14,444	151951	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 49.0 in stage 0.0 (TID 49) in 22560 ms on 172.35.107.166 (executor 8) (48/590)
"
1760374094548,"INFO	2025-10-13T16:48:14,548	152055	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 66.0 in stage 0.0 (TID 66) (172.34.141.226, executor 2, partition 66, PROCESS_LOCAL, 29311 bytes) 
"
1760374094549,"INFO	2025-10-13T16:48:14,548	152055	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 47.0 in stage 0.0 (TID 47) in 24485 ms on 172.34.141.226 (executor 2) (49/590)
"
1760374094769,"INFO	2025-10-13T16:48:14,768	152275	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 67.0 in stage 0.0 (TID 67) (172.35.107.166, executor 8, partition 67, PROCESS_LOCAL, 29311 bytes) 
"
1760374094769,"INFO	2025-10-13T16:48:14,769	152276	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 50.0 in stage 0.0 (TID 50) in 22637 ms on 172.35.107.166 (executor 8) (50/590)
"
1760374095055,"INFO	2025-10-13T16:48:15,054	152561	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 68.0 in stage 0.0 (TID 68) (172.34.194.6, executor 7, partition 68, PROCESS_LOCAL, 29311 bytes) 
"
1760374095055,"INFO	2025-10-13T16:48:15,055	152562	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 55.0 in stage 0.0 (TID 55) in 21883 ms on 172.34.194.6 (executor 7) (51/590)
"
1760374095311,"INFO	2025-10-13T16:48:15,310	152817	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 69.0 in stage 0.0 (TID 69) (172.34.141.226, executor 2, partition 69, PROCESS_LOCAL, 29311 bytes) 
"
1760374095330,"INFO	2025-10-13T16:48:15,311	152818	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 48.0 in stage 0.0 (TID 48) in 24670 ms on 172.34.141.226 (executor 2) (52/590)
"
1760374095517,"INFO	2025-10-13T16:48:15,516	153023	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 70.0 in stage 0.0 (TID 70) (172.34.141.1, executor 4, partition 70, PROCESS_LOCAL, 29311 bytes) 
"
1760374095517,"INFO	2025-10-13T16:48:15,517	153024	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 52.0 in stage 0.0 (TID 52) in 23024 ms on 172.34.141.1 (executor 4) (53/590)
"
1760374095573,"INFO	2025-10-13T16:48:15,573	153080	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 71.0 in stage 0.0 (TID 71) (172.35.24.244, executor 3, partition 71, PROCESS_LOCAL, 29311 bytes) 
"
1760374095574,"INFO	2025-10-13T16:48:15,573	153080	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 53.0 in stage 0.0 (TID 53) in 22459 ms on 172.35.24.244 (executor 3) (54/590)
"
1760374095715,"INFO	2025-10-13T16:48:15,715	153222	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 72.0 in stage 0.0 (TID 72) (172.34.141.1, executor 4, partition 72, PROCESS_LOCAL, 29311 bytes) 
"
1760374095716,"INFO	2025-10-13T16:48:15,715	153222	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 51.0 in stage 0.0 (TID 51) in 23230 ms on 172.34.141.1 (executor 4) (55/590)
"
1760374095735,"INFO	2025-10-13T16:48:15,735	153242	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 73.0 in stage 0.0 (TID 73) (172.35.24.244, executor 3, partition 73, PROCESS_LOCAL, 29311 bytes) 
"
1760374095735,"INFO	2025-10-13T16:48:15,735	153242	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 54.0 in stage 0.0 (TID 54) in 22588 ms on 172.35.24.244 (executor 3) (56/590)
"
1760374096278,"INFO	2025-10-13T16:48:16,278	153785	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 74.0 in stage 0.0 (TID 74) (172.34.206.195, executor 6, partition 74, PROCESS_LOCAL, 29311 bytes) 
"
1760374096279,"INFO	2025-10-13T16:48:16,279	153786	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 56.0 in stage 0.0 (TID 56) in 22657 ms on 172.34.206.195 (executor 6) (57/590)
"
1760374096563,"INFO	2025-10-13T16:48:16,562	154069	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 75.0 in stage 0.0 (TID 75) (172.34.206.195, executor 6, partition 75, PROCESS_LOCAL, 29311 bytes) 
"
1760374096563,"INFO	2025-10-13T16:48:16,563	154070	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 57.0 in stage 0.0 (TID 57) in 22773 ms on 172.34.206.195 (executor 6) (58/590)
"
1760374097532,"INFO	2025-10-13T16:48:17,532	155039	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 76.0 in stage 0.0 (TID 76) (172.34.194.6, executor 7, partition 76, PROCESS_LOCAL, 29311 bytes) 
"
1760374097533,"INFO	2025-10-13T16:48:17,533	155040	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 58.0 in stage 0.0 (TID 58) in 22281 ms on 172.34.194.6 (executor 7) (59/590)
"
1760374103605,"INFO	2025-10-13T16:48:23,605	161112	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 77.0 in stage 0.0 (TID 77) (172.34.46.142, executor 1, partition 77, PROCESS_LOCAL, 29311 bytes) 
"
1760374103606,"INFO	2025-10-13T16:48:23,605	161112	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 59.0 in stage 0.0 (TID 59) in 21221 ms on 172.34.46.142 (executor 1) (60/590)
"
1760374105181,"INFO	2025-10-13T16:48:25,180	162687	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374105181,"INFO	2025-10-13T16:48:25,181	162688	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 23, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374105181,"INFO	2025-10-13T16:48:25,181	162688	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 23; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_23_a_spark-application-1760373954341_p_1
"
1760374105181,"INFO	2025-10-13T16:48:25,181	162688	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374105226,"INFO	2025-10-13T16:48:25,226	162733	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374105226,"INFO	2025-10-13T16:48:25,226	162733	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 102aa205-303d-447c-be61-c94e38ee0ebe)
"
1760374105226,"INFO	2025-10-13T16:48:25,226	162733	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 23 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374106044,"INFO	2025-10-13T16:48:26,043	163550	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 78.0 in stage 0.0 (TID 78) (172.34.46.142, executor 1, partition 78, PROCESS_LOCAL, 29311 bytes) 
"
1760374106044,"INFO	2025-10-13T16:48:26,044	163551	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 60.0 in stage 0.0 (TID 60) in 21639 ms on 172.34.46.142 (executor 1) (61/590)
"
1760374107043,"INFO	2025-10-13T16:48:27,043	164550	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 79.0 in stage 0.0 (TID 79) (172.35.201.115, executor 5, partition 79, PROCESS_LOCAL, 29311 bytes) 
"
1760374107044,"INFO	2025-10-13T16:48:27,044	164551	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 61.0 in stage 0.0 (TID 61) in 22231 ms on 172.35.201.115 (executor 5) (62/590)
"
1760374111489,"INFO	2025-10-13T16:48:31,489	168996	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 80.0 in stage 0.0 (TID 80) (172.34.27.84, executor 9, partition 80, PROCESS_LOCAL, 29311 bytes) 
"
1760374111490,"INFO	2025-10-13T16:48:31,489	168996	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 62.0 in stage 0.0 (TID 62) in 21416 ms on 172.34.27.84 (executor 9) (63/590)
"
1760374111919,"INFO	2025-10-13T16:48:31,919	169426	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 81.0 in stage 0.0 (TID 81) (172.34.27.84, executor 9, partition 81, PROCESS_LOCAL, 29311 bytes) 
"
1760374111920,"INFO	2025-10-13T16:48:31,920	169427	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 63.0 in stage 0.0 (TID 63) in 21306 ms on 172.34.27.84 (executor 9) (64/590)
"
1760374112982,"INFO	2025-10-13T16:48:32,981	170488	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374112982,"INFO	2025-10-13T16:48:32,982	170489	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 24, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374112982,"INFO	2025-10-13T16:48:32,982	170489	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 24; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_24_a_spark-application-1760373954341_p_1
"
1760374112983,"INFO	2025-10-13T16:48:32,982	170489	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374113024,"INFO	2025-10-13T16:48:33,023	170530	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374113024,"INFO	2025-10-13T16:48:33,024	170531	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 118ed2a4-0bbb-410b-b730-f2f2b8ed8d93)
"
1760374113024,"INFO	2025-10-13T16:48:33,024	170531	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 24 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374114233,"INFO	2025-10-13T16:48:34,233	171740	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 82.0 in stage 0.0 (TID 82) (172.35.201.115, executor 5, partition 82, PROCESS_LOCAL, 29311 bytes) 
"
1760374114234,"INFO	2025-10-13T16:48:34,233	171740	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 64.0 in stage 0.0 (TID 64) in 22654 ms on 172.35.201.115 (executor 5) (65/590)
"
1760374116321,"INFO	2025-10-13T16:48:36,321	173828	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 83.0 in stage 0.0 (TID 83) (172.35.107.166, executor 8, partition 83, PROCESS_LOCAL, 29311 bytes) 
"
1760374116322,"INFO	2025-10-13T16:48:36,321	173828	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 65.0 in stage 0.0 (TID 65) in 21878 ms on 172.35.107.166 (executor 8) (66/590)
"
1760374116462,"INFO	2025-10-13T16:48:36,462	173969	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 84.0 in stage 0.0 (TID 84) (172.34.194.6, executor 7, partition 84, PROCESS_LOCAL, 29311 bytes) 
"
1760374116462,"INFO	2025-10-13T16:48:36,462	173969	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 68.0 in stage 0.0 (TID 68) in 21408 ms on 172.34.194.6 (executor 7) (67/590)
"
1760374117158,"INFO	2025-10-13T16:48:37,157	174664	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 85.0 in stage 0.0 (TID 85) (172.35.107.166, executor 8, partition 85, PROCESS_LOCAL, 29311 bytes) 
"
1760374117158,"INFO	2025-10-13T16:48:37,158	174665	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 67.0 in stage 0.0 (TID 67) in 22390 ms on 172.35.107.166 (executor 8) (68/590)
"
1760374117421,"INFO	2025-10-13T16:48:37,420	174927	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 86.0 in stage 0.0 (TID 86) (172.35.24.244, executor 3, partition 86, PROCESS_LOCAL, 29311 bytes) 
"
1760374117421,"INFO	2025-10-13T16:48:37,421	174928	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 71.0 in stage 0.0 (TID 71) in 21849 ms on 172.35.24.244 (executor 3) (69/590)
"
1760374118172,"INFO	2025-10-13T16:48:38,171	175678	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 87.0 in stage 0.0 (TID 87) (172.35.24.244, executor 3, partition 87, PROCESS_LOCAL, 29311 bytes) 
"
1760374118172,"INFO	2025-10-13T16:48:38,172	175679	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 73.0 in stage 0.0 (TID 73) in 22438 ms on 172.35.24.244 (executor 3) (70/590)
"
1760374118372,"INFO	2025-10-13T16:48:38,371	175878	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 88.0 in stage 0.0 (TID 88) (172.34.141.1, executor 4, partition 88, PROCESS_LOCAL, 29311 bytes) 
"
1760374118372,"INFO	2025-10-13T16:48:38,372	175879	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 70.0 in stage 0.0 (TID 70) in 22856 ms on 172.34.141.1 (executor 4) (71/590)
"
1760374118380,"INFO	2025-10-13T16:48:38,380	175887	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 89.0 in stage 0.0 (TID 89) (172.34.141.226, executor 2, partition 89, PROCESS_LOCAL, 29311 bytes) 
"
1760374118381,"INFO	2025-10-13T16:48:38,381	175888	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 66.0 in stage 0.0 (TID 66) in 23833 ms on 172.34.141.226 (executor 2) (72/590)
"
1760374118392,"INFO	2025-10-13T16:48:38,392	175899	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 90.0 in stage 0.0 (TID 90) (172.34.141.1, executor 4, partition 90, PROCESS_LOCAL, 29311 bytes) 
"
1760374118393,"INFO	2025-10-13T16:48:38,392	175899	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 72.0 in stage 0.0 (TID 72) in 22678 ms on 172.34.141.1 (executor 4) (73/590)
"
1760374118709,"INFO	2025-10-13T16:48:38,708	176215	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374118709,"INFO	2025-10-13T16:48:38,709	176216	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 25, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374118709,"INFO	2025-10-13T16:48:38,709	176216	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 25; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_25_a_spark-application-1760373954341_p_1
"
1760374118709,"INFO	2025-10-13T16:48:38,709	176216	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374118714,"INFO	2025-10-13T16:48:38,713	176220	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 91.0 in stage 0.0 (TID 91) (172.34.206.195, executor 6, partition 91, PROCESS_LOCAL, 29311 bytes) 
"
1760374118714,"INFO	2025-10-13T16:48:38,714	176221	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 74.0 in stage 0.0 (TID 74) in 22436 ms on 172.34.206.195 (executor 6) (74/590)
"
1760374118748,"INFO	2025-10-13T16:48:38,747	176254	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374118748,"INFO	2025-10-13T16:48:38,748	176255	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 12db8227-b69a-4097-b138-4d6ea49dcdb1)
"
1760374118748,"INFO	2025-10-13T16:48:38,748	176255	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 25 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374119241,"INFO	2025-10-13T16:48:39,240	176747	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 92.0 in stage 0.0 (TID 92) (172.34.194.6, executor 7, partition 92, PROCESS_LOCAL, 29311 bytes) 
"
1760374119241,"INFO	2025-10-13T16:48:39,241	176748	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 76.0 in stage 0.0 (TID 76) in 21709 ms on 172.34.194.6 (executor 7) (75/590)
"
1760374119476,"INFO	2025-10-13T16:48:39,475	176982	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 93.0 in stage 0.0 (TID 93) (172.34.141.226, executor 2, partition 93, PROCESS_LOCAL, 29311 bytes) 
"
1760374119476,"INFO	2025-10-13T16:48:39,476	176983	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 69.0 in stage 0.0 (TID 69) in 24166 ms on 172.34.141.226 (executor 2) (76/590)
"
1760374119536,"INFO	2025-10-13T16:48:39,536	177043	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 94.0 in stage 0.0 (TID 94) (172.34.206.195, executor 6, partition 94, PROCESS_LOCAL, 29311 bytes) 
"
1760374119537,"INFO	2025-10-13T16:48:39,537	177044	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 75.0 in stage 0.0 (TID 75) in 22974 ms on 172.34.206.195 (executor 6) (77/590)
"
1760374124793,"INFO	2025-10-13T16:48:44,792	182299	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 95.0 in stage 0.0 (TID 95) (172.34.46.142, executor 1, partition 95, PROCESS_LOCAL, 29311 bytes) 
"
1760374124793,"INFO	2025-10-13T16:48:44,793	182300	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 77.0 in stage 0.0 (TID 77) in 21189 ms on 172.34.46.142 (executor 1) (78/590)
"
1760374126567,"INFO	2025-10-13T16:48:46,567	184074	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374126568,"INFO	2025-10-13T16:48:46,567	184074	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 26, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374126568,"INFO	2025-10-13T16:48:46,568	184075	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 26; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_26_a_spark-application-1760373954341_p_1
"
1760374126568,"INFO	2025-10-13T16:48:46,568	184075	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374126609,"INFO	2025-10-13T16:48:46,609	184116	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374126609,"INFO	2025-10-13T16:48:46,609	184116	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: acd2db14-9134-4aef-9cc6-ca5006a23c1a)
"
1760374126609,"INFO	2025-10-13T16:48:46,609	184116	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 26 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374127319,"INFO	2025-10-13T16:48:47,319	184826	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 96.0 in stage 0.0 (TID 96) (172.34.46.142, executor 1, partition 96, PROCESS_LOCAL, 29311 bytes) 
"
1760374127320,"INFO	2025-10-13T16:48:47,319	184826	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 78.0 in stage 0.0 (TID 78) in 21276 ms on 172.34.46.142 (executor 1) (79/590)
"
1760374129872,"INFO	2025-10-13T16:48:49,871	187378	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 97.0 in stage 0.0 (TID 97) (172.35.201.115, executor 5, partition 97, PROCESS_LOCAL, 29311 bytes) 
"
1760374129872,"INFO	2025-10-13T16:48:49,872	187379	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 79.0 in stage 0.0 (TID 79) in 22829 ms on 172.35.201.115 (executor 5) (80/590)
"
1760374132841,"INFO	2025-10-13T16:48:52,840	190347	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 98.0 in stage 0.0 (TID 98) (172.34.27.84, executor 9, partition 98, PROCESS_LOCAL, 29311 bytes) 
"
1760374132841,"INFO	2025-10-13T16:48:52,841	190348	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 80.0 in stage 0.0 (TID 80) in 21353 ms on 172.34.27.84 (executor 9) (81/590)
"
1760374133593,"INFO	2025-10-13T16:48:53,592	191099	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 99.0 in stage 0.0 (TID 99) (172.34.27.84, executor 9, partition 99, PROCESS_LOCAL, 29311 bytes) 
"
1760374133593,"INFO	2025-10-13T16:48:53,593	191100	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 81.0 in stage 0.0 (TID 81) in 21674 ms on 172.34.27.84 (executor 9) (82/590)
"
1760374134472,"INFO	2025-10-13T16:48:54,472	191979	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374134472,"INFO	2025-10-13T16:48:54,472	191979	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374135275,"INFO	2025-10-13T16:48:55,274	192781	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374135275,"INFO	2025-10-13T16:48:55,275	192782	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 27, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374135275,"INFO	2025-10-13T16:48:55,275	192782	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 27; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_27_a_spark-application-1760373954341_p_1
"
1760374135275,"INFO	2025-10-13T16:48:55,275	192782	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374135317,"INFO	2025-10-13T16:48:55,317	192824	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374135318,"INFO	2025-10-13T16:48:55,317	192824	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: e44f0961-f41e-4f0d-a224-8b7eacfebfee)
"
1760374135318,"INFO	2025-10-13T16:48:55,317	192824	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 27 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374136588,"INFO	2025-10-13T16:48:56,588	194095	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 100.0 in stage 0.0 (TID 100) (172.35.201.115, executor 5, partition 100, PROCESS_LOCAL, 29311 bytes) 
"
1760374136588,"INFO	2025-10-13T16:48:56,588	194095	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 82.0 in stage 0.0 (TID 82) in 22356 ms on 172.35.201.115 (executor 5) (83/590)
"
1760374138102,"INFO	2025-10-13T16:48:58,102	195609	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 101.0 in stage 0.0 (TID 101) (172.34.194.6, executor 7, partition 101, PROCESS_LOCAL, 29311 bytes) 
"
1760374138103,"INFO	2025-10-13T16:48:58,102	195609	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 84.0 in stage 0.0 (TID 84) in 21641 ms on 172.34.194.6 (executor 7) (84/590)
"
1760374138231,"INFO	2025-10-13T16:48:58,230	195737	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 102.0 in stage 0.0 (TID 102) (172.35.107.166, executor 8, partition 102, PROCESS_LOCAL, 29311 bytes) 
"
1760374138231,"INFO	2025-10-13T16:48:58,231	195738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 83.0 in stage 0.0 (TID 83) in 21911 ms on 172.35.107.166 (executor 8) (85/590)
"
1760374138876,"INFO	2025-10-13T16:48:58,876	196383	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 103.0 in stage 0.0 (TID 103) (172.35.24.244, executor 3, partition 103, PROCESS_LOCAL, 29311 bytes) 
"
1760374138877,"INFO	2025-10-13T16:48:58,876	196383	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 86.0 in stage 0.0 (TID 86) in 21456 ms on 172.35.24.244 (executor 3) (86/590)
"
1760374139242,"INFO	2025-10-13T16:48:59,241	196748	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 104.0 in stage 0.0 (TID 104) (172.35.107.166, executor 8, partition 104, PROCESS_LOCAL, 29311 bytes) 
"
1760374139242,"INFO	2025-10-13T16:48:59,242	196749	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 85.0 in stage 0.0 (TID 85) in 22085 ms on 172.35.107.166 (executor 8) (87/590)
"
1760374139649,"INFO	2025-10-13T16:48:59,648	197155	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 105.0 in stage 0.0 (TID 105) (172.35.24.244, executor 3, partition 105, PROCESS_LOCAL, 29311 bytes) 
"
1760374139649,"INFO	2025-10-13T16:48:59,649	197156	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 87.0 in stage 0.0 (TID 87) in 21478 ms on 172.35.24.244 (executor 3) (88/590)
"
1760374140316,"INFO	2025-10-13T16:49:00,316	197823	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374140320,"INFO	2025-10-13T16:49:00,316	197823	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 28, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374140321,"INFO	2025-10-13T16:49:00,317	197824	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 28; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_28_a_spark-application-1760373954341_p_1
"
1760374140321,"INFO	2025-10-13T16:49:00,317	197824	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374140353,"INFO	2025-10-13T16:49:00,353	197860	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374140354,"INFO	2025-10-13T16:49:00,353	197860	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 0c925c4e-e318-46fe-be8e-542514261997)
"
1760374140354,"INFO	2025-10-13T16:49:00,353	197860	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 28 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374140963,"INFO	2025-10-13T16:49:00,963	198470	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 106.0 in stage 0.0 (TID 106) (172.34.141.1, executor 4, partition 106, PROCESS_LOCAL, 29311 bytes) 
"
1760374140964,"INFO	2025-10-13T16:49:00,964	198471	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 88.0 in stage 0.0 (TID 88) in 22592 ms on 172.34.141.1 (executor 4) (89/590)
"
1760374141200,"INFO	2025-10-13T16:49:01,200	198707	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 107.0 in stage 0.0 (TID 107) (172.34.194.6, executor 7, partition 107, PROCESS_LOCAL, 29311 bytes) 
"
1760374141201,"INFO	2025-10-13T16:49:01,201	198708	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 92.0 in stage 0.0 (TID 92) in 21961 ms on 172.34.194.6 (executor 7) (90/590)
"
1760374141348,"INFO	2025-10-13T16:49:01,348	198855	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 108.0 in stage 0.0 (TID 108) (172.34.206.195, executor 6, partition 108, PROCESS_LOCAL, 29311 bytes) 
"
1760374141349,"INFO	2025-10-13T16:49:01,348	198855	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 91.0 in stage 0.0 (TID 91) in 22635 ms on 172.34.206.195 (executor 6) (91/590)
"
1760374141455,"INFO	2025-10-13T16:49:01,455	198962	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 109.0 in stage 0.0 (TID 109) (172.34.141.1, executor 4, partition 109, PROCESS_LOCAL, 29311 bytes) 
"
1760374141456,"INFO	2025-10-13T16:49:01,455	198962	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 90.0 in stage 0.0 (TID 90) in 23063 ms on 172.34.141.1 (executor 4) (92/590)
"
1760374142323,"INFO	2025-10-13T16:49:02,323	199830	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 110.0 in stage 0.0 (TID 110) (172.34.141.226, executor 2, partition 110, PROCESS_LOCAL, 29311 bytes) 
"
1760374142323,"INFO	2025-10-13T16:49:02,323	199830	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 89.0 in stage 0.0 (TID 89) in 23943 ms on 172.34.141.226 (executor 2) (93/590)
"
1760374142529,"INFO	2025-10-13T16:49:02,528	200035	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 111.0 in stage 0.0 (TID 111) (172.34.206.195, executor 6, partition 111, PROCESS_LOCAL, 29311 bytes) 
"
1760374142529,"INFO	2025-10-13T16:49:02,529	200036	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 94.0 in stage 0.0 (TID 94) in 22993 ms on 172.34.206.195 (executor 6) (94/590)
"
1760374143853,"INFO	2025-10-13T16:49:03,853	201360	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374143853,"INFO	2025-10-13T16:49:03,853	201360	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 29, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374143853,"INFO	2025-10-13T16:49:03,853	201360	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 29; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_29_a_spark-application-1760373954341_p_1
"
1760374143854,"INFO	2025-10-13T16:49:03,853	201360	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374143899,"INFO	2025-10-13T16:49:03,898	201405	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374143899,"INFO	2025-10-13T16:49:03,899	201406	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a54c5e42-7663-4b31-ad41-92b8c091cc6c)
"
1760374143899,"INFO	2025-10-13T16:49:03,899	201406	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 29 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374143975,"INFO	2025-10-13T16:49:03,975	201482	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 112.0 in stage 0.0 (TID 112) (172.34.141.226, executor 2, partition 112, PROCESS_LOCAL, 29311 bytes) 
"
1760374143975,"INFO	2025-10-13T16:49:03,975	201482	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 93.0 in stage 0.0 (TID 93) in 24500 ms on 172.34.141.226 (executor 2) (95/590)
"
1760374145941,"INFO	2025-10-13T16:49:05,941	203448	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 113.0 in stage 0.0 (TID 113) (172.34.46.142, executor 1, partition 113, PROCESS_LOCAL, 29311 bytes) 
"
1760374145942,"INFO	2025-10-13T16:49:05,942	203449	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 95.0 in stage 0.0 (TID 95) in 21150 ms on 172.34.46.142 (executor 1) (96/590)
"
1760374148961,"INFO	2025-10-13T16:49:08,960	206467	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 114.0 in stage 0.0 (TID 114) (172.34.46.142, executor 1, partition 114, PROCESS_LOCAL, 29311 bytes) 
"
1760374148961,"INFO	2025-10-13T16:49:08,961	206468	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 96.0 in stage 0.0 (TID 96) in 21643 ms on 172.34.46.142 (executor 1) (97/590)
"
1760374151917,"INFO	2025-10-13T16:49:11,917	209424	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 115.0 in stage 0.0 (TID 115) (172.35.201.115, executor 5, partition 115, PROCESS_LOCAL, 29311 bytes) 
"
1760374151918,"INFO	2025-10-13T16:49:11,917	209424	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 97.0 in stage 0.0 (TID 97) in 22046 ms on 172.35.201.115 (executor 5) (98/590)
"
1760374153774,"INFO	2025-10-13T16:49:13,773	211280	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 116.0 in stage 0.0 (TID 116) (172.34.27.84, executor 9, partition 116, PROCESS_LOCAL, 29311 bytes) 
"
1760374153774,"INFO	2025-10-13T16:49:13,774	211281	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 98.0 in stage 0.0 (TID 98) in 20934 ms on 172.34.27.84 (executor 9) (99/590)
"
1760374155032,"INFO	2025-10-13T16:49:15,032	212539	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374155032,"INFO	2025-10-13T16:49:15,032	212539	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 30, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374155033,"INFO	2025-10-13T16:49:15,032	212539	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 30; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_30_a_spark-application-1760373954341_p_1
"
1760374155033,"INFO	2025-10-13T16:49:15,033	212540	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374155062,"INFO	2025-10-13T16:49:15,061	212568	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374155062,"INFO	2025-10-13T16:49:15,062	212569	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 59380030-536f-4dc2-914a-3020ce63b0f6)
"
1760374155062,"INFO	2025-10-13T16:49:15,062	212569	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 30 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374155085,"INFO	2025-10-13T16:49:15,085	212592	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 117.0 in stage 0.0 (TID 117) (172.34.27.84, executor 9, partition 117, PROCESS_LOCAL, 29311 bytes) 
"
1760374155086,"INFO	2025-10-13T16:49:15,085	212592	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 99.0 in stage 0.0 (TID 99) in 21493 ms on 172.34.27.84 (executor 9) (100/590)
"
1760374158528,"INFO	2025-10-13T16:49:18,527	216034	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 118.0 in stage 0.0 (TID 118) (172.35.201.115, executor 5, partition 118, PROCESS_LOCAL, 29311 bytes) 
"
1760374158528,"INFO	2025-10-13T16:49:18,528	216035	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 100.0 in stage 0.0 (TID 100) in 21941 ms on 172.35.201.115 (executor 5) (101/590)
"
1760374159421,"INFO	2025-10-13T16:49:19,421	216928	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 119.0 in stage 0.0 (TID 119) (172.34.194.6, executor 7, partition 119, PROCESS_LOCAL, 29311 bytes) 
"
1760374159421,"INFO	2025-10-13T16:49:19,421	216928	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 101.0 in stage 0.0 (TID 101) in 21320 ms on 172.34.194.6 (executor 7) (102/590)
"
1760374160252,"INFO	2025-10-13T16:49:20,251	217758	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 120.0 in stage 0.0 (TID 120) (172.35.24.244, executor 3, partition 120, PROCESS_LOCAL, 29311 bytes) 
"
1760374160252,"INFO	2025-10-13T16:49:20,252	217759	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 103.0 in stage 0.0 (TID 103) in 21377 ms on 172.35.24.244 (executor 3) (103/590)
"
1760374161074,"INFO	2025-10-13T16:49:21,074	218581	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 121.0 in stage 0.0 (TID 121) (172.35.107.166, executor 8, partition 121, PROCESS_LOCAL, 29311 bytes) 
"
1760374161075,"INFO	2025-10-13T16:49:21,075	218582	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 102.0 in stage 0.0 (TID 102) in 22844 ms on 172.35.107.166 (executor 8) (104/590)
"
1760374161467,"INFO	2025-10-13T16:49:21,467	218974	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 122.0 in stage 0.0 (TID 122) (172.35.24.244, executor 3, partition 122, PROCESS_LOCAL, 29311 bytes) 
"
1760374161468,"INFO	2025-10-13T16:49:21,467	218974	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 105.0 in stage 0.0 (TID 105) in 21819 ms on 172.35.24.244 (executor 3) (105/590)
"
1760374162583,"INFO	2025-10-13T16:49:22,582	220089	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 123.0 in stage 0.0 (TID 123) (172.35.107.166, executor 8, partition 123, PROCESS_LOCAL, 29311 bytes) 
"
1760374162583,"INFO	2025-10-13T16:49:22,583	220090	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 104.0 in stage 0.0 (TID 104) in 23342 ms on 172.35.107.166 (executor 8) (106/590)
"
1760374162647,"INFO	2025-10-13T16:49:22,646	220153	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 124.0 in stage 0.0 (TID 124) (172.34.194.6, executor 7, partition 124, PROCESS_LOCAL, 29311 bytes) 
"
1760374162647,"INFO	2025-10-13T16:49:22,647	220154	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 107.0 in stage 0.0 (TID 107) in 21447 ms on 172.34.194.6 (executor 7) (107/590)
"
1760374163529,"INFO	2025-10-13T16:49:23,528	221035	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 125.0 in stage 0.0 (TID 125) (172.34.141.1, executor 4, partition 125, PROCESS_LOCAL, 29311 bytes) 
"
1760374163529,"INFO	2025-10-13T16:49:23,529	221036	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 106.0 in stage 0.0 (TID 106) in 22566 ms on 172.34.141.1 (executor 4) (108/590)
"
1760374163900,"INFO	2025-10-13T16:49:23,899	221406	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 126.0 in stage 0.0 (TID 126) (172.34.206.195, executor 6, partition 126, PROCESS_LOCAL, 29311 bytes) 
"
1760374163900,"INFO	2025-10-13T16:49:23,900	221407	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 108.0 in stage 0.0 (TID 108) in 22552 ms on 172.34.206.195 (executor 6) (109/590)
"
1760374164051,"INFO	2025-10-13T16:49:24,050	221557	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 127.0 in stage 0.0 (TID 127) (172.34.141.1, executor 4, partition 127, PROCESS_LOCAL, 29311 bytes) 
"
1760374164051,"INFO	2025-10-13T16:49:24,051	221558	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 109.0 in stage 0.0 (TID 109) in 22597 ms on 172.34.141.1 (executor 4) (110/590)
"
1760374165441,"INFO	2025-10-13T16:49:25,441	222948	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 128.0 in stage 0.0 (TID 128) (172.34.206.195, executor 6, partition 128, PROCESS_LOCAL, 29311 bytes) 
"
1760374165441,"INFO	2025-10-13T16:49:25,441	222948	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 111.0 in stage 0.0 (TID 111) in 22913 ms on 172.34.206.195 (executor 6) (111/590)
"
1760374166218,"INFO	2025-10-13T16:49:26,217	223724	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 129.0 in stage 0.0 (TID 129) (172.34.141.226, executor 2, partition 129, PROCESS_LOCAL, 29311 bytes) 
"
1760374166218,"INFO	2025-10-13T16:49:26,218	223725	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 110.0 in stage 0.0 (TID 110) in 23896 ms on 172.34.141.226 (executor 2) (112/590)
"
1760374167247,"INFO	2025-10-13T16:49:27,246	224753	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 130.0 in stage 0.0 (TID 130) (172.34.46.142, executor 1, partition 130, PROCESS_LOCAL, 29311 bytes) 
"
1760374167247,"INFO	2025-10-13T16:49:27,247	224754	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 113.0 in stage 0.0 (TID 113) in 21306 ms on 172.34.46.142 (executor 1) (113/590)
"
1760374167529,"INFO	2025-10-13T16:49:27,529	225036	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374167530,"INFO	2025-10-13T16:49:27,529	225036	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 31, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374167530,"INFO	2025-10-13T16:49:27,530	225037	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 31; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_31_a_spark-application-1760373954341_p_1
"
1760374167530,"INFO	2025-10-13T16:49:27,530	225037	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374167567,"INFO	2025-10-13T16:49:27,567	225074	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374167567,"INFO	2025-10-13T16:49:27,567	225074	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 75d88ca6-4bf5-4735-aaea-5160ca753dd5)
"
1760374167567,"INFO	2025-10-13T16:49:27,567	225074	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 31 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374167941,"INFO	2025-10-13T16:49:27,940	225447	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 131.0 in stage 0.0 (TID 131) (172.34.141.226, executor 2, partition 131, PROCESS_LOCAL, 29311 bytes) 
"
1760374167941,"INFO	2025-10-13T16:49:27,941	225448	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 112.0 in stage 0.0 (TID 112) in 23967 ms on 172.34.141.226 (executor 2) (114/590)
"
1760374170396,"INFO	2025-10-13T16:49:30,395	227902	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 132.0 in stage 0.0 (TID 132) (172.34.46.142, executor 1, partition 132, PROCESS_LOCAL, 29311 bytes) 
"
1760374170396,"INFO	2025-10-13T16:49:30,396	227903	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 114.0 in stage 0.0 (TID 114) in 21436 ms on 172.34.46.142 (executor 1) (115/590)
"
1760374173625,"INFO	2025-10-13T16:49:33,624	231131	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374173625,"INFO	2025-10-13T16:49:33,625	231132	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 32, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374173625,"INFO	2025-10-13T16:49:33,625	231132	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 32; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_32_a_spark-application-1760373954341_p_1
"
1760374173625,"INFO	2025-10-13T16:49:33,625	231132	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374173660,"INFO	2025-10-13T16:49:33,659	231166	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374173660,"INFO	2025-10-13T16:49:33,660	231167	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: fb995f42-c1c5-41b5-902c-f6a32d6234c6)
"
1760374173660,"INFO	2025-10-13T16:49:33,660	231167	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 32 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374174136,"INFO	2025-10-13T16:49:34,136	231643	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 133.0 in stage 0.0 (TID 133) (172.35.201.115, executor 5, partition 133, PROCESS_LOCAL, 29311 bytes) 
"
1760374174137,"INFO	2025-10-13T16:49:34,136	231643	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 115.0 in stage 0.0 (TID 115) in 22219 ms on 172.35.201.115 (executor 5) (116/590)
"
1760374175297,"INFO	2025-10-13T16:49:35,297	232804	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 134.0 in stage 0.0 (TID 134) (172.34.27.84, executor 9, partition 134, PROCESS_LOCAL, 29311 bytes) 
"
1760374175298,"INFO	2025-10-13T16:49:35,297	232804	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 116.0 in stage 0.0 (TID 116) in 21524 ms on 172.34.27.84 (executor 9) (117/590)
"
1760374176611,"INFO	2025-10-13T16:49:36,611	234118	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 135.0 in stage 0.0 (TID 135) (172.34.27.84, executor 9, partition 135, PROCESS_LOCAL, 29311 bytes) 
"
1760374176611,"INFO	2025-10-13T16:49:36,611	234118	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 117.0 in stage 0.0 (TID 117) in 21526 ms on 172.34.27.84 (executor 9) (118/590)
"
1760374180612,"INFO	2025-10-13T16:49:40,612	238119	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 136.0 in stage 0.0 (TID 136) (172.35.201.115, executor 5, partition 136, PROCESS_LOCAL, 29311 bytes) 
"
1760374180612,"INFO	2025-10-13T16:49:40,612	238119	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 118.0 in stage 0.0 (TID 118) in 22085 ms on 172.35.201.115 (executor 5) (119/590)
"
1760374180854,"INFO	2025-10-13T16:49:40,854	238361	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 137.0 in stage 0.0 (TID 137) (172.34.194.6, executor 7, partition 137, PROCESS_LOCAL, 29311 bytes) 
"
1760374180854,"INFO	2025-10-13T16:49:40,854	238361	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 119.0 in stage 0.0 (TID 119) in 21434 ms on 172.34.194.6 (executor 7) (120/590)
"
1760374181788,"INFO	2025-10-13T16:49:41,788	239295	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 138.0 in stage 0.0 (TID 138) (172.35.24.244, executor 3, partition 138, PROCESS_LOCAL, 29311 bytes) 
"
1760374181788,"INFO	2025-10-13T16:49:41,788	239295	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 120.0 in stage 0.0 (TID 120) in 21537 ms on 172.35.24.244 (executor 3) (121/590)
"
1760374181813,"INFO	2025-10-13T16:49:41,813	239320	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374181813,"INFO	2025-10-13T16:49:41,813	239320	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 33, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374181814,"INFO	2025-10-13T16:49:41,813	239320	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 33; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_33_a_spark-application-1760373954341_p_1
"
1760374181814,"INFO	2025-10-13T16:49:41,814	239321	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374181855,"INFO	2025-10-13T16:49:41,855	239362	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374181856,"INFO	2025-10-13T16:49:41,855	239362	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: bec6fef8-5986-41e6-b1fa-e11138be578a)
"
1760374181856,"INFO	2025-10-13T16:49:41,855	239362	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 33 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374182785,"INFO	2025-10-13T16:49:42,785	240292	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 139.0 in stage 0.0 (TID 139) (172.35.107.166, executor 8, partition 139, PROCESS_LOCAL, 29311 bytes) 
"
1760374182786,"INFO	2025-10-13T16:49:42,785	240292	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 121.0 in stage 0.0 (TID 121) in 21711 ms on 172.35.107.166 (executor 8) (122/590)
"
1760374183875,"INFO	2025-10-13T16:49:43,874	241381	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 140.0 in stage 0.0 (TID 140) (172.35.24.244, executor 3, partition 140, PROCESS_LOCAL, 29311 bytes) 
"
1760374183875,"INFO	2025-10-13T16:49:43,875	241382	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 122.0 in stage 0.0 (TID 122) in 22409 ms on 172.35.24.244 (executor 3) (123/590)
"
1760374184532,"INFO	2025-10-13T16:49:44,531	242038	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 141.0 in stage 0.0 (TID 141) (172.34.194.6, executor 7, partition 141, PROCESS_LOCAL, 29311 bytes) 
"
1760374184532,"INFO	2025-10-13T16:49:44,532	242039	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 124.0 in stage 0.0 (TID 124) in 21886 ms on 172.34.194.6 (executor 7) (124/590)
"
1760374184541,"INFO	2025-10-13T16:49:44,540	242047	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 142.0 in stage 0.0 (TID 142) (172.35.107.166, executor 8, partition 142, PROCESS_LOCAL, 29311 bytes) 
"
1760374184541,"INFO	2025-10-13T16:49:44,541	242048	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 123.0 in stage 0.0 (TID 123) in 21959 ms on 172.35.107.166 (executor 8) (125/590)
"
1760374186135,"INFO	2025-10-13T16:49:46,135	243642	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 143.0 in stage 0.0 (TID 143) (172.34.141.1, executor 4, partition 143, PROCESS_LOCAL, 29311 bytes) 
"
1760374186135,"INFO	2025-10-13T16:49:46,135	243642	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 125.0 in stage 0.0 (TID 125) in 22607 ms on 172.34.141.1 (executor 4) (126/590)
"
1760374186162,"INFO	2025-10-13T16:49:46,162	243669	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 144.0 in stage 0.0 (TID 144) (172.34.206.195, executor 6, partition 144, PROCESS_LOCAL, 29311 bytes) 
"
1760374186163,"INFO	2025-10-13T16:49:46,162	243669	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 126.0 in stage 0.0 (TID 126) in 22263 ms on 172.34.206.195 (executor 6) (127/590)
"
1760374187135,"INFO	2025-10-13T16:49:47,135	244642	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 145.0 in stage 0.0 (TID 145) (172.34.141.1, executor 4, partition 145, PROCESS_LOCAL, 29311 bytes) 
"
1760374187136,"INFO	2025-10-13T16:49:47,136	244643	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 127.0 in stage 0.0 (TID 127) in 23085 ms on 172.34.141.1 (executor 4) (128/590)
"
1760374187596,"INFO	2025-10-13T16:49:47,596	245103	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 146.0 in stage 0.0 (TID 146) (172.34.206.195, executor 6, partition 146, PROCESS_LOCAL, 29311 bytes) 
"
1760374187596,"INFO	2025-10-13T16:49:47,596	245103	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 128.0 in stage 0.0 (TID 128) in 22156 ms on 172.34.206.195 (executor 6) (129/590)
"
1760374188713,"INFO	2025-10-13T16:49:48,713	246220	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 147.0 in stage 0.0 (TID 147) (172.34.46.142, executor 1, partition 147, PROCESS_LOCAL, 29311 bytes) 
"
1760374188714,"INFO	2025-10-13T16:49:48,714	246221	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 130.0 in stage 0.0 (TID 130) in 21468 ms on 172.34.46.142 (executor 1) (130/590)
"
1760374189858,"INFO	2025-10-13T16:49:49,858	247365	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 148.0 in stage 0.0 (TID 148) (172.34.141.226, executor 2, partition 148, PROCESS_LOCAL, 29311 bytes) 
"
1760374189859,"INFO	2025-10-13T16:49:49,859	247366	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 129.0 in stage 0.0 (TID 129) in 23642 ms on 172.34.141.226 (executor 2) (131/590)
"
1760374192131,"INFO	2025-10-13T16:49:52,130	249637	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 149.0 in stage 0.0 (TID 149) (172.34.141.226, executor 2, partition 149, PROCESS_LOCAL, 29311 bytes) 
"
1760374192131,"INFO	2025-10-13T16:49:52,131	249638	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 131.0 in stage 0.0 (TID 131) in 24191 ms on 172.34.141.226 (executor 2) (132/590)
"
1760374192546,"INFO	2025-10-13T16:49:52,546	250053	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 150.0 in stage 0.0 (TID 150) (172.34.46.142, executor 1, partition 150, PROCESS_LOCAL, 29311 bytes) 
"
1760374192546,"INFO	2025-10-13T16:49:52,546	250053	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 132.0 in stage 0.0 (TID 132) in 22151 ms on 172.34.46.142 (executor 1) (133/590)
"
1760374194305,"INFO	2025-10-13T16:49:54,305	251812	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374194305,"INFO	2025-10-13T16:49:54,305	251812	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 34, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374194305,"INFO	2025-10-13T16:49:54,305	251812	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 34; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_34_a_spark-application-1760373954341_p_1
"
1760374194306,"INFO	2025-10-13T16:49:54,305	251812	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374194337,"INFO	2025-10-13T16:49:54,337	251844	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374194337,"INFO	2025-10-13T16:49:54,337	251844	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 97ab109e-997c-4092-93fd-691829396ff2)
"
1760374194338,"INFO	2025-10-13T16:49:54,337	251844	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 34 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374194473,"INFO	2025-10-13T16:49:54,472	251979	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374194473,"INFO	2025-10-13T16:49:54,473	251980	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374196537,"INFO	2025-10-13T16:49:56,537	254044	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 151.0 in stage 0.0 (TID 151) (172.35.201.115, executor 5, partition 151, PROCESS_LOCAL, 29311 bytes) 
"
1760374196538,"INFO	2025-10-13T16:49:56,538	254045	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 133.0 in stage 0.0 (TID 133) in 22402 ms on 172.35.201.115 (executor 5) (134/590)
"
1760374196597,"INFO	2025-10-13T16:49:56,597	254104	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 152.0 in stage 0.0 (TID 152) (172.34.27.84, executor 9, partition 152, PROCESS_LOCAL, 29311 bytes) 
"
1760374196598,"INFO	2025-10-13T16:49:56,598	254105	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 134.0 in stage 0.0 (TID 134) in 21302 ms on 172.34.27.84 (executor 9) (135/590)
"
1760374198817,"INFO	2025-10-13T16:49:58,816	256323	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 153.0 in stage 0.0 (TID 153) (172.34.27.84, executor 9, partition 153, PROCESS_LOCAL, 29311 bytes) 
"
1760374198817,"INFO	2025-10-13T16:49:58,817	256324	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 135.0 in stage 0.0 (TID 135) in 22207 ms on 172.34.27.84 (executor 9) (136/590)
"
1760374202438,"INFO	2025-10-13T16:50:02,438	259945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 154.0 in stage 0.0 (TID 154) (172.34.194.6, executor 7, partition 154, PROCESS_LOCAL, 29311 bytes) 
"
1760374202439,"INFO	2025-10-13T16:50:02,439	259946	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 137.0 in stage 0.0 (TID 137) in 21586 ms on 172.34.194.6 (executor 7) (137/590)
"
1760374202732,"INFO	2025-10-13T16:50:02,731	260238	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 155.0 in stage 0.0 (TID 155) (172.35.201.115, executor 5, partition 155, PROCESS_LOCAL, 29311 bytes) 
"
1760374202732,"INFO	2025-10-13T16:50:02,732	260239	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 136.0 in stage 0.0 (TID 136) in 22121 ms on 172.35.201.115 (executor 5) (138/590)
"
1760374203380,"INFO	2025-10-13T16:50:03,380	260887	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 156.0 in stage 0.0 (TID 156) (172.35.24.244, executor 3, partition 156, PROCESS_LOCAL, 29311 bytes) 
"
1760374203381,"INFO	2025-10-13T16:50:03,380	260887	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 138.0 in stage 0.0 (TID 138) in 21593 ms on 172.35.24.244 (executor 3) (139/590)
"
1760374204410,"INFO	2025-10-13T16:50:04,410	261917	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 157.0 in stage 0.0 (TID 157) (172.35.107.166, executor 8, partition 157, PROCESS_LOCAL, 29311 bytes) 
"
1760374204411,"INFO	2025-10-13T16:50:04,410	261917	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 139.0 in stage 0.0 (TID 139) in 21626 ms on 172.35.107.166 (executor 8) (140/590)
"
1760374205673,"INFO	2025-10-13T16:50:05,673	263180	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 158.0 in stage 0.0 (TID 158) (172.35.24.244, executor 3, partition 158, PROCESS_LOCAL, 29311 bytes) 
"
1760374205674,"INFO	2025-10-13T16:50:05,673	263180	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 140.0 in stage 0.0 (TID 140) in 21799 ms on 172.35.24.244 (executor 3) (141/590)
"
1760374206148,"INFO	2025-10-13T16:50:06,147	263654	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 159.0 in stage 0.0 (TID 159) (172.34.194.6, executor 7, partition 159, PROCESS_LOCAL, 29311 bytes) 
"
1760374206148,"INFO	2025-10-13T16:50:06,148	263655	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 141.0 in stage 0.0 (TID 141) in 21617 ms on 172.34.194.6 (executor 7) (142/590)
"
1760374206769,"INFO	2025-10-13T16:50:06,768	264275	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 160.0 in stage 0.0 (TID 160) (172.35.107.166, executor 8, partition 160, PROCESS_LOCAL, 29311 bytes) 
"
1760374206769,"INFO	2025-10-13T16:50:06,769	264276	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 142.0 in stage 0.0 (TID 142) in 22229 ms on 172.35.107.166 (executor 8) (143/590)
"
1760374207209,"INFO	2025-10-13T16:50:07,209	264716	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374207209,"INFO	2025-10-13T16:50:07,209	264716	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 35, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374207209,"INFO	2025-10-13T16:50:07,209	264716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 35; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_35_a_spark-application-1760373954341_p_1
"
1760374207209,"INFO	2025-10-13T16:50:07,209	264716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374207251,"INFO	2025-10-13T16:50:07,251	264758	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374207252,"INFO	2025-10-13T16:50:07,251	264758	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: cb4ccbf7-552a-4474-ad1c-75f08ba979b1)
"
1760374207252,"INFO	2025-10-13T16:50:07,251	264758	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 35 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374208432,"INFO	2025-10-13T16:50:08,432	265939	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 161.0 in stage 0.0 (TID 161) (172.34.206.195, executor 6, partition 161, PROCESS_LOCAL, 29311 bytes) 
"
1760374208433,"INFO	2025-10-13T16:50:08,432	265939	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 144.0 in stage 0.0 (TID 144) in 22270 ms on 172.34.206.195 (executor 6) (144/590)
"
1760374208726,"INFO	2025-10-13T16:50:08,726	266233	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 162.0 in stage 0.0 (TID 162) (172.34.141.1, executor 4, partition 162, PROCESS_LOCAL, 29311 bytes) 
"
1760374208727,"INFO	2025-10-13T16:50:08,726	266233	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 143.0 in stage 0.0 (TID 143) in 22592 ms on 172.34.141.1 (executor 4) (145/590)
"
1760374209660,"INFO	2025-10-13T16:50:09,660	267167	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 163.0 in stage 0.0 (TID 163) (172.34.141.1, executor 4, partition 163, PROCESS_LOCAL, 29311 bytes) 
"
1760374209660,"INFO	2025-10-13T16:50:09,660	267167	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 145.0 in stage 0.0 (TID 145) in 22525 ms on 172.34.141.1 (executor 4) (146/590)
"
1760374210246,"INFO	2025-10-13T16:50:10,245	267752	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 164.0 in stage 0.0 (TID 164) (172.34.46.142, executor 1, partition 164, PROCESS_LOCAL, 29311 bytes) 
"
1760374210246,"INFO	2025-10-13T16:50:10,246	267753	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 147.0 in stage 0.0 (TID 147) in 21533 ms on 172.34.46.142 (executor 1) (147/590)
"
1760374210330,"INFO	2025-10-13T16:50:10,329	267836	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 165.0 in stage 0.0 (TID 165) (172.34.206.195, executor 6, partition 165, PROCESS_LOCAL, 29311 bytes) 
"
1760374210330,"INFO	2025-10-13T16:50:10,330	267837	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 146.0 in stage 0.0 (TID 146) in 22735 ms on 172.34.206.195 (executor 6) (148/590)
"
1760374213733,"INFO	2025-10-13T16:50:13,732	271239	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 166.0 in stage 0.0 (TID 166) (172.34.141.226, executor 2, partition 166, PROCESS_LOCAL, 29311 bytes) 
"
1760374213733,"INFO	2025-10-13T16:50:13,733	271240	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 148.0 in stage 0.0 (TID 148) in 23875 ms on 172.34.141.226 (executor 2) (149/590)
"
1760374214079,"INFO	2025-10-13T16:50:14,078	271585	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 167.0 in stage 0.0 (TID 167) (172.34.46.142, executor 1, partition 167, PROCESS_LOCAL, 29311 bytes) 
"
1760374214079,"INFO	2025-10-13T16:50:14,079	271586	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 150.0 in stage 0.0 (TID 150) in 21534 ms on 172.34.46.142 (executor 1) (150/590)
"
1760374216044,"INFO	2025-10-13T16:50:16,043	273550	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 168.0 in stage 0.0 (TID 168) (172.34.141.226, executor 2, partition 168, PROCESS_LOCAL, 29311 bytes) 
"
1760374216044,"INFO	2025-10-13T16:50:16,043	273550	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 149.0 in stage 0.0 (TID 149) in 23913 ms on 172.34.141.226 (executor 2) (151/590)
"
1760374216554,"INFO	2025-10-13T16:50:16,554	274061	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374216554,"INFO	2025-10-13T16:50:16,554	274061	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 36, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374216555,"INFO	2025-10-13T16:50:16,554	274061	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 36; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_36_a_spark-application-1760373954341_p_1
"
1760374216555,"INFO	2025-10-13T16:50:16,555	274062	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374216594,"INFO	2025-10-13T16:50:16,594	274101	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374216594,"INFO	2025-10-13T16:50:16,594	274101	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 31cdf632-d96e-4e73-a3e8-5899925e4681)
"
1760374216594,"INFO	2025-10-13T16:50:16,594	274101	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 36 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374218283,"INFO	2025-10-13T16:50:18,282	275789	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 169.0 in stage 0.0 (TID 169) (172.34.27.84, executor 9, partition 169, PROCESS_LOCAL, 29311 bytes) 
"
1760374218283,"INFO	2025-10-13T16:50:18,283	275790	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 152.0 in stage 0.0 (TID 152) in 21686 ms on 172.34.27.84 (executor 9) (152/590)
"
1760374218771,"INFO	2025-10-13T16:50:18,770	276277	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 170.0 in stage 0.0 (TID 170) (172.35.201.115, executor 5, partition 170, PROCESS_LOCAL, 29311 bytes) 
"
1760374218771,"INFO	2025-10-13T16:50:18,771	276278	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 151.0 in stage 0.0 (TID 151) in 22234 ms on 172.35.201.115 (executor 5) (153/590)
"
1760374220476,"INFO	2025-10-13T16:50:20,476	277983	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 171.0 in stage 0.0 (TID 171) (172.34.27.84, executor 9, partition 171, PROCESS_LOCAL, 29311 bytes) 
"
1760374220476,"INFO	2025-10-13T16:50:20,476	277983	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 153.0 in stage 0.0 (TID 153) in 21660 ms on 172.34.27.84 (executor 9) (154/590)
"
1760374221596,"INFO	2025-10-13T16:50:21,595	279102	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374221596,"INFO	2025-10-13T16:50:21,596	279103	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 37, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374221596,"INFO	2025-10-13T16:50:21,596	279103	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 37; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_37_a_spark-application-1760373954341_p_1
"
1760374221596,"INFO	2025-10-13T16:50:21,596	279103	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374221634,"INFO	2025-10-13T16:50:21,634	279141	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374221634,"INFO	2025-10-13T16:50:21,634	279141	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 4ac7e3c9-dbea-43ed-9103-91b211e4a734)
"
1760374221634,"INFO	2025-10-13T16:50:21,634	279141	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 37 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374224510,"INFO	2025-10-13T16:50:24,509	282016	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 172.0 in stage 0.0 (TID 172) (172.34.194.6, executor 7, partition 172, PROCESS_LOCAL, 29311 bytes) 
"
1760374224510,"INFO	2025-10-13T16:50:24,510	282017	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 154.0 in stage 0.0 (TID 154) in 22072 ms on 172.34.194.6 (executor 7) (155/590)
"
1760374224778,"INFO	2025-10-13T16:50:24,777	282284	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 173.0 in stage 0.0 (TID 173) (172.35.201.115, executor 5, partition 173, PROCESS_LOCAL, 29311 bytes) 
"
1760374224778,"INFO	2025-10-13T16:50:24,778	282285	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 155.0 in stage 0.0 (TID 155) in 22047 ms on 172.35.201.115 (executor 5) (156/590)
"
1760374224974,"INFO	2025-10-13T16:50:24,974	282481	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 174.0 in stage 0.0 (TID 174) (172.35.24.244, executor 3, partition 174, PROCESS_LOCAL, 29311 bytes) 
"
1760374224975,"INFO	2025-10-13T16:50:24,974	282481	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 156.0 in stage 0.0 (TID 156) in 21595 ms on 172.35.24.244 (executor 3) (157/590)
"
1760374225963,"INFO	2025-10-13T16:50:25,962	283469	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 175.0 in stage 0.0 (TID 175) (172.35.107.166, executor 8, partition 175, PROCESS_LOCAL, 29311 bytes) 
"
1760374225963,"INFO	2025-10-13T16:50:25,963	283470	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 157.0 in stage 0.0 (TID 157) in 21554 ms on 172.35.107.166 (executor 8) (158/590)
"
1760374227760,"INFO	2025-10-13T16:50:27,760	285267	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 176.0 in stage 0.0 (TID 176) (172.35.24.244, executor 3, partition 176, PROCESS_LOCAL, 29311 bytes) 
"
1760374227761,"INFO	2025-10-13T16:50:27,760	285267	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 158.0 in stage 0.0 (TID 158) in 22088 ms on 172.35.24.244 (executor 3) (159/590)
"
1760374228513,"INFO	2025-10-13T16:50:28,513	286020	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 177.0 in stage 0.0 (TID 177) (172.35.107.166, executor 8, partition 177, PROCESS_LOCAL, 29311 bytes) 
"
1760374228514,"INFO	2025-10-13T16:50:28,513	286020	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 160.0 in stage 0.0 (TID 160) in 21745 ms on 172.35.107.166 (executor 8) (160/590)
"
1760374228597,"INFO	2025-10-13T16:50:28,596	286103	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 178.0 in stage 0.0 (TID 178) (172.34.194.6, executor 7, partition 178, PROCESS_LOCAL, 29311 bytes) 
"
1760374228597,"INFO	2025-10-13T16:50:28,597	286104	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 159.0 in stage 0.0 (TID 159) in 22450 ms on 172.34.194.6 (executor 7) (161/590)
"
1760374230981,"INFO	2025-10-13T16:50:30,980	288487	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 179.0 in stage 0.0 (TID 179) (172.34.206.195, executor 6, partition 179, PROCESS_LOCAL, 29311 bytes) 
"
1760374230981,"INFO	2025-10-13T16:50:30,981	288488	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 161.0 in stage 0.0 (TID 161) in 22549 ms on 172.34.206.195 (executor 6) (162/590)
"
1760374231231,"INFO	2025-10-13T16:50:31,230	288737	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 180.0 in stage 0.0 (TID 180) (172.34.141.1, executor 4, partition 180, PROCESS_LOCAL, 29311 bytes) 
"
1760374231231,"INFO	2025-10-13T16:50:31,231	288738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 162.0 in stage 0.0 (TID 162) in 22505 ms on 172.34.141.1 (executor 4) (163/590)
"
1760374231571,"INFO	2025-10-13T16:50:31,570	289077	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 181.0 in stage 0.0 (TID 181) (172.34.46.142, executor 1, partition 181, PROCESS_LOCAL, 29311 bytes) 
"
1760374231571,"INFO	2025-10-13T16:50:31,571	289078	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 164.0 in stage 0.0 (TID 164) in 21326 ms on 172.34.46.142 (executor 1) (164/590)
"
1760374232658,"INFO	2025-10-13T16:50:32,658	290165	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 182.0 in stage 0.0 (TID 182) (172.34.141.1, executor 4, partition 182, PROCESS_LOCAL, 29311 bytes) 
"
1760374232659,"INFO	2025-10-13T16:50:32,658	290165	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 163.0 in stage 0.0 (TID 163) in 22999 ms on 172.34.141.1 (executor 4) (165/590)
"
1760374233095,"INFO	2025-10-13T16:50:33,095	290602	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 183.0 in stage 0.0 (TID 183) (172.34.206.195, executor 6, partition 183, PROCESS_LOCAL, 29311 bytes) 
"
1760374233096,"INFO	2025-10-13T16:50:33,096	290603	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 165.0 in stage 0.0 (TID 165) in 22767 ms on 172.34.206.195 (executor 6) (166/590)
"
1760374233811,"INFO	2025-10-13T16:50:33,810	291317	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374233811,"INFO	2025-10-13T16:50:33,811	291318	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 38, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374233811,"INFO	2025-10-13T16:50:33,811	291318	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 38; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_38_a_spark-application-1760373954341_p_1
"
1760374233811,"INFO	2025-10-13T16:50:33,811	291318	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374233855,"INFO	2025-10-13T16:50:33,854	291361	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374233855,"INFO	2025-10-13T16:50:33,855	291362	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: b8ed9c61-9eb0-4ed3-9d40-a905a17ad033)
"
1760374233855,"INFO	2025-10-13T16:50:33,855	291362	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 38 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374236410,"INFO	2025-10-13T16:50:36,410	293917	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 184.0 in stage 0.0 (TID 184) (172.34.46.142, executor 1, partition 184, PROCESS_LOCAL, 29311 bytes) 
"
1760374236411,"INFO	2025-10-13T16:50:36,410	293917	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 167.0 in stage 0.0 (TID 167) in 22332 ms on 172.34.46.142 (executor 1) (167/590)
"
1760374237712,"INFO	2025-10-13T16:50:37,712	295219	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 185.0 in stage 0.0 (TID 185) (172.34.141.226, executor 2, partition 185, PROCESS_LOCAL, 29311 bytes) 
"
1760374237713,"INFO	2025-10-13T16:50:37,713	295220	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 166.0 in stage 0.0 (TID 166) in 23980 ms on 172.34.141.226 (executor 2) (168/590)
"
1760374239499,"INFO	2025-10-13T16:50:39,499	297006	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 186.0 in stage 0.0 (TID 186) (172.34.27.84, executor 9, partition 186, PROCESS_LOCAL, 29311 bytes) 
"
1760374239499,"INFO	2025-10-13T16:50:39,499	297006	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 169.0 in stage 0.0 (TID 169) in 21217 ms on 172.34.27.84 (executor 9) (169/590)
"
1760374240171,"INFO	2025-10-13T16:50:40,171	297678	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 187.0 in stage 0.0 (TID 187) (172.34.141.226, executor 2, partition 187, PROCESS_LOCAL, 29311 bytes) 
"
1760374240171,"INFO	2025-10-13T16:50:40,171	297678	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 168.0 in stage 0.0 (TID 168) in 24129 ms on 172.34.141.226 (executor 2) (170/590)
"
1760374241007,"INFO	2025-10-13T16:50:41,007	298514	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 188.0 in stage 0.0 (TID 188) (172.35.201.115, executor 5, partition 188, PROCESS_LOCAL, 29311 bytes) 
"
1760374241008,"INFO	2025-10-13T16:50:41,007	298514	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 170.0 in stage 0.0 (TID 170) in 22237 ms on 172.35.201.115 (executor 5) (171/590)
"
1760374242367,"INFO	2025-10-13T16:50:42,367	299874	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 189.0 in stage 0.0 (TID 189) (172.34.27.84, executor 9, partition 189, PROCESS_LOCAL, 29311 bytes) 
"
1760374242368,"INFO	2025-10-13T16:50:42,368	299875	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 171.0 in stage 0.0 (TID 171) in 21893 ms on 172.34.27.84 (executor 9) (172/590)
"
1760374245747,"INFO	2025-10-13T16:50:45,747	303254	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 190.0 in stage 0.0 (TID 190) (172.34.194.6, executor 7, partition 190, PROCESS_LOCAL, 29311 bytes) 
"
1760374245748,"INFO	2025-10-13T16:50:45,748	303255	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 172.0 in stage 0.0 (TID 172) in 21239 ms on 172.34.194.6 (executor 7) (173/590)
"
1760374246341,"INFO	2025-10-13T16:50:46,341	303848	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 191.0 in stage 0.0 (TID 191) (172.35.24.244, executor 3, partition 191, PROCESS_LOCAL, 29311 bytes) 
"
1760374246341,"INFO	2025-10-13T16:50:46,341	303848	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 174.0 in stage 0.0 (TID 174) in 21367 ms on 172.35.24.244 (executor 3) (174/590)
"
1760374246649,"INFO	2025-10-13T16:50:46,649	304156	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 192.0 in stage 0.0 (TID 192) (172.35.201.115, executor 5, partition 192, PROCESS_LOCAL, 29311 bytes) 
"
1760374246649,"INFO	2025-10-13T16:50:46,649	304156	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 173.0 in stage 0.0 (TID 173) in 21872 ms on 172.35.201.115 (executor 5) (175/590)
"
1760374246730,"INFO	2025-10-13T16:50:46,730	304237	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374246731,"INFO	2025-10-13T16:50:46,730	304237	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 39, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374246731,"INFO	2025-10-13T16:50:46,731	304238	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 39; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_39_a_spark-application-1760373954341_p_1
"
1760374246731,"INFO	2025-10-13T16:50:46,731	304238	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374246765,"INFO	2025-10-13T16:50:46,765	304272	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374246765,"INFO	2025-10-13T16:50:46,765	304272	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: fa75034f-4c50-4d67-b0c7-00d0399395bf)
"
1760374246765,"INFO	2025-10-13T16:50:46,765	304272	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 39 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374247232,"INFO	2025-10-13T16:50:47,232	304739	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 193.0 in stage 0.0 (TID 193) (172.35.107.166, executor 8, partition 193, PROCESS_LOCAL, 29311 bytes) 
"
1760374247232,"INFO	2025-10-13T16:50:47,232	304739	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 175.0 in stage 0.0 (TID 175) in 21270 ms on 172.35.107.166 (executor 8) (176/590)
"
1760374249433,"INFO	2025-10-13T16:50:49,433	306940	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 194.0 in stage 0.0 (TID 194) (172.35.24.244, executor 3, partition 194, PROCESS_LOCAL, 29311 bytes) 
"
1760374249434,"INFO	2025-10-13T16:50:49,434	306941	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 176.0 in stage 0.0 (TID 176) in 21673 ms on 172.35.24.244 (executor 3) (177/590)
"
1760374250164,"INFO	2025-10-13T16:50:50,163	307670	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 195.0 in stage 0.0 (TID 195) (172.34.194.6, executor 7, partition 195, PROCESS_LOCAL, 29311 bytes) 
"
1760374250164,"INFO	2025-10-13T16:50:50,164	307671	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 178.0 in stage 0.0 (TID 178) in 21568 ms on 172.34.194.6 (executor 7) (178/590)
"
1760374250761,"INFO	2025-10-13T16:50:50,761	308268	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 196.0 in stage 0.0 (TID 196) (172.35.107.166, executor 8, partition 196, PROCESS_LOCAL, 29311 bytes) 
"
1760374250761,"INFO	2025-10-13T16:50:50,761	308268	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 177.0 in stage 0.0 (TID 177) in 22248 ms on 172.35.107.166 (executor 8) (179/590)
"
1760374252926,"INFO	2025-10-13T16:50:52,926	310433	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 197.0 in stage 0.0 (TID 197) (172.34.46.142, executor 1, partition 197, PROCESS_LOCAL, 29311 bytes) 
"
1760374252926,"INFO	2025-10-13T16:50:52,926	310433	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 181.0 in stage 0.0 (TID 181) in 21356 ms on 172.34.46.142 (executor 1) (180/590)
"
1760374253271,"INFO	2025-10-13T16:50:53,271	310778	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 198.0 in stage 0.0 (TID 198) (172.34.206.195, executor 6, partition 198, PROCESS_LOCAL, 29311 bytes) 
"
1760374253272,"INFO	2025-10-13T16:50:53,272	310779	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 179.0 in stage 0.0 (TID 179) in 22292 ms on 172.34.206.195 (executor 6) (181/590)
"
1760374253609,"INFO	2025-10-13T16:50:53,609	311116	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 199.0 in stage 0.0 (TID 199) (172.34.141.1, executor 4, partition 199, PROCESS_LOCAL, 29311 bytes) 
"
1760374253610,"INFO	2025-10-13T16:50:53,610	311117	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 180.0 in stage 0.0 (TID 180) in 22379 ms on 172.34.141.1 (executor 4) (182/590)
"
1760374254473,"INFO	2025-10-13T16:50:54,473	311980	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374254474,"INFO	2025-10-13T16:50:54,473	311980	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374255071,"INFO	2025-10-13T16:50:55,071	312578	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 200.0 in stage 0.0 (TID 200) (172.34.141.1, executor 4, partition 200, PROCESS_LOCAL, 29311 bytes) 
"
1760374255072,"INFO	2025-10-13T16:50:55,072	312579	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 182.0 in stage 0.0 (TID 182) in 22413 ms on 172.34.141.1 (executor 4) (183/590)
"
1760374255960,"INFO	2025-10-13T16:50:55,960	313467	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 201.0 in stage 0.0 (TID 201) (172.34.206.195, executor 6, partition 201, PROCESS_LOCAL, 29311 bytes) 
"
1760374255961,"INFO	2025-10-13T16:50:55,961	313468	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 183.0 in stage 0.0 (TID 183) in 22865 ms on 172.34.206.195 (executor 6) (184/590)
"
1760374256462,"INFO	2025-10-13T16:50:56,461	313968	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374256462,"INFO	2025-10-13T16:50:56,462	313969	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 40, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374256462,"INFO	2025-10-13T16:50:56,462	313969	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 40; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_40_a_spark-application-1760373954341_p_1
"
1760374256462,"INFO	2025-10-13T16:50:56,462	313969	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374256501,"INFO	2025-10-13T16:50:56,500	314007	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374256501,"INFO	2025-10-13T16:50:56,500	314007	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 7860171c-8a0e-47e7-88a5-4c111509339c)
"
1760374256501,"INFO	2025-10-13T16:50:56,501	314008	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 40 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374257946,"INFO	2025-10-13T16:50:57,946	315453	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 202.0 in stage 0.0 (TID 202) (172.34.46.142, executor 1, partition 202, PROCESS_LOCAL, 29311 bytes) 
"
1760374257947,"INFO	2025-10-13T16:50:57,946	315453	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 184.0 in stage 0.0 (TID 184) in 21536 ms on 172.34.46.142 (executor 1) (185/590)
"
1760374261013,"INFO	2025-10-13T16:51:01,013	318520	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 203.0 in stage 0.0 (TID 203) (172.34.141.226, executor 2, partition 203, PROCESS_LOCAL, 29311 bytes) 
"
1760374261013,"INFO	2025-10-13T16:51:01,013	318520	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 185.0 in stage 0.0 (TID 185) in 23301 ms on 172.34.141.226 (executor 2) (186/590)
"
1760374261027,"INFO	2025-10-13T16:51:01,026	318533	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 204.0 in stage 0.0 (TID 204) (172.34.27.84, executor 9, partition 204, PROCESS_LOCAL, 29311 bytes) 
"
1760374261027,"INFO	2025-10-13T16:51:01,027	318534	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 186.0 in stage 0.0 (TID 186) in 21529 ms on 172.34.27.84 (executor 9) (187/590)
"
1760374263605,"INFO	2025-10-13T16:51:03,604	321111	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 205.0 in stage 0.0 (TID 205) (172.34.141.226, executor 2, partition 205, PROCESS_LOCAL, 29311 bytes) 
"
1760374263605,"INFO	2025-10-13T16:51:03,605	321112	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 187.0 in stage 0.0 (TID 187) in 23435 ms on 172.34.141.226 (executor 2) (188/590)
"
1760374264107,"INFO	2025-10-13T16:51:04,106	321613	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 206.0 in stage 0.0 (TID 206) (172.35.201.115, executor 5, partition 206, PROCESS_LOCAL, 29311 bytes) 
"
1760374264107,"INFO	2025-10-13T16:51:04,107	321614	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 188.0 in stage 0.0 (TID 188) in 23101 ms on 172.35.201.115 (executor 5) (189/590)
"
1760374264525,"INFO	2025-10-13T16:51:04,524	322031	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 207.0 in stage 0.0 (TID 207) (172.34.27.84, executor 9, partition 207, PROCESS_LOCAL, 29311 bytes) 
"
1760374264525,"INFO	2025-10-13T16:51:04,525	322032	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 189.0 in stage 0.0 (TID 189) in 22158 ms on 172.34.27.84 (executor 9) (190/590)
"
1760374266056,"INFO	2025-10-13T16:51:06,056	323563	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374266056,"INFO	2025-10-13T16:51:06,056	323563	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 41, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374266057,"INFO	2025-10-13T16:51:06,056	323563	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 41; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_41_a_spark-application-1760373954341_p_1
"
1760374266057,"INFO	2025-10-13T16:51:06,057	323564	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374266089,"INFO	2025-10-13T16:51:06,089	323596	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374266090,"INFO	2025-10-13T16:51:06,089	323596	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 22a8bbd0-8d08-446f-acb1-2cbcd0ea4cbd)
"
1760374266090,"INFO	2025-10-13T16:51:06,089	323596	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 41 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374267652,"INFO	2025-10-13T16:51:07,652	325159	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 208.0 in stage 0.0 (TID 208) (172.34.194.6, executor 7, partition 208, PROCESS_LOCAL, 29311 bytes) 
"
1760374267653,"INFO	2025-10-13T16:51:07,652	325159	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 190.0 in stage 0.0 (TID 190) in 21905 ms on 172.34.194.6 (executor 7) (191/590)
"
1760374268389,"INFO	2025-10-13T16:51:08,389	325896	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 209.0 in stage 0.0 (TID 209) (172.35.24.244, executor 3, partition 209, PROCESS_LOCAL, 29311 bytes) 
"
1760374268390,"INFO	2025-10-13T16:51:08,389	325896	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 191.0 in stage 0.0 (TID 191) in 22049 ms on 172.35.24.244 (executor 3) (192/590)
"
1760374269199,"INFO	2025-10-13T16:51:09,199	326706	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 210.0 in stage 0.0 (TID 210) (172.35.107.166, executor 8, partition 210, PROCESS_LOCAL, 29311 bytes) 
"
1760374269200,"INFO	2025-10-13T16:51:09,199	326706	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 193.0 in stage 0.0 (TID 193) in 21968 ms on 172.35.107.166 (executor 8) (193/590)
"
1760374269439,"INFO	2025-10-13T16:51:09,438	326945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 211.0 in stage 0.0 (TID 211) (172.35.201.115, executor 5, partition 211, PROCESS_LOCAL, 29311 bytes) 
"
1760374269439,"INFO	2025-10-13T16:51:09,439	326946	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 192.0 in stage 0.0 (TID 192) in 22791 ms on 172.35.201.115 (executor 5) (194/590)
"
1760374272135,"INFO	2025-10-13T16:51:12,134	329641	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 212.0 in stage 0.0 (TID 212) (172.35.24.244, executor 3, partition 212, PROCESS_LOCAL, 29311 bytes) 
"
1760374272135,"INFO	2025-10-13T16:51:12,135	329642	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 194.0 in stage 0.0 (TID 194) in 22702 ms on 172.35.24.244 (executor 3) (195/590)
"
1760374272813,"INFO	2025-10-13T16:51:12,813	330320	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 213.0 in stage 0.0 (TID 213) (172.34.194.6, executor 7, partition 213, PROCESS_LOCAL, 29311 bytes) 
"
1760374272814,"INFO	2025-10-13T16:51:12,814	330321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 195.0 in stage 0.0 (TID 195) in 22651 ms on 172.34.194.6 (executor 7) (196/590)
"
1760374273461,"INFO	2025-10-13T16:51:13,461	330968	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 214.0 in stage 0.0 (TID 214) (172.35.107.166, executor 8, partition 214, PROCESS_LOCAL, 29311 bytes) 
"
1760374273462,"INFO	2025-10-13T16:51:13,461	330968	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 196.0 in stage 0.0 (TID 196) in 22701 ms on 172.35.107.166 (executor 8) (197/590)
"
1760374275369,"INFO	2025-10-13T16:51:15,369	332876	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 215.0 in stage 0.0 (TID 215) (172.34.46.142, executor 1, partition 215, PROCESS_LOCAL, 29311 bytes) 
"
1760374275369,"INFO	2025-10-13T16:51:15,369	332876	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 197.0 in stage 0.0 (TID 197) in 22444 ms on 172.34.46.142 (executor 1) (198/590)
"
1760374275977,"INFO	2025-10-13T16:51:15,976	333483	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 216.0 in stage 0.0 (TID 216) (172.34.206.195, executor 6, partition 216, PROCESS_LOCAL, 29311 bytes) 
"
1760374275977,"INFO	2025-10-13T16:51:15,977	333484	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 198.0 in stage 0.0 (TID 198) in 22706 ms on 172.34.206.195 (executor 6) (199/590)
"
1760374276413,"INFO	2025-10-13T16:51:16,413	333920	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374276413,"INFO	2025-10-13T16:51:16,413	333920	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 42, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374276413,"INFO	2025-10-13T16:51:16,413	333920	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 42; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_42_a_spark-application-1760373954341_p_1
"
1760374276413,"INFO	2025-10-13T16:51:16,413	333920	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374276447,"INFO	2025-10-13T16:51:16,447	333954	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374276447,"INFO	2025-10-13T16:51:16,447	333954	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: e39fee7f-ca2b-4609-a218-dd1b8293d1c8)
"
1760374276447,"INFO	2025-10-13T16:51:16,447	333954	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 42 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374276828,"INFO	2025-10-13T16:51:16,828	334335	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 217.0 in stage 0.0 (TID 217) (172.34.141.1, executor 4, partition 217, PROCESS_LOCAL, 29311 bytes) 
"
1760374276829,"INFO	2025-10-13T16:51:16,829	334336	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 199.0 in stage 0.0 (TID 199) in 23220 ms on 172.34.141.1 (executor 4) (200/590)
"
1760374278639,"INFO	2025-10-13T16:51:18,639	336146	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 218.0 in stage 0.0 (TID 218) (172.34.206.195, executor 6, partition 218, PROCESS_LOCAL, 29311 bytes) 
"
1760374278639,"INFO	2025-10-13T16:51:18,639	336146	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 201.0 in stage 0.0 (TID 201) in 22679 ms on 172.34.206.195 (executor 6) (201/590)
"
1760374278718,"INFO	2025-10-13T16:51:18,718	336225	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 219.0 in stage 0.0 (TID 219) (172.34.141.1, executor 4, partition 219, PROCESS_LOCAL, 29311 bytes) 
"
1760374278719,"INFO	2025-10-13T16:51:18,718	336225	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 200.0 in stage 0.0 (TID 200) in 23647 ms on 172.34.141.1 (executor 4) (202/590)
"
1760374279927,"INFO	2025-10-13T16:51:19,927	337434	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 220.0 in stage 0.0 (TID 220) (172.34.46.142, executor 1, partition 220, PROCESS_LOCAL, 29311 bytes) 
"
1760374279927,"INFO	2025-10-13T16:51:19,927	337434	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 202.0 in stage 0.0 (TID 202) in 21982 ms on 172.34.46.142 (executor 1) (203/590)
"
1760374282850,"INFO	2025-10-13T16:51:22,849	340356	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 221.0 in stage 0.0 (TID 221) (172.34.27.84, executor 9, partition 221, PROCESS_LOCAL, 29311 bytes) 
"
1760374282850,"INFO	2025-10-13T16:51:22,850	340357	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 204.0 in stage 0.0 (TID 204) in 21824 ms on 172.34.27.84 (executor 9) (204/590)
"
1760374285150,"INFO	2025-10-13T16:51:25,150	342657	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 222.0 in stage 0.0 (TID 222) (172.34.141.226, executor 2, partition 222, PROCESS_LOCAL, 29311 bytes) 
"
1760374285151,"INFO	2025-10-13T16:51:25,151	342658	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 203.0 in stage 0.0 (TID 203) in 24138 ms on 172.34.141.226 (executor 2) (205/590)
"
1760374286237,"INFO	2025-10-13T16:51:26,236	343743	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 223.0 in stage 0.0 (TID 223) (172.35.201.115, executor 5, partition 223, PROCESS_LOCAL, 29311 bytes) 
"
1760374286237,"INFO	2025-10-13T16:51:26,237	343744	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 206.0 in stage 0.0 (TID 206) in 22131 ms on 172.35.201.115 (executor 5) (206/590)
"
1760374286697,"INFO	2025-10-13T16:51:26,697	344204	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 224.0 in stage 0.0 (TID 224) (172.34.27.84, executor 9, partition 224, PROCESS_LOCAL, 29311 bytes) 
"
1760374286698,"INFO	2025-10-13T16:51:26,697	344204	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 207.0 in stage 0.0 (TID 207) in 22173 ms on 172.34.27.84 (executor 9) (207/590)
"
1760374287758,"INFO	2025-10-13T16:51:27,758	345265	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 225.0 in stage 0.0 (TID 225) (172.34.141.226, executor 2, partition 225, PROCESS_LOCAL, 29311 bytes) 
"
1760374287758,"INFO	2025-10-13T16:51:27,758	345265	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 205.0 in stage 0.0 (TID 205) in 24154 ms on 172.34.141.226 (executor 2) (208/590)
"
1760374289176,"INFO	2025-10-13T16:51:29,175	346682	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 226.0 in stage 0.0 (TID 226) (172.34.194.6, executor 7, partition 226, PROCESS_LOCAL, 29311 bytes) 
"
1760374289176,"INFO	2025-10-13T16:51:29,176	346683	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 208.0 in stage 0.0 (TID 208) in 21525 ms on 172.34.194.6 (executor 7) (209/590)
"
1760374289871,"INFO	2025-10-13T16:51:29,870	347377	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 227.0 in stage 0.0 (TID 227) (172.35.24.244, executor 3, partition 227, PROCESS_LOCAL, 29311 bytes) 
"
1760374289871,"INFO	2025-10-13T16:51:29,871	347378	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 209.0 in stage 0.0 (TID 209) in 21482 ms on 172.35.24.244 (executor 3) (210/590)
"
1760374291274,"INFO	2025-10-13T16:51:31,274	348781	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374291275,"INFO	2025-10-13T16:51:31,274	348781	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 43, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374291275,"INFO	2025-10-13T16:51:31,275	348782	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 43; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_43_a_spark-application-1760373954341_p_1
"
1760374291275,"INFO	2025-10-13T16:51:31,275	348782	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374291282,"INFO	2025-10-13T16:51:31,281	348788	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 228.0 in stage 0.0 (TID 228) (172.35.107.166, executor 8, partition 228, PROCESS_LOCAL, 29311 bytes) 
"
1760374291282,"INFO	2025-10-13T16:51:31,282	348789	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 210.0 in stage 0.0 (TID 210) in 22083 ms on 172.35.107.166 (executor 8) (211/590)
"
1760374291304,"INFO	2025-10-13T16:51:31,303	348810	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374291304,"INFO	2025-10-13T16:51:31,304	348811	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: c6b25fd0-5f58-4645-bc27-a97e4053033c)
"
1760374291304,"INFO	2025-10-13T16:51:31,304	348811	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 43 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374291542,"INFO	2025-10-13T16:51:31,541	349048	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 229.0 in stage 0.0 (TID 229) (172.35.201.115, executor 5, partition 229, PROCESS_LOCAL, 29311 bytes) 
"
1760374291542,"INFO	2025-10-13T16:51:31,542	349049	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 211.0 in stage 0.0 (TID 211) in 22104 ms on 172.35.201.115 (executor 5) (212/590)
"
1760374293600,"INFO	2025-10-13T16:51:33,599	351106	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 230.0 in stage 0.0 (TID 230) (172.35.24.244, executor 3, partition 230, PROCESS_LOCAL, 29311 bytes) 
"
1760374293600,"INFO	2025-10-13T16:51:33,600	351107	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 212.0 in stage 0.0 (TID 212) in 21466 ms on 172.35.24.244 (executor 3) (213/590)
"
1760374294589,"INFO	2025-10-13T16:51:34,589	352096	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 231.0 in stage 0.0 (TID 231) (172.34.194.6, executor 7, partition 231, PROCESS_LOCAL, 29311 bytes) 
"
1760374294590,"INFO	2025-10-13T16:51:34,589	352096	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 213.0 in stage 0.0 (TID 213) in 21776 ms on 172.34.194.6 (executor 7) (214/590)
"
1760374296096,"INFO	2025-10-13T16:51:36,096	353603	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 232.0 in stage 0.0 (TID 232) (172.35.107.166, executor 8, partition 232, PROCESS_LOCAL, 29311 bytes) 
"
1760374296096,"INFO	2025-10-13T16:51:36,096	353603	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 214.0 in stage 0.0 (TID 214) in 22635 ms on 172.35.107.166 (executor 8) (215/590)
"
1760374297400,"INFO	2025-10-13T16:51:37,399	354906	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 233.0 in stage 0.0 (TID 233) (172.34.46.142, executor 1, partition 233, PROCESS_LOCAL, 29311 bytes) 
"
1760374297400,"INFO	2025-10-13T16:51:37,400	354907	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 215.0 in stage 0.0 (TID 215) in 22032 ms on 172.34.46.142 (executor 1) (216/590)
"
1760374298237,"INFO	2025-10-13T16:51:38,236	355743	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 234.0 in stage 0.0 (TID 234) (172.34.206.195, executor 6, partition 234, PROCESS_LOCAL, 29311 bytes) 
"
1760374298237,"INFO	2025-10-13T16:51:38,237	355744	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 216.0 in stage 0.0 (TID 216) in 22261 ms on 172.34.206.195 (executor 6) (217/590)
"
1760374299052,"INFO	2025-10-13T16:51:39,052	356559	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374299052,"INFO	2025-10-13T16:51:39,052	356559	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 44, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374299053,"INFO	2025-10-13T16:51:39,052	356559	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 44; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_44_a_spark-application-1760373954341_p_1
"
1760374299053,"INFO	2025-10-13T16:51:39,053	356560	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374299085,"INFO	2025-10-13T16:51:39,085	356592	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374299085,"INFO	2025-10-13T16:51:39,085	356592	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5aa375c9-ffa7-4786-b805-ebf87b1436a9)
"
1760374299085,"INFO	2025-10-13T16:51:39,085	356592	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 44 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374300169,"INFO	2025-10-13T16:51:40,169	357676	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 235.0 in stage 0.0 (TID 235) (172.34.141.1, executor 4, partition 235, PROCESS_LOCAL, 29311 bytes) 
"
1760374300170,"INFO	2025-10-13T16:51:40,170	357677	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 217.0 in stage 0.0 (TID 217) in 23342 ms on 172.34.141.1 (executor 4) (218/590)
"
1760374301281,"INFO	2025-10-13T16:51:41,280	358787	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 236.0 in stage 0.0 (TID 236) (172.34.206.195, executor 6, partition 236, PROCESS_LOCAL, 29311 bytes) 
"
1760374301281,"INFO	2025-10-13T16:51:41,281	358788	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 218.0 in stage 0.0 (TID 218) in 22643 ms on 172.34.206.195 (executor 6) (219/590)
"
1760374301520,"INFO	2025-10-13T16:51:41,520	359027	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 237.0 in stage 0.0 (TID 237) (172.34.141.1, executor 4, partition 237, PROCESS_LOCAL, 29311 bytes) 
"
1760374301521,"INFO	2025-10-13T16:51:41,520	359027	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 219.0 in stage 0.0 (TID 219) in 22802 ms on 172.34.141.1 (executor 4) (220/590)
"
1760374301563,"INFO	2025-10-13T16:51:41,562	359069	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 238.0 in stage 0.0 (TID 238) (172.34.46.142, executor 1, partition 238, PROCESS_LOCAL, 29311 bytes) 
"
1760374301563,"INFO	2025-10-13T16:51:41,563	359070	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 220.0 in stage 0.0 (TID 220) in 21637 ms on 172.34.46.142 (executor 1) (221/590)
"
1760374304638,"INFO	2025-10-13T16:51:44,638	362145	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 239.0 in stage 0.0 (TID 239) (172.34.27.84, executor 9, partition 239, PROCESS_LOCAL, 29311 bytes) 
"
1760374304639,"INFO	2025-10-13T16:51:44,639	362146	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 221.0 in stage 0.0 (TID 221) in 21790 ms on 172.34.27.84 (executor 9) (222/590)
"
1760374308403,"INFO	2025-10-13T16:51:48,402	365909	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 240.0 in stage 0.0 (TID 240) (172.35.201.115, executor 5, partition 240, PROCESS_LOCAL, 29311 bytes) 
"
1760374308403,"INFO	2025-10-13T16:51:48,403	365910	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 223.0 in stage 0.0 (TID 223) in 22167 ms on 172.35.201.115 (executor 5) (223/590)
"
1760374308796,"INFO	2025-10-13T16:51:48,795	366302	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 241.0 in stage 0.0 (TID 241) (172.34.27.84, executor 9, partition 241, PROCESS_LOCAL, 29311 bytes) 
"
1760374308796,"INFO	2025-10-13T16:51:48,796	366303	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 224.0 in stage 0.0 (TID 224) in 22099 ms on 172.34.27.84 (executor 9) (224/590)
"
1760374308818,"INFO	2025-10-13T16:51:48,818	366325	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 242.0 in stage 0.0 (TID 242) (172.34.141.226, executor 2, partition 242, PROCESS_LOCAL, 29311 bytes) 
"
1760374308818,"INFO	2025-10-13T16:51:48,818	366325	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 222.0 in stage 0.0 (TID 222) in 23668 ms on 172.34.141.226 (executor 2) (225/590)
"
1760374309861,"INFO	2025-10-13T16:51:49,860	367367	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374309861,"INFO	2025-10-13T16:51:49,861	367368	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 45, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374309861,"INFO	2025-10-13T16:51:49,861	367368	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 45; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_45_a_spark-application-1760373954341_p_1
"
1760374309861,"INFO	2025-10-13T16:51:49,861	367368	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374309894,"INFO	2025-10-13T16:51:49,893	367400	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374309894,"INFO	2025-10-13T16:51:49,894	367401	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: f4a9be1d-f8e6-43ea-a15f-3dcfe90c8f3c)
"
1760374309894,"INFO	2025-10-13T16:51:49,894	367401	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 45 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374310980,"INFO	2025-10-13T16:51:50,979	368486	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 243.0 in stage 0.0 (TID 243) (172.34.194.6, executor 7, partition 243, PROCESS_LOCAL, 29311 bytes) 
"
1760374310980,"INFO	2025-10-13T16:51:50,980	368487	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 226.0 in stage 0.0 (TID 226) in 21805 ms on 172.34.194.6 (executor 7) (226/590)
"
1760374311748,"INFO	2025-10-13T16:51:51,747	369254	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 244.0 in stage 0.0 (TID 244) (172.35.24.244, executor 3, partition 244, PROCESS_LOCAL, 29311 bytes) 
"
1760374311748,"INFO	2025-10-13T16:51:51,748	369255	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 227.0 in stage 0.0 (TID 227) in 21878 ms on 172.35.24.244 (executor 3) (227/590)
"
1760374311845,"INFO	2025-10-13T16:51:51,845	369352	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 245.0 in stage 0.0 (TID 245) (172.34.141.226, executor 2, partition 245, PROCESS_LOCAL, 29311 bytes) 
"
1760374311846,"INFO	2025-10-13T16:51:51,845	369352	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 225.0 in stage 0.0 (TID 225) in 24088 ms on 172.34.141.226 (executor 2) (228/590)
"
1760374313687,"INFO	2025-10-13T16:51:53,687	371194	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 246.0 in stage 0.0 (TID 246) (172.35.201.115, executor 5, partition 246, PROCESS_LOCAL, 29311 bytes) 
"
1760374313688,"INFO	2025-10-13T16:51:53,687	371194	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 229.0 in stage 0.0 (TID 229) in 22146 ms on 172.35.201.115 (executor 5) (229/590)
"
1760374314064,"INFO	2025-10-13T16:51:54,064	371571	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 247.0 in stage 0.0 (TID 247) (172.35.107.166, executor 8, partition 247, PROCESS_LOCAL, 29311 bytes) 
"
1760374314065,"INFO	2025-10-13T16:51:54,064	371571	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 228.0 in stage 0.0 (TID 228) in 22783 ms on 172.35.107.166 (executor 8) (230/590)
"
1760374314474,"INFO	2025-10-13T16:51:54,474	371981	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374314474,"INFO	2025-10-13T16:51:54,474	371981	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374315622,"INFO	2025-10-13T16:51:55,622	373129	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 248.0 in stage 0.0 (TID 248) (172.35.24.244, executor 3, partition 248, PROCESS_LOCAL, 29311 bytes) 
"
1760374315622,"INFO	2025-10-13T16:51:55,622	373129	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 230.0 in stage 0.0 (TID 230) in 22023 ms on 172.35.24.244 (executor 3) (231/590)
"
1760374316413,"INFO	2025-10-13T16:51:56,413	373920	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 249.0 in stage 0.0 (TID 249) (172.34.194.6, executor 7, partition 249, PROCESS_LOCAL, 29311 bytes) 
"
1760374316413,"INFO	2025-10-13T16:51:56,413	373920	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 231.0 in stage 0.0 (TID 231) in 21824 ms on 172.34.194.6 (executor 7) (232/590)
"
1760374318727,"INFO	2025-10-13T16:51:58,727	376234	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 250.0 in stage 0.0 (TID 250) (172.35.107.166, executor 8, partition 250, PROCESS_LOCAL, 29311 bytes) 
"
1760374318727,"INFO	2025-10-13T16:51:58,727	376234	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 232.0 in stage 0.0 (TID 232) in 22632 ms on 172.35.107.166 (executor 8) (233/590)
"
1760374319168,"INFO	2025-10-13T16:51:59,168	376675	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 251.0 in stage 0.0 (TID 251) (172.34.46.142, executor 1, partition 251, PROCESS_LOCAL, 29311 bytes) 
"
1760374319168,"INFO	2025-10-13T16:51:59,168	376675	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 233.0 in stage 0.0 (TID 233) in 21769 ms on 172.34.46.142 (executor 1) (234/590)
"
1760374320813,"INFO	2025-10-13T16:52:00,812	378319	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 252.0 in stage 0.0 (TID 252) (172.34.206.195, executor 6, partition 252, PROCESS_LOCAL, 29311 bytes) 
INFO	2025-10-13T16:52:00,812	378319	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 234.0 in stage 0.0 (TID 234) in 22576 ms on 172.34.206.195 (executor 6) (235/590)
"
1760374323163,"INFO	2025-10-13T16:52:03,163	380670	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 253.0 in stage 0.0 (TID 253) (172.34.141.1, executor 4, partition 253, PROCESS_LOCAL, 29311 bytes) 
"
1760374323164,"INFO	2025-10-13T16:52:03,164	380671	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 235.0 in stage 0.0 (TID 235) in 22995 ms on 172.34.141.1 (executor 4) (236/590)
"
1760374323214,"INFO	2025-10-13T16:52:03,214	380721	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374323214,"INFO	2025-10-13T16:52:03,214	380721	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 46, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374323215,"INFO	2025-10-13T16:52:03,214	380721	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 46; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_46_a_spark-application-1760373954341_p_1
"
1760374323215,"INFO	2025-10-13T16:52:03,215	380722	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374323244,"INFO	2025-10-13T16:52:03,243	380750	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374323244,"INFO	2025-10-13T16:52:03,244	380751	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: ff7587cc-7c67-4481-98ce-790fd90efcbb)
"
1760374323244,"INFO	2025-10-13T16:52:03,244	380751	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 46 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374323563,"INFO	2025-10-13T16:52:03,562	381069	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 254.0 in stage 0.0 (TID 254) (172.34.46.142, executor 1, partition 254, PROCESS_LOCAL, 29311 bytes) 
"
1760374323563,"INFO	2025-10-13T16:52:03,563	381070	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 238.0 in stage 0.0 (TID 238) in 22001 ms on 172.34.46.142 (executor 1) (237/590)
"
1760374323923,"INFO	2025-10-13T16:52:03,923	381430	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 255.0 in stage 0.0 (TID 255) (172.34.206.195, executor 6, partition 255, PROCESS_LOCAL, 29311 bytes) 
"
1760374323924,"INFO	2025-10-13T16:52:03,923	381430	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 236.0 in stage 0.0 (TID 236) in 22643 ms on 172.34.206.195 (executor 6) (238/590)
"
1760374324687,"INFO	2025-10-13T16:52:04,687	382194	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 256.0 in stage 0.0 (TID 256) (172.34.141.1, executor 4, partition 256, PROCESS_LOCAL, 29311 bytes) 
"
1760374324687,"INFO	2025-10-13T16:52:04,687	382194	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 237.0 in stage 0.0 (TID 237) in 23168 ms on 172.34.141.1 (executor 4) (239/590)
"
1760374326943,"INFO	2025-10-13T16:52:06,942	384449	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 257.0 in stage 0.0 (TID 257) (172.34.27.84, executor 9, partition 257, PROCESS_LOCAL, 29311 bytes) 
"
1760374326943,"INFO	2025-10-13T16:52:06,943	384450	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 239.0 in stage 0.0 (TID 239) in 22305 ms on 172.34.27.84 (executor 9) (240/590)
"
1760374327729,"INFO	2025-10-13T16:52:07,729	385236	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374327729,"INFO	2025-10-13T16:52:07,729	385236	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 47, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374327729,"INFO	2025-10-13T16:52:07,729	385236	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 47; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_47_a_spark-application-1760373954341_p_1
"
1760374327730,"INFO	2025-10-13T16:52:07,729	385236	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374327771,"INFO	2025-10-13T16:52:07,771	385278	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374327771,"INFO	2025-10-13T16:52:07,771	385278	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: ebb10639-8ab6-498c-b507-710dd4235e03)
"
1760374327771,"INFO	2025-10-13T16:52:07,771	385278	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 47 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374329209,"INFO	2025-10-13T16:52:09,208	386715	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374329209,"INFO	2025-10-13T16:52:09,209	386716	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 48, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374329209,"INFO	2025-10-13T16:52:09,209	386716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 48; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_48_a_spark-application-1760373954341_p_1
"
1760374329209,"INFO	2025-10-13T16:52:09,209	386716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374329252,"INFO	2025-10-13T16:52:09,251	386758	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374329252,"INFO	2025-10-13T16:52:09,251	386758	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: db53d0c1-fcc7-494d-8bc2-dc1656d1f71e)
"
1760374329252,"INFO	2025-10-13T16:52:09,252	386759	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 48 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374330814,"INFO	2025-10-13T16:52:10,814	388321	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 258.0 in stage 0.0 (TID 258) (172.35.201.115, executor 5, partition 258, PROCESS_LOCAL, 29311 bytes) 
"
1760374330815,"INFO	2025-10-13T16:52:10,814	388321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 240.0 in stage 0.0 (TID 240) in 22412 ms on 172.35.201.115 (executor 5) (241/590)
"
1760374330830,"INFO	2025-10-13T16:52:10,830	388337	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 259.0 in stage 0.0 (TID 259) (172.34.27.84, executor 9, partition 259, PROCESS_LOCAL, 29311 bytes) 
"
1760374330831,"INFO	2025-10-13T16:52:10,831	388338	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 241.0 in stage 0.0 (TID 241) in 22036 ms on 172.34.27.84 (executor 9) (242/590)
"
1760374332352,"INFO	2025-10-13T16:52:12,351	389858	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 260.0 in stage 0.0 (TID 260) (172.34.141.226, executor 2, partition 260, PROCESS_LOCAL, 29311 bytes) 
"
1760374332352,"INFO	2025-10-13T16:52:12,352	389859	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 242.0 in stage 0.0 (TID 242) in 23535 ms on 172.34.141.226 (executor 2) (243/590)
"
1760374332472,"INFO	2025-10-13T16:52:12,472	389979	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374332472,"INFO	2025-10-13T16:52:12,472	389979	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 49, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374332472,"INFO	2025-10-13T16:52:12,472	389979	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 49; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_49_a_spark-application-1760373954341_p_1
"
1760374332473,"INFO	2025-10-13T16:52:12,472	389979	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374332527,"INFO	2025-10-13T16:52:12,527	390034	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374332527,"INFO	2025-10-13T16:52:12,527	390034	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: dde4fc68-6e3a-4e3e-9168-dc78541179c2)
"
1760374332527,"INFO	2025-10-13T16:52:12,527	390034	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 49 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374332720,"INFO	2025-10-13T16:52:12,720	390227	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 261.0 in stage 0.0 (TID 261) (172.34.194.6, executor 7, partition 261, PROCESS_LOCAL, 29311 bytes) 
"
1760374332720,"INFO	2025-10-13T16:52:12,720	390227	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 243.0 in stage 0.0 (TID 243) in 21741 ms on 172.34.194.6 (executor 7) (244/590)
"
1760374333205,"INFO	2025-10-13T16:52:13,205	390712	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 262.0 in stage 0.0 (TID 262) (172.35.24.244, executor 3, partition 262, PROCESS_LOCAL, 29311 bytes) 
"
1760374333205,"INFO	2025-10-13T16:52:13,205	390712	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 244.0 in stage 0.0 (TID 244) in 21458 ms on 172.35.24.244 (executor 3) (245/590)
"
1760374335782,"INFO	2025-10-13T16:52:15,781	393288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 263.0 in stage 0.0 (TID 263) (172.34.141.226, executor 2, partition 263, PROCESS_LOCAL, 29311 bytes) 
"
1760374335782,"INFO	2025-10-13T16:52:15,782	393289	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 245.0 in stage 0.0 (TID 245) in 23937 ms on 172.34.141.226 (executor 2) (246/590)
"
1760374336012,"INFO	2025-10-13T16:52:16,012	393519	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 264.0 in stage 0.0 (TID 264) (172.35.201.115, executor 5, partition 264, PROCESS_LOCAL, 29311 bytes) 
"
1760374336013,"INFO	2025-10-13T16:52:16,012	393519	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 246.0 in stage 0.0 (TID 246) in 22325 ms on 172.35.201.115 (executor 5) (247/590)
"
1760374337060,"INFO	2025-10-13T16:52:17,060	394567	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 265.0 in stage 0.0 (TID 265) (172.35.107.166, executor 8, partition 265, PROCESS_LOCAL, 29311 bytes) 
"
1760374337060,"INFO	2025-10-13T16:52:17,060	394567	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 247.0 in stage 0.0 (TID 247) in 22996 ms on 172.35.107.166 (executor 8) (248/590)
"
1760374337104,"INFO	2025-10-13T16:52:17,104	394611	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 266.0 in stage 0.0 (TID 266) (172.35.24.244, executor 3, partition 266, PROCESS_LOCAL, 29311 bytes) 
"
1760374337104,"INFO	2025-10-13T16:52:17,104	394611	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 248.0 in stage 0.0 (TID 248) in 21483 ms on 172.35.24.244 (executor 3) (249/590)
"
1760374337848,"INFO	2025-10-13T16:52:17,848	395355	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374337848,"INFO	2025-10-13T16:52:17,848	395355	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 50, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374337848,"INFO	2025-10-13T16:52:17,848	395355	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 50; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_50_a_spark-application-1760373954341_p_1
"
1760374337848,"INFO	2025-10-13T16:52:17,848	395355	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374337886,"INFO	2025-10-13T16:52:17,886	395393	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374337886,"INFO	2025-10-13T16:52:17,886	395393	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 08e0e31b-6201-4b2e-b9d0-5257f2224692)
"
1760374337886,"INFO	2025-10-13T16:52:17,886	395393	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 50 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374338312,"INFO	2025-10-13T16:52:18,311	395818	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 267.0 in stage 0.0 (TID 267) (172.34.194.6, executor 7, partition 267, PROCESS_LOCAL, 29311 bytes) 
"
1760374338312,"INFO	2025-10-13T16:52:18,312	395819	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 249.0 in stage 0.0 (TID 249) in 21900 ms on 172.34.194.6 (executor 7) (250/590)
"
1760374340796,"INFO	2025-10-13T16:52:20,795	398302	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 268.0 in stage 0.0 (TID 268) (172.34.46.142, executor 1, partition 268, PROCESS_LOCAL, 29311 bytes) 
"
1760374340796,"INFO	2025-10-13T16:52:20,796	398303	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 251.0 in stage 0.0 (TID 251) in 21629 ms on 172.34.46.142 (executor 1) (251/590)
"
1760374342095,"INFO	2025-10-13T16:52:22,094	399601	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 269.0 in stage 0.0 (TID 269) (172.35.107.166, executor 8, partition 269, PROCESS_LOCAL, 29311 bytes) 
"
1760374342095,"INFO	2025-10-13T16:52:22,095	399602	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 250.0 in stage 0.0 (TID 250) in 23369 ms on 172.35.107.166 (executor 8) (252/590)
"
1760374343669,"INFO	2025-10-13T16:52:23,669	401176	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 270.0 in stage 0.0 (TID 270) (172.34.206.195, executor 6, partition 270, PROCESS_LOCAL, 29311 bytes) 
"
1760374343670,"INFO	2025-10-13T16:52:23,669	401176	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 252.0 in stage 0.0 (TID 252) in 22857 ms on 172.34.206.195 (executor 6) (253/590)
"
1760374343926,"INFO	2025-10-13T16:52:23,925	401432	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374343926,"INFO	2025-10-13T16:52:23,926	401433	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 51, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374343926,"INFO	2025-10-13T16:52:23,926	401433	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 51; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_51_a_spark-application-1760373954341_p_1
"
1760374343926,"INFO	2025-10-13T16:52:23,926	401433	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374343957,"INFO	2025-10-13T16:52:23,957	401464	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374343957,"INFO	2025-10-13T16:52:23,957	401464	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 65bf4cb5-9715-4c72-8e68-f86f46112efd)
"
1760374343957,"INFO	2025-10-13T16:52:23,957	401464	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 51 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374345590,"INFO	2025-10-13T16:52:25,590	403097	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 271.0 in stage 0.0 (TID 271) (172.34.46.142, executor 1, partition 271, PROCESS_LOCAL, 29311 bytes) 
"
1760374345590,"INFO	2025-10-13T16:52:25,590	403097	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 254.0 in stage 0.0 (TID 254) in 22028 ms on 172.34.46.142 (executor 1) (254/590)
"
1760374345887,"INFO	2025-10-13T16:52:25,887	403394	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 272.0 in stage 0.0 (TID 272) (172.34.141.1, executor 4, partition 272, PROCESS_LOCAL, 29311 bytes) 
"
1760374345887,"INFO	2025-10-13T16:52:25,887	403394	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 253.0 in stage 0.0 (TID 253) in 22724 ms on 172.34.141.1 (executor 4) (255/590)
"
1760374346846,"INFO	2025-10-13T16:52:26,846	404353	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 273.0 in stage 0.0 (TID 273) (172.34.206.195, executor 6, partition 273, PROCESS_LOCAL, 29311 bytes) 
"
1760374346846,"INFO	2025-10-13T16:52:26,846	404353	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 255.0 in stage 0.0 (TID 255) in 22924 ms on 172.34.206.195 (executor 6) (256/590)
"
1760374347413,"INFO	2025-10-13T16:52:27,413	404920	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 274.0 in stage 0.0 (TID 274) (172.34.141.1, executor 4, partition 274, PROCESS_LOCAL, 29311 bytes) 
"
1760374347414,"INFO	2025-10-13T16:52:27,414	404921	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 256.0 in stage 0.0 (TID 256) in 22727 ms on 172.34.141.1 (executor 4) (257/590)
"
1760374347534,"INFO	2025-10-13T16:52:27,533	405040	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374347534,"INFO	2025-10-13T16:52:27,534	405041	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 52, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374347534,"INFO	2025-10-13T16:52:27,534	405041	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 52; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_52_a_spark-application-1760373954341_p_1
"
1760374347534,"INFO	2025-10-13T16:52:27,534	405041	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374347564,"INFO	2025-10-13T16:52:27,564	405071	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374347564,"INFO	2025-10-13T16:52:27,564	405071	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 557e5413-e178-4a36-a739-b9b7e8872ee3)
"
1760374347565,"INFO	2025-10-13T16:52:27,564	405071	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 52 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374348730,"INFO	2025-10-13T16:52:28,730	406237	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 275.0 in stage 0.0 (TID 275) (172.34.27.84, executor 9, partition 275, PROCESS_LOCAL, 29311 bytes) 
"
1760374348730,"INFO	2025-10-13T16:52:28,730	406237	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 257.0 in stage 0.0 (TID 257) in 21788 ms on 172.34.27.84 (executor 9) (258/590)
"
1760374351215,"INFO	2025-10-13T16:52:31,215	408722	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374351215,"INFO	2025-10-13T16:52:31,215	408722	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 53, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374351215,"INFO	2025-10-13T16:52:31,215	408722	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 53; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_53_a_spark-application-1760373954341_p_1
"
1760374351215,"INFO	2025-10-13T16:52:31,215	408722	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374351257,"INFO	2025-10-13T16:52:31,256	408763	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374351257,"INFO	2025-10-13T16:52:31,257	408764	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 0a61d760-758a-4ebe-9869-cff0ca697df7)
"
1760374351257,"INFO	2025-10-13T16:52:31,257	408764	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 53 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374352642,"INFO	2025-10-13T16:52:32,642	410149	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 276.0 in stage 0.0 (TID 276) (172.34.27.84, executor 9, partition 276, PROCESS_LOCAL, 29311 bytes) 
"
1760374352642,"INFO	2025-10-13T16:52:32,642	410149	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 259.0 in stage 0.0 (TID 259) in 21812 ms on 172.34.27.84 (executor 9) (259/590)
"
1760374352827,"INFO	2025-10-13T16:52:32,827	410334	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 277.0 in stage 0.0 (TID 277) (172.35.201.115, executor 5, partition 277, PROCESS_LOCAL, 29311 bytes) 
"
1760374352828,"INFO	2025-10-13T16:52:32,827	410334	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 258.0 in stage 0.0 (TID 258) in 22013 ms on 172.35.201.115 (executor 5) (260/590)
"
1760374354312,"INFO	2025-10-13T16:52:34,311	411818	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 278.0 in stage 0.0 (TID 278) (172.34.194.6, executor 7, partition 278, PROCESS_LOCAL, 29311 bytes) 
"
1760374354312,"INFO	2025-10-13T16:52:34,312	411819	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 261.0 in stage 0.0 (TID 261) in 21593 ms on 172.34.194.6 (executor 7) (261/590)
"
1760374354786,"INFO	2025-10-13T16:52:34,786	412293	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 279.0 in stage 0.0 (TID 279) (172.35.24.244, executor 3, partition 279, PROCESS_LOCAL, 29311 bytes) 
"
1760374354787,"INFO	2025-10-13T16:52:34,786	412293	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 262.0 in stage 0.0 (TID 262) in 21582 ms on 172.35.24.244 (executor 3) (262/590)
"
1760374356314,"INFO	2025-10-13T16:52:36,314	413821	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 280.0 in stage 0.0 (TID 280) (172.34.141.226, executor 2, partition 280, PROCESS_LOCAL, 29311 bytes) 
"
1760374356314,"INFO	2025-10-13T16:52:36,314	413821	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 260.0 in stage 0.0 (TID 260) in 23963 ms on 172.34.141.226 (executor 2) (263/590)
"
1760374356423,"INFO	2025-10-13T16:52:36,423	413930	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374356423,"INFO	2025-10-13T16:52:36,423	413930	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 54, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374356423,"INFO	2025-10-13T16:52:36,423	413930	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 54; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_54_a_spark-application-1760373954341_p_1
"
1760374356424,"INFO	2025-10-13T16:52:36,424	413931	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374356464,"INFO	2025-10-13T16:52:36,464	413971	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374356465,"INFO	2025-10-13T16:52:36,464	413971	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 6c6e7fdc-b0ab-46a8-9acc-d8559fb388ae)
"
1760374356465,"INFO	2025-10-13T16:52:36,464	413971	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 54 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374357145,"INFO	2025-10-13T16:52:37,145	414652	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374357145,"INFO	2025-10-13T16:52:37,145	414652	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 55, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374357145,"INFO	2025-10-13T16:52:37,145	414652	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 55; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_55_a_spark-application-1760373954341_p_1
"
1760374357145,"INFO	2025-10-13T16:52:37,145	414652	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374357182,"INFO	2025-10-13T16:52:37,182	414689	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374357182,"INFO	2025-10-13T16:52:37,182	414689	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 02c11812-4cc8-4b97-a560-6140ae9b29a2)
"
1760374357182,"INFO	2025-10-13T16:52:37,182	414689	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 55 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374358159,"INFO	2025-10-13T16:52:38,159	415666	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 281.0 in stage 0.0 (TID 281) (172.35.201.115, executor 5, partition 281, PROCESS_LOCAL, 29311 bytes) 
"
1760374358159,"INFO	2025-10-13T16:52:38,159	415666	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 264.0 in stage 0.0 (TID 264) in 22147 ms on 172.35.201.115 (executor 5) (264/590)
"
1760374358942,"INFO	2025-10-13T16:52:38,942	416449	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 282.0 in stage 0.0 (TID 282) (172.35.107.166, executor 8, partition 282, PROCESS_LOCAL, 29311 bytes) 
"
1760374358942,"INFO	2025-10-13T16:52:38,942	416449	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 265.0 in stage 0.0 (TID 265) in 21883 ms on 172.35.107.166 (executor 8) (265/590)
"
1760374359284,"INFO	2025-10-13T16:52:39,284	416791	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 283.0 in stage 0.0 (TID 283) (172.35.24.244, executor 3, partition 283, PROCESS_LOCAL, 29311 bytes) 
"
1760374359285,"INFO	2025-10-13T16:52:39,284	416791	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 266.0 in stage 0.0 (TID 266) in 22181 ms on 172.35.24.244 (executor 3) (266/590)
"
1760374359962,"INFO	2025-10-13T16:52:39,961	417468	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 284.0 in stage 0.0 (TID 284) (172.34.194.6, executor 7, partition 284, PROCESS_LOCAL, 29311 bytes) 
"
1760374359962,"INFO	2025-10-13T16:52:39,962	417469	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 267.0 in stage 0.0 (TID 267) in 21651 ms on 172.34.194.6 (executor 7) (267/590)
"
1760374359998,"INFO	2025-10-13T16:52:39,998	417505	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 285.0 in stage 0.0 (TID 285) (172.34.141.226, executor 2, partition 285, PROCESS_LOCAL, 29311 bytes) 
"
1760374359999,"INFO	2025-10-13T16:52:39,998	417505	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 263.0 in stage 0.0 (TID 263) in 24217 ms on 172.34.141.226 (executor 2) (268/590)
"
1760374362077,"INFO	2025-10-13T16:52:42,076	419583	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374362077,"INFO	2025-10-13T16:52:42,077	419584	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 56, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374362077,"INFO	2025-10-13T16:52:42,077	419584	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 56; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_56_a_spark-application-1760373954341_p_1
"
1760374362077,"INFO	2025-10-13T16:52:42,077	419584	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374362126,"INFO	2025-10-13T16:52:42,126	419633	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
INFO	2025-10-13T16:52:42,126	419633	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5be92581-f361-4925-81c1-4873a04da8e3)
"
1760374362127,"INFO	2025-10-13T16:52:42,126	419633	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 56 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374362292,"INFO	2025-10-13T16:52:42,292	419799	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 286.0 in stage 0.0 (TID 286) (172.34.46.142, executor 1, partition 286, PROCESS_LOCAL, 29311 bytes) 
"
1760374362293,"INFO	2025-10-13T16:52:42,293	419800	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 268.0 in stage 0.0 (TID 268) in 21498 ms on 172.34.46.142 (executor 1) (269/590)
"
1760374364069,"INFO	2025-10-13T16:52:44,069	421576	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 287.0 in stage 0.0 (TID 287) (172.35.107.166, executor 8, partition 287, PROCESS_LOCAL, 29311 bytes) 
"
1760374364069,"INFO	2025-10-13T16:52:44,069	421576	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 269.0 in stage 0.0 (TID 269) in 21975 ms on 172.35.107.166 (executor 8) (270/590)
"
1760374366892,"INFO	2025-10-13T16:52:46,892	424399	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 288.0 in stage 0.0 (TID 288) (172.34.206.195, executor 6, partition 288, PROCESS_LOCAL, 29311 bytes) 
"
1760374366893,"INFO	2025-10-13T16:52:46,893	424400	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 270.0 in stage 0.0 (TID 270) in 23223 ms on 172.34.206.195 (executor 6) (271/590)
"
1760374367463,"INFO	2025-10-13T16:52:47,463	424970	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 289.0 in stage 0.0 (TID 289) (172.34.46.142, executor 1, partition 289, PROCESS_LOCAL, 29311 bytes) 
"
1760374367463,"INFO	2025-10-13T16:52:47,463	424970	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 271.0 in stage 0.0 (TID 271) in 21874 ms on 172.34.46.142 (executor 1) (272/590)
"
1760374368884,"INFO	2025-10-13T16:52:48,884	426391	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 290.0 in stage 0.0 (TID 290) (172.34.141.1, executor 4, partition 290, PROCESS_LOCAL, 29311 bytes) 
"
1760374368884,"INFO	2025-10-13T16:52:48,884	426391	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 272.0 in stage 0.0 (TID 272) in 22998 ms on 172.34.141.1 (executor 4) (273/590)
"
1760374369752,"INFO	2025-10-13T16:52:49,751	427258	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 291.0 in stage 0.0 (TID 291) (172.34.206.195, executor 6, partition 291, PROCESS_LOCAL, 29311 bytes) 
"
1760374369752,"INFO	2025-10-13T16:52:49,752	427259	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 273.0 in stage 0.0 (TID 273) in 22907 ms on 172.34.206.195 (executor 6) (274/590)
"
1760374370689,"INFO	2025-10-13T16:52:50,689	428196	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 292.0 in stage 0.0 (TID 292) (172.34.141.1, executor 4, partition 292, PROCESS_LOCAL, 29311 bytes) 
INFO	2025-10-13T16:52:50,689	428196	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 274.0 in stage 0.0 (TID 274) in 23276 ms on 172.34.141.1 (executor 4) (275/590)
"
1760374370943,"INFO	2025-10-13T16:52:50,943	428450	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 293.0 in stage 0.0 (TID 293) (172.34.27.84, executor 9, partition 293, PROCESS_LOCAL, 29311 bytes) 
"
1760374370944,"INFO	2025-10-13T16:52:50,943	428450	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 275.0 in stage 0.0 (TID 275) in 22214 ms on 172.34.27.84 (executor 9) (276/590)
"
1760374374474,"INFO	2025-10-13T16:52:54,474	431981	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374374475,"INFO	2025-10-13T16:52:54,474	431981	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374374873,"INFO	2025-10-13T16:52:54,872	432379	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 294.0 in stage 0.0 (TID 294) (172.34.27.84, executor 9, partition 294, PROCESS_LOCAL, 29311 bytes) 
"
1760374374873,"INFO	2025-10-13T16:52:54,873	432380	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 276.0 in stage 0.0 (TID 276) in 22232 ms on 172.34.27.84 (executor 9) (277/590)
"
1760374374968,"INFO	2025-10-13T16:52:54,968	432475	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 295.0 in stage 0.0 (TID 295) (172.35.201.115, executor 5, partition 295, PROCESS_LOCAL, 29311 bytes) 
"
1760374374968,"INFO	2025-10-13T16:52:54,968	432475	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 277.0 in stage 0.0 (TID 277) in 22141 ms on 172.35.201.115 (executor 5) (278/590)
"
1760374375970,"INFO	2025-10-13T16:52:55,969	433476	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 296.0 in stage 0.0 (TID 296) (172.34.194.6, executor 7, partition 296, PROCESS_LOCAL, 29311 bytes) 
"
1760374375970,"INFO	2025-10-13T16:52:55,970	433477	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 278.0 in stage 0.0 (TID 278) in 21659 ms on 172.34.194.6 (executor 7) (279/590)
"
1760374376555,"INFO	2025-10-13T16:52:56,555	434062	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 297.0 in stage 0.0 (TID 297) (172.35.24.244, executor 3, partition 297, PROCESS_LOCAL, 29311 bytes) 
"
1760374376556,"INFO	2025-10-13T16:52:56,555	434062	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 279.0 in stage 0.0 (TID 279) in 21769 ms on 172.35.24.244 (executor 3) (280/590)
"
1760374376799,"INFO	2025-10-13T16:52:56,799	434306	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374376799,"INFO	2025-10-13T16:52:56,799	434306	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 57, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374376799,"INFO	2025-10-13T16:52:56,799	434306	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 57; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_57_a_spark-application-1760373954341_p_1
"
1760374376800,"INFO	2025-10-13T16:52:56,799	434306	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374376832,"INFO	2025-10-13T16:52:56,832	434339	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374376832,"INFO	2025-10-13T16:52:56,832	434339	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5f5b8ae7-9bca-42fc-82bc-ffbb8261493c)
"
1760374376832,"INFO	2025-10-13T16:52:56,832	434339	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 57 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374380535,"INFO	2025-10-13T16:53:00,534	438041	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 298.0 in stage 0.0 (TID 298) (172.35.201.115, executor 5, partition 298, PROCESS_LOCAL, 29311 bytes) 
"
1760374380535,"INFO	2025-10-13T16:53:00,535	438042	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 281.0 in stage 0.0 (TID 281) in 22377 ms on 172.35.201.115 (executor 5) (281/590)
"
1760374380781,"INFO	2025-10-13T16:53:00,781	438288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 299.0 in stage 0.0 (TID 299) (172.35.107.166, executor 8, partition 299, PROCESS_LOCAL, 29311 bytes) 
"
1760374380782,"INFO	2025-10-13T16:53:00,782	438289	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 282.0 in stage 0.0 (TID 282) in 21840 ms on 172.35.107.166 (executor 8) (282/590)
"
1760374380877,"INFO	2025-10-13T16:53:00,877	438384	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 300.0 in stage 0.0 (TID 300) (172.34.141.226, executor 2, partition 300, PROCESS_LOCAL, 29311 bytes) 
"
1760374380877,"INFO	2025-10-13T16:53:00,877	438384	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 280.0 in stage 0.0 (TID 280) in 24564 ms on 172.34.141.226 (executor 2) (283/590)
"
1760374380989,"INFO	2025-10-13T16:53:00,989	438496	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 301.0 in stage 0.0 (TID 301) (172.35.24.244, executor 3, partition 301, PROCESS_LOCAL, 29311 bytes) 
"
1760374380989,"INFO	2025-10-13T16:53:00,989	438496	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 283.0 in stage 0.0 (TID 283) in 21705 ms on 172.35.24.244 (executor 3) (284/590)
"
1760374381573,"INFO	2025-10-13T16:53:01,572	439079	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 302.0 in stage 0.0 (TID 302) (172.34.194.6, executor 7, partition 302, PROCESS_LOCAL, 29311 bytes) 
"
1760374381573,"INFO	2025-10-13T16:53:01,573	439080	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 284.0 in stage 0.0 (TID 284) in 21612 ms on 172.34.194.6 (executor 7) (285/590)
"
1760374384142,"INFO	2025-10-13T16:53:04,141	441648	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 303.0 in stage 0.0 (TID 303) (172.34.46.142, executor 1, partition 303, PROCESS_LOCAL, 29311 bytes) 
"
1760374384142,"INFO	2025-10-13T16:53:04,142	441649	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 286.0 in stage 0.0 (TID 286) in 21850 ms on 172.34.46.142 (executor 1) (286/590)
"
1760374384414,"INFO	2025-10-13T16:53:04,413	441920	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 304.0 in stage 0.0 (TID 304) (172.34.141.226, executor 2, partition 304, PROCESS_LOCAL, 29311 bytes) 
"
1760374384414,"INFO	2025-10-13T16:53:04,414	441921	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 285.0 in stage 0.0 (TID 285) in 24416 ms on 172.34.141.226 (executor 2) (287/590)
"
1760374386194,"INFO	2025-10-13T16:53:06,194	443701	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 305.0 in stage 0.0 (TID 305) (172.35.107.166, executor 8, partition 305, PROCESS_LOCAL, 29311 bytes) 
"
1760374386194,"INFO	2025-10-13T16:53:06,194	443701	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 287.0 in stage 0.0 (TID 287) in 22126 ms on 172.35.107.166 (executor 8) (288/590)
"
1760374389236,"INFO	2025-10-13T16:53:09,235	446742	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 306.0 in stage 0.0 (TID 306) (172.34.46.142, executor 1, partition 306, PROCESS_LOCAL, 29311 bytes) 
"
1760374389236,"INFO	2025-10-13T16:53:09,236	446743	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 289.0 in stage 0.0 (TID 289) in 21774 ms on 172.34.46.142 (executor 1) (289/590)
"
1760374389458,"INFO	2025-10-13T16:53:09,458	446965	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 307.0 in stage 0.0 (TID 307) (172.34.206.195, executor 6, partition 307, PROCESS_LOCAL, 29311 bytes) 
"
1760374389458,"INFO	2025-10-13T16:53:09,458	446965	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 288.0 in stage 0.0 (TID 288) in 22566 ms on 172.34.206.195 (executor 6) (290/590)
"
1760374389746,"INFO	2025-10-13T16:53:09,746	447253	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374389747,"INFO	2025-10-13T16:53:09,747	447254	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 58, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374389747,"INFO	2025-10-13T16:53:09,747	447254	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 58; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_58_a_spark-application-1760373954341_p_1
"
1760374389747,"INFO	2025-10-13T16:53:09,747	447254	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374389786,"INFO	2025-10-13T16:53:09,786	447293	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374389786,"INFO	2025-10-13T16:53:09,786	447293	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: aeb39de1-d9b9-4e23-8c1f-2a03ef79ed53)
"
1760374389786,"INFO	2025-10-13T16:53:09,786	447293	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 58 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374391920,"INFO	2025-10-13T16:53:11,920	449427	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 308.0 in stage 0.0 (TID 308) (172.34.141.1, executor 4, partition 308, PROCESS_LOCAL, 29311 bytes) 
"
1760374391920,"INFO	2025-10-13T16:53:11,920	449427	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 290.0 in stage 0.0 (TID 290) in 23037 ms on 172.34.141.1 (executor 4) (291/590)
"
1760374392681,"INFO	2025-10-13T16:53:12,681	450188	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 309.0 in stage 0.0 (TID 309) (172.34.206.195, executor 6, partition 309, PROCESS_LOCAL, 29311 bytes) 
"
1760374392681,"INFO	2025-10-13T16:53:12,681	450188	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 291.0 in stage 0.0 (TID 291) in 22930 ms on 172.34.206.195 (executor 6) (292/590)
"
1760374392719,"INFO	2025-10-13T16:53:12,719	450226	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 310.0 in stage 0.0 (TID 310) (172.34.27.84, executor 9, partition 310, PROCESS_LOCAL, 29311 bytes) 
"
1760374392719,"INFO	2025-10-13T16:53:12,719	450226	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 293.0 in stage 0.0 (TID 293) in 21776 ms on 172.34.27.84 (executor 9) (293/590)
"
1760374393644,"INFO	2025-10-13T16:53:13,644	451151	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 311.0 in stage 0.0 (TID 311) (172.34.141.1, executor 4, partition 311, PROCESS_LOCAL, 29311 bytes) 
"
1760374393645,"INFO	2025-10-13T16:53:13,645	451152	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 292.0 in stage 0.0 (TID 292) in 22957 ms on 172.34.141.1 (executor 4) (294/590)
"
1760374396330,"INFO	2025-10-13T16:53:16,329	453836	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374396330,"INFO	2025-10-13T16:53:16,330	453837	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 59, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374396330,"INFO	2025-10-13T16:53:16,330	453837	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 59; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_59_a_spark-application-1760373954341_p_1
"
1760374396330,"INFO	2025-10-13T16:53:16,330	453837	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374396367,"INFO	2025-10-13T16:53:16,367	453874	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 312.0 in stage 0.0 (TID 312) (172.34.27.84, executor 9, partition 312, PROCESS_LOCAL, 29311 bytes) 
"
1760374396368,"INFO	2025-10-13T16:53:16,368	453875	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 294.0 in stage 0.0 (TID 294) in 21496 ms on 172.34.27.84 (executor 9) (295/590)
"
1760374396381,"INFO	2025-10-13T16:53:16,381	453888	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374396381,"INFO	2025-10-13T16:53:16,381	453888	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: d9ba49d9-92e5-426c-b685-b1a4ae7de853)
"
1760374396381,"INFO	2025-10-13T16:53:16,381	453888	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 59 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374397290,"INFO	2025-10-13T16:53:17,290	454797	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 313.0 in stage 0.0 (TID 313) (172.35.201.115, executor 5, partition 313, PROCESS_LOCAL, 29311 bytes) 
"
1760374397291,"INFO	2025-10-13T16:53:17,291	454798	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 295.0 in stage 0.0 (TID 295) in 22323 ms on 172.35.201.115 (executor 5) (296/590)
"
1760374397854,"INFO	2025-10-13T16:53:17,853	455360	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 314.0 in stage 0.0 (TID 314) (172.34.194.6, executor 7, partition 314, PROCESS_LOCAL, 29311 bytes) 
"
1760374397854,"INFO	2025-10-13T16:53:17,854	455361	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 296.0 in stage 0.0 (TID 296) in 21885 ms on 172.34.194.6 (executor 7) (297/590)
"
1760374398292,"INFO	2025-10-13T16:53:18,291	455798	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 315.0 in stage 0.0 (TID 315) (172.35.24.244, executor 3, partition 315, PROCESS_LOCAL, 29311 bytes) 
"
1760374398292,"INFO	2025-10-13T16:53:18,292	455799	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 297.0 in stage 0.0 (TID 297) in 21737 ms on 172.35.24.244 (executor 3) (298/590)
"
1760374401077,"INFO	2025-10-13T16:53:21,076	458583	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374401077,"INFO	2025-10-13T16:53:21,077	458584	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 60, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374401077,"INFO	2025-10-13T16:53:21,077	458584	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 60; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_60_a_spark-application-1760373954341_p_1
"
1760374401077,"INFO	2025-10-13T16:53:21,077	458584	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374401115,"INFO	2025-10-13T16:53:21,115	458622	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374401115,"INFO	2025-10-13T16:53:21,115	458622	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 8818f50c-9571-4b20-b096-123076457b58)
"
1760374401115,"INFO	2025-10-13T16:53:21,115	458622	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 60 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374402726,"INFO	2025-10-13T16:53:22,725	460232	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 316.0 in stage 0.0 (TID 316) (172.35.201.115, executor 5, partition 316, PROCESS_LOCAL, 29311 bytes) 
"
1760374402726,"INFO	2025-10-13T16:53:22,726	460233	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 298.0 in stage 0.0 (TID 298) in 22192 ms on 172.35.201.115 (executor 5) (299/590)
"
1760374402767,"INFO	2025-10-13T16:53:22,766	460273	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 317.0 in stage 0.0 (TID 317) (172.35.24.244, executor 3, partition 317, PROCESS_LOCAL, 29311 bytes) 
"
1760374402767,"INFO	2025-10-13T16:53:22,767	460274	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 301.0 in stage 0.0 (TID 301) in 21779 ms on 172.35.24.244 (executor 3) (300/590)
"
1760374402856,"INFO	2025-10-13T16:53:22,856	460363	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 318.0 in stage 0.0 (TID 318) (172.35.107.166, executor 8, partition 318, PROCESS_LOCAL, 29311 bytes) 
"
1760374402856,"INFO	2025-10-13T16:53:22,856	460363	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 299.0 in stage 0.0 (TID 299) in 22075 ms on 172.35.107.166 (executor 8) (301/590)
"
1760374403653,"INFO	2025-10-13T16:53:23,653	461160	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 319.0 in stage 0.0 (TID 319) (172.34.194.6, executor 7, partition 319, PROCESS_LOCAL, 29311 bytes) 
"
1760374403654,"INFO	2025-10-13T16:53:23,653	461160	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 302.0 in stage 0.0 (TID 302) in 22081 ms on 172.34.194.6 (executor 7) (302/590)
"
1760374404817,"INFO	2025-10-13T16:53:24,816	462323	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 320.0 in stage 0.0 (TID 320) (172.34.141.226, executor 2, partition 320, PROCESS_LOCAL, 29311 bytes) 
INFO	2025-10-13T16:53:24,817	462324	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 300.0 in stage 0.0 (TID 300) in 23941 ms on 172.34.141.226 (executor 2) (303/590)
"
1760374405940,"INFO	2025-10-13T16:53:25,940	463447	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 321.0 in stage 0.0 (TID 321) (172.34.46.142, executor 1, partition 321, PROCESS_LOCAL, 29311 bytes) 
"
1760374405940,"INFO	2025-10-13T16:53:25,940	463447	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 303.0 in stage 0.0 (TID 303) in 21799 ms on 172.34.46.142 (executor 1) (304/590)
"
1760374406127,"INFO	2025-10-13T16:53:26,127	463634	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374406127,"INFO	2025-10-13T16:53:26,127	463634	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 61, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374406127,"INFO	2025-10-13T16:53:26,127	463634	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 61; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_61_a_spark-application-1760373954341_p_1
"
1760374406127,"INFO	2025-10-13T16:53:26,127	463634	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374406168,"INFO	2025-10-13T16:53:26,168	463675	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374406168,"INFO	2025-10-13T16:53:26,168	463675	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a744a212-56e1-4305-a24a-738f9183e8e6)
"
1760374406168,"INFO	2025-10-13T16:53:26,168	463675	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 61 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374407929,"INFO	2025-10-13T16:53:27,928	465435	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 322.0 in stage 0.0 (TID 322) (172.35.107.166, executor 8, partition 322, PROCESS_LOCAL, 29311 bytes) 
"
1760374407929,"INFO	2025-10-13T16:53:27,929	465436	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 305.0 in stage 0.0 (TID 305) in 21736 ms on 172.35.107.166 (executor 8) (305/590)
"
1760374408287,"INFO	2025-10-13T16:53:28,287	465794	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 323.0 in stage 0.0 (TID 323) (172.34.141.226, executor 2, partition 323, PROCESS_LOCAL, 29311 bytes) 
"
1760374408287,"INFO	2025-10-13T16:53:28,287	465794	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 304.0 in stage 0.0 (TID 304) in 23874 ms on 172.34.141.226 (executor 2) (306/590)
"
1760374410171,"INFO	2025-10-13T16:53:30,171	467678	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374410172,"INFO	2025-10-13T16:53:30,171	467678	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 62, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374410172,"INFO	2025-10-13T16:53:30,172	467679	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 62; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_62_a_spark-application-1760373954341_p_1
"
1760374410172,"INFO	2025-10-13T16:53:30,172	467679	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374410202,"INFO	2025-10-13T16:53:30,201	467708	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374410202,"INFO	2025-10-13T16:53:30,202	467709	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 6dc43af2-3ead-43e5-9c5b-e2f510d93746)
"
1760374410202,"INFO	2025-10-13T16:53:30,202	467709	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 62 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374411012,"INFO	2025-10-13T16:53:31,012	468519	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 324.0 in stage 0.0 (TID 324) (172.34.46.142, executor 1, partition 324, PROCESS_LOCAL, 29311 bytes) 
"
1760374411012,"INFO	2025-10-13T16:53:31,012	468519	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 306.0 in stage 0.0 (TID 306) in 21777 ms on 172.34.46.142 (executor 1) (307/590)
"
1760374411809,"INFO	2025-10-13T16:53:31,809	469316	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 325.0 in stage 0.0 (TID 325) (172.34.206.195, executor 6, partition 325, PROCESS_LOCAL, 29311 bytes) 
"
1760374411809,"INFO	2025-10-13T16:53:31,809	469316	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 307.0 in stage 0.0 (TID 307) in 22352 ms on 172.34.206.195 (executor 6) (308/590)
"
1760374414347,"INFO	2025-10-13T16:53:34,347	471854	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 326.0 in stage 0.0 (TID 326) (172.34.27.84, executor 9, partition 326, PROCESS_LOCAL, 29311 bytes) 
"
1760374414348,"INFO	2025-10-13T16:53:34,347	471854	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 310.0 in stage 0.0 (TID 310) in 21629 ms on 172.34.27.84 (executor 9) (309/590)
"
1760374414904,"INFO	2025-10-13T16:53:34,904	472411	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 327.0 in stage 0.0 (TID 327) (172.34.141.1, executor 4, partition 327, PROCESS_LOCAL, 29311 bytes) 
"
1760374414904,"INFO	2025-10-13T16:53:34,904	472411	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 308.0 in stage 0.0 (TID 308) in 22985 ms on 172.34.141.1 (executor 4) (310/590)
"
1760374415081,"INFO	2025-10-13T16:53:35,081	472588	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 328.0 in stage 0.0 (TID 328) (172.34.206.195, executor 6, partition 328, PROCESS_LOCAL, 29311 bytes) 
"
1760374415082,"INFO	2025-10-13T16:53:35,082	472589	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 309.0 in stage 0.0 (TID 309) in 22402 ms on 172.34.206.195 (executor 6) (311/590)
"
1760374416781,"INFO	2025-10-13T16:53:36,781	474288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 329.0 in stage 0.0 (TID 329) (172.34.141.1, executor 4, partition 329, PROCESS_LOCAL, 29311 bytes) 
"
1760374416781,"INFO	2025-10-13T16:53:36,781	474288	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 311.0 in stage 0.0 (TID 311) in 23137 ms on 172.34.141.1 (executor 4) (312/590)
"
1760374418395,"INFO	2025-10-13T16:53:38,395	475902	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 330.0 in stage 0.0 (TID 330) (172.34.27.84, executor 9, partition 330, PROCESS_LOCAL, 29311 bytes) 
"
1760374418396,"INFO	2025-10-13T16:53:38,395	475902	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 312.0 in stage 0.0 (TID 312) in 22028 ms on 172.34.27.84 (executor 9) (313/590)
"
1760374419554,"INFO	2025-10-13T16:53:39,554	477061	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 331.0 in stage 0.0 (TID 331) (172.35.201.115, executor 5, partition 331, PROCESS_LOCAL, 29311 bytes) 
"
1760374419554,"INFO	2025-10-13T16:53:39,554	477061	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 313.0 in stage 0.0 (TID 313) in 22264 ms on 172.35.201.115 (executor 5) (314/590)
"
1760374419901,"INFO	2025-10-13T16:53:39,901	477408	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 332.0 in stage 0.0 (TID 332) (172.34.194.6, executor 7, partition 332, PROCESS_LOCAL, 29311 bytes) 
"
1760374419902,"INFO	2025-10-13T16:53:39,901	477408	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 314.0 in stage 0.0 (TID 314) in 22048 ms on 172.34.194.6 (executor 7) (315/590)
"
1760374419942,"INFO	2025-10-13T16:53:39,942	477449	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 333.0 in stage 0.0 (TID 333) (172.35.24.244, executor 3, partition 333, PROCESS_LOCAL, 29311 bytes) 
"
1760374419942,"INFO	2025-10-13T16:53:39,942	477449	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 315.0 in stage 0.0 (TID 315) in 21651 ms on 172.35.24.244 (executor 3) (316/590)
"
1760374423878,"INFO	2025-10-13T16:53:43,878	481385	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374423878,"INFO	2025-10-13T16:53:43,878	481385	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 63, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374423879,"INFO	2025-10-13T16:53:43,878	481385	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 63; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_63_a_spark-application-1760373954341_p_1
"
1760374423879,"INFO	2025-10-13T16:53:43,879	481386	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374423917,"INFO	2025-10-13T16:53:43,917	481424	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374423918,"INFO	2025-10-13T16:53:43,917	481424	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 17e305a3-238e-4ac4-9fcf-ae18c61d9eb6)
"
1760374423918,"INFO	2025-10-13T16:53:43,917	481424	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 63 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374424633,"INFO	2025-10-13T16:53:44,633	482140	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 334.0 in stage 0.0 (TID 334) (172.35.24.244, executor 3, partition 334, PROCESS_LOCAL, 29311 bytes) 
"
1760374424633,"INFO	2025-10-13T16:53:44,633	482140	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 317.0 in stage 0.0 (TID 317) in 21867 ms on 172.35.24.244 (executor 3) (317/590)
"
1760374425047,"INFO	2025-10-13T16:53:45,047	482554	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 335.0 in stage 0.0 (TID 335) (172.35.201.115, executor 5, partition 335, PROCESS_LOCAL, 29311 bytes) 
"
1760374425047,"INFO	2025-10-13T16:53:45,047	482554	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 316.0 in stage 0.0 (TID 316) in 22322 ms on 172.35.201.115 (executor 5) (318/590)
"
1760374425117,"INFO	2025-10-13T16:53:45,116	482623	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 336.0 in stage 0.0 (TID 336) (172.35.107.166, executor 8, partition 336, PROCESS_LOCAL, 29311 bytes) 
"
1760374425117,"INFO	2025-10-13T16:53:45,117	482624	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 318.0 in stage 0.0 (TID 318) in 22262 ms on 172.35.107.166 (executor 8) (319/590)
"
1760374425678,"INFO	2025-10-13T16:53:45,677	483184	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 337.0 in stage 0.0 (TID 337) (172.34.194.6, executor 7, partition 337, PROCESS_LOCAL, 29302 bytes) 
"
1760374425678,"INFO	2025-10-13T16:53:45,678	483185	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 319.0 in stage 0.0 (TID 319) in 22025 ms on 172.34.194.6 (executor 7) (320/590)
"
1760374427463,"INFO	2025-10-13T16:53:47,463	484970	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 338.0 in stage 0.0 (TID 338) (172.34.46.142, executor 1, partition 338, PROCESS_LOCAL, 29311 bytes) 
"
1760374427464,"INFO	2025-10-13T16:53:47,463	484970	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 321.0 in stage 0.0 (TID 321) in 21524 ms on 172.34.46.142 (executor 1) (321/590)
"
1760374428947,"INFO	2025-10-13T16:53:48,947	486454	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 339.0 in stage 0.0 (TID 339) (172.34.141.226, executor 2, partition 339, PROCESS_LOCAL, 29311 bytes) 
"
1760374428948,"INFO	2025-10-13T16:53:48,948	486455	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 320.0 in stage 0.0 (TID 320) in 24131 ms on 172.34.141.226 (executor 2) (322/590)
"
1760374429609,"INFO	2025-10-13T16:53:49,609	487116	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 340.0 in stage 0.0 (TID 340) (172.35.107.166, executor 8, partition 340, PROCESS_LOCAL, 29311 bytes) 
"
1760374429609,"INFO	2025-10-13T16:53:49,609	487116	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 322.0 in stage 0.0 (TID 322) in 21681 ms on 172.35.107.166 (executor 8) (323/590)
"
1760374432347,"INFO	2025-10-13T16:53:52,347	489854	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 341.0 in stage 0.0 (TID 341) (172.34.141.226, executor 2, partition 341, PROCESS_LOCAL, 29311 bytes) 
"
1760374432347,"INFO	2025-10-13T16:53:52,347	489854	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 323.0 in stage 0.0 (TID 323) in 24061 ms on 172.34.141.226 (executor 2) (324/590)
"
1760374433065,"INFO	2025-10-13T16:53:53,065	490572	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 342.0 in stage 0.0 (TID 342) (172.34.46.142, executor 1, partition 342, PROCESS_LOCAL, 29311 bytes) 
"
1760374433065,"INFO	2025-10-13T16:53:53,065	490572	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 324.0 in stage 0.0 (TID 324) in 22053 ms on 172.34.46.142 (executor 1) (325/590)
"
1760374433417,"INFO	2025-10-13T16:53:53,417	490924	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374433417,"INFO	2025-10-13T16:53:53,417	490924	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 64, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374433417,"INFO	2025-10-13T16:53:53,417	490924	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 64; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_64_a_spark-application-1760373954341_p_1
"
1760374433418,"INFO	2025-10-13T16:53:53,417	490924	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374433456,"INFO	2025-10-13T16:53:53,456	490963	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374433456,"INFO	2025-10-13T16:53:53,456	490963	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 25498dc0-246e-41f1-bd83-46add403247c)
"
1760374433456,"INFO	2025-10-13T16:53:53,456	490963	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 64 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374434475,"INFO	2025-10-13T16:53:54,475	491982	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374434475,"INFO	2025-10-13T16:53:54,475	491982	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374434847,"INFO	2025-10-13T16:53:54,847	492354	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 343.0 in stage 0.0 (TID 343) (172.34.206.195, executor 6, partition 343, PROCESS_LOCAL, 29311 bytes) 
"
1760374434847,"INFO	2025-10-13T16:53:54,847	492354	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 325.0 in stage 0.0 (TID 325) in 23039 ms on 172.34.206.195 (executor 6) (326/590)
"
1760374435990,"INFO	2025-10-13T16:53:55,990	493497	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 344.0 in stage 0.0 (TID 344) (172.34.27.84, executor 9, partition 344, PROCESS_LOCAL, 29311 bytes) 
"
1760374435991,"INFO	2025-10-13T16:53:55,990	493497	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 326.0 in stage 0.0 (TID 326) in 21643 ms on 172.34.27.84 (executor 9) (327/590)
"
1760374437635,"INFO	2025-10-13T16:53:57,634	495141	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 345.0 in stage 0.0 (TID 345) (172.34.206.195, executor 6, partition 345, PROCESS_LOCAL, 29311 bytes) 
"
1760374437635,"INFO	2025-10-13T16:53:57,635	495142	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 328.0 in stage 0.0 (TID 328) in 22554 ms on 172.34.206.195 (executor 6) (328/590)
"
1760374437638,"INFO	2025-10-13T16:53:57,638	495145	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 346.0 in stage 0.0 (TID 346) (172.34.141.1, executor 4, partition 346, PROCESS_LOCAL, 29311 bytes) 
"
1760374437638,"INFO	2025-10-13T16:53:57,638	495145	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 327.0 in stage 0.0 (TID 327) in 22735 ms on 172.34.141.1 (executor 4) (329/590)
"
1760374439917,"INFO	2025-10-13T16:53:59,917	497424	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 347.0 in stage 0.0 (TID 347) (172.34.141.1, executor 4, partition 347, PROCESS_LOCAL, 29311 bytes) 
"
1760374439918,"INFO	2025-10-13T16:53:59,918	497425	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 329.0 in stage 0.0 (TID 329) in 23138 ms on 172.34.141.1 (executor 4) (330/590)
"
1760374440039,"INFO	2025-10-13T16:54:00,038	497545	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 348.0 in stage 0.0 (TID 348) (172.34.27.84, executor 9, partition 348, PROCESS_LOCAL, 29311 bytes) 
"
1760374440040,"INFO	2025-10-13T16:54:00,039	497546	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 330.0 in stage 0.0 (TID 330) in 21644 ms on 172.34.27.84 (executor 9) (331/590)
"
1760374441491,"INFO	2025-10-13T16:54:01,491	498998	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 349.0 in stage 0.0 (TID 349) (172.35.201.115, executor 5, partition 349, PROCESS_LOCAL, 29311 bytes) 
"
1760374441491,"INFO	2025-10-13T16:54:01,491	498998	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 331.0 in stage 0.0 (TID 331) in 21938 ms on 172.35.201.115 (executor 5) (332/590)
"
1760374441555,"INFO	2025-10-13T16:54:01,555	499062	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 350.0 in stage 0.0 (TID 350) (172.34.194.6, executor 7, partition 350, PROCESS_LOCAL, 29311 bytes) 
"
1760374441556,"INFO	2025-10-13T16:54:01,555	499062	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 332.0 in stage 0.0 (TID 332) in 21654 ms on 172.34.194.6 (executor 7) (333/590)
"
1760374441669,"INFO	2025-10-13T16:54:01,668	499175	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374441669,"INFO	2025-10-13T16:54:01,669	499176	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 65, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374441669,"INFO	2025-10-13T16:54:01,669	499176	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 65; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_65_a_spark-application-1760373954341_p_1
"
1760374441669,"INFO	2025-10-13T16:54:01,669	499176	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374441712,"INFO	2025-10-13T16:54:01,712	499219	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374441713,"INFO	2025-10-13T16:54:01,712	499219	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: c4fa4b7d-e123-4b45-ba7a-5b62a2c672d8)
"
1760374441713,"INFO	2025-10-13T16:54:01,712	499219	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 65 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374441806,"INFO	2025-10-13T16:54:01,806	499313	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 351.0 in stage 0.0 (TID 351) (172.35.24.244, executor 3, partition 351, PROCESS_LOCAL, 29311 bytes) 
"
1760374441807,"INFO	2025-10-13T16:54:01,806	499313	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 333.0 in stage 0.0 (TID 333) in 21865 ms on 172.35.24.244 (executor 3) (334/590)
"
1760374446746,"INFO	2025-10-13T16:54:06,746	504253	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 352.0 in stage 0.0 (TID 352) (172.35.107.166, executor 8, partition 352, PROCESS_LOCAL, 29311 bytes) 
"
1760374446747,"INFO	2025-10-13T16:54:06,746	504253	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 336.0 in stage 0.0 (TID 336) in 21630 ms on 172.35.107.166 (executor 8) (335/590)
"
1760374446866,"INFO	2025-10-13T16:54:06,866	504373	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 353.0 in stage 0.0 (TID 353) (172.35.24.244, executor 3, partition 353, PROCESS_LOCAL, 29311 bytes) 
"
1760374446867,"INFO	2025-10-13T16:54:06,866	504373	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 334.0 in stage 0.0 (TID 334) in 22234 ms on 172.35.24.244 (executor 3) (336/590)
"
1760374447057,"INFO	2025-10-13T16:54:07,057	504564	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 354.0 in stage 0.0 (TID 354) (172.35.201.115, executor 5, partition 354, PROCESS_LOCAL, 29311 bytes) 
"
1760374447058,"INFO	2025-10-13T16:54:07,057	504564	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 335.0 in stage 0.0 (TID 335) in 22011 ms on 172.35.201.115 (executor 5) (337/590)
"
1760374447642,"INFO	2025-10-13T16:54:07,641	505148	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 355.0 in stage 0.0 (TID 355) (172.34.194.6, executor 7, partition 355, PROCESS_LOCAL, 29311 bytes) 
"
1760374447642,"INFO	2025-10-13T16:54:07,642	505149	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 337.0 in stage 0.0 (TID 337) in 21965 ms on 172.34.194.6 (executor 7) (338/590)
"
1760374449077,"INFO	2025-10-13T16:54:09,076	506583	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374449077,"INFO	2025-10-13T16:54:09,077	506584	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 66, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374449077,"INFO	2025-10-13T16:54:09,077	506584	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 66; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_66_a_spark-application-1760373954341_p_1
"
1760374449077,"INFO	2025-10-13T16:54:09,077	506584	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374449115,"INFO	2025-10-13T16:54:09,115	506622	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374449115,"INFO	2025-10-13T16:54:09,115	506622	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: f14483bc-0de5-440b-b1b7-5b11c6325c04)
"
1760374449115,"INFO	2025-10-13T16:54:09,115	506622	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 66 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374449404,"INFO	2025-10-13T16:54:09,404	506911	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374449405,"INFO	2025-10-13T16:54:09,405	506912	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 67, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374449405,"INFO	2025-10-13T16:54:09,405	506912	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 67; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_67_a_spark-application-1760373954341_p_1
"
1760374449405,"INFO	2025-10-13T16:54:09,405	506912	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374449436,"INFO	2025-10-13T16:54:09,436	506943	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374449437,"INFO	2025-10-13T16:54:09,436	506943	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: d340a3ae-bcb3-4d20-b63f-0875cddabac3)
"
1760374449437,"INFO	2025-10-13T16:54:09,436	506943	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 67 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374449634,"INFO	2025-10-13T16:54:09,633	507140	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 356.0 in stage 0.0 (TID 356) (172.34.46.142, executor 1, partition 356, PROCESS_LOCAL, 29311 bytes) 
"
1760374449634,"INFO	2025-10-13T16:54:09,634	507141	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 338.0 in stage 0.0 (TID 338) in 22171 ms on 172.34.46.142 (executor 1) (339/590)
"
1760374451421,"INFO	2025-10-13T16:54:11,420	508927	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 357.0 in stage 0.0 (TID 357) (172.35.107.166, executor 8, partition 357, PROCESS_LOCAL, 29311 bytes) 
"
1760374451421,"INFO	2025-10-13T16:54:11,421	508928	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 340.0 in stage 0.0 (TID 340) in 21813 ms on 172.35.107.166 (executor 8) (340/590)
"
1760374452504,"INFO	2025-10-13T16:54:12,504	510011	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374452504,"INFO	2025-10-13T16:54:12,504	510011	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 68, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374452504,"INFO	2025-10-13T16:54:12,504	510011	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 68; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_68_a_spark-application-1760373954341_p_1
"
1760374452505,"INFO	2025-10-13T16:54:12,505	510012	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374452543,"INFO	2025-10-13T16:54:12,542	510049	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374452543,"INFO	2025-10-13T16:54:12,542	510049	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 03765671-53d0-4656-a1ef-f763ca3fa681)
"
1760374452543,"INFO	2025-10-13T16:54:12,543	510050	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 68 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374453783,"INFO	2025-10-13T16:54:13,782	511289	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 358.0 in stage 0.0 (TID 358) (172.34.141.226, executor 2, partition 358, PROCESS_LOCAL, 29311 bytes) 
"
1760374453783,"INFO	2025-10-13T16:54:13,783	511290	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 339.0 in stage 0.0 (TID 339) in 24836 ms on 172.34.141.226 (executor 2) (341/590)
"
1760374455026,"INFO	2025-10-13T16:54:15,026	512533	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 359.0 in stage 0.0 (TID 359) (172.34.46.142, executor 1, partition 359, PROCESS_LOCAL, 29311 bytes) 
"
1760374455026,"INFO	2025-10-13T16:54:15,026	512533	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 342.0 in stage 0.0 (TID 342) in 21961 ms on 172.34.46.142 (executor 1) (342/590)
"
1760374456991,"INFO	2025-10-13T16:54:16,990	514497	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 360.0 in stage 0.0 (TID 360) (172.34.141.226, executor 2, partition 360, PROCESS_LOCAL, 29311 bytes) 
"
1760374456991,"INFO	2025-10-13T16:54:16,991	514498	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 341.0 in stage 0.0 (TID 341) in 24645 ms on 172.34.141.226 (executor 2) (343/590)
"
1760374457640,"INFO	2025-10-13T16:54:17,639	515146	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 361.0 in stage 0.0 (TID 361) (172.34.206.195, executor 6, partition 361, PROCESS_LOCAL, 29311 bytes) 
"
1760374457640,"INFO	2025-10-13T16:54:17,640	515147	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 343.0 in stage 0.0 (TID 343) in 22794 ms on 172.34.206.195 (executor 6) (344/590)
"
1760374458385,"INFO	2025-10-13T16:54:18,384	515891	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 362.0 in stage 0.0 (TID 362) (172.34.27.84, executor 9, partition 362, PROCESS_LOCAL, 29311 bytes) 
"
1760374458385,"INFO	2025-10-13T16:54:18,385	515892	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 344.0 in stage 0.0 (TID 344) in 22395 ms on 172.34.27.84 (executor 9) (345/590)
"
1760374460620,"INFO	2025-10-13T16:54:20,619	518126	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 363.0 in stage 0.0 (TID 363) (172.34.141.1, executor 4, partition 363, PROCESS_LOCAL, 29311 bytes) 
"
1760374460620,"INFO	2025-10-13T16:54:20,620	518127	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 346.0 in stage 0.0 (TID 346) in 22983 ms on 172.34.141.1 (executor 4) (346/590)
"
1760374460631,"INFO	2025-10-13T16:54:20,631	518138	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 364.0 in stage 0.0 (TID 364) (172.34.206.195, executor 6, partition 364, PROCESS_LOCAL, 29311 bytes) 
"
1760374460631,"INFO	2025-10-13T16:54:20,631	518138	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 345.0 in stage 0.0 (TID 345) in 22997 ms on 172.34.206.195 (executor 6) (347/590)
"
1760374462059,"INFO	2025-10-13T16:54:22,059	519566	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 365.0 in stage 0.0 (TID 365) (172.34.27.84, executor 9, partition 365, PROCESS_LOCAL, 29311 bytes) 
"
1760374462060,"INFO	2025-10-13T16:54:22,059	519566	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 348.0 in stage 0.0 (TID 348) in 22021 ms on 172.34.27.84 (executor 9) (348/590)
"
1760374463129,"INFO	2025-10-13T16:54:23,128	520635	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 366.0 in stage 0.0 (TID 366) (172.34.141.1, executor 4, partition 366, PROCESS_LOCAL, 29311 bytes) 
"
1760374463129,"INFO	2025-10-13T16:54:23,129	520636	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 347.0 in stage 0.0 (TID 347) in 23212 ms on 172.34.141.1 (executor 4) (349/590)
"
1760374463411,"INFO	2025-10-13T16:54:23,411	520918	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 367.0 in stage 0.0 (TID 367) (172.35.201.115, executor 5, partition 367, PROCESS_LOCAL, 29302 bytes) 
"
1760374463412,"INFO	2025-10-13T16:54:23,411	520918	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 349.0 in stage 0.0 (TID 349) in 21921 ms on 172.35.201.115 (executor 5) (350/590)
"
1760374463689,"INFO	2025-10-13T16:54:23,688	521195	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 368.0 in stage 0.0 (TID 368) (172.34.194.6, executor 7, partition 368, PROCESS_LOCAL, 29311 bytes) 
"
1760374463689,"INFO	2025-10-13T16:54:23,689	521196	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 350.0 in stage 0.0 (TID 350) in 22134 ms on 172.34.194.6 (executor 7) (351/590)
"
1760374464356,"INFO	2025-10-13T16:54:24,356	521863	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 369.0 in stage 0.0 (TID 369) (172.35.24.244, executor 3, partition 369, PROCESS_LOCAL, 29311 bytes) 
"
1760374464357,"INFO	2025-10-13T16:54:24,356	521863	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 351.0 in stage 0.0 (TID 351) in 22550 ms on 172.35.24.244 (executor 3) (352/590)
"
1760374466924,"INFO	2025-10-13T16:54:26,924	524431	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374466924,"INFO	2025-10-13T16:54:26,924	524431	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 69, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374466924,"INFO	2025-10-13T16:54:26,924	524431	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 69; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_69_a_spark-application-1760373954341_p_1
"
1760374466925,"INFO	2025-10-13T16:54:26,924	524431	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374466977,"INFO	2025-10-13T16:54:26,977	524484	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374466978,"INFO	2025-10-13T16:54:26,977	524484	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: b4ab5ffc-da15-4943-bec4-b956c58cf007)
"
1760374466978,"INFO	2025-10-13T16:54:26,977	524484	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 69 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374469045,"INFO	2025-10-13T16:54:29,045	526552	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 370.0 in stage 0.0 (TID 370) (172.35.107.166, executor 8, partition 370, PROCESS_LOCAL, 29311 bytes) 
"
1760374469046,"INFO	2025-10-13T16:54:29,045	526552	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 352.0 in stage 0.0 (TID 352) in 22299 ms on 172.35.107.166 (executor 8) (353/590)
"
1760374469470,"INFO	2025-10-13T16:54:29,469	526976	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 371.0 in stage 0.0 (TID 371) (172.35.24.244, executor 3, partition 371, PROCESS_LOCAL, 29311 bytes) 
"
1760374469470,"INFO	2025-10-13T16:54:29,470	526977	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 353.0 in stage 0.0 (TID 353) in 22604 ms on 172.35.24.244 (executor 3) (354/590)
"
1760374469804,"INFO	2025-10-13T16:54:29,804	527311	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 372.0 in stage 0.0 (TID 372) (172.35.201.115, executor 5, partition 372, PROCESS_LOCAL, 29311 bytes) 
"
1760374469805,"INFO	2025-10-13T16:54:29,804	527311	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 354.0 in stage 0.0 (TID 354) in 22747 ms on 172.35.201.115 (executor 5) (355/590)
"
1760374469931,"INFO	2025-10-13T16:54:29,931	527438	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 373.0 in stage 0.0 (TID 373) (172.34.194.6, executor 7, partition 373, PROCESS_LOCAL, 29311 bytes) 
"
1760374469932,"INFO	2025-10-13T16:54:29,931	527438	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 355.0 in stage 0.0 (TID 355) in 22290 ms on 172.34.194.6 (executor 7) (356/590)
"
1760374471388,"INFO	2025-10-13T16:54:31,388	528895	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 374.0 in stage 0.0 (TID 374) (172.34.46.142, executor 1, partition 374, PROCESS_LOCAL, 29311 bytes) 
"
1760374471388,"INFO	2025-10-13T16:54:31,388	528895	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 356.0 in stage 0.0 (TID 356) in 21755 ms on 172.34.46.142 (executor 1) (357/590)
"
1760374472921,"INFO	2025-10-13T16:54:32,921	530428	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 375.0 in stage 0.0 (TID 375) (172.35.107.166, executor 8, partition 375, PROCESS_LOCAL, 29311 bytes) 
"
1760374472921,"INFO	2025-10-13T16:54:32,921	530428	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 357.0 in stage 0.0 (TID 357) in 21501 ms on 172.35.107.166 (executor 8) (358/590)
"
1760374476731,"INFO	2025-10-13T16:54:36,731	534238	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 376.0 in stage 0.0 (TID 376) (172.34.46.142, executor 1, partition 376, PROCESS_LOCAL, 29311 bytes) 
"
1760374476732,"INFO	2025-10-13T16:54:36,731	534238	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 359.0 in stage 0.0 (TID 359) in 21706 ms on 172.34.46.142 (executor 1) (359/590)
"
1760374477881,"INFO	2025-10-13T16:54:37,880	535387	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 377.0 in stage 0.0 (TID 377) (172.34.141.226, executor 2, partition 377, PROCESS_LOCAL, 29311 bytes) 
"
1760374477881,"INFO	2025-10-13T16:54:37,881	535388	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 358.0 in stage 0.0 (TID 358) in 24099 ms on 172.34.141.226 (executor 2) (360/590)
"
1760374478754,"INFO	2025-10-13T16:54:38,754	536261	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 378.0 in stage 0.0 (TID 378) (172.34.27.84, executor 9, partition 378, PROCESS_LOCAL, 29311 bytes) 
"
1760374478754,"INFO	2025-10-13T16:54:38,754	536261	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 362.0 in stage 0.0 (TID 362) in 20370 ms on 172.34.27.84 (executor 9) (361/590)
"
1760374479830,"INFO	2025-10-13T16:54:39,830	537337	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 379.0 in stage 0.0 (TID 379) (172.34.206.195, executor 6, partition 379, PROCESS_LOCAL, 29311 bytes) 
"
1760374479831,"INFO	2025-10-13T16:54:39,831	537338	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 361.0 in stage 0.0 (TID 361) in 22192 ms on 172.34.206.195 (executor 6) (362/590)
"
1760374480431,"INFO	2025-10-13T16:54:40,431	537938	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374480431,"INFO	2025-10-13T16:54:40,431	537938	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 70, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374480431,"INFO	2025-10-13T16:54:40,431	537938	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 70; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_70_a_spark-application-1760373954341_p_1
"
1760374480432,"INFO	2025-10-13T16:54:40,431	537938	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374480479,"INFO	2025-10-13T16:54:40,479	537986	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374480479,"INFO	2025-10-13T16:54:40,479	537986	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 4095daf1-a3fa-4c8f-9db8-07033d1949a7)
"
1760374480479,"INFO	2025-10-13T16:54:40,479	537986	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 70 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374481027,"INFO	2025-10-13T16:54:41,027	538534	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 380.0 in stage 0.0 (TID 380) (172.34.141.226, executor 2, partition 380, PROCESS_LOCAL, 29311 bytes) 
"
1760374481028,"INFO	2025-10-13T16:54:41,027	538534	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 360.0 in stage 0.0 (TID 360) in 24037 ms on 172.34.141.226 (executor 2) (363/590)
"
1760374481509,"INFO	2025-10-13T16:54:41,508	539015	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374481509,"INFO	2025-10-13T16:54:41,509	539016	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 71, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374481509,"INFO	2025-10-13T16:54:41,509	539016	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 71; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_71_a_spark-application-1760373954341_p_1
"
1760374481509,"INFO	2025-10-13T16:54:41,509	539016	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374481556,"INFO	2025-10-13T16:54:41,556	539063	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374481556,"INFO	2025-10-13T16:54:41,556	539063	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a196fcbd-d854-4ab3-9848-4a2e0d0835aa)
"
1760374481556,"INFO	2025-10-13T16:54:41,556	539063	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 71 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374482395,"INFO	2025-10-13T16:54:42,395	539902	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 381.0 in stage 0.0 (TID 381) (172.34.27.84, executor 9, partition 381, PROCESS_LOCAL, 29311 bytes) 
"
1760374482396,"INFO	2025-10-13T16:54:42,395	539902	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 365.0 in stage 0.0 (TID 365) in 20336 ms on 172.34.27.84 (executor 9) (364/590)
"
1760374483266,"INFO	2025-10-13T16:54:43,265	540772	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 382.0 in stage 0.0 (TID 382) (172.34.206.195, executor 6, partition 382, PROCESS_LOCAL, 29302 bytes) 
"
1760374483266,"INFO	2025-10-13T16:54:43,266	540773	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 364.0 in stage 0.0 (TID 364) in 22635 ms on 172.34.206.195 (executor 6) (365/590)
"
1760374483336,"INFO	2025-10-13T16:54:43,336	540843	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 383.0 in stage 0.0 (TID 383) (172.34.141.1, executor 4, partition 383, PROCESS_LOCAL, 29311 bytes) 
"
1760374483337,"INFO	2025-10-13T16:54:43,336	540843	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 363.0 in stage 0.0 (TID 363) in 22717 ms on 172.34.141.1 (executor 4) (366/590)
"
1760374485341,"INFO	2025-10-13T16:54:45,341	542848	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 384.0 in stage 0.0 (TID 384) (172.35.201.115, executor 5, partition 384, PROCESS_LOCAL, 29311 bytes) 
"
1760374485342,"INFO	2025-10-13T16:54:45,341	542848	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 367.0 in stage 0.0 (TID 367) in 21930 ms on 172.35.201.115 (executor 5) (367/590)
"
1760374485806,"INFO	2025-10-13T16:54:45,805	543312	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 385.0 in stage 0.0 (TID 385) (172.34.141.1, executor 4, partition 385, PROCESS_LOCAL, 29311 bytes) 
"
1760374485806,"INFO	2025-10-13T16:54:45,806	543313	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 366.0 in stage 0.0 (TID 366) in 22678 ms on 172.34.141.1 (executor 4) (368/590)
"
1760374486481,"INFO	2025-10-13T16:54:46,480	543987	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 386.0 in stage 0.0 (TID 386) (172.34.194.6, executor 7, partition 386, PROCESS_LOCAL, 29311 bytes) 
"
1760374486481,"INFO	2025-10-13T16:54:46,481	543988	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 368.0 in stage 0.0 (TID 368) in 22793 ms on 172.34.194.6 (executor 7) (369/590)
"
1760374486834,"INFO	2025-10-13T16:54:46,833	544340	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 387.0 in stage 0.0 (TID 387) (172.35.24.244, executor 3, partition 387, PROCESS_LOCAL, 29311 bytes) 
"
1760374486834,"INFO	2025-10-13T16:54:46,834	544341	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 369.0 in stage 0.0 (TID 369) in 22478 ms on 172.35.24.244 (executor 3) (370/590)
"
1760374490500,"INFO	2025-10-13T16:54:50,499	548006	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374490500,"INFO	2025-10-13T16:54:50,500	548007	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 72, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374490500,"INFO	2025-10-13T16:54:50,500	548007	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 72; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_72_a_spark-application-1760373954341_p_1
"
1760374490500,"INFO	2025-10-13T16:54:50,500	548007	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374490532,"INFO	2025-10-13T16:54:50,531	548038	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374490532,"INFO	2025-10-13T16:54:50,532	548039	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 6053f438-640e-41c2-b7f9-449c1030b549)
"
1760374490532,"INFO	2025-10-13T16:54:50,532	548039	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 72 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374490579,"INFO	2025-10-13T16:54:50,579	548086	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 388.0 in stage 0.0 (TID 388) (172.35.201.115, executor 5, partition 388, PROCESS_LOCAL, 29311 bytes) 
"
1760374490579,"INFO	2025-10-13T16:54:50,579	548086	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 372.0 in stage 0.0 (TID 372) in 20775 ms on 172.35.201.115 (executor 5) (371/590)
"
1760374491108,"INFO	2025-10-13T16:54:51,107	548614	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 389.0 in stage 0.0 (TID 389) (172.35.107.166, executor 8, partition 389, PROCESS_LOCAL, 29311 bytes) 
"
1760374491108,"INFO	2025-10-13T16:54:51,108	548615	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 370.0 in stage 0.0 (TID 370) in 22063 ms on 172.35.107.166 (executor 8) (372/590)
"
1760374491255,"INFO	2025-10-13T16:54:51,255	548762	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 390.0 in stage 0.0 (TID 390) (172.34.194.6, executor 7, partition 390, PROCESS_LOCAL, 29311 bytes) 
"
1760374491255,"INFO	2025-10-13T16:54:51,255	548762	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 373.0 in stage 0.0 (TID 373) in 21324 ms on 172.34.194.6 (executor 7) (373/590)
"
1760374491656,"INFO	2025-10-13T16:54:51,655	549162	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 391.0 in stage 0.0 (TID 391) (172.35.24.244, executor 3, partition 391, PROCESS_LOCAL, 29311 bytes) 
"
1760374491656,"INFO	2025-10-13T16:54:51,656	549163	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 371.0 in stage 0.0 (TID 371) in 22187 ms on 172.35.24.244 (executor 3) (374/590)
"
1760374492006,"INFO	2025-10-13T16:54:52,005	549512	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 392.0 in stage 0.0 (TID 392) (172.34.46.142, executor 1, partition 392, PROCESS_LOCAL, 29311 bytes) 
"
1760374492006,"INFO	2025-10-13T16:54:52,006	549513	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 374.0 in stage 0.0 (TID 374) in 20619 ms on 172.34.46.142 (executor 1) (375/590)
"
1760374493667,"INFO	2025-10-13T16:54:53,666	551173	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 393.0 in stage 0.0 (TID 393) (172.35.107.166, executor 8, partition 393, PROCESS_LOCAL, 29311 bytes) 
"
1760374493667,"INFO	2025-10-13T16:54:53,667	551174	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 375.0 in stage 0.0 (TID 375) in 20762 ms on 172.35.107.166 (executor 8) (376/590)
"
1760374494012,"INFO	2025-10-13T16:54:54,012	551519	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374494012,"INFO	2025-10-13T16:54:54,012	551519	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 73, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374494012,"INFO	2025-10-13T16:54:54,012	551519	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 73; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_73_a_spark-application-1760373954341_p_1
"
1760374494013,"INFO	2025-10-13T16:54:54,013	551520	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374494063,"INFO	2025-10-13T16:54:54,063	551570	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374494063,"INFO	2025-10-13T16:54:54,063	551570	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: c3a86332-6285-4deb-befe-fef424404e3a)
"
1760374494063,"INFO	2025-10-13T16:54:54,063	551570	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 73 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374494475,"INFO	2025-10-13T16:54:54,475	551982	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374494476,"INFO	2025-10-13T16:54:54,475	551982	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374497313,"INFO	2025-10-13T16:54:57,313	554820	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 394.0 in stage 0.0 (TID 394) (172.34.46.142, executor 1, partition 394, PROCESS_LOCAL, 29311 bytes) 
"
1760374497313,"INFO	2025-10-13T16:54:57,313	554820	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 376.0 in stage 0.0 (TID 376) in 20582 ms on 172.34.46.142 (executor 1) (377/590)
"
1760374497984,"INFO	2025-10-13T16:54:57,984	555491	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 395.0 in stage 0.0 (TID 395) (172.34.27.84, executor 9, partition 395, PROCESS_LOCAL, 29311 bytes) 
"
1760374497985,"INFO	2025-10-13T16:54:57,984	555491	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 378.0 in stage 0.0 (TID 378) in 19230 ms on 172.34.27.84 (executor 9) (378/590)
"
1760374500215,"INFO	2025-10-13T16:55:00,215	557722	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 396.0 in stage 0.0 (TID 396) (172.34.141.226, executor 2, partition 396, PROCESS_LOCAL, 29311 bytes) 
"
1760374500215,"INFO	2025-10-13T16:55:00,215	557722	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 377.0 in stage 0.0 (TID 377) in 22335 ms on 172.34.141.226 (executor 2) (379/590)
"
1760374501513,"INFO	2025-10-13T16:55:01,513	559020	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 397.0 in stage 0.0 (TID 397) (172.34.27.84, executor 9, partition 397, PROCESS_LOCAL, 29302 bytes) 
"
1760374501514,"INFO	2025-10-13T16:55:01,513	559020	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 381.0 in stage 0.0 (TID 381) in 19118 ms on 172.34.27.84 (executor 9) (380/590)
"
1760374502965,"INFO	2025-10-13T16:55:02,965	560472	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 398.0 in stage 0.0 (TID 398) (172.34.206.195, executor 6, partition 398, PROCESS_LOCAL, 29311 bytes) 
"
1760374502965,"INFO	2025-10-13T16:55:02,965	560472	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 379.0 in stage 0.0 (TID 379) in 23135 ms on 172.34.206.195 (executor 6) (381/590)
"
1760374504005,"INFO	2025-10-13T16:55:04,004	561511	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 399.0 in stage 0.0 (TID 399) (172.34.141.226, executor 2, partition 399, PROCESS_LOCAL, 29311 bytes) 
"
1760374504005,"INFO	2025-10-13T16:55:04,005	561512	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 380.0 in stage 0.0 (TID 380) in 22978 ms on 172.34.141.226 (executor 2) (382/590)
"
1760374504007,"INFO	2025-10-13T16:55:04,007	561514	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 400.0 in stage 0.0 (TID 400) (172.34.206.195, executor 6, partition 400, PROCESS_LOCAL, 29311 bytes) 
"
1760374504007,"INFO	2025-10-13T16:55:04,007	561514	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 382.0 in stage 0.0 (TID 382) in 20742 ms on 172.34.206.195 (executor 6) (383/590)
"
1760374504813,"INFO	2025-10-13T16:55:04,812	562319	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 401.0 in stage 0.0 (TID 401) (172.34.141.1, executor 4, partition 401, PROCESS_LOCAL, 29311 bytes) 
"
1760374504813,"INFO	2025-10-13T16:55:04,813	562320	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 383.0 in stage 0.0 (TID 383) in 21477 ms on 172.34.141.1 (executor 4) (384/590)
"
1760374505217,"INFO	2025-10-13T16:55:05,217	562724	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374505218,"INFO	2025-10-13T16:55:05,218	562725	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 74, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374505218,"INFO	2025-10-13T16:55:05,218	562725	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 74; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_74_a_spark-application-1760373954341_p_1
"
1760374505218,"INFO	2025-10-13T16:55:05,218	562725	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374505248,"INFO	2025-10-13T16:55:05,248	562755	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374505248,"INFO	2025-10-13T16:55:05,248	562755	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 582ab998-c408-4a2c-a173-1465bdd48beb)
"
1760374505248,"INFO	2025-10-13T16:55:05,248	562755	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 74 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374505819,"INFO	2025-10-13T16:55:05,819	563326	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 402.0 in stage 0.0 (TID 402) (172.35.201.115, executor 5, partition 402, PROCESS_LOCAL, 29311 bytes) 
"
1760374505820,"INFO	2025-10-13T16:55:05,820	563327	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 384.0 in stage 0.0 (TID 384) in 20479 ms on 172.35.201.115 (executor 5) (385/590)
"
1760374509018,"INFO	2025-10-13T16:55:09,017	566524	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 403.0 in stage 0.0 (TID 403) (172.34.194.6, executor 7, partition 403, PROCESS_LOCAL, 29311 bytes) 
"
1760374509018,"INFO	2025-10-13T16:55:09,018	566525	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 386.0 in stage 0.0 (TID 386) in 22538 ms on 172.34.194.6 (executor 7) (386/590)
"
1760374509078,"INFO	2025-10-13T16:55:09,077	566584	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 404.0 in stage 0.0 (TID 404) (172.35.24.244, executor 3, partition 404, PROCESS_LOCAL, 29311 bytes) 
"
1760374509078,"INFO	2025-10-13T16:55:09,078	566585	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 387.0 in stage 0.0 (TID 387) in 22245 ms on 172.35.24.244 (executor 3) (387/590)
"
1760374509745,"INFO	2025-10-13T16:55:09,745	567252	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 405.0 in stage 0.0 (TID 405) (172.34.141.1, executor 4, partition 405, PROCESS_LOCAL, 29311 bytes) 
"
1760374509746,"INFO	2025-10-13T16:55:09,745	567252	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 385.0 in stage 0.0 (TID 385) in 23940 ms on 172.34.141.1 (executor 4) (388/590)
"
1760374513175,"INFO	2025-10-13T16:55:13,175	570682	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 406.0 in stage 0.0 (TID 406) (172.35.201.115, executor 5, partition 406, PROCESS_LOCAL, 29311 bytes) 
"
1760374513175,"INFO	2025-10-13T16:55:13,175	570682	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 388.0 in stage 0.0 (TID 388) in 22597 ms on 172.35.201.115 (executor 5) (389/590)
"
1760374513424,"INFO	2025-10-13T16:55:13,424	570931	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 407.0 in stage 0.0 (TID 407) (172.35.107.166, executor 8, partition 407, PROCESS_LOCAL, 29311 bytes) 
"
1760374513425,"INFO	2025-10-13T16:55:13,424	570931	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 389.0 in stage 0.0 (TID 389) in 22317 ms on 172.35.107.166 (executor 8) (390/590)
"
1760374513817,"INFO	2025-10-13T16:55:13,816	571323	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 408.0 in stage 0.0 (TID 408) (172.34.194.6, executor 7, partition 408, PROCESS_LOCAL, 29311 bytes) 
"
1760374513817,"INFO	2025-10-13T16:55:13,817	571324	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 390.0 in stage 0.0 (TID 390) in 22563 ms on 172.34.194.6 (executor 7) (391/590)
"
1760374513884,"INFO	2025-10-13T16:55:13,883	571390	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 409.0 in stage 0.0 (TID 409) (172.35.24.244, executor 3, partition 409, PROCESS_LOCAL, 29311 bytes) 
"
1760374513884,"INFO	2025-10-13T16:55:13,884	571391	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 391.0 in stage 0.0 (TID 391) in 22229 ms on 172.35.24.244 (executor 3) (392/590)
"
1760374514312,"INFO	2025-10-13T16:55:14,312	571819	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 410.0 in stage 0.0 (TID 410) (172.34.46.142, executor 1, partition 410, PROCESS_LOCAL, 29311 bytes) 
"
1760374514312,"INFO	2025-10-13T16:55:14,312	571819	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 392.0 in stage 0.0 (TID 392) in 22307 ms on 172.34.46.142 (executor 1) (393/590)
"
1760374514742,"INFO	2025-10-13T16:55:14,741	572248	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374514742,"INFO	2025-10-13T16:55:14,742	572249	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 75, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374514742,"INFO	2025-10-13T16:55:14,742	572249	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 75; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_75_a_spark-application-1760373954341_p_1
"
1760374514742,"INFO	2025-10-13T16:55:14,742	572249	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374514779,"INFO	2025-10-13T16:55:14,779	572286	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374514779,"INFO	2025-10-13T16:55:14,779	572286	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: d4afb6b0-f64c-4342-85e8-40dc37b4155e)
"
1760374514779,"INFO	2025-10-13T16:55:14,779	572286	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 75 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374515880,"INFO	2025-10-13T16:55:15,879	573386	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 411.0 in stage 0.0 (TID 411) (172.35.107.166, executor 8, partition 411, PROCESS_LOCAL, 29311 bytes) 
"
1760374515880,"INFO	2025-10-13T16:55:15,880	573387	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 393.0 in stage 0.0 (TID 393) in 22214 ms on 172.35.107.166 (executor 8) (394/590)
"
1760374519035,"INFO	2025-10-13T16:55:19,035	576542	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 412.0 in stage 0.0 (TID 412) (172.34.27.84, executor 9, partition 412, PROCESS_LOCAL, 29311 bytes) 
"
1760374519036,"INFO	2025-10-13T16:55:19,035	576542	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 395.0 in stage 0.0 (TID 395) in 21051 ms on 172.34.27.84 (executor 9) (395/590)
"
1760374519585,"INFO	2025-10-13T16:55:19,585	577092	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 413.0 in stage 0.0 (TID 413) (172.34.46.142, executor 1, partition 413, PROCESS_LOCAL, 29311 bytes) 
"
1760374519586,"INFO	2025-10-13T16:55:19,585	577092	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 394.0 in stage 0.0 (TID 394) in 22273 ms on 172.34.46.142 (executor 1) (396/590)
"
1760374520965,"INFO	2025-10-13T16:55:20,964	578471	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374520965,"INFO	2025-10-13T16:55:20,965	578472	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 76, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374520965,"INFO	2025-10-13T16:55:20,965	578472	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 76; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_76_a_spark-application-1760373954341_p_1
"
1760374520965,"INFO	2025-10-13T16:55:20,965	578472	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374521006,"INFO	2025-10-13T16:55:21,006	578513	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374521006,"INFO	2025-10-13T16:55:21,006	578513	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a13fbed6-69c9-4e2c-b355-1b8b020a65e5)
"
1760374521006,"INFO	2025-10-13T16:55:21,006	578513	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 76 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374523253,"INFO	2025-10-13T16:55:23,253	580760	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 414.0 in stage 0.0 (TID 414) (172.34.27.84, executor 9, partition 414, PROCESS_LOCAL, 29311 bytes) 
"
1760374523253,"INFO	2025-10-13T16:55:23,253	580760	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 397.0 in stage 0.0 (TID 397) in 21740 ms on 172.34.27.84 (executor 9) (397/590)
"
1760374523673,"INFO	2025-10-13T16:55:23,673	581180	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374523674,"INFO	2025-10-13T16:55:23,673	581180	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 77, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374523674,"INFO	2025-10-13T16:55:23,674	581181	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 77; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_77_a_spark-application-1760373954341_p_1
"
1760374523674,"INFO	2025-10-13T16:55:23,674	581181	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374523715,"INFO	2025-10-13T16:55:23,714	581221	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374523715,"INFO	2025-10-13T16:55:23,714	581221	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 76588c0a-fb01-49cc-8a85-32199ce07054)
"
1760374523715,"INFO	2025-10-13T16:55:23,715	581222	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 77 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374523819,"INFO	2025-10-13T16:55:23,819	581326	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 415.0 in stage 0.0 (TID 415) (172.34.206.195, executor 6, partition 415, PROCESS_LOCAL, 29311 bytes) 
"
1760374523820,"INFO	2025-10-13T16:55:23,820	581327	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 398.0 in stage 0.0 (TID 398) in 20855 ms on 172.34.206.195 (executor 6) (398/590)
"
1760374525038,"INFO	2025-10-13T16:55:25,038	582545	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 416.0 in stage 0.0 (TID 416) (172.34.206.195, executor 6, partition 416, PROCESS_LOCAL, 29311 bytes) 
"
1760374525038,"INFO	2025-10-13T16:55:25,038	582545	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 400.0 in stage 0.0 (TID 400) in 21032 ms on 172.34.206.195 (executor 6) (399/590)
"
1760374525351,"INFO	2025-10-13T16:55:25,351	582858	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 417.0 in stage 0.0 (TID 417) (172.34.141.226, executor 2, partition 417, PROCESS_LOCAL, 29311 bytes) 
"
1760374525352,"INFO	2025-10-13T16:55:25,351	582858	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 396.0 in stage 0.0 (TID 396) in 25137 ms on 172.34.141.226 (executor 2) (400/590)
"
1760374526368,"INFO	2025-10-13T16:55:26,367	583874	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 418.0 in stage 0.0 (TID 418) (172.34.141.1, executor 4, partition 418, PROCESS_LOCAL, 29311 bytes) 
"
1760374526368,"INFO	2025-10-13T16:55:26,368	583875	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 401.0 in stage 0.0 (TID 401) in 21556 ms on 172.34.141.1 (executor 4) (401/590)
"
1760374528753,"INFO	2025-10-13T16:55:28,752	586259	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 419.0 in stage 0.0 (TID 419) (172.34.141.226, executor 2, partition 419, PROCESS_LOCAL, 29311 bytes) 
"
1760374528753,"INFO	2025-10-13T16:55:28,753	586260	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 399.0 in stage 0.0 (TID 399) in 24749 ms on 172.34.141.226 (executor 2) (402/590)
"
1760374528949,"INFO	2025-10-13T16:55:28,948	586455	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 420.0 in stage 0.0 (TID 420) (172.35.201.115, executor 5, partition 420, PROCESS_LOCAL, 29311 bytes) 
"
1760374528949,"INFO	2025-10-13T16:55:28,949	586456	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 402.0 in stage 0.0 (TID 402) in 23130 ms on 172.35.201.115 (executor 5) (403/590)
"
1760374529385,"INFO	2025-10-13T16:55:29,384	586891	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 421.0 in stage 0.0 (TID 421) (172.35.24.244, executor 3, partition 421, PROCESS_LOCAL, 29311 bytes) 
"
1760374529385,"INFO	2025-10-13T16:55:29,385	586892	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 404.0 in stage 0.0 (TID 404) in 20308 ms on 172.35.24.244 (executor 3) (404/590)
"
1760374530941,"INFO	2025-10-13T16:55:30,941	588448	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 422.0 in stage 0.0 (TID 422) (172.34.141.1, executor 4, partition 422, PROCESS_LOCAL, 29311 bytes) 
"
1760374530942,"INFO	2025-10-13T16:55:30,942	588449	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 405.0 in stage 0.0 (TID 405) in 21197 ms on 172.34.141.1 (executor 4) (405/590)
"
1760374531718,"INFO	2025-10-13T16:55:31,717	589224	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 423.0 in stage 0.0 (TID 423) (172.34.194.6, executor 7, partition 423, PROCESS_LOCAL, 29311 bytes) 
"
1760374531718,"INFO	2025-10-13T16:55:31,718	589225	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 403.0 in stage 0.0 (TID 403) in 22701 ms on 172.34.194.6 (executor 7) (406/590)
"
1760374531995,"INFO	2025-10-13T16:55:31,995	589502	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374531995,"INFO	2025-10-13T16:55:31,995	589502	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 78, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374531995,"INFO	2025-10-13T16:55:31,995	589502	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 78; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_78_a_spark-application-1760373954341_p_1
"
1760374531996,"INFO	2025-10-13T16:55:31,996	589503	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374532030,"INFO	2025-10-13T16:55:32,029	589536	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374532030,"INFO	2025-10-13T16:55:32,030	589537	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 0d33b652-1fdf-4b2a-8d89-5c03d15031db)
"
1760374532030,"INFO	2025-10-13T16:55:32,030	589537	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 78 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374533558,"INFO	2025-10-13T16:55:33,558	591065	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 424.0 in stage 0.0 (TID 424) (172.35.107.166, executor 8, partition 424, PROCESS_LOCAL, 29311 bytes) 
"
1760374533559,"INFO	2025-10-13T16:55:33,559	591066	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 407.0 in stage 0.0 (TID 407) in 20134 ms on 172.35.107.166 (executor 8) (407/590)
"
1760374534424,"INFO	2025-10-13T16:55:34,424	591931	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 425.0 in stage 0.0 (TID 425) (172.35.201.115, executor 5, partition 425, PROCESS_LOCAL, 29311 bytes) 
"
1760374534425,"INFO	2025-10-13T16:55:34,425	591932	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 406.0 in stage 0.0 (TID 406) in 21251 ms on 172.35.201.115 (executor 5) (408/590)
"
1760374534470,"INFO	2025-10-13T16:55:34,470	591977	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 426.0 in stage 0.0 (TID 426) (172.35.24.244, executor 3, partition 426, PROCESS_LOCAL, 29311 bytes) 
"
1760374534471,"INFO	2025-10-13T16:55:34,471	591978	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 409.0 in stage 0.0 (TID 409) in 20587 ms on 172.35.24.244 (executor 3) (409/590)
"
1760374534642,"INFO	2025-10-13T16:55:34,642	592149	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 427.0 in stage 0.0 (TID 427) (172.34.194.6, executor 7, partition 427, PROCESS_LOCAL, 29311 bytes) 
"
1760374534642,"INFO	2025-10-13T16:55:34,642	592149	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 408.0 in stage 0.0 (TID 408) in 20826 ms on 172.34.194.6 (executor 7) (410/590)
"
1760374534789,"INFO	2025-10-13T16:55:34,789	592296	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 428.0 in stage 0.0 (TID 428) (172.34.46.142, executor 1, partition 428, PROCESS_LOCAL, 29311 bytes) 
"
1760374534790,"INFO	2025-10-13T16:55:34,789	592296	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 410.0 in stage 0.0 (TID 410) in 20478 ms on 172.34.46.142 (executor 1) (411/590)
"
1760374535891,"INFO	2025-10-13T16:55:35,890	593397	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 429.0 in stage 0.0 (TID 429) (172.35.107.166, executor 8, partition 429, PROCESS_LOCAL, 29311 bytes) 
"
1760374535891,"INFO	2025-10-13T16:55:35,891	593398	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 411.0 in stage 0.0 (TID 411) in 20012 ms on 172.35.107.166 (executor 8) (412/590)
"
1760374538295,"INFO	2025-10-13T16:55:38,295	595802	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 430.0 in stage 0.0 (TID 430) (172.34.27.84, executor 9, partition 430, PROCESS_LOCAL, 29311 bytes) 
"
1760374538296,"INFO	2025-10-13T16:55:38,296	595803	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 412.0 in stage 0.0 (TID 412) in 19261 ms on 172.34.27.84 (executor 9) (413/590)
"
1760374539844,"INFO	2025-10-13T16:55:39,844	597351	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 431.0 in stage 0.0 (TID 431) (172.34.46.142, executor 1, partition 431, PROCESS_LOCAL, 29311 bytes) 
"
1760374539844,"INFO	2025-10-13T16:55:39,844	597351	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 413.0 in stage 0.0 (TID 413) in 20259 ms on 172.34.46.142 (executor 1) (414/590)
"
1760374542509,"INFO	2025-10-13T16:55:42,509	600016	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 432.0 in stage 0.0 (TID 432) (172.34.27.84, executor 9, partition 432, PROCESS_LOCAL, 29311 bytes) 
"
1760374542509,"INFO	2025-10-13T16:55:42,509	600016	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 414.0 in stage 0.0 (TID 414) in 19257 ms on 172.34.27.84 (executor 9) (415/590)
"
1760374544893,"INFO	2025-10-13T16:55:44,893	602400	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 433.0 in stage 0.0 (TID 433) (172.34.206.195, executor 6, partition 433, PROCESS_LOCAL, 29311 bytes) 
"
1760374544894,"INFO	2025-10-13T16:55:44,894	602401	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 415.0 in stage 0.0 (TID 415) in 21075 ms on 172.34.206.195 (executor 6) (416/590)
"
1760374546073,"INFO	2025-10-13T16:55:46,073	603580	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 434.0 in stage 0.0 (TID 434) (172.34.206.195, executor 6, partition 434, PROCESS_LOCAL, 29311 bytes) 
"
1760374546073,"INFO	2025-10-13T16:55:46,073	603580	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 416.0 in stage 0.0 (TID 416) in 21036 ms on 172.34.206.195 (executor 6) (417/590)
"
1760374546109,"INFO	2025-10-13T16:55:46,109	603616	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374546109,"INFO	2025-10-13T16:55:46,109	603616	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 79, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374546109,"INFO	2025-10-13T16:55:46,109	603616	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 79; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_79_a_spark-application-1760373954341_p_1
"
1760374546110,"INFO	2025-10-13T16:55:46,110	603617	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374546145,"INFO	2025-10-13T16:55:46,144	603651	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374546145,"INFO	2025-10-13T16:55:46,145	603652	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 69a3f8a1-e3f4-42aa-8208-05d7a70f80b8)
"
1760374546145,"INFO	2025-10-13T16:55:46,145	603652	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 79 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374547566,"INFO	2025-10-13T16:55:47,566	605073	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 435.0 in stage 0.0 (TID 435) (172.34.141.1, executor 4, partition 435, PROCESS_LOCAL, 29311 bytes) 
"
1760374547566,"INFO	2025-10-13T16:55:47,566	605073	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 418.0 in stage 0.0 (TID 418) in 21199 ms on 172.34.141.1 (executor 4) (418/590)
"
1760374547802,"INFO	2025-10-13T16:55:47,802	605309	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 436.0 in stage 0.0 (TID 436) (172.34.141.226, executor 2, partition 436, PROCESS_LOCAL, 29311 bytes) 
"
1760374547802,"INFO	2025-10-13T16:55:47,802	605309	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 417.0 in stage 0.0 (TID 417) in 22451 ms on 172.34.141.226 (executor 2) (419/590)
"
1760374549475,"INFO	2025-10-13T16:55:49,474	606981	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 437.0 in stage 0.0 (TID 437) (172.35.201.115, executor 5, partition 437, PROCESS_LOCAL, 29311 bytes) 
"
1760374549475,"INFO	2025-10-13T16:55:49,475	606982	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 420.0 in stage 0.0 (TID 420) in 20527 ms on 172.35.201.115 (executor 5) (420/590)
"
1760374549849,"INFO	2025-10-13T16:55:49,849	607356	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 438.0 in stage 0.0 (TID 438) (172.35.24.244, executor 3, partition 438, PROCESS_LOCAL, 29311 bytes) 
"
1760374549850,"INFO	2025-10-13T16:55:49,849	607356	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 421.0 in stage 0.0 (TID 421) in 20465 ms on 172.35.24.244 (executor 3) (421/590)
"
1760374551771,"INFO	2025-10-13T16:55:51,771	609278	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 439.0 in stage 0.0 (TID 439) (172.34.141.226, executor 2, partition 439, PROCESS_LOCAL, 29311 bytes) 
"
1760374551772,"INFO	2025-10-13T16:55:51,771	609278	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 419.0 in stage 0.0 (TID 419) in 23019 ms on 172.34.141.226 (executor 2) (422/590)
"
1760374552252,"INFO	2025-10-13T16:55:52,252	609759	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 440.0 in stage 0.0 (TID 440) (172.34.194.6, executor 7, partition 440, PROCESS_LOCAL, 29311 bytes) 
"
1760374552252,"INFO	2025-10-13T16:55:52,252	609759	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 423.0 in stage 0.0 (TID 423) in 20535 ms on 172.34.194.6 (executor 7) (423/590)
"
1760374552254,"INFO	2025-10-13T16:55:52,254	609761	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 441.0 in stage 0.0 (TID 441) (172.34.141.1, executor 4, partition 441, PROCESS_LOCAL, 29311 bytes) 
"
1760374552255,"INFO	2025-10-13T16:55:52,255	609762	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 422.0 in stage 0.0 (TID 422) in 21314 ms on 172.34.141.1 (executor 4) (424/590)
"
1760374553938,"INFO	2025-10-13T16:55:53,937	611444	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 442.0 in stage 0.0 (TID 442) (172.35.107.166, executor 8, partition 442, PROCESS_LOCAL, 29311 bytes) 
"
1760374553938,"INFO	2025-10-13T16:55:53,938	611445	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 424.0 in stage 0.0 (TID 424) in 20380 ms on 172.35.107.166 (executor 8) (425/590)
"
1760374554476,"INFO	2025-10-13T16:55:54,476	611983	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374554476,"INFO	2025-10-13T16:55:54,476	611983	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374555069,"INFO	2025-10-13T16:55:55,068	612575	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 443.0 in stage 0.0 (TID 443) (172.35.201.115, executor 5, partition 443, PROCESS_LOCAL, 29311 bytes) 
"
1760374555069,"INFO	2025-10-13T16:55:55,068	612575	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 425.0 in stage 0.0 (TID 425) in 20644 ms on 172.35.201.115 (executor 5) (426/590)
"
1760374555098,"INFO	2025-10-13T16:55:55,097	612604	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 444.0 in stage 0.0 (TID 444) (172.35.24.244, executor 3, partition 444, PROCESS_LOCAL, 29311 bytes) 
"
1760374555098,"INFO	2025-10-13T16:55:55,098	612605	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 426.0 in stage 0.0 (TID 426) in 20628 ms on 172.35.24.244 (executor 3) (427/590)
"
1760374555494,"INFO	2025-10-13T16:55:55,493	613000	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 445.0 in stage 0.0 (TID 445) (172.34.194.6, executor 7, partition 445, PROCESS_LOCAL, 29311 bytes) 
"
1760374555494,"INFO	2025-10-13T16:55:55,494	613001	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 427.0 in stage 0.0 (TID 427) in 20853 ms on 172.34.194.6 (executor 7) (428/590)
"
1760374555498,"INFO	2025-10-13T16:55:55,498	613005	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 446.0 in stage 0.0 (TID 446) (172.34.46.142, executor 1, partition 446, PROCESS_LOCAL, 29311 bytes) 
"
1760374555498,"INFO	2025-10-13T16:55:55,498	613005	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 428.0 in stage 0.0 (TID 428) in 20709 ms on 172.34.46.142 (executor 1) (429/590)
"
1760374557265,"INFO	2025-10-13T16:55:57,265	614772	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 447.0 in stage 0.0 (TID 447) (172.35.107.166, executor 8, partition 447, PROCESS_LOCAL, 29311 bytes) 
"
1760374557266,"INFO	2025-10-13T16:55:57,265	614772	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 429.0 in stage 0.0 (TID 429) in 21375 ms on 172.35.107.166 (executor 8) (430/590)
"
1760374557753,"INFO	2025-10-13T16:55:57,753	615260	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 448.0 in stage 0.0 (TID 448) (172.34.27.84, executor 9, partition 448, PROCESS_LOCAL, 29311 bytes) 
"
1760374557753,"INFO	2025-10-13T16:55:57,753	615260	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 430.0 in stage 0.0 (TID 430) in 19458 ms on 172.34.27.84 (executor 9) (431/590)
"
1760374559400,"INFO	2025-10-13T16:55:59,400	616907	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374559400,"INFO	2025-10-13T16:55:59,400	616907	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 80, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374559400,"INFO	2025-10-13T16:55:59,400	616907	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 80; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_80_a_spark-application-1760373954341_p_1
"
1760374559401,"INFO	2025-10-13T16:55:59,400	616907	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374559439,"INFO	2025-10-13T16:55:59,438	616945	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374559439,"INFO	2025-10-13T16:55:59,439	616946	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a810a2f8-5d8e-4721-833f-9b20ab57c7f6)
"
1760374559439,"INFO	2025-10-13T16:55:59,439	616946	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 80 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374560709,"INFO	2025-10-13T16:56:00,709	618216	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 449.0 in stage 0.0 (TID 449) (172.34.46.142, executor 1, partition 449, PROCESS_LOCAL, 29311 bytes) 
"
1760374560709,"INFO	2025-10-13T16:56:00,709	618216	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 431.0 in stage 0.0 (TID 431) in 20866 ms on 172.34.46.142 (executor 1) (432/590)
"
1760374562373,"INFO	2025-10-13T16:56:02,373	619880	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 450.0 in stage 0.0 (TID 450) (172.34.27.84, executor 9, partition 450, PROCESS_LOCAL, 29311 bytes) 
"
1760374562374,"INFO	2025-10-13T16:56:02,373	619880	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 432.0 in stage 0.0 (TID 432) in 19865 ms on 172.34.27.84 (executor 9) (433/590)
"
1760374565937,"INFO	2025-10-13T16:56:05,937	623444	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 451.0 in stage 0.0 (TID 451) (172.34.206.195, executor 6, partition 451, PROCESS_LOCAL, 29311 bytes) 
"
1760374565937,"INFO	2025-10-13T16:56:05,937	623444	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 433.0 in stage 0.0 (TID 433) in 21044 ms on 172.34.206.195 (executor 6) (434/590)
"
1760374567402,"INFO	2025-10-13T16:56:07,402	624909	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 452.0 in stage 0.0 (TID 452) (172.34.206.195, executor 6, partition 452, PROCESS_LOCAL, 29311 bytes) 
"
1760374567403,"INFO	2025-10-13T16:56:07,403	624910	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 434.0 in stage 0.0 (TID 434) in 21330 ms on 172.34.206.195 (executor 6) (435/590)
"
1760374569159,"INFO	2025-10-13T16:56:09,159	626666	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 453.0 in stage 0.0 (TID 453) (172.34.141.1, executor 4, partition 453, PROCESS_LOCAL, 29311 bytes) 
"
1760374569159,"INFO	2025-10-13T16:56:09,159	626666	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 435.0 in stage 0.0 (TID 435) in 21594 ms on 172.34.141.1 (executor 4) (436/590)
"
1760374570104,"INFO	2025-10-13T16:56:10,104	627611	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 454.0 in stage 0.0 (TID 454) (172.35.201.115, executor 5, partition 454, PROCESS_LOCAL, 29311 bytes) 
"
1760374570104,"INFO	2025-10-13T16:56:10,104	627611	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 437.0 in stage 0.0 (TID 437) in 20630 ms on 172.35.201.115 (executor 5) (437/590)
"
1760374570231,"INFO	2025-10-13T16:56:10,231	627738	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 455.0 in stage 0.0 (TID 455) (172.34.141.226, executor 2, partition 455, PROCESS_LOCAL, 29311 bytes) 
"
1760374570232,"INFO	2025-10-13T16:56:10,231	627738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 436.0 in stage 0.0 (TID 436) in 22430 ms on 172.34.141.226 (executor 2) (438/590)
"
1760374570611,"INFO	2025-10-13T16:56:10,611	628118	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 456.0 in stage 0.0 (TID 456) (172.35.24.244, executor 3, partition 456, PROCESS_LOCAL, 29311 bytes) 
"
1760374570611,"INFO	2025-10-13T16:56:10,611	628118	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 438.0 in stage 0.0 (TID 438) in 20762 ms on 172.35.24.244 (executor 3) (439/590)
"
1760374572562,"INFO	2025-10-13T16:56:12,562	630069	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374572562,"INFO	2025-10-13T16:56:12,562	630069	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 81, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374572563,"INFO	2025-10-13T16:56:12,562	630069	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 81; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_81_a_spark-application-1760373954341_p_1
"
1760374572563,"INFO	2025-10-13T16:56:12,563	630070	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374572601,"INFO	2025-10-13T16:56:12,601	630108	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374572601,"INFO	2025-10-13T16:56:12,601	630108	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a373b470-4535-46dc-8b76-a33526e27ef4)
"
1760374572601,"INFO	2025-10-13T16:56:12,601	630108	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 81 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374574113,"INFO	2025-10-13T16:56:14,113	631620	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 457.0 in stage 0.0 (TID 457) (172.34.194.6, executor 7, partition 457, PROCESS_LOCAL, 29311 bytes) 
"
1760374574113,"INFO	2025-10-13T16:56:14,113	631620	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 440.0 in stage 0.0 (TID 440) in 21862 ms on 172.34.194.6 (executor 7) (440/590)
"
1760374574489,"INFO	2025-10-13T16:56:14,488	631995	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 458.0 in stage 0.0 (TID 458) (172.34.141.226, executor 2, partition 458, PROCESS_LOCAL, 29311 bytes) 
"
1760374574489,"INFO	2025-10-13T16:56:14,489	631996	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 439.0 in stage 0.0 (TID 439) in 22718 ms on 172.34.141.226 (executor 2) (441/590)
"
1760374575196,"INFO	2025-10-13T16:56:15,195	632702	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 459.0 in stage 0.0 (TID 459) (172.34.141.1, executor 4, partition 459, PROCESS_LOCAL, 29311 bytes) 
"
1760374575196,"INFO	2025-10-13T16:56:15,196	632703	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 441.0 in stage 0.0 (TID 441) in 22942 ms on 172.34.141.1 (executor 4) (442/590)
"
1760374576037,"INFO	2025-10-13T16:56:16,037	633544	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 460.0 in stage 0.0 (TID 460) (172.35.107.166, executor 8, partition 460, PROCESS_LOCAL, 29311 bytes) 
"
1760374576037,"INFO	2025-10-13T16:56:16,037	633544	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 442.0 in stage 0.0 (TID 442) in 22100 ms on 172.35.107.166 (executor 8) (443/590)
"
1760374576905,"INFO	2025-10-13T16:56:16,905	634412	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 461.0 in stage 0.0 (TID 461) (172.35.24.244, executor 3, partition 461, PROCESS_LOCAL, 29311 bytes) 
"
1760374576905,"INFO	2025-10-13T16:56:16,905	634412	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 444.0 in stage 0.0 (TID 444) in 21808 ms on 172.35.24.244 (executor 3) (444/590)
"
1760374576986,"INFO	2025-10-13T16:56:16,986	634493	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 462.0 in stage 0.0 (TID 462) (172.35.201.115, executor 5, partition 462, PROCESS_LOCAL, 29311 bytes) 
"
1760374576986,"INFO	2025-10-13T16:56:16,986	634493	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 443.0 in stage 0.0 (TID 443) in 21918 ms on 172.35.201.115 (executor 5) (445/590)
"
1760374577262,"INFO	2025-10-13T16:56:17,262	634769	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 463.0 in stage 0.0 (TID 463) (172.34.46.142, executor 1, partition 463, PROCESS_LOCAL, 29311 bytes) 
"
1760374577263,"INFO	2025-10-13T16:56:17,262	634769	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 446.0 in stage 0.0 (TID 446) in 21764 ms on 172.34.46.142 (executor 1) (446/590)
"
1760374577900,"INFO	2025-10-13T16:56:17,899	635406	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 464.0 in stage 0.0 (TID 464) (172.34.194.6, executor 7, partition 464, PROCESS_LOCAL, 29311 bytes) 
"
1760374577900,"INFO	2025-10-13T16:56:17,900	635407	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 445.0 in stage 0.0 (TID 445) in 22407 ms on 172.34.194.6 (executor 7) (447/590)
"
1760374578047,"INFO	2025-10-13T16:56:18,046	635553	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 465.0 in stage 0.0 (TID 465) (172.34.27.84, executor 9, partition 465, PROCESS_LOCAL, 29311 bytes) 
"
1760374578047,"INFO	2025-10-13T16:56:18,047	635554	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 448.0 in stage 0.0 (TID 448) in 20295 ms on 172.34.27.84 (executor 9) (448/590)
"
1760374579204,"INFO	2025-10-13T16:56:19,203	636710	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 466.0 in stage 0.0 (TID 466) (172.35.107.166, executor 8, partition 466, PROCESS_LOCAL, 29311 bytes) 
"
1760374579204,"INFO	2025-10-13T16:56:19,204	636711	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 447.0 in stage 0.0 (TID 447) in 21939 ms on 172.35.107.166 (executor 8) (449/590)
"
1760374580877,"INFO	2025-10-13T16:56:20,877	638384	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374580878,"INFO	2025-10-13T16:56:20,878	638385	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 82, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374580878,"INFO	2025-10-13T16:56:20,878	638385	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 82; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_82_a_spark-application-1760373954341_p_1
"
1760374580878,"INFO	2025-10-13T16:56:20,878	638385	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374580908,"INFO	2025-10-13T16:56:20,908	638415	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374580909,"INFO	2025-10-13T16:56:20,908	638415	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 21584d9c-793b-4942-8834-68672a1cdd1d)
"
1760374580909,"INFO	2025-10-13T16:56:20,908	638415	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 82 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374582442,"INFO	2025-10-13T16:56:22,441	639948	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 467.0 in stage 0.0 (TID 467) (172.34.46.142, executor 1, partition 467, PROCESS_LOCAL, 29311 bytes) 
"
1760374582442,"INFO	2025-10-13T16:56:22,442	639949	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 449.0 in stage 0.0 (TID 449) in 21733 ms on 172.34.46.142 (executor 1) (450/590)
"
1760374582870,"INFO	2025-10-13T16:56:22,870	640377	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 468.0 in stage 0.0 (TID 468) (172.34.27.84, executor 9, partition 468, PROCESS_LOCAL, 29311 bytes) 
"
1760374582871,"INFO	2025-10-13T16:56:22,871	640378	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 450.0 in stage 0.0 (TID 450) in 20498 ms on 172.34.27.84 (executor 9) (451/590)
"
1760374588247,"INFO	2025-10-13T16:56:28,246	645753	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 469.0 in stage 0.0 (TID 469) (172.34.206.195, executor 6, partition 469, PROCESS_LOCAL, 29311 bytes) 
"
1760374588247,"INFO	2025-10-13T16:56:28,247	645754	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 451.0 in stage 0.0 (TID 451) in 22311 ms on 172.34.206.195 (executor 6) (452/590)
"
1760374590322,"INFO	2025-10-13T16:56:30,322	647829	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 470.0 in stage 0.0 (TID 470) (172.34.206.195, executor 6, partition 470, PROCESS_LOCAL, 29311 bytes) 
"
1760374590322,"INFO	2025-10-13T16:56:30,322	647829	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 452.0 in stage 0.0 (TID 452) in 22920 ms on 172.34.206.195 (executor 6) (453/590)
"
1760374590425,"INFO	2025-10-13T16:56:30,425	647932	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374590425,"INFO	2025-10-13T16:56:30,425	647932	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 83, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374590425,"INFO	2025-10-13T16:56:30,425	647932	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 83; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_83_a_spark-application-1760373954341_p_1
"
1760374590426,"INFO	2025-10-13T16:56:30,425	647932	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374590463,"INFO	2025-10-13T16:56:30,463	647970	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374590463,"INFO	2025-10-13T16:56:30,463	647970	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: b0f2582c-7413-49bf-9a8f-ae6329b23e3d)
"
1760374590463,"INFO	2025-10-13T16:56:30,463	647970	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 83 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374592062,"INFO	2025-10-13T16:56:32,062	649569	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 471.0 in stage 0.0 (TID 471) (172.34.141.1, executor 4, partition 471, PROCESS_LOCAL, 29311 bytes) 
"
1760374592062,"INFO	2025-10-13T16:56:32,062	649569	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 453.0 in stage 0.0 (TID 453) in 22904 ms on 172.34.141.1 (executor 4) (454/590)
"
1760374592160,"INFO	2025-10-13T16:56:32,160	649667	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 472.0 in stage 0.0 (TID 472) (172.35.201.115, executor 5, partition 472, PROCESS_LOCAL, 29311 bytes) 
"
1760374592161,"INFO	2025-10-13T16:56:32,160	649667	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 454.0 in stage 0.0 (TID 454) in 22057 ms on 172.35.201.115 (executor 5) (455/590)
"
1760374592528,"INFO	2025-10-13T16:56:32,528	650035	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 473.0 in stage 0.0 (TID 473) (172.35.24.244, executor 3, partition 473, PROCESS_LOCAL, 29311 bytes) 
"
1760374592528,"INFO	2025-10-13T16:56:32,528	650035	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 456.0 in stage 0.0 (TID 456) in 21918 ms on 172.35.24.244 (executor 3) (456/590)
"
1760374594061,"INFO	2025-10-13T16:56:34,060	651567	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 474.0 in stage 0.0 (TID 474) (172.34.141.226, executor 2, partition 474, PROCESS_LOCAL, 29311 bytes) 
"
1760374594061,"INFO	2025-10-13T16:56:34,061	651568	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 455.0 in stage 0.0 (TID 455) in 23830 ms on 172.34.141.226 (executor 2) (457/590)
"
1760374595855,"INFO	2025-10-13T16:56:35,855	653362	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 475.0 in stage 0.0 (TID 475) (172.34.194.6, executor 7, partition 475, PROCESS_LOCAL, 29311 bytes) 
"
1760374595856,"INFO	2025-10-13T16:56:35,855	653362	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 457.0 in stage 0.0 (TID 457) in 21743 ms on 172.34.194.6 (executor 7) (458/590)
"
1760374597516,"INFO	2025-10-13T16:56:37,516	655023	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 476.0 in stage 0.0 (TID 476) (172.34.27.84, executor 9, partition 476, PROCESS_LOCAL, 29311 bytes) 
"
1760374597517,"INFO	2025-10-13T16:56:37,516	655023	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 465.0 in stage 0.0 (TID 465) in 19470 ms on 172.34.27.84 (executor 9) (459/590)
"
1760374597553,"INFO	2025-10-13T16:56:37,552	655059	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 477.0 in stage 0.0 (TID 477) (172.35.201.115, executor 5, partition 477, PROCESS_LOCAL, 29311 bytes) 
"
1760374597553,"INFO	2025-10-13T16:56:37,553	655060	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 462.0 in stage 0.0 (TID 462) in 20568 ms on 172.35.201.115 (executor 5) (460/590)
"
1760374597759,"INFO	2025-10-13T16:56:37,759	655266	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 478.0 in stage 0.0 (TID 478) (172.35.24.244, executor 3, partition 478, PROCESS_LOCAL, 29311 bytes) 
"
1760374597759,"INFO	2025-10-13T16:56:37,759	655266	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 461.0 in stage 0.0 (TID 461) in 20855 ms on 172.35.24.244 (executor 3) (461/590)
"
1760374597927,"INFO	2025-10-13T16:56:37,927	655434	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 479.0 in stage 0.0 (TID 479) (172.34.46.142, executor 1, partition 479, PROCESS_LOCAL, 29311 bytes) 
"
1760374597927,"INFO	2025-10-13T16:56:37,927	655434	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 463.0 in stage 0.0 (TID 463) in 20665 ms on 172.34.46.142 (executor 1) (462/590)
"
1760374598175,"INFO	2025-10-13T16:56:38,174	655681	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 480.0 in stage 0.0 (TID 480) (172.34.141.1, executor 4, partition 480, PROCESS_LOCAL, 29311 bytes) 
"
1760374598175,"INFO	2025-10-13T16:56:38,175	655682	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 459.0 in stage 0.0 (TID 459) in 22980 ms on 172.34.141.1 (executor 4) (463/590)
"
1760374598185,"INFO	2025-10-13T16:56:38,184	655691	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 481.0 in stage 0.0 (TID 481) (172.35.107.166, executor 8, partition 481, PROCESS_LOCAL, 29311 bytes) 
"
1760374598185,"INFO	2025-10-13T16:56:38,185	655692	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 460.0 in stage 0.0 (TID 460) in 22149 ms on 172.35.107.166 (executor 8) (464/590)
"
1760374598433,"INFO	2025-10-13T16:56:38,433	655940	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 482.0 in stage 0.0 (TID 482) (172.34.141.226, executor 2, partition 482, PROCESS_LOCAL, 29311 bytes) 
"
1760374598433,"INFO	2025-10-13T16:56:38,433	655940	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 458.0 in stage 0.0 (TID 458) in 23945 ms on 172.34.141.226 (executor 2) (465/590)
"
1760374598536,"INFO	2025-10-13T16:56:38,535	656042	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 483.0 in stage 0.0 (TID 483) (172.34.194.6, executor 7, partition 483, PROCESS_LOCAL, 29311 bytes) 
"
1760374598536,"INFO	2025-10-13T16:56:38,536	656043	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 464.0 in stage 0.0 (TID 464) in 20637 ms on 172.34.194.6 (executor 7) (466/590)
"
1760374600425,"INFO	2025-10-13T16:56:40,425	657932	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 484.0 in stage 0.0 (TID 484) (172.35.107.166, executor 8, partition 484, PROCESS_LOCAL, 29311 bytes) 
"
1760374600425,"INFO	2025-10-13T16:56:40,425	657932	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 466.0 in stage 0.0 (TID 466) in 21222 ms on 172.35.107.166 (executor 8) (467/590)
"
1760374602166,"INFO	2025-10-13T16:56:42,165	659672	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 485.0 in stage 0.0 (TID 485) (172.34.27.84, executor 9, partition 485, PROCESS_LOCAL, 29311 bytes) 
"
1760374602166,"INFO	2025-10-13T16:56:42,166	659673	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 468.0 in stage 0.0 (TID 468) in 19296 ms on 172.34.27.84 (executor 9) (468/590)
"
1760374603101,"INFO	2025-10-13T16:56:43,101	660608	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374603102,"INFO	2025-10-13T16:56:43,102	660609	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 84, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374603102,"INFO	2025-10-13T16:56:43,102	660609	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 84; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_84_a_spark-application-1760373954341_p_1
"
1760374603102,"INFO	2025-10-13T16:56:43,102	660609	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374603142,"INFO	2025-10-13T16:56:43,141	660648	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374603142,"INFO	2025-10-13T16:56:43,142	660649	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: d1e71b53-8022-4f54-b43d-39068bb278f6)
"
1760374603142,"INFO	2025-10-13T16:56:43,142	660649	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 84 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374604256,"INFO	2025-10-13T16:56:44,256	661763	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 486.0 in stage 0.0 (TID 486) (172.34.46.142, executor 1, partition 486, PROCESS_LOCAL, 29311 bytes) 
"
1760374604256,"INFO	2025-10-13T16:56:44,256	661763	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 467.0 in stage 0.0 (TID 467) in 21815 ms on 172.34.46.142 (executor 1) (469/590)
"
1760374610385,"INFO	2025-10-13T16:56:50,385	667892	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 487.0 in stage 0.0 (TID 487) (172.34.206.195, executor 6, partition 487, PROCESS_LOCAL, 29311 bytes) 
"
1760374610385,"INFO	2025-10-13T16:56:50,385	667892	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 469.0 in stage 0.0 (TID 469) in 22139 ms on 172.34.206.195 (executor 6) (470/590)
"
1760374611288,"INFO	2025-10-13T16:56:51,287	668794	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 488.0 in stage 0.0 (TID 488) (172.34.206.195, executor 6, partition 488, PROCESS_LOCAL, 29311 bytes) 
"
1760374611288,"INFO	2025-10-13T16:56:51,288	668795	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 470.0 in stage 0.0 (TID 470) in 20967 ms on 172.34.206.195 (executor 6) (471/590)
"
1760374614477,"INFO	2025-10-13T16:56:54,476	671983	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374614477,"INFO	2025-10-13T16:56:54,476	671983	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374614584,"INFO	2025-10-13T16:56:54,584	672091	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 489.0 in stage 0.0 (TID 489) (172.35.201.115, executor 5, partition 489, PROCESS_LOCAL, 29311 bytes) 
"
1760374614584,"INFO	2025-10-13T16:56:54,584	672091	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 472.0 in stage 0.0 (TID 472) in 22424 ms on 172.35.201.115 (executor 5) (472/590)
"
1760374614651,"INFO	2025-10-13T16:56:54,651	672158	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 490.0 in stage 0.0 (TID 490) (172.35.24.244, executor 3, partition 490, PROCESS_LOCAL, 29311 bytes) 
"
1760374614651,"INFO	2025-10-13T16:56:54,651	672158	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 473.0 in stage 0.0 (TID 473) in 22124 ms on 172.35.24.244 (executor 3) (473/590)
"
1760374615295,"INFO	2025-10-13T16:56:55,295	672802	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 491.0 in stage 0.0 (TID 491) (172.34.141.1, executor 4, partition 491, PROCESS_LOCAL, 29311 bytes) 
"
1760374615295,"INFO	2025-10-13T16:56:55,295	672802	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 471.0 in stage 0.0 (TID 471) in 23234 ms on 172.34.141.1 (executor 4) (474/590)
"
1760374616314,"INFO	2025-10-13T16:56:56,314	673821	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374616314,"INFO	2025-10-13T16:56:56,314	673821	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 85, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374616314,"INFO	2025-10-13T16:56:56,314	673821	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 85; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_85_a_spark-application-1760373954341_p_1
"
1760374616315,"INFO	2025-10-13T16:56:56,314	673821	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374616354,"INFO	2025-10-13T16:56:56,354	673861	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374616354,"INFO	2025-10-13T16:56:56,354	673861	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: c22f2125-d6db-4608-9c80-f6e07e4e2d48)
"
1760374616354,"INFO	2025-10-13T16:56:56,354	673861	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 85 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374617871,"INFO	2025-10-13T16:56:57,871	675378	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 492.0 in stage 0.0 (TID 492) (172.34.194.6, executor 7, partition 492, PROCESS_LOCAL, 29311 bytes) 
"
1760374617872,"INFO	2025-10-13T16:56:57,871	675378	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 475.0 in stage 0.0 (TID 475) in 22016 ms on 172.34.194.6 (executor 7) (475/590)
"
1760374618178,"INFO	2025-10-13T16:56:58,178	675685	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 493.0 in stage 0.0 (TID 493) (172.34.141.226, executor 2, partition 493, PROCESS_LOCAL, 29311 bytes) 
"
1760374618178,"INFO	2025-10-13T16:56:58,178	675685	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 474.0 in stage 0.0 (TID 474) in 24118 ms on 172.34.141.226 (executor 2) (476/590)
"
1760374618180,"INFO	2025-10-13T16:56:58,180	675687	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 494.0 in stage 0.0 (TID 494) (172.34.27.84, executor 9, partition 494, PROCESS_LOCAL, 29311 bytes) 
"
1760374618180,"INFO	2025-10-13T16:56:58,180	675687	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 476.0 in stage 0.0 (TID 476) in 20664 ms on 172.34.27.84 (executor 9) (477/590)
"
1760374619524,"INFO	2025-10-13T16:56:59,524	677031	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 495.0 in stage 0.0 (TID 495) (172.35.107.166, executor 8, partition 495, PROCESS_LOCAL, 29311 bytes) 
"
1760374619524,"INFO	2025-10-13T16:56:59,524	677031	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 481.0 in stage 0.0 (TID 481) in 21340 ms on 172.35.107.166 (executor 8) (478/590)
"
1760374619541,"INFO	2025-10-13T16:56:59,540	677047	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 496.0 in stage 0.0 (TID 496) (172.35.24.244, executor 3, partition 496, PROCESS_LOCAL, 29311 bytes) 
"
1760374619541,"INFO	2025-10-13T16:56:59,541	677048	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 478.0 in stage 0.0 (TID 478) in 21783 ms on 172.35.24.244 (executor 3) (479/590)
"
1760374619720,"INFO	2025-10-13T16:56:59,719	677226	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 497.0 in stage 0.0 (TID 497) (172.34.46.142, executor 1, partition 497, PROCESS_LOCAL, 29311 bytes) 
"
1760374619720,"INFO	2025-10-13T16:56:59,720	677227	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 479.0 in stage 0.0 (TID 479) in 21794 ms on 172.34.46.142 (executor 1) (480/590)
"
1760374619949,"INFO	2025-10-13T16:56:59,949	677456	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 498.0 in stage 0.0 (TID 498) (172.35.201.115, executor 5, partition 498, PROCESS_LOCAL, 29311 bytes) 
"
1760374619950,"INFO	2025-10-13T16:56:59,950	677457	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 477.0 in stage 0.0 (TID 477) in 22397 ms on 172.35.201.115 (executor 5) (481/590)
"
1760374620868,"INFO	2025-10-13T16:57:00,868	678375	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 499.0 in stage 0.0 (TID 499) (172.34.194.6, executor 7, partition 499, PROCESS_LOCAL, 29311 bytes) 
"
1760374620869,"INFO	2025-10-13T16:57:00,868	678375	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 483.0 in stage 0.0 (TID 483) in 22333 ms on 172.34.194.6 (executor 7) (482/590)
"
1760374621050,"INFO	2025-10-13T16:57:01,050	678557	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 500.0 in stage 0.0 (TID 500) (172.34.141.1, executor 4, partition 500, PROCESS_LOCAL, 29311 bytes) 
"
1760374621051,"INFO	2025-10-13T16:57:01,050	678557	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 480.0 in stage 0.0 (TID 480) in 22876 ms on 172.34.141.1 (executor 4) (483/590)
"
1760374622012,"INFO	2025-10-13T16:57:02,012	679519	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 501.0 in stage 0.0 (TID 501) (172.35.107.166, executor 8, partition 501, PROCESS_LOCAL, 29311 bytes) 
"
1760374622013,"INFO	2025-10-13T16:57:02,012	679519	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 484.0 in stage 0.0 (TID 484) in 21587 ms on 172.35.107.166 (executor 8) (484/590)
"
1760374622330,"INFO	2025-10-13T16:57:02,330	679837	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 502.0 in stage 0.0 (TID 502) (172.34.141.226, executor 2, partition 502, PROCESS_LOCAL, 29311 bytes) 
"
1760374622330,"INFO	2025-10-13T16:57:02,330	679837	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 482.0 in stage 0.0 (TID 482) in 23898 ms on 172.34.141.226 (executor 2) (485/590)
"
1760374623611,"INFO	2025-10-13T16:57:03,611	681118	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 503.0 in stage 0.0 (TID 503) (172.34.27.84, executor 9, partition 503, PROCESS_LOCAL, 29311 bytes) 
"
1760374623612,"INFO	2025-10-13T16:57:03,611	681118	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 485.0 in stage 0.0 (TID 485) in 21446 ms on 172.34.27.84 (executor 9) (486/590)
"
1760374626097,"INFO	2025-10-13T16:57:06,097	683604	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 504.0 in stage 0.0 (TID 504) (172.34.46.142, executor 1, partition 504, PROCESS_LOCAL, 29311 bytes) 
"
1760374626097,"INFO	2025-10-13T16:57:06,097	683604	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 486.0 in stage 0.0 (TID 486) in 21842 ms on 172.34.46.142 (executor 1) (487/590)
"
1760374627665,"INFO	2025-10-13T16:57:07,664	685171	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374627665,"INFO	2025-10-13T16:57:07,665	685172	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 86, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374627665,"INFO	2025-10-13T16:57:07,665	685172	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 86; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_86_a_spark-application-1760373954341_p_1
"
1760374627665,"INFO	2025-10-13T16:57:07,665	685172	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374627705,"INFO	2025-10-13T16:57:07,704	685211	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374627705,"INFO	2025-10-13T16:57:07,705	685212	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 788fd335-a1c5-44e1-9b86-5f58a5143046)
"
1760374627705,"INFO	2025-10-13T16:57:07,705	685212	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 86 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374631490,"INFO	2025-10-13T16:57:11,490	688997	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374631490,"INFO	2025-10-13T16:57:11,490	688997	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 87, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374631490,"INFO	2025-10-13T16:57:11,490	688997	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 87; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_87_a_spark-application-1760373954341_p_1
"
1760374631491,"INFO	2025-10-13T16:57:11,491	688998	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374631522,"INFO	2025-10-13T16:57:11,522	689029	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
INFO	2025-10-13T16:57:11,522	689029	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: ee522393-41be-444f-86be-04050e653f53)
"
1760374631522,"INFO	2025-10-13T16:57:11,522	689029	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 87 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374633060,"INFO	2025-10-13T16:57:13,059	690566	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374633060,"INFO	2025-10-13T16:57:13,060	690567	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 88, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374633060,"INFO	2025-10-13T16:57:13,060	690567	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 88; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_88_a_spark-application-1760373954341_p_1
"
1760374633060,"INFO	2025-10-13T16:57:13,060	690567	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374633090,"INFO	2025-10-13T16:57:13,089	690596	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374633090,"INFO	2025-10-13T16:57:13,090	690597	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: d835015e-2b28-47e0-8a7b-e57293bcbfd7)
"
1760374633090,"INFO	2025-10-13T16:57:13,090	690597	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 88 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374633271,"INFO	2025-10-13T16:57:13,270	690777	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 505.0 in stage 0.0 (TID 505) (172.34.206.195, executor 6, partition 505, PROCESS_LOCAL, 29311 bytes) 
"
1760374633271,"INFO	2025-10-13T16:57:13,271	690778	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 487.0 in stage 0.0 (TID 487) in 22887 ms on 172.34.206.195 (executor 6) (488/590)
"
1760374634352,"INFO	2025-10-13T16:57:14,352	691859	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 506.0 in stage 0.0 (TID 506) (172.34.206.195, executor 6, partition 506, PROCESS_LOCAL, 29311 bytes) 
"
1760374634353,"INFO	2025-10-13T16:57:14,353	691860	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 488.0 in stage 0.0 (TID 488) in 23066 ms on 172.34.206.195 (executor 6) (489/590)
"
1760374636509,"INFO	2025-10-13T16:57:16,509	694016	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 507.0 in stage 0.0 (TID 507) (172.35.24.244, executor 3, partition 507, PROCESS_LOCAL, 29311 bytes) 
"
1760374636509,"INFO	2025-10-13T16:57:16,509	694016	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 490.0 in stage 0.0 (TID 490) in 21858 ms on 172.35.24.244 (executor 3) (490/590)
"
1760374636869,"INFO	2025-10-13T16:57:16,868	694375	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 508.0 in stage 0.0 (TID 508) (172.35.201.115, executor 5, partition 508, PROCESS_LOCAL, 29311 bytes) 
"
1760374636869,"INFO	2025-10-13T16:57:16,869	694376	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 489.0 in stage 0.0 (TID 489) in 22285 ms on 172.35.201.115 (executor 5) (491/590)
"
1760374638481,"INFO	2025-10-13T16:57:18,481	695988	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 509.0 in stage 0.0 (TID 509) (172.34.141.1, executor 4, partition 509, PROCESS_LOCAL, 29311 bytes) 
"
1760374638482,"INFO	2025-10-13T16:57:18,482	695989	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 491.0 in stage 0.0 (TID 491) in 23188 ms on 172.34.141.1 (executor 4) (492/590)
"
1760374639707,"INFO	2025-10-13T16:57:19,707	697214	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 510.0 in stage 0.0 (TID 510) (172.34.27.84, executor 9, partition 510, PROCESS_LOCAL, 29311 bytes) 
"
1760374639707,"INFO	2025-10-13T16:57:19,707	697214	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 494.0 in stage 0.0 (TID 494) in 21527 ms on 172.34.27.84 (executor 9) (493/590)
"
1760374639770,"INFO	2025-10-13T16:57:19,770	697277	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 511.0 in stage 0.0 (TID 511) (172.34.194.6, executor 7, partition 511, PROCESS_LOCAL, 29311 bytes) 
"
1760374639771,"INFO	2025-10-13T16:57:19,771	697278	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 492.0 in stage 0.0 (TID 492) in 21899 ms on 172.34.194.6 (executor 7) (494/590)
"
1760374640710,"INFO	2025-10-13T16:57:20,710	698217	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 512.0 in stage 0.0 (TID 512) (172.34.46.142, executor 1, partition 512, PROCESS_LOCAL, 29311 bytes) 
"
1760374640710,"INFO	2025-10-13T16:57:20,710	698217	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 497.0 in stage 0.0 (TID 497) in 20991 ms on 172.34.46.142 (executor 1) (495/590)
"
1760374640774,"INFO	2025-10-13T16:57:20,774	698281	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 513.0 in stage 0.0 (TID 513) (172.35.107.166, executor 8, partition 513, PROCESS_LOCAL, 29311 bytes) 
"
1760374640774,"INFO	2025-10-13T16:57:20,774	698281	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 495.0 in stage 0.0 (TID 495) in 21251 ms on 172.35.107.166 (executor 8) (496/590)
"
1760374640803,"INFO	2025-10-13T16:57:20,803	698310	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 514.0 in stage 0.0 (TID 514) (172.35.24.244, executor 3, partition 514, PROCESS_LOCAL, 29311 bytes) 
"
1760374640804,"INFO	2025-10-13T16:57:20,803	698310	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 496.0 in stage 0.0 (TID 496) in 21263 ms on 172.35.24.244 (executor 3) (497/590)
"
1760374640887,"INFO	2025-10-13T16:57:20,886	698393	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 515.0 in stage 0.0 (TID 515) (172.35.201.115, executor 5, partition 515, PROCESS_LOCAL, 29311 bytes) 
"
1760374640887,"INFO	2025-10-13T16:57:20,887	698394	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 498.0 in stage 0.0 (TID 498) in 20938 ms on 172.35.201.115 (executor 5) (498/590)
"
1760374641653,"INFO	2025-10-13T16:57:21,653	699160	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 516.0 in stage 0.0 (TID 516) (172.34.194.6, executor 7, partition 516, PROCESS_LOCAL, 29311 bytes) 
"
1760374641653,"INFO	2025-10-13T16:57:21,653	699160	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 499.0 in stage 0.0 (TID 499) in 20785 ms on 172.34.194.6 (executor 7) (499/590)
"
1760374642146,"INFO	2025-10-13T16:57:22,145	699652	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 517.0 in stage 0.0 (TID 517) (172.34.141.226, executor 2, partition 517, PROCESS_LOCAL, 29311 bytes) 
"
1760374642146,"INFO	2025-10-13T16:57:22,146	699653	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 493.0 in stage 0.0 (TID 493) in 23969 ms on 172.34.141.226 (executor 2) (500/590)
"
1760374643817,"INFO	2025-10-13T16:57:23,816	701323	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 518.0 in stage 0.0 (TID 518) (172.35.107.166, executor 8, partition 518, PROCESS_LOCAL, 29311 bytes) 
"
1760374643817,"INFO	2025-10-13T16:57:23,817	701324	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 501.0 in stage 0.0 (TID 501) in 21805 ms on 172.35.107.166 (executor 8) (501/590)
"
1760374644115,"INFO	2025-10-13T16:57:24,115	701622	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 519.0 in stage 0.0 (TID 519) (172.34.141.1, executor 4, partition 519, PROCESS_LOCAL, 29311 bytes) 
"
1760374644116,"INFO	2025-10-13T16:57:24,115	701622	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 500.0 in stage 0.0 (TID 500) in 23065 ms on 172.34.141.1 (executor 4) (502/590)
"
1760374645024,"INFO	2025-10-13T16:57:25,024	702531	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 520.0 in stage 0.0 (TID 520) (172.34.27.84, executor 9, partition 520, PROCESS_LOCAL, 29311 bytes) 
"
1760374645024,"INFO	2025-10-13T16:57:25,024	702531	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 503.0 in stage 0.0 (TID 503) in 21413 ms on 172.34.27.84 (executor 9) (503/590)
"
1760374646285,"INFO	2025-10-13T16:57:26,285	703792	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 521.0 in stage 0.0 (TID 521) (172.34.141.226, executor 2, partition 521, PROCESS_LOCAL, 29311 bytes) 
"
1760374646285,"INFO	2025-10-13T16:57:26,285	703792	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 502.0 in stage 0.0 (TID 502) in 23956 ms on 172.34.141.226 (executor 2) (504/590)
"
1760374647804,"INFO	2025-10-13T16:57:27,804	705311	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 522.0 in stage 0.0 (TID 522) (172.34.46.142, executor 1, partition 522, PROCESS_LOCAL, 29311 bytes) 
"
1760374647804,"INFO	2025-10-13T16:57:27,804	705311	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 504.0 in stage 0.0 (TID 504) in 21708 ms on 172.34.46.142 (executor 1) (505/590)
"
1760374648053,"INFO	2025-10-13T16:57:28,053	705560	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374648053,"INFO	2025-10-13T16:57:28,053	705560	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 89, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374648053,"INFO	2025-10-13T16:57:28,053	705560	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 89; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_89_a_spark-application-1760373954341_p_1
"
1760374648054,"INFO	2025-10-13T16:57:28,054	705561	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374648102,"INFO	2025-10-13T16:57:28,102	705609	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
INFO	2025-10-13T16:57:28,102	705609	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: bb16d655-1f7e-4e1e-bde0-2b36e1c357dd)
"
1760374648102,"INFO	2025-10-13T16:57:28,102	705609	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 89 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374655577,"INFO	2025-10-13T16:57:35,576	713083	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 523.0 in stage 0.0 (TID 523) (172.34.206.195, executor 6, partition 523, PROCESS_LOCAL, 29311 bytes) 
"
1760374655577,"INFO	2025-10-13T16:57:35,577	713084	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 505.0 in stage 0.0 (TID 505) in 22307 ms on 172.34.206.195 (executor 6) (506/590)
"
1760374656464,"INFO	2025-10-13T16:57:36,464	713971	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374656465,"INFO	2025-10-13T16:57:36,465	713972	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 90, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374656465,"INFO	2025-10-13T16:57:36,465	713972	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 90; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_90_a_spark-application-1760373954341_p_1
"
1760374656465,"INFO	2025-10-13T16:57:36,465	713972	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374656509,"INFO	2025-10-13T16:57:36,509	714016	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374656510,"INFO	2025-10-13T16:57:36,509	714016	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 6fb3e3f1-0b95-4903-a865-e6cf5182dd87)
"
1760374656510,"INFO	2025-10-13T16:57:36,509	714016	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 90 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374656577,"INFO	2025-10-13T16:57:36,577	714084	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 524.0 in stage 0.0 (TID 524) (172.34.206.195, executor 6, partition 524, PROCESS_LOCAL, 29311 bytes) 
"
1760374656577,"INFO	2025-10-13T16:57:36,577	714084	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 506.0 in stage 0.0 (TID 506) in 22225 ms on 172.34.206.195 (executor 6) (507/590)
"
1760374658356,"INFO	2025-10-13T16:57:38,356	715863	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 525.0 in stage 0.0 (TID 525) (172.35.24.244, executor 3, partition 525, PROCESS_LOCAL, 29311 bytes) 
"
1760374658356,"INFO	2025-10-13T16:57:38,356	715863	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 507.0 in stage 0.0 (TID 507) in 21848 ms on 172.35.24.244 (executor 3) (508/590)
"
1760374659284,"INFO	2025-10-13T16:57:39,283	716790	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 526.0 in stage 0.0 (TID 526) (172.35.201.115, executor 5, partition 526, PROCESS_LOCAL, 29311 bytes) 
"
1760374659284,"INFO	2025-10-13T16:57:39,284	716791	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 508.0 in stage 0.0 (TID 508) in 22416 ms on 172.35.201.115 (executor 5) (509/590)
"
1760374661028,"INFO	2025-10-13T16:57:41,027	718534	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 527.0 in stage 0.0 (TID 527) (172.34.27.84, executor 9, partition 527, PROCESS_LOCAL, 29287 bytes) 
"
1760374661028,"INFO	2025-10-13T16:57:41,028	718535	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 510.0 in stage 0.0 (TID 510) in 21322 ms on 172.34.27.84 (executor 9) (510/590)
"
1760374661475,"INFO	2025-10-13T16:57:41,475	718982	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 528.0 in stage 0.0 (TID 528) (172.34.141.1, executor 4, partition 528, PROCESS_LOCAL, 29287 bytes) 
"
1760374661475,"INFO	2025-10-13T16:57:41,475	718982	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 509.0 in stage 0.0 (TID 509) in 22994 ms on 172.34.141.1 (executor 4) (511/590)
"
1760374661713,"INFO	2025-10-13T16:57:41,713	719220	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 529.0 in stage 0.0 (TID 529) (172.34.194.6, executor 7, partition 529, PROCESS_LOCAL, 29287 bytes) 
"
1760374661713,"INFO	2025-10-13T16:57:41,713	719220	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 511.0 in stage 0.0 (TID 511) in 21944 ms on 172.34.194.6 (executor 7) (512/590)
"
1760374661905,"INFO	2025-10-13T16:57:41,904	719411	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374661905,"INFO	2025-10-13T16:57:41,905	719412	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 91, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374661905,"INFO	2025-10-13T16:57:41,905	719412	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 91; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_91_a_spark-application-1760373954341_p_1
"
1760374661905,"INFO	2025-10-13T16:57:41,905	719412	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374661964,"INFO	2025-10-13T16:57:41,964	719471	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374661965,"INFO	2025-10-13T16:57:41,964	719471	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 2bb89b7c-4333-4918-8bcc-3196254410b0)
"
1760374661965,"INFO	2025-10-13T16:57:41,964	719471	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 91 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374662148,"INFO	2025-10-13T16:57:42,148	719655	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 530.0 in stage 0.0 (TID 530) (172.35.107.166, executor 8, partition 530, PROCESS_LOCAL, 29287 bytes) 
"
1760374662148,"INFO	2025-10-13T16:57:42,148	719655	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 513.0 in stage 0.0 (TID 513) in 21375 ms on 172.35.107.166 (executor 8) (513/590)
"
1760374662445,"INFO	2025-10-13T16:57:42,445	719952	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 531.0 in stage 0.0 (TID 531) (172.35.24.244, executor 3, partition 531, PROCESS_LOCAL, 29287 bytes) 
"
1760374662446,"INFO	2025-10-13T16:57:42,445	719952	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 514.0 in stage 0.0 (TID 514) in 21642 ms on 172.35.24.244 (executor 3) (514/590)
"
1760374662514,"INFO	2025-10-13T16:57:42,513	720020	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 19
"
1760374662514,"INFO	2025-10-13T16:57:42,513	720020	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 19
"
1760374662590,"INFO	2025-10-13T16:57:42,590	720097	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 532.0 in stage 0.0 (TID 532) (172.34.46.142, executor 1, partition 532, PROCESS_LOCAL, 29287 bytes) 
"
1760374662591,"INFO	2025-10-13T16:57:42,590	720097	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 512.0 in stage 0.0 (TID 512) in 21881 ms on 172.34.46.142 (executor 1) (515/590)
"
1760374663142,"INFO	2025-10-13T16:57:43,142	720649	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 533.0 in stage 0.0 (TID 533) (172.35.201.115, executor 5, partition 533, PROCESS_LOCAL, 29287 bytes) 
"
1760374663142,"INFO	2025-10-13T16:57:43,142	720649	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 515.0 in stage 0.0 (TID 515) in 22256 ms on 172.35.201.115 (executor 5) (516/590)
"
1760374663904,"INFO	2025-10-13T16:57:43,904	721411	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 534.0 in stage 0.0 (TID 534) (172.34.194.6, executor 7, partition 534, PROCESS_LOCAL, 29287 bytes) 
"
1760374663905,"INFO	2025-10-13T16:57:43,905	721412	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 516.0 in stage 0.0 (TID 516) in 22252 ms on 172.34.194.6 (executor 7) (517/590)
"
1760374665347,"INFO	2025-10-13T16:57:45,347	722854	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 535.0 in stage 0.0 (TID 535) (172.35.107.166, executor 8, partition 535, PROCESS_LOCAL, 29287 bytes) 
"
1760374665348,"INFO	2025-10-13T16:57:45,347	722854	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 518.0 in stage 0.0 (TID 518) in 21531 ms on 172.35.107.166 (executor 8) (518/590)
"
1760374665418,"INFO	2025-10-13T16:57:45,418	722925	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 18
INFO	2025-10-13T16:57:45,418	722925	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 18
"
1760374666106,"INFO	2025-10-13T16:57:46,106	723613	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 536.0 in stage 0.0 (TID 536) (172.34.141.226, executor 2, partition 536, PROCESS_LOCAL, 29287 bytes) 
"
1760374666107,"INFO	2025-10-13T16:57:46,106	723613	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 517.0 in stage 0.0 (TID 517) in 23961 ms on 172.34.141.226 (executor 2) (519/590)
"
1760374666578,"INFO	2025-10-13T16:57:46,578	724085	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 537.0 in stage 0.0 (TID 537) (172.34.27.84, executor 9, partition 537, PROCESS_LOCAL, 29287 bytes) 
"
1760374666579,"INFO	2025-10-13T16:57:46,578	724085	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 520.0 in stage 0.0 (TID 520) in 21554 ms on 172.34.27.84 (executor 9) (520/590)
"
1760374666971,"INFO	2025-10-13T16:57:46,971	724478	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 538.0 in stage 0.0 (TID 538) (172.34.141.1, executor 4, partition 538, PROCESS_LOCAL, 29287 bytes) 
"
1760374666971,"INFO	2025-10-13T16:57:46,971	724478	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 519.0 in stage 0.0 (TID 519) in 22856 ms on 172.34.141.1 (executor 4) (521/590)
"
1760374670003,"INFO	2025-10-13T16:57:50,003	727510	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 539.0 in stage 0.0 (TID 539) (172.34.46.142, executor 1, partition 539, PROCESS_LOCAL, 29287 bytes) 
"
1760374670003,"INFO	2025-10-13T16:57:50,003	727510	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 522.0 in stage 0.0 (TID 522) in 22200 ms on 172.34.46.142 (executor 1) (522/590)
"
1760374670024,"INFO	2025-10-13T16:57:50,024	727531	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 17
"
1760374670024,"INFO	2025-10-13T16:57:50,024	727531	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 17
"
1760374670515,"INFO	2025-10-13T16:57:50,514	728021	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 540.0 in stage 0.0 (TID 540) (172.34.141.226, executor 2, partition 540, PROCESS_LOCAL, 29287 bytes) 
"
1760374670515,"INFO	2025-10-13T16:57:50,515	728022	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 521.0 in stage 0.0 (TID 521) in 24231 ms on 172.34.141.226 (executor 2) (523/590)
"
1760374674477,"INFO	2025-10-13T16:57:54,477	731984	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374674477,"INFO	2025-10-13T16:57:54,477	731984	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374676062,"INFO	2025-10-13T16:57:56,062	733569	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374676062,"INFO	2025-10-13T16:57:56,062	733569	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 92, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374676062,"INFO	2025-10-13T16:57:56,062	733569	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 92; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_92_a_spark-application-1760373954341_p_1
"
1760374676063,"INFO	2025-10-13T16:57:56,062	733569	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374676103,"INFO	2025-10-13T16:57:56,103	733610	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374676103,"INFO	2025-10-13T16:57:56,103	733610	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 663f7f5d-96ce-48d3-8cbc-e7756603da04)
"
1760374676103,"INFO	2025-10-13T16:57:56,103	733610	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 92 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374678205,"INFO	2025-10-13T16:57:58,204	735711	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 541.0 in stage 0.0 (TID 541) (172.34.206.195, executor 6, partition 541, PROCESS_LOCAL, 29287 bytes) 
"
1760374678205,"INFO	2025-10-13T16:57:58,205	735712	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 523.0 in stage 0.0 (TID 523) in 22629 ms on 172.34.206.195 (executor 6) (524/590)
"
1760374679689,"INFO	2025-10-13T16:57:59,689	737196	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 542.0 in stage 0.0 (TID 542) (172.34.206.195, executor 6, partition 542, PROCESS_LOCAL, 29287 bytes) 
"
1760374679689,"INFO	2025-10-13T16:57:59,689	737196	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 524.0 in stage 0.0 (TID 524) in 23113 ms on 172.34.206.195 (executor 6) (525/590)
"
1760374680334,"INFO	2025-10-13T16:58:00,333	737840	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 543.0 in stage 0.0 (TID 543) (172.35.24.244, executor 3, partition 543, PROCESS_LOCAL, 29287 bytes) 
"
1760374680334,"INFO	2025-10-13T16:58:00,334	737841	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 525.0 in stage 0.0 (TID 525) in 21979 ms on 172.35.24.244 (executor 3) (526/590)
"
1760374680335,"INFO	2025-10-13T16:58:00,335	737842	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 16
"
1760374680335,"INFO	2025-10-13T16:58:00,335	737842	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 16
"
1760374681793,"INFO	2025-10-13T16:58:01,792	739299	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 544.0 in stage 0.0 (TID 544) (172.34.27.84, executor 9, partition 544, PROCESS_LOCAL, 29287 bytes) 
"
1760374681793,"INFO	2025-10-13T16:58:01,793	739300	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 527.0 in stage 0.0 (TID 527) in 20766 ms on 172.34.27.84 (executor 9) (527/590)
"
1760374682261,"INFO	2025-10-13T16:58:02,261	739768	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 545.0 in stage 0.0 (TID 545) (172.35.201.115, executor 5, partition 545, PROCESS_LOCAL, 29287 bytes) 
"
1760374682261,"INFO	2025-10-13T16:58:02,261	739768	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 526.0 in stage 0.0 (TID 526) in 22978 ms on 172.35.201.115 (executor 5) (528/590)
"
1760374683003,"INFO	2025-10-13T16:58:03,003	740510	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 546.0 in stage 0.0 (TID 546) (172.34.194.6, executor 7, partition 546, PROCESS_LOCAL, 29287 bytes) 
"
1760374683003,"INFO	2025-10-13T16:58:03,003	740510	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 529.0 in stage 0.0 (TID 529) in 21291 ms on 172.34.194.6 (executor 7) (529/590)
"
1760374683116,"INFO	2025-10-13T16:58:03,116	740623	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 547.0 in stage 0.0 (TID 547) (172.35.107.166, executor 8, partition 547, PROCESS_LOCAL, 29287 bytes) 
"
1760374683117,"INFO	2025-10-13T16:58:03,117	740624	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 530.0 in stage 0.0 (TID 530) in 20969 ms on 172.35.107.166 (executor 8) (530/590)
"
1760374683138,"INFO	2025-10-13T16:58:03,138	740645	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 15
INFO	2025-10-13T16:58:03,138	740645	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 15
"
1760374683841,"INFO	2025-10-13T16:58:03,841	741348	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 548.0 in stage 0.0 (TID 548) (172.34.46.142, executor 1, partition 548, PROCESS_LOCAL, 29287 bytes) 
"
1760374683842,"INFO	2025-10-13T16:58:03,841	741348	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 532.0 in stage 0.0 (TID 532) in 21251 ms on 172.34.46.142 (executor 1) (531/590)
"
1760374683949,"INFO	2025-10-13T16:58:03,949	741456	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 549.0 in stage 0.0 (TID 549) (172.34.141.1, executor 4, partition 549, PROCESS_LOCAL, 29287 bytes) 
"
1760374683949,"INFO	2025-10-13T16:58:03,949	741456	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 528.0 in stage 0.0 (TID 528) in 22474 ms on 172.34.141.1 (executor 4) (532/590)
"
1760374684244,"INFO	2025-10-13T16:58:04,243	741750	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 550.0 in stage 0.0 (TID 550) (172.35.24.244, executor 3, partition 550, PROCESS_LOCAL, 29287 bytes) 
"
1760374684244,"INFO	2025-10-13T16:58:04,244	741751	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 531.0 in stage 0.0 (TID 531) in 21799 ms on 172.35.24.244 (executor 3) (533/590)
"
1760374685629,"INFO	2025-10-13T16:58:05,628	743135	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 551.0 in stage 0.0 (TID 551) (172.34.194.6, executor 7, partition 551, PROCESS_LOCAL, 29287 bytes) 
"
1760374685629,"INFO	2025-10-13T16:58:05,629	743136	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 534.0 in stage 0.0 (TID 534) in 21725 ms on 172.34.194.6 (executor 7) (534/590)
"
1760374685641,"INFO	2025-10-13T16:58:05,641	743148	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 14
"
1760374685641,"INFO	2025-10-13T16:58:05,641	743148	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 14
"
1760374685913,"INFO	2025-10-13T16:58:05,912	743419	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 552.0 in stage 0.0 (TID 552) (172.35.201.115, executor 5, partition 552, PROCESS_LOCAL, 29287 bytes) 
"
1760374685913,"INFO	2025-10-13T16:58:05,913	743420	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 533.0 in stage 0.0 (TID 533) in 22772 ms on 172.35.201.115 (executor 5) (535/590)
"
1760374686211,"INFO	2025-10-13T16:58:06,211	743718	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 553.0 in stage 0.0 (TID 553) (172.35.107.166, executor 8, partition 553, PROCESS_LOCAL, 29287 bytes) 
"
1760374686212,"INFO	2025-10-13T16:58:06,211	743718	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 535.0 in stage 0.0 (TID 535) in 20864 ms on 172.35.107.166 (executor 8) (536/590)
"
1760374687692,"INFO	2025-10-13T16:58:07,692	745199	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 554.0 in stage 0.0 (TID 554) (172.34.27.84, executor 9, partition 554, PROCESS_LOCAL, 29287 bytes) 
"
1760374687692,"INFO	2025-10-13T16:58:07,692	745199	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 537.0 in stage 0.0 (TID 537) in 21114 ms on 172.34.27.84 (executor 9) (537/590)
"
1760374689267,"INFO	2025-10-13T16:58:09,267	746774	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 555.0 in stage 0.0 (TID 555) (172.34.141.226, executor 2, partition 555, PROCESS_LOCAL, 29287 bytes) 
"
1760374689268,"INFO	2025-10-13T16:58:09,267	746774	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 536.0 in stage 0.0 (TID 536) in 23161 ms on 172.34.141.226 (executor 2) (538/590)
"
1760374689345,"INFO	2025-10-13T16:58:09,345	746852	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 13
"
1760374689345,"INFO	2025-10-13T16:58:09,345	746852	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 13
"
1760374689347,"INFO	2025-10-13T16:58:09,347	746854	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 556.0 in stage 0.0 (TID 556) (172.34.141.1, executor 4, partition 556, PROCESS_LOCAL, 29287 bytes) 
"
1760374689347,"INFO	2025-10-13T16:58:09,347	746854	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 538.0 in stage 0.0 (TID 538) in 22377 ms on 172.34.141.1 (executor 4) (539/590)
"
1760374690145,"INFO	2025-10-13T16:58:10,144	747651	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374690145,"INFO	2025-10-13T16:58:10,145	747652	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 93, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374690145,"INFO	2025-10-13T16:58:10,145	747652	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 93; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_93_a_spark-application-1760373954341_p_1
"
1760374690145,"INFO	2025-10-13T16:58:10,145	747652	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374690188,"INFO	2025-10-13T16:58:10,188	747695	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374690188,"INFO	2025-10-13T16:58:10,188	747695	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 8758e56b-6e82-4c23-8bf9-fbf95fa8e781)
"
1760374690188,"INFO	2025-10-13T16:58:10,188	747695	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 93 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374691468,"INFO	2025-10-13T16:58:11,467	748974	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 557.0 in stage 0.0 (TID 557) (172.34.46.142, executor 1, partition 557, PROCESS_LOCAL, 29287 bytes) 
"
1760374691468,"INFO	2025-10-13T16:58:11,468	748975	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 539.0 in stage 0.0 (TID 539) in 21466 ms on 172.34.46.142 (executor 1) (540/590)
"
1760374693780,"INFO	2025-10-13T16:58:13,779	751286	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 558.0 in stage 0.0 (TID 558) (172.34.141.226, executor 2, partition 558, PROCESS_LOCAL, 29287 bytes) 
"
1760374693780,"INFO	2025-10-13T16:58:13,780	751287	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 540.0 in stage 0.0 (TID 540) in 23266 ms on 172.34.141.226 (executor 2) (541/590)
"
1760374696092,"INFO	2025-10-13T16:58:16,092	753599	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374696092,"INFO	2025-10-13T16:58:16,092	753599	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 94, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374696092,"INFO	2025-10-13T16:58:16,092	753599	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 94; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_94_a_spark-application-1760373954341_p_1
"
1760374696093,"INFO	2025-10-13T16:58:16,092	753599	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374696130,"INFO	2025-10-13T16:58:16,130	753637	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374696130,"INFO	2025-10-13T16:58:16,130	753637	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: 81f40a18-c12b-4f0b-9009-01b91560ca8c)
"
1760374696131,"INFO	2025-10-13T16:58:16,130	753637	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 94 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374697919,"INFO	2025-10-13T16:58:17,919	755426	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374697919,"INFO	2025-10-13T16:58:17,919	755426	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 95, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374697919,"INFO	2025-10-13T16:58:17,919	755426	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 95; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_95_a_spark-application-1760373954341_p_1
"
1760374697919,"INFO	2025-10-13T16:58:17,919	755426	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374697959,"INFO	2025-10-13T16:58:17,959	755466	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
INFO	2025-10-13T16:58:17,959	755466	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a002f899-75c7-4573-9e52-acfe049bcc9f)
"
1760374697960,"INFO	2025-10-13T16:58:17,959	755466	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 95 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374699942,"INFO	2025-10-13T16:58:19,942	757449	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 559.0 in stage 0.0 (TID 559) (172.34.206.195, executor 6, partition 559, PROCESS_LOCAL, 29287 bytes) 
"
1760374699942,"INFO	2025-10-13T16:58:19,942	757449	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 541.0 in stage 0.0 (TID 541) in 21738 ms on 172.34.206.195 (executor 6) (542/590)
"
1760374699956,"INFO	2025-10-13T16:58:19,956	757463	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 12
INFO	2025-10-13T16:58:19,956	757463	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 12
"
1760374701448,"INFO	2025-10-13T16:58:21,447	758954	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 560.0 in stage 0.0 (TID 560) (172.34.206.195, executor 6, partition 560, PROCESS_LOCAL, 29278 bytes) 
"
1760374701448,"INFO	2025-10-13T16:58:21,448	758955	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 542.0 in stage 0.0 (TID 542) in 21760 ms on 172.34.206.195 (executor 6) (543/590)
"
1760374701745,"INFO	2025-10-13T16:58:21,745	759252	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 561.0 in stage 0.0 (TID 561) (172.35.24.244, executor 3, partition 561, PROCESS_LOCAL, 29287 bytes) 
"
1760374701746,"INFO	2025-10-13T16:58:21,745	759252	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 543.0 in stage 0.0 (TID 543) in 21412 ms on 172.35.24.244 (executor 3) (544/590)
"
1760374702542,"INFO	2025-10-13T16:58:22,542	760049	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 562.0 in stage 0.0 (TID 562) (172.34.27.84, executor 9, partition 562, PROCESS_LOCAL, 29287 bytes) 
"
1760374702543,"INFO	2025-10-13T16:58:22,543	760050	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 544.0 in stage 0.0 (TID 544) in 20750 ms on 172.34.27.84 (executor 9) (545/590)
"
1760374703838,"INFO	2025-10-13T16:58:23,838	761345	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 563.0 in stage 0.0 (TID 563) (172.35.201.115, executor 5, partition 563, PROCESS_LOCAL, 29287 bytes) 
"
1760374703839,"INFO	2025-10-13T16:58:23,839	761346	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 545.0 in stage 0.0 (TID 545) in 21578 ms on 172.35.201.115 (executor 5) (546/590)
"
1760374703861,"INFO	2025-10-13T16:58:23,860	761367	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 11
INFO	2025-10-13T16:58:23,860	761367	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 11
"
1760374704148,"INFO	2025-10-13T16:58:24,147	761654	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 564.0 in stage 0.0 (TID 564) (172.35.107.166, executor 8, partition 564, PROCESS_LOCAL, 29287 bytes) 
"
1760374704148,"INFO	2025-10-13T16:58:24,148	761655	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 547.0 in stage 0.0 (TID 547) in 21032 ms on 172.35.107.166 (executor 8) (547/590)
"
1760374704469,"INFO	2025-10-13T16:58:24,469	761976	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 565.0 in stage 0.0 (TID 565) (172.34.194.6, executor 7, partition 565, PROCESS_LOCAL, 29287 bytes) 
"
1760374704470,"INFO	2025-10-13T16:58:24,470	761977	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 546.0 in stage 0.0 (TID 546) in 21467 ms on 172.34.194.6 (executor 7) (548/590)
"
1760374705065,"INFO	2025-10-13T16:58:25,065	762572	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 566.0 in stage 0.0 (TID 566) (172.34.46.142, executor 1, partition 566, PROCESS_LOCAL, 29287 bytes) 
"
1760374705066,"INFO	2025-10-13T16:58:25,065	762572	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 548.0 in stage 0.0 (TID 548) in 21224 ms on 172.34.46.142 (executor 1) (549/590)
"
1760374705530,"INFO	2025-10-13T16:58:25,530	763037	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 567.0 in stage 0.0 (TID 567) (172.35.24.244, executor 3, partition 567, PROCESS_LOCAL, 29287 bytes) 
"
1760374705531,"INFO	2025-10-13T16:58:25,530	763037	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 550.0 in stage 0.0 (TID 550) in 21287 ms on 172.35.24.244 (executor 3) (550/590)
"
1760374705563,"INFO	2025-10-13T16:58:25,562	763069	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 10
INFO	2025-10-13T16:58:25,563	763070	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 10
"
1760374706207,"INFO	2025-10-13T16:58:26,206	763713	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374706207,"INFO	2025-10-13T16:58:26,207	763714	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 96, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374706207,"INFO	2025-10-13T16:58:26,207	763714	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 96; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_96_a_spark-application-1760373954341_p_1
"
1760374706207,"INFO	2025-10-13T16:58:26,207	763714	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374706247,"INFO	2025-10-13T16:58:26,247	763754	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374706248,"INFO	2025-10-13T16:58:26,247	763754	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: c24eaf53-d82f-42f3-8e5c-1fb9dea689cf)
"
1760374706248,"INFO	2025-10-13T16:58:26,247	763754	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 96 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374706269,"INFO	2025-10-13T16:58:26,269	763776	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 568.0 in stage 0.0 (TID 568) (172.34.141.1, executor 4, partition 568, PROCESS_LOCAL, 29287 bytes) 
"
1760374706269,"INFO	2025-10-13T16:58:26,269	763776	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 549.0 in stage 0.0 (TID 549) in 22321 ms on 172.34.141.1 (executor 4) (551/590)
"
1760374707037,"INFO	2025-10-13T16:58:27,037	764544	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 569.0 in stage 0.0 (TID 569) (172.34.194.6, executor 7, partition 569, PROCESS_LOCAL, 29287 bytes) 
"
1760374707037,"INFO	2025-10-13T16:58:27,037	764544	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 551.0 in stage 0.0 (TID 551) in 21409 ms on 172.34.194.6 (executor 7) (552/590)
"
1760374707626,"INFO	2025-10-13T16:58:27,626	765133	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 570.0 in stage 0.0 (TID 570) (172.35.201.115, executor 5, partition 570, PROCESS_LOCAL, 29287 bytes) 
"
1760374707626,"INFO	2025-10-13T16:58:27,626	765133	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 552.0 in stage 0.0 (TID 552) in 21714 ms on 172.35.201.115 (executor 5) (553/590)
"
1760374707883,"INFO	2025-10-13T16:58:27,882	765389	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 571.0 in stage 0.0 (TID 571) (172.35.107.166, executor 8, partition 571, PROCESS_LOCAL, 29287 bytes) 
"
1760374707883,"INFO	2025-10-13T16:58:27,883	765390	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 553.0 in stage 0.0 (TID 553) in 21672 ms on 172.35.107.166 (executor 8) (554/590)
"
1760374707966,"INFO	2025-10-13T16:58:27,965	765472	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 9
INFO	2025-10-13T16:58:27,966	765473	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 9
"
1760374709440,"INFO	2025-10-13T16:58:29,440	766947	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 572.0 in stage 0.0 (TID 572) (172.34.27.84, executor 9, partition 572, PROCESS_LOCAL, 29287 bytes) 
"
1760374709440,"INFO	2025-10-13T16:58:29,440	766947	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 554.0 in stage 0.0 (TID 554) in 21749 ms on 172.34.27.84 (executor 9) (555/590)
"
1760374709516,"INFO	2025-10-13T16:58:29,516	767023	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760373954341 with resource profile 0
"
1760374709516,"INFO	2025-10-13T16:58:29,516	767023	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.216.56:45217, --executor-id, 97, --app-id, spark-application-1760373954341, --cores, 2, --resourceProfileId, 0)
"
1760374709516,"INFO	2025-10-13T16:58:29,516	767023	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 97; clientToken gr_140a23f9-7ea9-4510-a047-b7dd132ba107_e_97_a_spark-application-1760373954341_p_1
"
1760374709516,"INFO	2025-10-13T16:58:29,516	767023	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760374709548,"INFO	2025-10-13T16:58:29,548	767055	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760374709549,"INFO	2025-10-13T16:58:29,548	767055	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 10.0 for groupId 140a23f9-7ea9-4510-a047-b7dd132ba107 (Service: GlueJobExecutor, Status Code: 400, Request ID: a30c0b51-578d-4077-a457-115f3f2dd3f2)
"
1760374709549,"INFO	2025-10-13T16:58:29,548	767055	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 97 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760374712157,"INFO	2025-10-13T16:58:32,157	769664	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 573.0 in stage 0.0 (TID 573) (172.34.141.1, executor 4, partition 573, PROCESS_LOCAL, 29287 bytes) 
"
1760374712157,"INFO	2025-10-13T16:58:32,157	769664	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 556.0 in stage 0.0 (TID 556) in 22810 ms on 172.34.141.1 (executor 4) (556/590)
"
1760374712676,"INFO	2025-10-13T16:58:32,676	770183	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 574.0 in stage 0.0 (TID 574) (172.34.141.226, executor 2, partition 574, PROCESS_LOCAL, 29287 bytes) 
"
1760374712676,"INFO	2025-10-13T16:58:32,676	770183	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 555.0 in stage 0.0 (TID 555) in 23409 ms on 172.34.141.226 (executor 2) (557/590)
"
1760374712888,"INFO	2025-10-13T16:58:32,888	770395	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 575.0 in stage 0.0 (TID 575) (172.34.46.142, executor 1, partition 575, PROCESS_LOCAL, 29287 bytes) 
"
1760374712889,"INFO	2025-10-13T16:58:32,888	770395	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 557.0 in stage 0.0 (TID 557) in 21421 ms on 172.34.46.142 (executor 1) (558/590)
"
1760374712971,"INFO	2025-10-13T16:58:32,971	770478	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 8
INFO	2025-10-13T16:58:32,971	770478	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 8
"
1760374717019,"INFO	2025-10-13T16:58:37,018	774525	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 576.0 in stage 0.0 (TID 576) (172.34.141.226, executor 2, partition 576, PROCESS_LOCAL, 29287 bytes) 
"
1760374717019,"INFO	2025-10-13T16:58:37,019	774526	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 558.0 in stage 0.0 (TID 558) in 23240 ms on 172.34.141.226 (executor 2) (559/590)
"
1760374722008,"INFO	2025-10-13T16:58:42,008	779515	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 577.0 in stage 0.0 (TID 577) (172.34.206.195, executor 6, partition 577, PROCESS_LOCAL, 29287 bytes) 
"
1760374722008,"INFO	2025-10-13T16:58:42,008	779515	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 559.0 in stage 0.0 (TID 559) in 22067 ms on 172.34.206.195 (executor 6) (560/590)
"
1760374723191,"INFO	2025-10-13T16:58:43,190	780697	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 578.0 in stage 0.0 (TID 578) (172.35.24.244, executor 3, partition 578, PROCESS_LOCAL, 29287 bytes) 
"
1760374723191,"INFO	2025-10-13T16:58:43,191	780698	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 561.0 in stage 0.0 (TID 561) in 21446 ms on 172.35.24.244 (executor 3) (561/590)
"
1760374723326,"INFO	2025-10-13T16:58:43,326	780833	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 579.0 in stage 0.0 (TID 579) (172.34.27.84, executor 9, partition 579, PROCESS_LOCAL, 29287 bytes) 
"
1760374723327,"INFO	2025-10-13T16:58:43,326	780833	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 562.0 in stage 0.0 (TID 562) in 20784 ms on 172.34.27.84 (executor 9) (562/590)
"
1760374723382,"INFO	2025-10-13T16:58:43,382	780889	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 7
INFO	2025-10-13T16:58:43,382	780889	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 7
"
1760374723494,"INFO	2025-10-13T16:58:43,494	781001	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 580.0 in stage 0.0 (TID 580) (172.34.206.195, executor 6, partition 580, PROCESS_LOCAL, 29287 bytes) 
"
1760374723494,"INFO	2025-10-13T16:58:43,494	781001	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 560.0 in stage 0.0 (TID 560) in 22047 ms on 172.34.206.195 (executor 6) (563/590)
"
1760374724959,"INFO	2025-10-13T16:58:44,958	782465	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 581.0 in stage 0.0 (TID 581) (172.35.107.166, executor 8, partition 581, PROCESS_LOCAL, 29287 bytes) 
"
1760374724959,"INFO	2025-10-13T16:58:44,959	782466	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 564.0 in stage 0.0 (TID 564) in 20812 ms on 172.35.107.166 (executor 8) (564/590)
"
1760374725492,"INFO	2025-10-13T16:58:45,492	782999	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 582.0 in stage 0.0 (TID 582) (172.35.201.115, executor 5, partition 582, PROCESS_LOCAL, 29287 bytes) 
"
1760374725492,"INFO	2025-10-13T16:58:45,492	782999	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 563.0 in stage 0.0 (TID 563) in 21654 ms on 172.35.201.115 (executor 5) (565/590)
"
1760374725764,"INFO	2025-10-13T16:58:45,764	783271	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 583.0 in stage 0.0 (TID 583) (172.34.194.6, executor 7, partition 583, PROCESS_LOCAL, 29287 bytes) 
"
1760374725764,"INFO	2025-10-13T16:58:45,764	783271	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 565.0 in stage 0.0 (TID 565) in 21295 ms on 172.34.194.6 (executor 7) (566/590)
"
1760374725785,"INFO	2025-10-13T16:58:45,785	783292	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 6
"
1760374725785,"INFO	2025-10-13T16:58:45,785	783292	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 6
"
1760374726448,"INFO	2025-10-13T16:58:46,447	783954	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 584.0 in stage 0.0 (TID 584) (172.34.46.142, executor 1, partition 584, PROCESS_LOCAL, 29287 bytes) 
"
1760374726448,"INFO	2025-10-13T16:58:46,448	783955	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 566.0 in stage 0.0 (TID 566) in 21383 ms on 172.34.46.142 (executor 1) (567/590)
"
1760374726829,"INFO	2025-10-13T16:58:46,829	784336	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 585.0 in stage 0.0 (TID 585) (172.35.24.244, executor 3, partition 585, PROCESS_LOCAL, 29287 bytes) 
"
1760374726829,"INFO	2025-10-13T16:58:46,829	784336	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 567.0 in stage 0.0 (TID 567) in 21299 ms on 172.35.24.244 (executor 3) (568/590)
"
1760374728473,"INFO	2025-10-13T16:58:48,472	785979	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 586.0 in stage 0.0 (TID 586) (172.34.141.1, executor 4, partition 586, PROCESS_LOCAL, 29287 bytes) 
"
1760374728473,"INFO	2025-10-13T16:58:48,473	785980	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 568.0 in stage 0.0 (TID 568) in 22205 ms on 172.34.141.1 (executor 4) (569/590)
"
1760374728649,"INFO	2025-10-13T16:58:48,649	786156	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 587.0 in stage 0.0 (TID 587) (172.35.107.166, executor 8, partition 587, PROCESS_LOCAL, 29287 bytes) 
"
1760374728650,"INFO	2025-10-13T16:58:48,650	786157	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 571.0 in stage 0.0 (TID 571) in 20767 ms on 172.35.107.166 (executor 8) (570/590)
"
1760374728688,"INFO	2025-10-13T16:58:48,688	786195	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 5
INFO	2025-10-13T16:58:48,688	786195	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 5
"
1760374729034,"INFO	2025-10-13T16:58:49,033	786540	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 588.0 in stage 0.0 (TID 588) (172.34.194.6, executor 7, partition 588, PROCESS_LOCAL, 29287 bytes) 
"
1760374729034,"INFO	2025-10-13T16:58:49,034	786541	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 569.0 in stage 0.0 (TID 569) in 21998 ms on 172.34.194.6 (executor 7) (571/590)
"
1760374729050,"INFO	2025-10-13T16:58:49,050	786557	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 589.0 in stage 0.0 (TID 589) (172.35.201.115, executor 5, partition 589, PROCESS_LOCAL, 29287 bytes) 
"
1760374729051,"INFO	2025-10-13T16:58:49,051	786558	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 570.0 in stage 0.0 (TID 570) in 21425 ms on 172.35.201.115 (executor 5) (572/590)
"
1760374731092,"INFO	2025-10-13T16:58:51,091	788598	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 572.0 in stage 0.0 (TID 572) in 21652 ms on 172.34.27.84 (executor 9) (573/590)
"
1760374734259,"INFO	2025-10-13T16:58:54,259	791766	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 573.0 in stage 0.0 (TID 573) in 22102 ms on 172.34.141.1 (executor 4) (574/590)
"
1760374734294,"INFO	2025-10-13T16:58:54,294	791801	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 4
"
1760374734294,"INFO	2025-10-13T16:58:54,294	791801	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 4
"
1760374734478,"INFO	2025-10-13T16:58:54,477	791984	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760374734478,"INFO	2025-10-13T16:58:54,477	791984	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 9 executor task status
"
1760374734560,"INFO	2025-10-13T16:58:54,560	792067	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 575.0 in stage 0.0 (TID 575) in 21672 ms on 172.34.46.142 (executor 1) (575/590)
"
1760374735932,"INFO	2025-10-13T16:58:55,931	793438	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 574.0 in stage 0.0 (TID 574) in 23256 ms on 172.34.141.226 (executor 2) (576/590)
"
1760374740418,"INFO	2025-10-13T16:59:00,418	797925	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 576.0 in stage 0.0 (TID 576) in 23399 ms on 172.34.141.226 (executor 2) (577/590)
"
1760374743337,"INFO	2025-10-13T16:59:03,337	800844	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 579.0 in stage 0.0 (TID 579) in 20010 ms on 172.34.27.84 (executor 9) (578/590)
"
1760374743403,"INFO	2025-10-13T16:59:03,403	800910	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 3
"
1760374743403,"INFO	2025-10-13T16:59:03,403	800910	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 3
"
1760374744205,"INFO	2025-10-13T16:59:04,205	801712	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 577.0 in stage 0.0 (TID 577) in 22198 ms on 172.34.206.195 (executor 6) (579/590)
"
1760374744494,"INFO	2025-10-13T16:59:04,493	802000	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 578.0 in stage 0.0 (TID 578) in 21303 ms on 172.35.24.244 (executor 3) (580/590)
"
1760374745892,"INFO	2025-10-13T16:59:05,891	803398	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 581.0 in stage 0.0 (TID 581) in 20933 ms on 172.35.107.166 (executor 8) (581/590)
"
1760374746369,"INFO	2025-10-13T16:59:06,369	803876	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 580.0 in stage 0.0 (TID 580) in 22876 ms on 172.34.206.195 (executor 6) (582/590)
"
1760374746406,"INFO	2025-10-13T16:59:06,406	803913	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
"
1760374746406,"INFO	2025-10-13T16:59:06,406	803913	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
"
1760374747336,"INFO	2025-10-13T16:59:07,336	804843	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 582.0 in stage 0.0 (TID 582) in 21845 ms on 172.35.201.115 (executor 5) (583/590)
"
1760374747422,"INFO	2025-10-13T16:59:07,422	804929	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 584.0 in stage 0.0 (TID 584) in 20975 ms on 172.34.46.142 (executor 1) (584/590)
"
1760374747610,"INFO	2025-10-13T16:59:07,609	805116	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 583.0 in stage 0.0 (TID 583) in 21846 ms on 172.34.194.6 (executor 7) (585/590)
"
1760374748966,"INFO	2025-10-13T16:59:08,965	806472	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 585.0 in stage 0.0 (TID 585) in 22137 ms on 172.35.24.244 (executor 3) (586/590)
"
1760374749010,"INFO	2025-10-13T16:59:09,009	806516	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760374749010,"INFO	2025-10-13T16:59:09,009	806516	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 1
"
1760374749318,"INFO	2025-10-13T16:59:09,318	806825	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 587.0 in stage 0.0 (TID 587) in 20669 ms on 172.35.107.166 (executor 8) (587/590)
"
1760374749603,"ERROR	2025-10-13T16:59:09,603	807110	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	76	threshold for consecutive executor task creation reached
"
1760374749606,"INFO	2025-10-13T16:59:09,605	807112	org.apache.spark.SparkContext	[shutdown-hook-0]	60	Invoking stop() from shutdown hook
"
1760374749606,"INFO	2025-10-13T16:59:09,606	807113	org.apache.spark.SparkContext	[shutdown-hook-0]	60	SparkContext is stopping with exitCode 0.
"
1760374749611,"INFO	2025-10-13T16:59:09,611	807118	org.apache.spark.scheduler.DAGScheduler	[shutdown-hook-0]	60	ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0) failed in 782.288 s due to Stage cancelled because SparkContext was shut down
"
1760374749613,"INFO	2025-10-13T16:59:09,612	807119	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[spark-listener-group-shared]	70	Logs, events processed and insights are written to file /tmp/glue-exception-analysis-logs/spark-application-1760373954341
"
1760374749613,"INFO	2025-10-13T16:59:09,613	807120	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[shutdown-hook-0]	60	Stopping JES Scheduler Backend.
"
1760374749614,"INFO	2025-10-13T16:59:09,614	807121	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[shutdown-hook-0]	60	Shutting down all executors
"
1760374749614,"INFO	2025-10-13T16:59:09,614	807121	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Asking each executor to shut down
"
1760374749620,"ERROR	2025-10-13T16:59:09,620	807127	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisStageFailed"",""Timestamp"":1760374749611,""Failure Reason"":""Stage cancelled because SparkContext was shut down"",""Stack Trace"":[],""Stage ID"":0,""Stage Attempt ID"":0,""Number of Tasks"":590}
"
1760374749624,"ERROR	2025-10-13T16:59:09,624	807131	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisJobFailed"",""Timestamp"":1760374749622,""Failure Reason"":""org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down"",""Stack Trace"":[{""Declaring Class"":""org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down)"",""Method Name"":""TopLevelFailedReason"",""File Name"":""TopLevelFailedReason"",""Line Number"":-1}],""Job Id"":0,""Job Result"":""JobFailed"",""Failed Stage Id"":-1}
"
1760374749624,"INFO	2025-10-13T16:59:09,624	807131	org.apache.spark.sql.execution.SQLExecution	[Thread-7]	60	Skipped SparkListenerSQLExecutionObfuscatedInfo event due to NON_EMPTY_ERROR.
"
1760374749634,"INFO	2025-10-13T16:59:09,633	807140	org.apache.spark.MapOutputTrackerMasterEndpoint	[dispatcher-event-loop-1]	60	MapOutputTrackerMasterEndpoint stopped!
"
1760374749645,"INFO	2025-10-13T16:59:09,645	807152	org.apache.spark.storage.memory.MemoryStore	[shutdown-hook-0]	60	MemoryStore cleared
"
1760374749645,"INFO	2025-10-13T16:59:09,645	807152	org.apache.spark.storage.BlockManager	[shutdown-hook-0]	60	BlockManager stopped
"
1760374749652,"INFO	2025-10-13T16:59:09,652	807159	org.apache.spark.storage.BlockManagerMaster	[shutdown-hook-0]	60	BlockManagerMaster stopped
"
1760374749654,"INFO	2025-10-13T16:59:09,654	807161	org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint	[dispatcher-event-loop-6]	60	OutputCommitCoordinator stopped!
"
1760374749702,"INFO	2025-10-13T16:59:09,701	807208	org.apache.spark.SparkContext	[shutdown-hook-0]	60	Successfully stopped SparkContext
"
1760374749703,"INFO	2025-10-13T16:59:09,702	807209	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Shutdown hook called
"
1760374749703,"INFO	2025-10-13T16:59:09,703	807210	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-1c64ab29-0127-4caf-a731-51091bf66ccf
"
1760374749708,"INFO	2025-10-13T16:59:09,708	807215	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-fdce11ed-4f9f-4482-b121-c0e7162906bc
"
1760374749714,"INFO	2025-10-13T16:59:09,714	807221	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-1c64ab29-0127-4caf-a731-51091bf66ccf/pyspark-92deac67-c540-4609-a332-87755bdc6cbe
"