timestamp,message
1760334697283,"Preparing ...
"
1760334697289,"Mon Oct 13 05:51:37 UTC 2025
"
1760334697294,"/etc/alternatives/jre/bin/java --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions -Djavax.net.ssl.trustStore=/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -Djavax.net.ssl.trustStoreType=JKS -Djavax.net.ssl.trustStorePassword=amazon -DRDS_ROOT_CERT_PATH=/opt/amazon/certs/rds-combined-ca-bundle.pem -DREDSHIFT_ROOT_CERT_PATH=/opt/amazon/certs/redshift-ssl-ca-cert.pem -DRDS_TRUSTSTORE_URL=file:/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -cp /usr/share/aws/aws-glue-shuffle/*:/usr/share/aws/emr-glue-bootstrap/*:/usr/lib/spark/jars/*:/usr/lib/spark/conf:/usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/aws/hmclient/lib/*:/usr/share/aws/iceberg/lib/*:/usr/share/aws/delta/lib/*:/usr/lib/hudi/*:/usr/share/aws/redshift/jdbc/*:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/glue-connectors/lib/*:/usr/share/aws/glue-pii-dependencies/lib/*:/usr/share/aws/datazone-openlineage-spark/lib/*:/usr/lib/hadoop/lib/*::/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/cloudwatch-sink/lib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/lib/hadoop/*:/etc/hadoop/conf:/usr/share/java/Hive-JSON-Serde/* -Dlog4j2.configurationFile=/etc/spark/conf.dist/log4j2.properties com.amazonaws.services.glue.GlueBootstrap --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.maxExecutors=19 --conf spark.executor.memory=10g --conf spark.driver.memory=10g --conf spark.network.timeout=600 --app_name maximo_dq_invuseline    --glue-di-packages-correlation-ids 20250828-143656_,20250828-143656_,6378082053,6378082053 --TempDir s3://aws-glue-assets-331875467123-us-gov-west-1/entergy-gov-data-core-code/temporary/ --internal-lib-urls https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/004/Glue5.0/aws-glue-dataplane-python/java17/5.0.704/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip?X-Amz-Security-Token=FwoDYXdzEDwaDHJhgshbEymvrBmMXCKuATjk%2FR8LRwJs%2BUER19I0jHvu0weF4OtRa1sImgYkdEbq3oh3nZME62ZgyeyglOMbsWpAN2LtL7%2FDU614hwIrxjrhFkHHG%2FgoZtHrcjRoYlyyKC8G81wqSXQ16PBcQRIJ3qvu4G793hpbTgAGtb4spNbK%2FcSQi7SXmk9xKNeTt%2FFPsTUpmFwF0p2%2Fbj2Tem3TwNKd6r%2FXunDsNWwMdmcoU%2FCFjeyr%2Ftv9jLyM6djQxSjgprLHBjIfShX9SEFSPThemsaL%2BMVItiKddNj9yomjej7sqV8UCA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055128Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3ANFZN4LQ%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=e823f25a989878ffe4b35161300158830141d1346fbac368747918767d2501e8,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/004/Glue5.0/aws-glue-di-libs/java17/5.0.704/odvJng-aws-glue-di-package-5.0.704.jar?X-Amz-Security-Token=FwoDYXdzEDwaDHJhgshbEymvrBmMXCKuATjk%2FR8LRwJs%2BUER19I0jHvu0weF4OtRa1sImgYkdEbq3oh3nZME62ZgyeyglOMbsWpAN2LtL7%2FDU614hwIrxjrhFkHHG%2FgoZtHrcjRoYlyyKC8G81wqSXQ16PBcQRIJ3qvu4G793hpbTgAGtb4spNbK%2FcSQi7SXmk9xKNeTt%2FFPsTUpmFwF0p2%2Fbj2Tem3TwNKd6r%2FXunDsNWwMdmcoU%2FCFjeyr%2Ftv9jLyM6djQxSjgprLHBjIfShX9SEFSPThemsaL%2BMVItiKddNj9yomjej7sqV8UCA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055128Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3ANFZN4LQ%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=f1ba5b6ea41dbeda4fb060f38eca6baf681cca9b233657e3af1502e62a6a7f38,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/004/Glue5.0/AwsGlueMLLibsPython/java17/5.0.382/yzED3c-AwsGlueMLLibs.py.zip?X-Amz-Security-Token=FwoDYXdzEDwaDHJhgshbEymvrBmMXCKuATjk%2FR8LRwJs%2BUER19I0jHvu0weF4OtRa1sImgYkdEbq3oh3nZME62ZgyeyglOMbsWpAN2LtL7%2FDU614hwIrxjrhFkHHG%2FgoZtHrcjRoYlyyKC8G81wqSXQ16PBcQRIJ3qvu4G793hpbTgAGtb4spNbK%2FcSQi7SXmk9xKNeTt%2FFPsTUpmFwF0p2%2Fbj2Tem3TwNKd6r%2FXunDsNWwMdmcoU%2FCFjeyr%2Ftv9jLyM6djQxSjgprLHBjIfShX9SEFSPThemsaL%2BMVItiKddNj9yomjej7sqV8UCA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055128Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3ANFZN4LQ%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=59f44729f31ec8ea6b6b785771e029a83cda8654bad4b6de9bc41679c3533d1a,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/004/Glue5.0/AwsGlueMLLibs/java17/5.0.382/ImuwKQ-AwsGlueMLLibs.jar?X-Amz-Security-Token=FwoDYXdzEDwaDHJhgshbEymvrBmMXCKuATjk%2FR8LRwJs%2BUER19I0jHvu0weF4OtRa1sImgYkdEbq3oh3nZME62ZgyeyglOMbsWpAN2LtL7%2FDU614hwIrxjrhFkHHG%2FgoZtHrcjRoYlyyKC8G81wqSXQ16PBcQRIJ3qvu4G793hpbTgAGtb4spNbK%2FcSQi7SXmk9xKNeTt%2FFPsTUpmFwF0p2%2Fbj2Tem3TwNKd6r%2FXunDsNWwMdmcoU%2FCFjeyr%2Ftv9jLyM6djQxSjgprLHBjIfShX9SEFSPThemsaL%2BMVItiKddNj9yomjej7sqV8UCA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251013T055128Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3ANFZN4LQ%2F20251013%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=f47941506ed1a43fd90a6df8606164297c675ee2863c8610c4345e14bd2d6d7f --config s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/config/maximo/dq/invuseline.yaml  --job_type data_quality --JOB_ID j_efa31fc869c8dee42e4d418a22ff814987235318d8124ea647e103b402305b1b --extra-py-files s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/mosaic.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/sqlglot.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/yaml.zip   --JOB_RUN_ID jr_6e4215beaae06c43035bb6f6ed52905fdcf5c47cfd64ff58e3bde585e98d8c35_attempt_3 --scriptLocation s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py  --tenant-internal glue --enable-auto-scaling true --JOB_NAME maximo_dq_invuseline
"
1760334697385,"openjdk version ""17.0.16"" 2025-07-15 LTS
OpenJDK Runtime Environment Corretto-17.0.16.8.1 (build 17.0.16+8-LTS)
"
1760334697385,"OpenJDK 64-Bit Server VM Corretto-17.0.16.8.1 (build 17.0.16+8-LTS, mixed mode, sharing)
"
1760334698537,"25/10/13 05:51:38 INFO GlueBootstrap: Glue Bootstrapping...
"
1760334698541,"25/10/13 05:51:38 INFO GlueBootstrap: Glue Bootstrapping the driver...
"
1760334698566,"25/10/13 05:51:38 INFO GlueBootstrap: Downloading Glue libs...
"
1760334698578,"25/10/13 05:51:38 INFO GlueBootstrap: Downloading customer supplied extra files...
"
1760334698674,"25/10/13 05:51:38 WARN VersionInfoUtils: The AWS SDK for Java 1.x entered maintenance mode starting July 31, 2024 and will reach end of support on December 31, 2025. For more information, see https://aws.amazon.com/blogs/developer/the-aws-sdk-for-java-1-x-is-in-maintenance-mode-effective-july-31-2024/
You can print where on the file system the AWS SDK for Java 1.x core runtime is located by setting the AWS_JAVA_V1_PRINT_LOCATION environment variable or aws.java.v1.printLocation system property to 'true'.
This message can be disabled by setting the AWS_JAVA_V1_DISABLE_DEPRECATION_ANNOUNCEMENT environment variable or aws.java.v1.disableDeprecationAnnouncement system property to 'true'.
The AWS SDK for Java 1.x is being used here:
at java.base/java.lang.Thread.getStackTrace(Thread.java:1619)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.printDeprecationAnnouncement(VersionInfoUtils.java:81)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.<clinit>(VersionInfoUtils.java:59)
at glue.shaded.com.amazonaws.internal.EC2ResourceFetcher.<clinit>(EC2ResourceFetcher.java:44)
at glue.shaded.com.amazonaws.auth.InstanceMetadataServiceCredentialsFetcher.<init>(InstanceMetadataServiceCredentialsFetcher.java:38)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:111)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:91)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:75)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<clinit>(InstanceProfileCredentialsProvider.java:58)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.initializeProvider(EC2ContainerCredentialsProviderWrapper.java:66)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.<init>(EC2ContainerCredentialsProviderWrapper.java:55)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<init>(DefaultAWSCredentialsProviderChain.java:60)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<clinit>(DefaultAWSCredentialsProviderChain.java:54)
at glue.shaded.com.amazonaws.services.s3.AmazonS3ClientBuilder.standard(AmazonS3ClientBuilder.java:46)
at glue.shaded.com.amazonaws.services.s3.AmazonS3Client.builder(AmazonS3Client.java:740)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.getS3Client(GlueLibsDownloader.java:289)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.build(GlueLibsDownloader.java:281)
at com.amazonaws.services.glue.GlueBootstrap.downloadGlueLibs(GlueBootstrap.java:373)
at com.amazonaws.services.glue.GlueBootstrap.lambda$setUpGlueAndUserLibs$1(GlueBootstrap.java:124)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
at java.base/java.lang.Thread.run(Thread.java:840)
"
1760334700410,"25/10/13 05:51:40 INFO GlueLibsDownloader: Elapsed time: 884 millis
"
1760334700811,"25/10/13 05:51:40 INFO GlueLibsDownloader: Elapsed time: 1289 millis
"
1760334701012,"1760334701009
"
1760334701865,"INFO	2025-10-13T05:51:41,864	4450	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	25	Setting Up Virtual Env and Application/Customer Provided Python Modules started in async mode
"
1760334701869,"INFO	2025-10-13T05:51:41,869	4455	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute python3.11 -m venv --clear /tmp/glue_venv
"
1760334701878,"INFO	2025-10-13T05:51:41,878	4464	com.amazonaws.services.glue.launch.helpers.PrepareLaunchProperties	[main]	89	Get job script: raw_dq_load.py.
"
1760334701922,"INFO	2025-10-13T05:51:41,921	4507	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	99	
proxy {
  host = null
  port = -1
}
"
1760334701928,"INFO	2025-10-13T05:51:41,927	4513	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
"
1760334702141,"INFO	2025-10-13T05:51:42,140	4726	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
"
1760334702173,"INFO	2025-10-13T05:51:42,172	4758	com.amazonaws.services.glue.utils.AWSClientUtils$	[main]	98	AWSClientUtils: create aws sts client with conf: proxy hostnull, proxy port 0
"
1760334702763,"INFO	2025-10-13T05:51:42,762	5348	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	113	optimizeParallelismConfigs started 
"
1760334702768,"INFO	2025-10-13T05:51:42,768	5354	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	59	glue.etl.telemetry.runtimeImproveFeature.autoscaling, jr_6e4215beaae06c43035bb6f6ed52905fdcf5c47cfd64ff58e3bde585e98d8c35_attempt_3
"
1760334702769,"INFO	2025-10-13T05:51:42,769	5355	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	31	setupLoggerProperties...
"
1760334702772,"WARN	2025-10-13T05:51:42,771	5357	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	60	Logger setup failed for exception analysis: Cannot invoke ""java.net.URL.toURI()"" because the return value of ""java.lang.Class.getResource(String)"" is null
"
1760334702775,"INFO	2025-10-13T05:51:42,775	5361	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading /tmp/glue-13706448924914820478log4j2.properties file to destination location: /tmp/glue-job-4545763110303658273/glue-13706448924914820478log4j2.properties
"
1760334703087,"INFO	2025-10-13T05:51:43,086	5672	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	78	setting up the log4j.configurationFile=/tmp/glue-job-4545763110303658273/glue-13706448924914820478log4j2.properties
"
1760334703101,"INFO	2025-10-13T05:51:43,100	5686	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/aws_glue_connectors
"
1760334703101,"INFO	2025-10-13T05:51:43,101	5687	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/aws_glue_connectors/selected
"
1760334703101,"INFO	2025-10-13T05:51:43,101	5687	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/exception_catch
"
1760334703101,"INFO	2025-10-13T05:51:43,101	5687	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/amazon
"
1760334703102,"INFO	2025-10-13T05:51:43,101	5687	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/amazon/certs
"
1760334703106,"INFO	2025-10-13T05:51:43,102	5688	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/aws_glue_connectors/selected/native
INFO	2025-10-13T05:51:43,102	5688	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-4545763110303658273/aws_glue_connectors/marketplace
"
1760334703210,"INFO	2025-10-13T05:51:43,210	5796	com.amazonaws.services.glue.launch.helpers.ConnectionsManager	[main]	78	GLUE_CONNECTIVITY: attached connection types: ListBuffer()
"
1760334703459,"INFO	2025-10-13T05:51:43,459	6045	com.amazonaws.services.glue.PrepareLaunch	[main]	194	list of connectors to be added in classpath: List()
"
1760334703461,"INFO	2025-10-13T05:51:43,461	6047	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py file to destination location: /tmp/glue-job-4545763110303658273/raw_dq_load.py
"
1760334703632,"INFO	2025-10-13T05:51:43,631	6217	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	32	Encoding S3 URI s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
"
1760334703632,"INFO	2025-10-13T05:51:43,632	6218	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	37	Encoded S3 URI to s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
"
1760334703639,"INFO	2025-10-13T05:51:43,639	6225	com.amazonaws.services.glue.FileDownloader	[main]	138	Download bucket: entergy-govdatacore-dataeng-code-repo-dev key: entergy-gov-data-core-code/scripts/raw_dq_load.py to /tmp/glue-job-4545763110303658273/raw_dq_load.py with usingProxy: false and isProxyDisabled: true
"
1760334704584,"INFO	2025-10-13T05:51:44,584	7170	com.amazonaws.services.glue.launch.helpers.FileManager	[main]	119	Script should be downloaded at /tmp/glue-job-4545763110303658273/raw_dq_load.py 
"
1760334704584,"INFO	2025-10-13T05:51:44,584	7170	com.amazonaws.services.glue.FileDownloader	[sdk-async-response-2-0]	145	Object downloaded. Details: GetObjectResponse(AcceptRanges=bytes, LastModified=2025-10-10T16:51:03Z, ContentLength=453, ETag=""3f516bac98ff6f23cf7791a839a72cc0"", ContentType=binary/octet-stream, ServerSideEncryption=AES256, Metadata={})
"
1760334709525,"INFO	2025-10-13T05:51:49,525	12111	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-4545763110303658273/python/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip -d /tmp/glue-job-4545763110303658273/python/ufak9W-AWSGlueDataplanePython-5.0.704
"
1760334709562,"INFO	2025-10-13T05:51:49,562	12148	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-4545763110303658273/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-4545763110303658273/python/ufak9W-AWSGlueDataplanePython-5.0.704/amzn_awsgluelibs-5.0.704-py3-none-any.whl
"
1760334712207,"INFO	2025-10-13T05:51:52,207	14793	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-4545763110303658273/python/yzED3c-AwsGlueMLLibs.py.zip -d /tmp/glue-job-4545763110303658273/python/yzED3c-AwsGlueMLLibs
"
1760334712213,"INFO	2025-10-13T05:51:52,212	14798	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-4545763110303658273/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-4545763110303658273/python/yzED3c-AwsGlueMLLibs/amzn_awsgluemlpythonlibs-1.0-py3-none-any.whl
"
1760334718104,"INFO	2025-10-13T05:51:58,104	20690	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-4545763110303658273/pythonmodules/createvenvzip.sh /tmp/glue_venv /tmp/glue-job-4545763110303658273_glue_venv.zip
"
1760334718260,"INFO	2025-10-13T05:51:58,260	20846	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	39	Setting Up Virtual Env and Application Python Modules has been completed in async mode
"
1760334718268,"INFO	2025-10-13T05:51:58,268	20854	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	50	shutdownAsyncProcessing has been Started
"
1760334718269,"INFO	2025-10-13T05:51:58,269	20855	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	76	shutdownAsyncProcessing has been completed
"
1760334718634,"Launching ...
"
1760334718636,"Mon Oct 13 05:51:58 UTC 2025
"
1760334720732,"INFO	2025-10-13T05:52:00,729	2039	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
"
1760334721072,"INFO	2025-10-13T05:52:01,072	2382	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
"
1760334721254,"INFO	2025-10-13T05:52:01,254	2564	com.amazonaws.services.glue.SafeLogging	[main]	60	Initializing logging subsystem
"
1760334726318,"INFO	2025-10-13T05:52:06,317	7627	org.apache.spark.emr.EMRParamSideChannel	[Thread-7]	177	Setting FGAC mode to false
"
1760334726331,"INFO	2025-10-13T05:52:06,330	7640	org.apache.spark.SparkContext	[Thread-7]	60	Running Spark version 3.5.4-amzn-0
"
1760334726331,"INFO	2025-10-13T05:52:06,331	7641	org.apache.spark.SparkContext	[Thread-7]	60	OS info Linux, 5.10.240-238.966.amzn2.x86_64, amd64
"
1760334726332,"INFO	2025-10-13T05:52:06,332	7642	org.apache.spark.SparkContext	[Thread-7]	60	Java version 17.0.16
"
1760334726513,"INFO	2025-10-13T05:52:06,512	7822	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
"
1760334726513,"INFO	2025-10-13T05:52:06,513	7823	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	No custom resources configured for spark.driver.
"
1760334726514,"INFO	2025-10-13T05:52:06,513	7823	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
"
1760334726514,"INFO	2025-10-13T05:52:06,514	7824	org.apache.spark.SparkContext	[Thread-7]	60	Submitted application: maximo_dq_invuseline
"
1760334726544,"INFO	2025-10-13T05:52:06,543	7853	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Default ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
"
1760334726554,"INFO	2025-10-13T05:52:06,551	7861	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
"
1760334726557,"INFO	2025-10-13T05:52:06,556	7866	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 0
"
1760334726560,"INFO	2025-10-13T05:52:06,560	7870	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	User executor ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
"
1760334726561,"INFO	2025-10-13T05:52:06,560	7870	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
"
1760334726561,"INFO	2025-10-13T05:52:06,561	7871	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 1
"
1760334726635,"INFO	2025-10-13T05:52:06,635	7945	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls to: hadoop
"
1760334726636,"INFO	2025-10-13T05:52:06,636	7946	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls to: hadoop
"
1760334726636,"INFO	2025-10-13T05:52:06,636	7946	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls groups to: 
"
1760334726637,"INFO	2025-10-13T05:52:06,637	7947	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls groups to: 
"
1760334726637,"INFO	2025-10-13T05:52:06,637	7947	org.apache.spark.SecurityManager	[Thread-7]	60	SecurityManager: authentication enabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
"
1760334726943,"INFO	2025-10-13T05:52:06,942	8252	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'sparkDriver' on port 41007.
"
1760334726991,"INFO	2025-10-13T05:52:06,990	8300	org.apache.spark.SparkEnv	[Thread-7]	60	Registering MapOutputTracker
"
1760334727031,"INFO	2025-10-13T05:52:07,030	8340	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMaster
"
1760334727054,"INFO	2025-10-13T05:52:07,053	8363	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
"
1760334727054,"INFO	2025-10-13T05:52:07,054	8364	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	BlockManagerMasterEndpoint up
"
1760334727059,"INFO	2025-10-13T05:52:07,059	8369	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMasterHeartbeat
"
1760334727088,"INFO	2025-10-13T05:52:07,088	8398	org.apache.spark.storage.DiskBlockManager	[Thread-7]	60	Created local directory at /tmp/blockmgr-7e00db20-bcb0-4d45-8d37-cabf703cbe5c
"
1760334727107,"INFO	2025-10-13T05:52:07,107	8417	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	MemoryStore started with capacity 5.8 GiB
"
1760334727159,"INFO	2025-10-13T05:52:07,158	8468	org.apache.spark.SparkEnv	[Thread-7]	60	Registering OutputCommitCoordinator
"
1760334727165,"INFO	2025-10-13T05:52:07,165	8475	org.apache.spark.subresultcache.SubResultCacheManager	[Thread-7]	60	Sub-result caches are disabled.
"
1760334727226,"INFO	2025-10-13T05:52:07,225	8535	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-4545763110303658273/jars/ImuwKQ-AwsGlueMLLibs.jar at spark://172.35.202.190:41007/jars/ImuwKQ-AwsGlueMLLibs.jar with timestamp 1760334726319
"
1760334727227,"INFO	2025-10-13T05:52:07,227	8537	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-4545763110303658273/jars/odvJng-aws-glue-di-package-5.0.704.jar at spark://172.35.202.190:41007/jars/odvJng-aws-glue-di-package-5.0.704.jar with timestamp 1760334726319
"
1760334727389,"INFO	2025-10-13T05:52:07,389	8699	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-4545763110303658273/extra-py-files/sqlglot.zip at spark://172.35.202.190:41007/files/sqlglot.zip with timestamp 1760334726319
"
1760334727390,"INFO	2025-10-13T05:52:07,390	8700	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-4545763110303658273/extra-py-files/sqlglot.zip to /tmp/spark-d3c2de48-694d-42d2-aed3-82a2c5b5822d/userFiles-d251016e-4b53-42df-a238-62c0ce6fa84b/sqlglot.zip
"
1760334727402,"INFO	2025-10-13T05:52:07,402	8712	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-4545763110303658273/extra-py-files/mosaic.zip at spark://172.35.202.190:41007/files/mosaic.zip with timestamp 1760334726319
"
1760334727403,"INFO	2025-10-13T05:52:07,403	8713	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-4545763110303658273/extra-py-files/mosaic.zip to /tmp/spark-d3c2de48-694d-42d2-aed3-82a2c5b5822d/userFiles-d251016e-4b53-42df-a238-62c0ce6fa84b/mosaic.zip
"
1760334727408,"INFO	2025-10-13T05:52:07,408	8718	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-4545763110303658273/extra-py-files/yaml.zip at spark://172.35.202.190:41007/files/yaml.zip with timestamp 1760334726319
"
1760334727408,"INFO	2025-10-13T05:52:07,408	8718	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-4545763110303658273/extra-py-files/yaml.zip to /tmp/spark-d3c2de48-694d-42d2-aed3-82a2c5b5822d/userFiles-d251016e-4b53-42df-a238-62c0ce6fa84b/yaml.zip
"
1760334727451,"INFO	2025-10-13T05:52:07,451	8761	org.apache.spark.SparkContext	[Thread-7]	60	Added archive /tmp/glue-job-4545763110303658273_glue_venv.zip#python_environment at spark://172.35.202.190:41007/files/glue-job-4545763110303658273_glue_venv.zip with timestamp 1760334726319
"
1760334727452,"INFO	2025-10-13T05:52:07,452	8762	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-4545763110303658273_glue_venv.zip to /tmp/spark-d768328c-c5fd-414d-b03a-43b98c4f3acd/glue-job-4545763110303658273_glue_venv.zip
"
1760334727467,"INFO	2025-10-13T05:52:07,466	8776	org.apache.spark.SparkContext	[Thread-7]	60	Unpacking an archive /tmp/glue-job-4545763110303658273_glue_venv.zip#python_environment from /tmp/spark-d768328c-c5fd-414d-b03a-43b98c4f3acd/glue-job-4545763110303658273_glue_venv.zip to /tmp/spark-d3c2de48-694d-42d2-aed3-82a2c5b5822d/userFiles-d251016e-4b53-42df-a238-62c0ce6fa84b/python_environment
"
1760334727897,"INFO	2025-10-13T05:52:07,897	9207	org.apache.spark.scheduler.cluster.glue.JESClusterManager	[Thread-7]	121	Python path for executors: sqlglot.zip:mosaic.zip:yaml.zip:python_environment
"
1760334727916,"INFO	2025-10-13T05:52:07,900	9210	org.apache.spark.deploy.glue.client.GlueRMClientFactory	[Thread-7]	60	JESClusterManager: Initializing JES client with endpoint: https://glue-jes.us-gov-west-1.amazonaws.com
"
1760334728574,"INFO	2025-10-13T05:52:08,573	9883	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	JESSchedulerBackend
"
1760334728576,"INFO	2025-10-13T05:52:08,576	9886	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
"
1760334728617,"INFO	2025-10-13T05:52:08,616	9926	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Starting JES Scheduler Backend.
"
1760334728619,"INFO	2025-10-13T05:52:08,618	9928	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760334728619,"INFO	2025-10-13T05:52:08,619	9929	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Initial executors are 1
"
1760334728629,"INFO	2025-10-13T05:52:08,628	9938	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334728631,"INFO	2025-10-13T05:52:08,631	9941	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 1, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334728633,"INFO	2025-10-13T05:52:08,632	9942	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 1; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_1_a_spark-application-1760334728567_p_1
"
1760334728647,"INFO	2025-10-13T05:52:08,647	9957	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334728653,"INFO	2025-10-13T05:52:08,652	9962	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36949.
"
1760334728653,"INFO	2025-10-13T05:52:08,653	9963	org.apache.spark.network.netty.NettyBlockTransferService	[Thread-7]	88	Server created on 172.35.202.190:36949
"
1760334728656,"INFO	2025-10-13T05:52:08,655	9965	org.apache.spark.storage.BlockManager	[Thread-7]	60	Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
"
1760334728665,"INFO	2025-10-13T05:52:08,665	9975	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registering BlockManager BlockManagerId(driver, 172.35.202.190, 36949, None)
"
1760334728670,"INFO	2025-10-13T05:52:08,669	9979	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.202.190:36949 with 5.8 GiB RAM, BlockManagerId(driver, 172.35.202.190, 36949, None)
"
1760334728672,"INFO	2025-10-13T05:52:08,672	9982	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registered BlockManager BlockManagerId(driver, 172.35.202.190, 36949, None)
"
1760334728673,"INFO	2025-10-13T05:52:08,672	9982	org.apache.spark.storage.BlockManager	[Thread-7]	60	Initialized BlockManager: BlockManagerId(driver, 172.35.202.190, 36949, None)
"
1760334728873,"INFO	2025-10-13T05:52:08,873	10183	org.apache.spark.deploy.history.SingleEventLogFileWriter	[Thread-7]	60	Logging events to file:/var/log/spark/apps/spark-application-1760334728567.inprogress
"
1760334729047,"INFO	2025-10-13T05:52:09,047	10357	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
"
1760334729049,"INFO	2025-10-13T05:52:09,048	10358	org.apache.spark.ExecutorAllocationManager	[Thread-7]	60	Dynamic allocation is enabled without a shuffle service.
"
1760334729078,"INFO	2025-10-13T05:52:09,078	10388	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760334729079,"INFO	2025-10-13T05:52:09,078	10388	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Requested total executors are 1
"
1760334729130,"INFO	2025-10-13T05:52:09,130	10440	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[Thread-7]	51	Started file writer for com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter
"
1760334729140,"INFO	2025-10-13T05:52:09,140	10450	org.apache.spark.SparkContext	[Thread-7]	60	Registered listener com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener
"
1760334729180,"INFO	2025-10-13T05:52:09,180	10490	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	getDriverLogUrls Map()
"
1760334729184,"INFO	2025-10-13T05:52:09,184	10494	org.apache.spark.executor.ExecutorLogUrlHandler	[Thread-7]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
"
1760334729189,"INFO	2025-10-13T05:52:09,189	10499	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
"
1760334729358,"INFO	2025-10-13T05:52:09,358	10668	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334729359,"INFO	2025-10-13T05:52:09,359	10669	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-68906cdc20362d64dcb8c9312b662ce7834af3f6 created for executor 1 in resource profile 0
"
1760334729765,"INFO	2025-10-13T05:52:09,764	11074	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Setting hive.metastore.warehouse.dir ('/tmp/spark-warehouse') to the value of spark.sql.warehouse.dir.
"
1760334729769,"INFO	2025-10-13T05:52:09,768	11078	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Warehouse path is 'file:/home/hadoop/spark-warehouse'.
"
1760334732468,"INFO	2025-10-13T05:52:12,467	13777	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
"
1760334733303,"WARN	2025-10-13T05:52:13,302	14612	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
"
1760334733303,"INFO	2025-10-13T05:52:13,303	14613	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
"
1760334733417,"INFO	2025-10-13T05:52:13,417	14727	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-raw-dev/maximo_raw.db/invuseline/metadata/00062-237a3a9b-faae-4f18-9d45-3d92894779fd.metadata.json
"
1760334733881,"INFO	2025-10-13T05:52:13,881	15191	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_raw.invuseline
"
1760334733903,"INFO	2025-10-13T05:52:13,902	15212	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_raw.invuseline loaded Spark schema: StructType(StructField(invusenum,StringType,true),StructField(usetype,StringType,true),StructField(itemnum,StringType,true),StructField(itemsetid,StringType,true),StructField(tostoreloc,StringType,true),StructField(tositeid,StringType,true),StructField(quantity,DecimalType(15,2),true),StructField(fromconditioncode,StringType,true),StructField(orgid,StringType,true),StructField(requestnum,StringType,true),StructField(sendersysid,StringType,true),StructField(validated,DecimalType(38,10),true),StructField(financialperiod,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(toconditioncode,StringType,true),StructField(linetype,StringType,true),StructField(remark,StringType,true),StructField(tobin,StringType,true),StructField(tolot,StringType,true),StructField(fromstoreloc,StringType,true),StructField(enterby,StringType,true),StructField(siteid,StringType,true),StructField(invuselinenum,DecimalType(38,10),true),StructField(issueid,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(issueto,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(refwo,StringType,true),StructField(actualdate,TimestampType,true),StructField(conversion,DecimalType(19,6),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(ponum,StringType,true),StructField(porevisionnum,DecimalType(38,10),true),StructField(polinenum,DecimalType(38,10),true),StructField(positeid,StringType,true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(prsiteid,StringType,true),StructField(rotassetnum,StringType,true),StructField(fromlot,StringType,true),StructField(frombin,StringType,true),StructField(physcnt,DecimalType(15,2),true),StructField(physcntdate,TimestampType,true),StructField(split,DecimalType(38,10),true),StructField(newassetnum,StringType,true),StructField(returnagainstissue,DecimalType(38,10),true),StructField(toorgid,StringType,true),StructField(receiptscomplete,DecimalType(38,10),true),StructField(receivedqty,DecimalType(15,2),true),StructField(description,StringType,true),StructField(returnedqty,DecimalType(15,2),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(hasld,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(invpicklistnum,StringType,true),StructField(openqty,DecimalType(15,2),true),StructField(pickedqty,DecimalType(15,2),true),StructField(stagedqty,DecimalType(15,2),true),StructField(issuedqty,DecimalType(15,2),true),StructField(displayname,StringType,true),StructField(etraddress1,StringType,true),StructField(etraddressee,StringType,true),StructField(etraimmwr,DecimalType(38,10),true),StructField(etrbintype,StringType,true),StructField(etrchemctrlnum,StringType,true),StructField(etrcity,StringType,true),StructField(etrcommandpickqty,DecimalType(16,2),true),StructField(etrcountry,StringType,true),StructField(etrdropship,DecimalType(38,10),true),StructField(etrgeocode,StringType,true),StructField(etrissuereason,StringType,true),StructField(etrkit,DecimalType(38,10),true),StructField(etrorigtranstic,StringType,true),StructField(etrpartnum,StringType,true),StructField(etrpostalcode,StringType,true),StructField(etrrequiredby,TimestampType,true),StructField(etrreturnreason,StringType,true),StructField(etrserialnum,StringType,true),StructField(etrshippingnotes,StringType,true),StructField(etrshipto,StringType,true),StructField(etrstateprovince,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrtotaltax,DecimalType(16,2),true),StructField(etrtp,DecimalType(38,10),true),StructField(etrtracetype,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(etrvendor,StringType,true),StructField(shiptoattn,StringType,true),StructField(etrterm,DecimalType(38,10),true),StructField(plustype,StringType,true),StructField(rowstamp,StringType,true),StructField(etrdispcannibalized,StringType,true),StructField(etrdispcapspare,StringType,true),StructField(etrdispclean,StringType,true),StructField(etrdispdamage,StringType,true),StructField(etrdisplowcontrol,StringType,true),StructField(etrdispmark,StringType,true),StructField(etrdispnewitem,StringType,true),StructField(etrdispondemand,StringType,true),StructField(etrdisprepairreq,StringType,true),StructField(etrdispstorage,StringType,true),StructField(etrdisptrace,StringType,true),StructField(etrshipvendor,StringType,true),StructField(etrstagingbin,StringType,true),StructField(etrreturninvreserve,DecimalType(38,10),true),StructField(etractualexpirationdate,TimestampType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760334734711,"INFO	2025-10-13T05:52:14,710	16020	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
"
1760334734859,"WARN	2025-10-13T05:52:14,858	16168	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
"
1760334734859,"INFO	2025-10-13T05:52:14,859	16169	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
"
1760334734982,"INFO	2025-10-13T05:52:14,982	16292	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-dq-dev/maximo_dq.db/invuseline/metadata/00010-13405169-b972-46a7-8ae2-85e5cd5fea71.metadata.json
"
1760334735147,"INFO	2025-10-13T05:52:15,147	16457	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_dq.invuseline
"
1760334735150,"INFO	2025-10-13T05:52:15,150	16460	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.invuseline loaded Spark schema: StructType(StructField(invusenum,StringType,true),StructField(usetype,StringType,true),StructField(itemnum,StringType,true),StructField(itemsetid,StringType,true),StructField(tostoreloc,StringType,true),StructField(tositeid,StringType,true),StructField(quantity,DecimalType(15,2),true),StructField(fromconditioncode,StringType,true),StructField(orgid,StringType,true),StructField(requestnum,StringType,true),StructField(sendersysid,StringType,true),StructField(validated,DecimalType(38,10),true),StructField(financialperiod,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(toconditioncode,StringType,true),StructField(linetype,StringType,true),StructField(remark,StringType,true),StructField(tobin,StringType,true),StructField(tolot,StringType,true),StructField(fromstoreloc,StringType,true),StructField(enterby,StringType,true),StructField(siteid,StringType,true),StructField(invuselinenum,DecimalType(38,10),true),StructField(issueid,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(issueto,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(refwo,StringType,true),StructField(actualdate,TimestampType,true),StructField(conversion,DecimalType(19,6),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(ponum,StringType,true),StructField(porevisionnum,DecimalType(38,10),true),StructField(polinenum,DecimalType(38,10),true),StructField(positeid,StringType,true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(prsiteid,StringType,true),StructField(rotassetnum,StringType,true),StructField(fromlot,StringType,true),StructField(frombin,StringType,true),StructField(physcnt,DecimalType(15,2),true),StructField(physcntdate,TimestampType,true),StructField(split,DecimalType(38,10),true),StructField(newassetnum,StringType,true),StructField(returnagainstissue,DecimalType(38,10),true),StructField(toorgid,StringType,true),StructField(receiptscomplete,DecimalType(38,10),true),StructField(receivedqty,DecimalType(15,2),true),StructField(description,StringType,true),StructField(returnedqty,DecimalType(15,2),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(hasld,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(invpicklistnum,StringType,true),StructField(openqty,DecimalType(15,2),true),StructField(pickedqty,DecimalType(15,2),true),StructField(stagedqty,DecimalType(15,2),true),StructField(issuedqty,DecimalType(15,2),true),StructField(displayname,StringType,true),StructField(etraddress1,StringType,true),StructField(etraddressee,StringType,true),StructField(etraimmwr,DecimalType(38,10),true),StructField(etrbintype,StringType,true),StructField(etrchemctrlnum,StringType,true),StructField(etrcity,StringType,true),StructField(etrcommandpickqty,DecimalType(16,2),true),StructField(etrcountry,StringType,true),StructField(etrdropship,DecimalType(38,10),true),StructField(etrgeocode,StringType,true),StructField(etrissuereason,StringType,true),StructField(etrkit,DecimalType(38,10),true),StructField(etrorigtranstic,StringType,true),StructField(etrpartnum,StringType,true),StructField(etrpostalcode,StringType,true),StructField(etrrequiredby,TimestampType,true),StructField(etrreturnreason,StringType,true),StructField(etrserialnum,StringType,true),StructField(etrshippingnotes,StringType,true),StructField(etrshipto,StringType,true),StructField(etrstateprovince,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrtotaltax,DecimalType(16,2),true),StructField(etrtp,DecimalType(38,10),true),StructField(etrtracetype,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(etrvendor,StringType,true),StructField(shiptoattn,StringType,true),StructField(etrterm,DecimalType(38,10),true),StructField(plustype,StringType,true),StructField(rowstamp,StringType,true),StructField(etrdispcannibalized,StringType,true),StructField(etrdispcapspare,StringType,true),StructField(etrdispclean,StringType,true),StructField(etrdispdamage,StringType,true),StructField(etrdisplowcontrol,StringType,true),StructField(etrdispmark,StringType,true),StructField(etrdispnewitem,StringType,true),StructField(etrdispondemand,StringType,true),StructField(etrdisprepairreq,StringType,true),StructField(etrdispstorage,StringType,true),StructField(etrdisptrace,StringType,true),StructField(etrshipvendor,StringType,true),StructField(etrstagingbin,StringType,true),StructField(etrreturninvreserve,DecimalType(38,10),true),StructField(etractualexpirationdate,TimestampType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760334736868,"INFO	2025-10-13T05:52:16,868	18178	org.opensearch.hadoop.util.Version	[Thread-7]	143	OpenSearch Hadoop v1.2.0 [2a4148055f]
"
1760334737061,"INFO	2025-10-13T05:52:17,060	18370	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.invuseline loaded Spark schema: StructType(StructField(invusenum,StringType,true),StructField(usetype,StringType,true),StructField(itemnum,StringType,true),StructField(itemsetid,StringType,true),StructField(tostoreloc,StringType,true),StructField(tositeid,StringType,true),StructField(quantity,DecimalType(15,2),true),StructField(fromconditioncode,StringType,true),StructField(orgid,StringType,true),StructField(requestnum,StringType,true),StructField(sendersysid,StringType,true),StructField(validated,DecimalType(38,10),true),StructField(financialperiod,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(toconditioncode,StringType,true),StructField(linetype,StringType,true),StructField(remark,StringType,true),StructField(tobin,StringType,true),StructField(tolot,StringType,true),StructField(fromstoreloc,StringType,true),StructField(enterby,StringType,true),StructField(siteid,StringType,true),StructField(invuselinenum,DecimalType(38,10),true),StructField(issueid,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(issueto,StringType,true),StructField(gldebitacct,StringType,true),StructField(glcreditacct,StringType,true),StructField(refwo,StringType,true),StructField(actualdate,TimestampType,true),StructField(conversion,DecimalType(19,6),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(ponum,StringType,true),StructField(porevisionnum,DecimalType(38,10),true),StructField(polinenum,DecimalType(38,10),true),StructField(positeid,StringType,true),StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(prsiteid,StringType,true),StructField(rotassetnum,StringType,true),StructField(fromlot,StringType,true),StructField(frombin,StringType,true),StructField(physcnt,DecimalType(15,2),true),StructField(physcntdate,TimestampType,true),StructField(split,DecimalType(38,10),true),StructField(newassetnum,StringType,true),StructField(returnagainstissue,DecimalType(38,10),true),StructField(toorgid,StringType,true),StructField(receiptscomplete,DecimalType(38,10),true),StructField(receivedqty,DecimalType(15,2),true),StructField(description,StringType,true),StructField(returnedqty,DecimalType(15,2),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(invuselineid,DecimalType(38,10),true),StructField(hasld,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(invpicklistnum,StringType,true),StructField(openqty,DecimalType(15,2),true),StructField(pickedqty,DecimalType(15,2),true),StructField(stagedqty,DecimalType(15,2),true),StructField(issuedqty,DecimalType(15,2),true),StructField(displayname,StringType,true),StructField(etraddress1,StringType,true),StructField(etraddressee,StringType,true),StructField(etraimmwr,DecimalType(38,10),true),StructField(etrbintype,StringType,true),StructField(etrchemctrlnum,StringType,true),StructField(etrcity,StringType,true),StructField(etrcommandpickqty,DecimalType(16,2),true),StructField(etrcountry,StringType,true),StructField(etrdropship,DecimalType(38,10),true),StructField(etrgeocode,StringType,true),StructField(etrissuereason,StringType,true),StructField(etrkit,DecimalType(38,10),true),StructField(etrorigtranstic,StringType,true),StructField(etrpartnum,StringType,true),StructField(etrpostalcode,StringType,true),StructField(etrrequiredby,TimestampType,true),StructField(etrreturnreason,StringType,true),StructField(etrserialnum,StringType,true),StructField(etrshippingnotes,StringType,true),StructField(etrshipto,StringType,true),StructField(etrstateprovince,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrtotaltax,DecimalType(16,2),true),StructField(etrtp,DecimalType(38,10),true),StructField(etrtracetype,StringType,true),StructField(etrusetaxcode,StringType,true),StructField(etrvendor,StringType,true),StructField(shiptoattn,StringType,true),StructField(etrterm,DecimalType(38,10),true),StructField(plustype,StringType,true),StructField(rowstamp,StringType,true),StructField(etrdispcannibalized,StringType,true),StructField(etrdispcapspare,StringType,true),StructField(etrdispclean,StringType,true),StructField(etrdispdamage,StringType,true),StructField(etrdisplowcontrol,StringType,true),StructField(etrdispmark,StringType,true),StructField(etrdispnewitem,StringType,true),StructField(etrdispondemand,StringType,true),StructField(etrdisprepairreq,StringType,true),StructField(etrdispstorage,StringType,true),StructField(etrdisptrace,StringType,true),StructField(etrshipvendor,StringType,true),StructField(etrstagingbin,StringType,true),StructField(etrreturninvreserve,DecimalType(38,10),true),StructField(etractualexpirationdate,TimestampType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
"
1760334737099,"WARN	2025-10-13T05:52:17,098	18408	org.apache.spark.sql.catalyst.util.SparkStringUtils	[Thread-7]	72	Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
"
1760334737569,"INFO	2025-10-13T05:52:17,568	18878	org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown	[Thread-7]	60	
Output: invusenum#0, usetype#1, itemnum#2, itemsetid#3, tostoreloc#4, tositeid#5, quantity#6, fromconditioncode#7, orgid#8, requestnum#9, sendersysid#10, validated#11, financialperiod#12, enteredastask#13, toconditioncode#14, linetype#15, remark#16, tobin#17, tolot#18, fromstoreloc#19, enterby#20, siteid#21, invuselinenum#22, issueid#23, assetnum#24, location#25, issueto#26, gldebitacct#27, glcreditacct#28, refwo#29, actualdate#30, conversion#31, unitcost#32, linecost#33, commoditygroup#34, commodity#35, ponum#36, porevisionnum#37, polinenum#38, positeid#39, mrnum#40, mrlinenum#41, prsiteid#42, rotassetnum#43, fromlot#44, frombin#45, physcnt#46, physcntdate#47, split#48, newassetnum#49, returnagainstissue#50, toorgid#51, receiptscomplete#52, receivedqty#53, description#54, returnedqty#55, inspectionrequired#56, invuselineid#57, hasld#58, langcode#59, invpicklistnum#60, openqty#61, pickedqty#62, stagedqty#63, issuedqty#64, displayname#65, etraddress1#66, etraddressee#67, etraimmwr#68, etrbintype#69, etrchemctrlnum#70, etrcity#71, etrcommandpickqty#72, etrcountry#73, etrdropship#74, etrgeocode#75, etrissuereason#76, etrkit#77, etrorigtranstic#78, etrpartnum#79, etrpostalcode#80, etrrequiredby#81, etrreturnreason#82, etrserialnum#83, etrshippingnotes#84, etrshipto#85, etrstateprovince#86, etrtdwonum#87, etrtotaltax#88, etrtp#89, etrtracetype#90, etrusetaxcode#91, etrvendor#92, shiptoattn#93, etrterm#94, plustype#95, rowstamp#96, etrdispcannibalized#97, etrdispcapspare#98, etrdispclean#99, etrdispdamage#100, etrdisplowcontrol#101, etrdispmark#102, etrdispnewitem#103, etrdispondemand#104, etrdisprepairreq#105, etrdispstorage#106, etrdisptrace#107, etrshipvendor#108, etrstagingbin#109, etrreturninvreserve#110, etractualexpirationdate#111, pk_hash#112, edl_load_date#113
        
"
1760334737578,"INFO	2025-10-13T05:52:17,577	18887	org.apache.iceberg.SnapshotScan	[Thread-7]	124	Scanning table glue_catalog.maximo_raw.invuseline snapshot 2712825793381406464 created at 2025-10-13T05:15:07.706+00:00 with filter true
"
1760334737881,"INFO	2025-10-13T05:52:17,881	19191	org.apache.iceberg.BaseDistributedDataScan	[Thread-7]	278	Planning file tasks locally for table glue_catalog.maximo_raw.invuseline
"
1760334738632,"INFO	2025-10-13T05:52:18,631	19941	org.apache.iceberg.spark.source.SparkPartitioningAwareScan	[Thread-7]	119	Reporting UnknownPartitioning with 590 partition(s) for table glue_catalog.maximo_raw.invuseline
"
1760334738668,"INFO	2025-10-13T05:52:18,668	19978	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	157	Requesting 0 bytes advisory partition size for table glue_catalog.maximo_dq.invuseline
"
1760334738668,"INFO	2025-10-13T05:52:18,668	19978	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	138	Requesting UnspecifiedDistribution as write distribution for table glue_catalog.maximo_dq.invuseline
"
1760334738670,"INFO	2025-10-13T05:52:18,670	19980	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	150	Requesting [] as write ordering for table glue_catalog.maximo_dq.invuseline
"
1760334738952,"INFO	2025-10-13T05:52:18,952	20262	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334738973,"INFO	2025-10-13T05:52:18,973	20283	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334738978,"INFO	2025-10-13T05:52:18,977	20287	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334738992,"INFO	2025-10-13T05:52:18,992	20302	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334738999,"INFO	2025-10-13T05:52:18,999	20309	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334739005,"INFO	2025-10-13T05:52:19,005	20315	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334739006,"INFO	2025-10-13T05:52:19,006	20316	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
"
1760334739082,"INFO	2025-10-13T05:52:19,082	20392	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 5.8 GiB)
"
1760334739154,"INFO	2025-10-13T05:52:19,154	20464	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.8 KiB, actual size: 4.8 KiB, free 5.8 GiB)
"
1760334739156,"INFO	2025-10-13T05:52:19,156	20466	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_0_piece0 in memory on 172.35.202.190:36949 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334739160,"INFO	2025-10-13T05:52:19,160	20470	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 0 from broadcast at SparkBatch.java:85
"
1760334739497,"INFO	2025-10-13T05:52:19,496	20806	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1 stored as values in memory (estimated size 32.0 KiB, free 5.8 GiB)
"
1760334739500,"INFO	2025-10-13T05:52:19,500	20810	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KiB, actual size: 4.8 KiB, free 5.8 GiB)
"
1760334739501,"INFO	2025-10-13T05:52:19,501	20811	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.202.190:36949 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334739505,"INFO	2025-10-13T05:52:19,505	20815	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 1 from broadcast at SparkBatch.java:85
"
1760334739730,"INFO	2025-10-13T05:52:19,729	21039	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Registering RDD 5 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
"
1760334739735,"INFO	2025-10-13T05:52:19,734	21044	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Got map stage job 0 (save at NativeMethodAccessorImpl.java:0) with 590 output partitions
"
1760334739735,"INFO	2025-10-13T05:52:19,735	21045	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Final stage: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0)
"
1760334739736,"INFO	2025-10-13T05:52:19,735	21045	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Parents of final stage: List()
"
1760334739737,"INFO	2025-10-13T05:52:19,737	21047	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Missing parents: List()
"
1760334739752,"INFO	2025-10-13T05:52:19,751	21061	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
"
1760334739933,"INFO	2025-10-13T05:52:19,932	21242	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2 stored as values in memory (estimated size 39.4 KiB, free 5.8 GiB)
"
1760334739937,"INFO	2025-10-13T05:52:19,937	21247	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.6 KiB, actual size: 16.6 KiB, free 5.8 GiB)
"
1760334739938,"INFO	2025-10-13T05:52:19,938	21248	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.202.190:36949 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334739939,"INFO	2025-10-13T05:52:19,939	21249	org.apache.spark.SparkContext	[dag-scheduler-event-loop]	60	Created broadcast 2 from broadcast at DAGScheduler.scala:1664
"
1760334739961,"INFO	2025-10-13T05:52:19,960	21270	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting 590 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
"
1760334739962,"INFO	2025-10-13T05:52:19,962	21272	org.apache.spark.scheduler.TaskSchedulerImpl	[dag-scheduler-event-loop]	60	Adding task set 0.0 with 590 tasks resource profile 0
"
1760334749636,"INFO	2025-10-13T05:52:29,636	30946	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.30.152:52056) with ID 1,  ResourceProfileId 0
"
1760334749637,"INFO	2025-10-13T05:52:29,637	30947	org.apache.spark.executor.ExecutorLogUrlHandler	[dispatcher-CoarseGrainedScheduler]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
"
1760334749638,"INFO	2025-10-13T05:52:29,638	30948	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 1 @ 1760334749637
"
1760334749639,"INFO	2025-10-13T05:52:29,638	30948	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 1
"
1760334749642,"INFO	2025-10-13T05:52:29,642	30952	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 1 has registered (new total is 1)
"
1760334749719,"INFO	2025-10-13T05:52:29,719	31029	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.30.152:38317 with 5.8 GiB RAM, BlockManagerId(1, 172.35.30.152, 38317, None)
"
1760334751014,"INFO	2025-10-13T05:52:31,014	32324	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 0.0 in stage 0.0 (TID 0) (172.35.30.152, executor 1, partition 0, PROCESS_LOCAL, 44965 bytes) 
"
1760334751020,"INFO	2025-10-13T05:52:31,019	32329	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 1.0 in stage 0.0 (TID 1) (172.35.30.152, executor 1, partition 1, PROCESS_LOCAL, 44965 bytes) 
"
1760334752214,"INFO	2025-10-13T05:52:32,214	33524	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.30.152:38317 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334754119,"INFO	2025-10-13T05:52:34,119	35429	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.30.152:38317 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334769883,"INFO	2025-10-13T05:52:49,882	51192	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
"
1760334769883,"INFO	2025-10-13T05:52:49,883	51193	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
"
1760334769884,"INFO	2025-10-13T05:52:49,884	51194	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 1 new executor because tasks are backlogged (new desired total will be 2 for resource profile id: 0)
"
1760334770369,"INFO	2025-10-13T05:52:50,368	51678	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334770369,"INFO	2025-10-13T05:52:50,369	51679	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 2, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334770369,"INFO	2025-10-13T05:52:50,369	51679	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 2; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_2_a_spark-application-1760334728567_p_1
"
1760334770370,"INFO	2025-10-13T05:52:50,369	51679	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334770526,"INFO	2025-10-13T05:52:50,525	51835	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334770526,"INFO	2025-10-13T05:52:50,525	51835	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-d5c56e216df1b75b022ee14e28947941d997c9cb created for executor 2 in resource profile 0
"
1760334777001,"INFO	2025-10-13T05:52:56,998	58308	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 2.0 in stage 0.0 (TID 2) (172.35.30.152, executor 1, partition 2, PROCESS_LOCAL, 44723 bytes) 
"
1760334777007,"INFO	2025-10-13T05:52:57,007	58317	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 1.0 in stage 0.0 (TID 1) in 25988 ms on 172.35.30.152 (executor 1) (1/590)
"
1760334777022,"INFO	2025-10-13T05:52:57,022	58332	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 3.0 in stage 0.0 (TID 3) (172.35.30.152, executor 1, partition 3, PROCESS_LOCAL, 44106 bytes) 
"
1760334777023,"INFO	2025-10-13T05:52:57,023	58333	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 0.0 in stage 0.0 (TID 0) in 26033 ms on 172.35.30.152 (executor 1) (2/590)
"
1760334779899,"INFO	2025-10-13T05:52:59,898	61208	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 4
"
1760334779899,"INFO	2025-10-13T05:52:59,899	61209	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 4
"
1760334779899,"INFO	2025-10-13T05:52:59,899	61209	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 2 new executors because tasks are backlogged (new desired total will be 4 for resource profile id: 0)
"
1760334780528,"INFO	2025-10-13T05:53:00,528	61838	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334780529,"INFO	2025-10-13T05:53:00,528	61838	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 3, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334780529,"INFO	2025-10-13T05:53:00,529	61839	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 3; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_3_a_spark-application-1760334728567_p_1
"
1760334780529,"INFO	2025-10-13T05:53:00,529	61839	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334780713,"INFO	2025-10-13T05:53:00,713	62023	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334780714,"INFO	2025-10-13T05:53:00,713	62023	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-33c47aa9d8016fd6468b3661d447c645ea4b6547 created for executor 3 in resource profile 0
"
1760334780714,"INFO	2025-10-13T05:53:00,713	62023	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334780714,"INFO	2025-10-13T05:53:00,714	62024	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 4, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334780714,"INFO	2025-10-13T05:53:00,714	62024	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 4; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_4_a_spark-application-1760334728567_p_1
"
1760334780714,"INFO	2025-10-13T05:53:00,714	62024	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334780858,"INFO	2025-10-13T05:53:00,858	62168	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334780858,"INFO	2025-10-13T05:53:00,858	62168	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-2d132207b6473f359c713a3f5353e290cf9449f4 created for executor 4 in resource profile 0
"
1760334786193,"INFO	2025-10-13T05:53:06,193	67503	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.158.2:37454) with ID 2,  ResourceProfileId 0
"
1760334786194,"INFO	2025-10-13T05:53:06,194	67504	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 2 @ 1760334786194
INFO	2025-10-13T05:53:06,194	67504	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 2
INFO	2025-10-13T05:53:06,194	67504	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 2 has registered (new total is 2)
"
1760334786301,"INFO	2025-10-13T05:53:06,301	67611	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.158.2:34481 with 5.8 GiB RAM, BlockManagerId(2, 172.34.158.2, 34481, None)
"
1760334787650,"INFO	2025-10-13T05:53:07,649	68959	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 4.0 in stage 0.0 (TID 4) (172.34.158.2, executor 2, partition 4, PROCESS_LOCAL, 31635 bytes) 
"
1760334787651,"INFO	2025-10-13T05:53:07,651	68961	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 5.0 in stage 0.0 (TID 5) (172.34.158.2, executor 2, partition 5, PROCESS_LOCAL, 31038 bytes) 
"
1760334788548,"INFO	2025-10-13T05:53:08,547	69857	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 6.0 in stage 0.0 (TID 6) (172.35.30.152, executor 1, partition 6, PROCESS_LOCAL, 31038 bytes) 
"
1760334788549,"INFO	2025-10-13T05:53:08,549	69859	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 2.0 in stage 0.0 (TID 2) in 11553 ms on 172.35.30.152 (executor 1) (3/590)
"
1760334788620,"INFO	2025-10-13T05:53:08,620	69930	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334788621,"INFO	2025-10-13T05:53:08,620	69930	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 4 executor task status
"
1760334788621,"INFO	2025-10-13T05:53:08,621	69931	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling 2 pending JES executor tasks for status
"
1760334788623,"INFO	2025-10-13T05:53:08,623	69933	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-2d132207b6473f359c713a3f5353e290cf9449f4
"
1760334788664,"INFO	2025-10-13T05:53:08,664	69974	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 4 g-2d132207b6473f359c713a3f5353e290cf9449f4 status is PENDING_EXECUTION
"
1760334788665,"INFO	2025-10-13T05:53:08,664	69974	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorStatus-poller]	60	getting status for executor task g-33c47aa9d8016fd6468b3661d447c645ea4b6547
"
1760334788690,"INFO	2025-10-13T05:53:08,690	70000	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	executor 3 g-33c47aa9d8016fd6468b3661d447c645ea4b6547 status is PENDING_EXECUTION
"
1760334788787,"INFO	2025-10-13T05:53:08,787	70097	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.158.2:34481 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334789915,"INFO	2025-10-13T05:53:09,915	71225	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 8
"
1760334789915,"INFO	2025-10-13T05:53:09,915	71225	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 8
"
1760334789915,"INFO	2025-10-13T05:53:09,915	71225	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 4 new executors because tasks are backlogged (new desired total will be 8 for resource profile id: 0)
"
1760334790561,"INFO	2025-10-13T05:53:10,560	71870	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 7.0 in stage 0.0 (TID 7) (172.35.30.152, executor 1, partition 7, PROCESS_LOCAL, 31038 bytes) 
"
1760334790562,"INFO	2025-10-13T05:53:10,561	71871	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 3.0 in stage 0.0 (TID 3) in 13541 ms on 172.35.30.152 (executor 1) (4/590)
"
1760334790625,"INFO	2025-10-13T05:53:10,625	71935	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.158.2:34481 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334790861,"INFO	2025-10-13T05:53:10,860	72170	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334790861,"INFO	2025-10-13T05:53:10,861	72171	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 5, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334790861,"INFO	2025-10-13T05:53:10,861	72171	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 5; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_5_a_spark-application-1760334728567_p_1
"
1760334790862,"INFO	2025-10-13T05:53:10,861	72171	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334791031,"INFO	2025-10-13T05:53:11,030	72340	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334791031,"INFO	2025-10-13T05:53:11,031	72341	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-fbe7418c6d59a10ca09d1288c545a905e2e9f845 created for executor 5 in resource profile 0
"
1760334791031,"INFO	2025-10-13T05:53:11,031	72341	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334791032,"INFO	2025-10-13T05:53:11,031	72341	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 6, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334791032,"INFO	2025-10-13T05:53:11,032	72342	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 6; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_6_a_spark-application-1760334728567_p_1
"
1760334791033,"INFO	2025-10-13T05:53:11,032	72342	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334791192,"INFO	2025-10-13T05:53:11,192	72502	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334791193,"INFO	2025-10-13T05:53:11,192	72502	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-69a907576edf66995eb7f7c96eae88c1dcbed443 created for executor 6 in resource profile 0
INFO	2025-10-13T05:53:11,192	72502	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
INFO	2025-10-13T05:53:11,192	72502	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 7, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-13T05:53:11,193	72503	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 7; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_7_a_spark-application-1760334728567_p_1
INFO	2025-10-13T05:53:11,193	72503	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334791345,"INFO	2025-10-13T05:53:11,345	72655	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334791346,"INFO	2025-10-13T05:53:11,345	72655	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-6f0d93b5303bf256e20a7e0d376bd4cb38571854 created for executor 7 in resource profile 0
INFO	2025-10-13T05:53:11,345	72655	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334791346,"INFO	2025-10-13T05:53:11,346	72656	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 8, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334791346,"INFO	2025-10-13T05:53:11,346	72656	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 8; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_8_a_spark-application-1760334728567_p_1
"
1760334791347,"INFO	2025-10-13T05:53:11,346	72656	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334791502,"INFO	2025-10-13T05:53:11,501	72811	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334791502,"INFO	2025-10-13T05:53:11,502	72812	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-aa16e079f601fb8a5cc7fc108cfa72051052529e created for executor 8 in resource profile 0
"
1760334799928,"INFO	2025-10-13T05:53:19,928	81238	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 16
"
1760334799928,"INFO	2025-10-13T05:53:19,928	81238	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 16
"
1760334799928,"INFO	2025-10-13T05:53:19,928	81238	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 8 new executors because tasks are backlogged (new desired total will be 16 for resource profile id: 0)
"
1760334800465,"INFO	2025-10-13T05:53:20,464	81774	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.116.46:50318) with ID 4,  ResourceProfileId 0
"
1760334800465,"INFO	2025-10-13T05:53:20,465	81775	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 4 @ 1760334800465
INFO	2025-10-13T05:53:20,465	81775	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 4 has registered (new total is 3)
INFO	2025-10-13T05:53:20,465	81775	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 4
"
1760334800504,"INFO	2025-10-13T05:53:20,504	81814	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334800504,"INFO	2025-10-13T05:53:20,504	81814	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 9, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334800505,"INFO	2025-10-13T05:53:20,504	81814	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 9; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_9_a_spark-application-1760334728567_p_1
"
1760334800505,"INFO	2025-10-13T05:53:20,505	81815	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334800539,"INFO	2025-10-13T05:53:20,539	81849	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.116.46:45957 with 5.8 GiB RAM, BlockManagerId(4, 172.35.116.46, 45957, None)
"
1760334800651,"INFO	2025-10-13T05:53:20,651	81961	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334800653,"INFO	2025-10-13T05:53:20,651	81961	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-d19f2db6eff55aa52843fc38bf22d56c60ba39a0 created for executor 9 in resource profile 0
INFO	2025-10-13T05:53:20,651	81961	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
INFO	2025-10-13T05:53:20,651	81961	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 10, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-13T05:53:20,651	81961	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 10; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_10_a_spark-application-1760334728567_p_1
INFO	2025-10-13T05:53:20,652	81962	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334800811,"INFO	2025-10-13T05:53:20,811	82121	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334800812,"INFO	2025-10-13T05:53:20,811	82121	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-608cb5cc6772d40cc407a9fee1e66da65b8e54a0 created for executor 10 in resource profile 0
"
1760334800812,"INFO	2025-10-13T05:53:20,811	82121	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334800812,"INFO	2025-10-13T05:53:20,812	82122	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 11, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334800812,"INFO	2025-10-13T05:53:20,812	82122	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 11; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_11_a_spark-application-1760334728567_p_1
"
1760334800812,"INFO	2025-10-13T05:53:20,812	82122	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334800954,"INFO	2025-10-13T05:53:20,953	82263	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334800954,"INFO	2025-10-13T05:53:20,954	82264	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-3fcab3492491997155a9b7e20847df9bf672286c created for executor 11 in resource profile 0
"
1760334800954,"INFO	2025-10-13T05:53:20,954	82264	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334800954,"INFO	2025-10-13T05:53:20,954	82264	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 12, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334800955,"INFO	2025-10-13T05:53:20,954	82264	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 12; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_12_a_spark-application-1760334728567_p_1
"
1760334800955,"INFO	2025-10-13T05:53:20,955	82265	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334801105,"INFO	2025-10-13T05:53:21,105	82415	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334801106,"INFO	2025-10-13T05:53:21,105	82415	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-d3496e78f396a6194ba7da2a5b8e5f436d2d3f3a created for executor 12 in resource profile 0
"
1760334801106,"INFO	2025-10-13T05:53:21,105	82415	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334801106,"INFO	2025-10-13T05:53:21,106	82416	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 13, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334801106,"INFO	2025-10-13T05:53:21,106	82416	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 13; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_13_a_spark-application-1760334728567_p_1
"
1760334801107,"INFO	2025-10-13T05:53:21,106	82416	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334801269,"INFO	2025-10-13T05:53:21,269	82579	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334801270,"INFO	2025-10-13T05:53:21,269	82579	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-b74f3f63d603384ad3c6c64fe64bcfc0d5398ec1 created for executor 13 in resource profile 0
"
1760334801270,"INFO	2025-10-13T05:53:21,270	82580	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334801270,"INFO	2025-10-13T05:53:21,270	82580	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 14, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334801270,"INFO	2025-10-13T05:53:21,270	82580	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 14; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_14_a_spark-application-1760334728567_p_1
"
1760334801270,"INFO	2025-10-13T05:53:21,270	82580	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334801423,"INFO	2025-10-13T05:53:21,423	82733	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334801423,"INFO	2025-10-13T05:53:21,423	82733	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-1a97468031ca44fa6a49455eeacac6a19710304f created for executor 14 in resource profile 0
"
1760334801424,"INFO	2025-10-13T05:53:21,423	82733	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334801424,"INFO	2025-10-13T05:53:21,424	82734	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 15, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334801424,"INFO	2025-10-13T05:53:21,424	82734	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 15; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_15_a_spark-application-1760334728567_p_1
"
1760334801424,"INFO	2025-10-13T05:53:21,424	82734	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334801562,"INFO	2025-10-13T05:53:21,561	82871	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334801562,"INFO	2025-10-13T05:53:21,561	82871	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-3ec1ea948e2ee46290922be260210a53454c3b20 created for executor 15 in resource profile 0
"
1760334801562,"INFO	2025-10-13T05:53:21,562	82872	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334801575,"INFO	2025-10-13T05:53:21,562	82872	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 16, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334801576,"INFO	2025-10-13T05:53:21,562	82872	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 16; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_16_a_spark-application-1760334728567_p_1
"
1760334801576,"INFO	2025-10-13T05:53:21,563	82873	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334801713,"INFO	2025-10-13T05:53:21,713	83023	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334801713,"INFO	2025-10-13T05:53:21,713	83023	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-17064a0a1cbfbc0c9267353153c5807027ae818a created for executor 16 in resource profile 0
"
1760334801726,"INFO	2025-10-13T05:53:21,726	83036	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 8.0 in stage 0.0 (TID 8) (172.35.116.46, executor 4, partition 8, PROCESS_LOCAL, 31038 bytes) 
"
1760334801727,"INFO	2025-10-13T05:53:21,727	83037	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 9.0 in stage 0.0 (TID 9) (172.35.116.46, executor 4, partition 9, PROCESS_LOCAL, 31038 bytes) 
"
1760334802936,"INFO	2025-10-13T05:53:22,936	84246	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.116.46:45957 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334803791,"INFO	2025-10-13T05:53:23,791	85101	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.230.30:44330) with ID 7,  ResourceProfileId 0
"
1760334803792,"INFO	2025-10-13T05:53:23,792	85102	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 7 @ 1760334803791
INFO	2025-10-13T05:53:23,792	85102	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 7 has registered (new total is 4)
"
1760334803792,"INFO	2025-10-13T05:53:23,792	85102	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 7
"
1760334803867,"INFO	2025-10-13T05:53:23,867	85177	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 10.0 in stage 0.0 (TID 10) (172.35.30.152, executor 1, partition 10, PROCESS_LOCAL, 31038 bytes) 
"
1760334803869,"INFO	2025-10-13T05:53:23,868	85178	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 6.0 in stage 0.0 (TID 6) in 15322 ms on 172.35.30.152 (executor 1) (5/590)
"
1760334803901,"INFO	2025-10-13T05:53:23,900	85210	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.230.30:40175 with 5.8 GiB RAM, BlockManagerId(7, 172.35.230.30, 40175, None)
"
1760334804407,"INFO	2025-10-13T05:53:24,407	85717	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.116.46:45957 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334805204,"INFO	2025-10-13T05:53:25,204	86514	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 11.0 in stage 0.0 (TID 11) (172.35.230.30, executor 7, partition 11, PROCESS_LOCAL, 31038 bytes) 
"
1760334805205,"INFO	2025-10-13T05:53:25,205	86515	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 12.0 in stage 0.0 (TID 12) (172.35.230.30, executor 7, partition 12, PROCESS_LOCAL, 30456 bytes) 
"
1760334805631,"INFO	2025-10-13T05:53:25,631	86941	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 13.0 in stage 0.0 (TID 13) (172.35.30.152, executor 1, partition 13, PROCESS_LOCAL, 30456 bytes) 
"
1760334805632,"INFO	2025-10-13T05:53:25,632	86942	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 7.0 in stage 0.0 (TID 7) in 15073 ms on 172.35.30.152 (executor 1) (6/590)
"
1760334806249,"INFO	2025-10-13T05:53:26,249	87559	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.230.30:40175 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334808136,"INFO	2025-10-13T05:53:28,135	89445	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.230.30:40175 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334808453,"INFO	2025-10-13T05:53:28,453	89763	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.115.9:33786) with ID 10,  ResourceProfileId 0
"
1760334808454,"INFO	2025-10-13T05:53:28,453	89763	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 10 @ 1760334808453
"
1760334808454,"INFO	2025-10-13T05:53:28,454	89764	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 10
"
1760334808454,"INFO	2025-10-13T05:53:28,454	89764	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 10 has registered (new total is 5)
"
1760334808522,"INFO	2025-10-13T05:53:28,521	89831	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.115.9:33135 with 5.8 GiB RAM, BlockManagerId(10, 172.35.115.9, 33135, None)
"
1760334809775,"INFO	2025-10-13T05:53:29,774	91084	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 14.0 in stage 0.0 (TID 14) (172.35.115.9, executor 10, partition 14, PROCESS_LOCAL, 30456 bytes) 
"
1760334809775,"INFO	2025-10-13T05:53:29,775	91085	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 15.0 in stage 0.0 (TID 15) (172.35.115.9, executor 10, partition 15, PROCESS_LOCAL, 30456 bytes) 
"
1760334809942,"INFO	2025-10-13T05:53:29,941	91251	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 20
"
1760334809942,"INFO	2025-10-13T05:53:29,942	91252	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 20
"
1760334809942,"INFO	2025-10-13T05:53:29,942	91252	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 4 new executors because tasks are backlogged (new desired total will be 20 for resource profile id: 0)
"
1760334810716,"INFO	2025-10-13T05:53:30,715	92025	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334810716,"INFO	2025-10-13T05:53:30,716	92026	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 17, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334810716,"INFO	2025-10-13T05:53:30,716	92026	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 17; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_17_a_spark-application-1760334728567_p_1
"
1760334810717,"INFO	2025-10-13T05:53:30,716	92026	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334810846,"INFO	2025-10-13T05:53:30,846	92156	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.115.9:33135 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334810866,"INFO	2025-10-13T05:53:30,866	92176	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334810866,"INFO	2025-10-13T05:53:30,866	92176	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-fa168fc945a0b99ff302ceb588cae58a28bc7f18 created for executor 17 in resource profile 0
"
1760334810867,"INFO	2025-10-13T05:53:30,867	92177	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334810867,"INFO	2025-10-13T05:53:30,867	92177	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 18, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334810867,"INFO	2025-10-13T05:53:30,867	92177	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 18; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_18_a_spark-application-1760334728567_p_1
"
1760334810868,"INFO	2025-10-13T05:53:30,867	92177	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334811035,"INFO	2025-10-13T05:53:31,034	92344	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334811035,"INFO	2025-10-13T05:53:31,035	92345	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-b3ba812a8d9ecccf382c86518791c1d3d02c8b7a created for executor 18 in resource profile 0
"
1760334811035,"INFO	2025-10-13T05:53:31,035	92345	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334811035,"INFO	2025-10-13T05:53:31,035	92345	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 19, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334811036,"INFO	2025-10-13T05:53:31,035	92345	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 19; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_19_a_spark-application-1760334728567_p_1
"
1760334811036,"INFO	2025-10-13T05:53:31,036	92346	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334811186,"INFO	2025-10-13T05:53:31,185	92495	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
"
1760334811186,"INFO	2025-10-13T05:53:31,186	92496	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-315dc814d6d5143d81e24fee099bfcf4cb6bbbd3 created for executor 19 in resource profile 0
"
1760334811186,"INFO	2025-10-13T05:53:31,186	92496	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334811186,"INFO	2025-10-13T05:53:31,186	92496	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 20, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334811187,"INFO	2025-10-13T05:53:31,186	92496	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 20; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_20_a_spark-application-1760334728567_p_1
"
1760334811187,"INFO	2025-10-13T05:53:31,187	92497	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334811224,"INFO	2025-10-13T05:53:31,224	92534	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334811226,"INFO	2025-10-13T05:53:31,226	92536	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 05b2d5b4-772b-4044-89e6-c16bd1558889)
"
1760334811226,"INFO	2025-10-13T05:53:31,226	92536	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 20 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334812740,"INFO	2025-10-13T05:53:32,739	94049	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.115.9:33135 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334813658,"INFO	2025-10-13T05:53:33,658	94968	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.34.68:44954) with ID 9,  ResourceProfileId 0
"
1760334813659,"INFO	2025-10-13T05:53:33,659	94969	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 9 has registered (new total is 6)
"
1760334813659,"INFO	2025-10-13T05:53:33,659	94969	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 9 @ 1760334813658
INFO	2025-10-13T05:53:33,659	94969	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 9
"
1760334813746,"INFO	2025-10-13T05:53:33,746	95056	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.34.68:40587 with 5.8 GiB RAM, BlockManagerId(9, 172.35.34.68, 40587, None)
"
1760334815103,"INFO	2025-10-13T05:53:35,102	96412	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 16.0 in stage 0.0 (TID 16) (172.35.34.68, executor 9, partition 16, PROCESS_LOCAL, 30456 bytes) 
"
1760334815103,"INFO	2025-10-13T05:53:35,103	96413	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 17.0 in stage 0.0 (TID 17) (172.35.34.68, executor 9, partition 17, PROCESS_LOCAL, 30456 bytes) 
"
1760334816143,"INFO	2025-10-13T05:53:36,143	97453	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.34.68:40587 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334816162,"INFO	2025-10-13T05:53:36,161	97471	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.145.94:45162) with ID 3,  ResourceProfileId 0
"
1760334816162,"INFO	2025-10-13T05:53:36,162	97472	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 3 @ 1760334816162
INFO	2025-10-13T05:53:36,162	97472	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 3
INFO	2025-10-13T05:53:36,162	97472	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 3 has registered (new total is 7)
"
1760334816236,"INFO	2025-10-13T05:53:36,236	97546	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.145.94:42691 with 5.8 GiB RAM, BlockManagerId(3, 172.34.145.94, 42691, None)
"
1760334817562,"INFO	2025-10-13T05:53:37,561	98871	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 18.0 in stage 0.0 (TID 18) (172.34.145.94, executor 3, partition 18, PROCESS_LOCAL, 30456 bytes) 
"
1760334817563,"INFO	2025-10-13T05:53:37,562	98872	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 19.0 in stage 0.0 (TID 19) (172.34.145.94, executor 3, partition 19, PROCESS_LOCAL, 30456 bytes) 
"
1760334818226,"INFO	2025-10-13T05:53:38,226	99536	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.34.68:40587 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334818444,"INFO	2025-10-13T05:53:38,444	99754	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 20.0 in stage 0.0 (TID 20) (172.35.30.152, executor 1, partition 20, PROCESS_LOCAL, 30456 bytes) 
"
1760334818445,"INFO	2025-10-13T05:53:38,445	99755	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 13.0 in stage 0.0 (TID 13) in 12815 ms on 172.35.30.152 (executor 1) (7/590)
"
1760334818472,"INFO	2025-10-13T05:53:38,472	99782	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.249.48:52594) with ID 17,  ResourceProfileId 0
"
1760334818473,"INFO	2025-10-13T05:53:38,472	99782	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 17 @ 1760334818472
"
1760334818473,"INFO	2025-10-13T05:53:38,473	99783	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 17
"
1760334818473,"INFO	2025-10-13T05:53:38,473	99783	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 17 has registered (new total is 8)
"
1760334818546,"INFO	2025-10-13T05:53:38,546	99856	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.249.48:40597 with 5.8 GiB RAM, BlockManagerId(17, 172.34.249.48, 40597, None)
"
1760334818659,"INFO	2025-10-13T05:53:38,659	99969	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.78.80:54056) with ID 12,  ResourceProfileId 0
"
1760334818660,"INFO	2025-10-13T05:53:38,660	99970	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 12 @ 1760334818659
"
1760334818660,"INFO	2025-10-13T05:53:38,660	99970	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 12
"
1760334818660,"INFO	2025-10-13T05:53:38,660	99970	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 12 has registered (new total is 9)
"
1760334818715,"INFO	2025-10-13T05:53:38,715	100025	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.145.94:42691 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334818750,"INFO	2025-10-13T05:53:38,750	100060	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.78.80:45713 with 5.8 GiB RAM, BlockManagerId(12, 172.34.78.80, 45713, None)
"
1760334818834,"INFO	2025-10-13T05:53:38,834	100144	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.233.198:50866) with ID 5,  ResourceProfileId 0
"
1760334818835,"INFO	2025-10-13T05:53:38,834	100144	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 5 @ 1760334818834
"
1760334818835,"INFO	2025-10-13T05:53:38,835	100145	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 5
"
1760334818835,"INFO	2025-10-13T05:53:38,835	100145	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 5 has registered (new total is 10)
"
1760334818920,"INFO	2025-10-13T05:53:38,920	100230	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.233.198:45305 with 5.8 GiB RAM, BlockManagerId(5, 172.34.233.198, 45305, None)
"
1760334818942,"INFO	2025-10-13T05:53:38,942	100252	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.53.249:43134) with ID 8,  ResourceProfileId 0
"
1760334818943,"INFO	2025-10-13T05:53:38,942	100252	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 8 @ 1760334818942
"
1760334818957,"INFO	2025-10-13T05:53:38,943	100253	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 8 has registered (new total is 11)
INFO	2025-10-13T05:53:38,943	100253	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 8
"
1760334819026,"INFO	2025-10-13T05:53:39,025	100335	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.53.249:42363 with 5.8 GiB RAM, BlockManagerId(8, 172.35.53.249, 42363, None)
"
1760334819432,"INFO	2025-10-13T05:53:39,432	100742	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.59.71:42386) with ID 19,  ResourceProfileId 0
"
1760334819433,"INFO	2025-10-13T05:53:39,432	100742	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 19 @ 1760334819432
"
1760334819433,"INFO	2025-10-13T05:53:39,432	100742	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 19 has registered (new total is 12)
"
1760334819433,"INFO	2025-10-13T05:53:39,433	100743	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 19
"
1760334819507,"INFO	2025-10-13T05:53:39,507	100817	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.59.71:32891 with 5.8 GiB RAM, BlockManagerId(19, 172.34.59.71, 32891, None)
"
1760334819909,"INFO	2025-10-13T05:53:39,908	101218	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 21.0 in stage 0.0 (TID 21) (172.34.249.48, executor 17, partition 21, PROCESS_LOCAL, 30456 bytes) 
"
1760334819910,"INFO	2025-10-13T05:53:39,909	101219	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 22.0 in stage 0.0 (TID 22) (172.34.249.48, executor 17, partition 22, PROCESS_LOCAL, 29292 bytes) 
"
1760334820023,"INFO	2025-10-13T05:53:40,023	101333	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 23.0 in stage 0.0 (TID 23) (172.34.78.80, executor 12, partition 23, PROCESS_LOCAL, 29316 bytes) 
"
1760334820024,"INFO	2025-10-13T05:53:40,024	101334	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 24.0 in stage 0.0 (TID 24) (172.34.78.80, executor 12, partition 24, PROCESS_LOCAL, 29316 bytes) 
"
1760334820189,"INFO	2025-10-13T05:53:40,189	101499	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 25.0 in stage 0.0 (TID 25) (172.34.233.198, executor 5, partition 25, PROCESS_LOCAL, 29316 bytes) 
"
1760334820190,"INFO	2025-10-13T05:53:40,190	101500	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 26.0 in stage 0.0 (TID 26) (172.34.233.198, executor 5, partition 26, PROCESS_LOCAL, 29316 bytes) 
"
1760334820251,"INFO	2025-10-13T05:53:40,250	101560	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 27.0 in stage 0.0 (TID 27) (172.35.30.152, executor 1, partition 27, PROCESS_LOCAL, 29316 bytes) 
"
1760334820252,"INFO	2025-10-13T05:53:40,251	101561	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 10.0 in stage 0.0 (TID 10) in 16384 ms on 172.35.30.152 (executor 1) (8/590)
"
1760334820316,"INFO	2025-10-13T05:53:40,316	101626	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 28.0 in stage 0.0 (TID 28) (172.35.53.249, executor 8, partition 28, PROCESS_LOCAL, 29316 bytes) 
"
1760334820317,"INFO	2025-10-13T05:53:40,317	101627	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 29.0 in stage 0.0 (TID 29) (172.35.53.249, executor 8, partition 29, PROCESS_LOCAL, 29316 bytes) 
"
1760334820568,"INFO	2025-10-13T05:53:40,567	101877	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.145.94:42691 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334820841,"INFO	2025-10-13T05:53:40,841	102151	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 30.0 in stage 0.0 (TID 30) (172.34.59.71, executor 19, partition 30, PROCESS_LOCAL, 29316 bytes) 
"
1760334820842,"INFO	2025-10-13T05:53:40,841	102151	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 31.0 in stage 0.0 (TID 31) (172.34.59.71, executor 19, partition 31, PROCESS_LOCAL, 29316 bytes) 
"
1760334820909,"INFO	2025-10-13T05:53:40,909	102219	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.249.48:40597 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334821123,"INFO	2025-10-13T05:53:41,123	102433	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.76.221:38866) with ID 11,  ResourceProfileId 0
"
1760334821124,"INFO	2025-10-13T05:53:41,123	102433	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 11 @ 1760334821123
"
1760334821124,"INFO	2025-10-13T05:53:41,123	102433	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 11
"
1760334821124,"INFO	2025-10-13T05:53:41,124	102434	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 11 has registered (new total is 13)
"
1760334821135,"INFO	2025-10-13T05:53:41,135	102445	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 32.0 in stage 0.0 (TID 32) (172.34.158.2, executor 2, partition 32, PROCESS_LOCAL, 29316 bytes) 
"
1760334821136,"INFO	2025-10-13T05:53:41,136	102446	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 5.0 in stage 0.0 (TID 5) in 33486 ms on 172.34.158.2 (executor 2) (9/590)
"
1760334821164,"INFO	2025-10-13T05:53:41,164	102474	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.78.80:45713 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334821215,"INFO	2025-10-13T05:53:41,215	102525	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.76.221:36173 with 5.8 GiB RAM, BlockManagerId(11, 172.34.76.221, 36173, None)
"
1760334821246,"INFO	2025-10-13T05:53:41,246	102556	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.53.249:42363 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334821444,"INFO	2025-10-13T05:53:41,444	102754	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.233.198:45305 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334821518,"INFO	2025-10-13T05:53:41,517	102827	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 33.0 in stage 0.0 (TID 33) (172.34.158.2, executor 2, partition 33, PROCESS_LOCAL, 29316 bytes) 
"
1760334821519,"INFO	2025-10-13T05:53:41,519	102829	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 4.0 in stage 0.0 (TID 4) in 33869 ms on 172.34.158.2 (executor 2) (10/590)
"
1760334821629,"INFO	2025-10-13T05:53:41,628	102938	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.117.91:52372) with ID 13,  ResourceProfileId 0
"
1760334821629,"INFO	2025-10-13T05:53:41,629	102939	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 13 @ 1760334821629
"
1760334821629,"INFO	2025-10-13T05:53:41,629	102939	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 13
"
1760334821630,"INFO	2025-10-13T05:53:41,629	102939	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 13 has registered (new total is 14)
"
1760334821701,"INFO	2025-10-13T05:53:41,701	103011	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.1.110:53806) with ID 14,  ResourceProfileId 0
"
1760334821702,"INFO	2025-10-13T05:53:41,702	103012	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 14 @ 1760334821701
"
1760334821702,"INFO	2025-10-13T05:53:41,702	103012	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 14 has registered (new total is 15)
INFO	2025-10-13T05:53:41,702	103012	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 14
"
1760334821707,"INFO	2025-10-13T05:53:41,707	103017	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.117.91:33289 with 5.8 GiB RAM, BlockManagerId(13, 172.34.117.91, 33289, None)
"
1760334821779,"INFO	2025-10-13T05:53:41,779	103089	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.1.110:46749 with 5.8 GiB RAM, BlockManagerId(14, 172.34.1.110, 46749, None)
"
1760334822033,"INFO	2025-10-13T05:53:42,032	103342	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.59.71:32891 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334822112,"INFO	2025-10-13T05:53:42,112	103422	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.247.5:56518) with ID 6,  ResourceProfileId 0
"
1760334822113,"INFO	2025-10-13T05:53:42,113	103423	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 6 has registered (new total is 16)
"
1760334822114,"INFO	2025-10-13T05:53:42,113	103423	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 6 @ 1760334822112
"
1760334822114,"INFO	2025-10-13T05:53:42,114	103424	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 6
"
1760334822190,"INFO	2025-10-13T05:53:42,190	103500	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.247.5:39977 with 5.8 GiB RAM, BlockManagerId(6, 172.34.247.5, 39977, None)
"
1760334822229,"INFO	2025-10-13T05:53:42,229	103539	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.139.155:47800) with ID 15,  ResourceProfileId 0
"
1760334822230,"INFO	2025-10-13T05:53:42,230	103540	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 15 has registered (new total is 17)
"
1760334822230,"INFO	2025-10-13T05:53:42,230	103540	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 15 @ 1760334822229
"
1760334822231,"INFO	2025-10-13T05:53:42,230	103540	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 15
"
1760334822245,"INFO	2025-10-13T05:53:42,245	103555	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.89.92:53236) with ID 16,  ResourceProfileId 0
"
1760334822246,"INFO	2025-10-13T05:53:42,245	103555	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 16 has registered (new total is 18)
"
1760334822246,"INFO	2025-10-13T05:53:42,245	103555	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 16 @ 1760334822245
"
1760334822246,"INFO	2025-10-13T05:53:42,246	103556	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 16
"
1760334822328,"INFO	2025-10-13T05:53:42,328	103638	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.139.155:44645 with 5.8 GiB RAM, BlockManagerId(15, 172.34.139.155, 44645, None)
"
1760334822330,"INFO	2025-10-13T05:53:42,330	103640	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.89.92:42809 with 5.8 GiB RAM, BlockManagerId(16, 172.34.89.92, 42809, None)
"
1760334822748,"INFO	2025-10-13T05:53:42,748	104058	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 34.0 in stage 0.0 (TID 34) (172.34.76.221, executor 11, partition 34, PROCESS_LOCAL, 29316 bytes) 
"
1760334822749,"INFO	2025-10-13T05:53:42,749	104059	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 35.0 in stage 0.0 (TID 35) (172.34.76.221, executor 11, partition 35, PROCESS_LOCAL, 29316 bytes) 
"
1760334822853,"INFO	2025-10-13T05:53:42,852	104162	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 36.0 in stage 0.0 (TID 36) (172.34.117.91, executor 13, partition 36, PROCESS_LOCAL, 29316 bytes) 
"
1760334822854,"INFO	2025-10-13T05:53:42,853	104163	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 37.0 in stage 0.0 (TID 37) (172.34.117.91, executor 13, partition 37, PROCESS_LOCAL, 29316 bytes) 
"
1760334822961,"INFO	2025-10-13T05:53:42,961	104271	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.102.82:49272) with ID 18,  ResourceProfileId 0
"
1760334822975,"INFO	2025-10-13T05:53:42,962	104272	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 18 @ 1760334822961
INFO	2025-10-13T05:53:42,962	104272	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 18
INFO	2025-10-13T05:53:42,962	104272	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 18 has registered (new total is 19)
"
1760334822979,"INFO	2025-10-13T05:53:42,978	104288	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.249.48:40597 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334823063,"INFO	2025-10-13T05:53:43,063	104373	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.102.82:44879 with 5.8 GiB RAM, BlockManagerId(18, 172.34.102.82, 44879, None)
"
1760334823104,"INFO	2025-10-13T05:53:43,104	104414	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.53.249:42363 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334823121,"INFO	2025-10-13T05:53:43,121	104431	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 38.0 in stage 0.0 (TID 38) (172.34.1.110, executor 14, partition 38, PROCESS_LOCAL, 29316 bytes) 
"
1760334823122,"INFO	2025-10-13T05:53:43,122	104432	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 39.0 in stage 0.0 (TID 39) (172.34.1.110, executor 14, partition 39, PROCESS_LOCAL, 29316 bytes) 
"
1760334823209,"INFO	2025-10-13T05:53:43,209	104519	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.78.80:45713 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334823341,"INFO	2025-10-13T05:53:43,340	104650	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.233.198:45305 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334823566,"INFO	2025-10-13T05:53:43,566	104876	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 40.0 in stage 0.0 (TID 40) (172.34.89.92, executor 16, partition 40, PROCESS_LOCAL, 29316 bytes) 
"
1760334823567,"INFO	2025-10-13T05:53:43,566	104876	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 41.0 in stage 0.0 (TID 41) (172.34.89.92, executor 16, partition 41, PROCESS_LOCAL, 29316 bytes) 
"
1760334823619,"INFO	2025-10-13T05:53:43,619	104929	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 42.0 in stage 0.0 (TID 42) (172.34.247.5, executor 6, partition 42, PROCESS_LOCAL, 29316 bytes) 
"
1760334823619,"INFO	2025-10-13T05:53:43,619	104929	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 43.0 in stage 0.0 (TID 43) (172.34.247.5, executor 6, partition 43, PROCESS_LOCAL, 29316 bytes) 
"
1760334823681,"INFO	2025-10-13T05:53:43,680	104990	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 44.0 in stage 0.0 (TID 44) (172.34.139.155, executor 15, partition 44, PROCESS_LOCAL, 29316 bytes) 
"
1760334823681,"INFO	2025-10-13T05:53:43,681	104991	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 45.0 in stage 0.0 (TID 45) (172.34.139.155, executor 15, partition 45, PROCESS_LOCAL, 29316 bytes) 
"
1760334823758,"INFO	2025-10-13T05:53:43,758	105068	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.76.221:36173 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334823812,"INFO	2025-10-13T05:53:43,812	105122	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.117.91:33289 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334824113,"INFO	2025-10-13T05:53:44,113	105423	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.59.71:32891 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334824192,"INFO	2025-10-13T05:53:44,191	105501	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.1.110:46749 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334824336,"INFO	2025-10-13T05:53:44,336	105646	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 46.0 in stage 0.0 (TID 46) (172.34.102.82, executor 18, partition 46, PROCESS_LOCAL, 29316 bytes) 
"
1760334824337,"INFO	2025-10-13T05:53:44,337	105647	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 47.0 in stage 0.0 (TID 47) (172.34.102.82, executor 18, partition 47, PROCESS_LOCAL, 29316 bytes) 
"
1760334824459,"INFO	2025-10-13T05:53:44,459	105769	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334824459,"INFO	2025-10-13T05:53:44,459	105769	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 21, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334824459,"INFO	2025-10-13T05:53:44,459	105769	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 21; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_21_a_spark-application-1760334728567_p_1
"
1760334824460,"INFO	2025-10-13T05:53:44,460	105770	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334824499,"INFO	2025-10-13T05:53:44,499	105809	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334824499,"INFO	2025-10-13T05:53:44,499	105809	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 16901e9e-7e9c-41e5-a64b-dbe16ce01175)
"
1760334824499,"INFO	2025-10-13T05:53:44,499	105809	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 21 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334824790,"INFO	2025-10-13T05:53:44,789	106099	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.247.5:39977 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334824874,"INFO	2025-10-13T05:53:44,874	106184	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.89.92:42809 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334824926,"INFO	2025-10-13T05:53:44,925	106235	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.139.155:44645 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334825416,"INFO	2025-10-13T05:53:45,416	106726	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.102.82:44879 (size: 16.6 KiB, free: 5.8 GiB)
"
1760334825566,"INFO	2025-10-13T05:53:45,565	106875	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.76.221:36173 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334825711,"INFO	2025-10-13T05:53:45,710	107020	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.117.91:33289 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334825845,"INFO	2025-10-13T05:53:45,845	107155	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.1.110:46749 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334826792,"INFO	2025-10-13T05:53:46,792	108102	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.89.92:42809 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334826803,"INFO	2025-10-13T05:53:46,803	108113	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.247.5:39977 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334826903,"INFO	2025-10-13T05:53:46,902	108212	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.139.155:44645 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334827387,"INFO	2025-10-13T05:53:47,387	108697	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.102.82:44879 (size: 4.8 KiB, free: 5.8 GiB)
"
1760334832279,"INFO	2025-10-13T05:53:52,277	113587	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 48.0 in stage 0.0 (TID 48) (172.35.30.152, executor 1, partition 48, PROCESS_LOCAL, 29316 bytes) 
"
1760334832279,"INFO	2025-10-13T05:53:52,278	113588	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 20.0 in stage 0.0 (TID 20) in 13835 ms on 172.35.30.152 (executor 1) (11/590)
"
1760334834153,"INFO	2025-10-13T05:53:54,152	115462	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334834153,"INFO	2025-10-13T05:53:54,153	115463	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 22, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334834153,"INFO	2025-10-13T05:53:54,153	115463	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 22; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_22_a_spark-application-1760334728567_p_1
"
1760334834154,"INFO	2025-10-13T05:53:54,153	115463	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334834201,"INFO	2025-10-13T05:53:54,200	115510	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334834201,"INFO	2025-10-13T05:53:54,201	115511	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 0d6982ad-3b75-4f86-8fbc-9252d244cc19)
"
1760334834201,"INFO	2025-10-13T05:53:54,201	115511	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 22 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334834279,"INFO	2025-10-13T05:53:54,278	115588	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 49.0 in stage 0.0 (TID 49) (172.35.116.46, executor 4, partition 49, PROCESS_LOCAL, 29316 bytes) 
"
1760334834279,"INFO	2025-10-13T05:53:54,279	115589	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 8.0 in stage 0.0 (TID 8) in 32554 ms on 172.35.116.46 (executor 4) (12/590)
"
1760334834922,"INFO	2025-10-13T05:53:54,921	116231	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 50.0 in stage 0.0 (TID 50) (172.35.116.46, executor 4, partition 50, PROCESS_LOCAL, 29316 bytes) 
"
1760334834922,"INFO	2025-10-13T05:53:54,922	116232	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 9.0 in stage 0.0 (TID 9) in 33196 ms on 172.35.116.46 (executor 4) (13/590)
"
1760334836065,"INFO	2025-10-13T05:53:56,064	117374	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334836065,"INFO	2025-10-13T05:53:56,065	117375	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 23, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334836065,"INFO	2025-10-13T05:53:56,065	117375	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 23; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_23_a_spark-application-1760334728567_p_1
"
1760334836065,"INFO	2025-10-13T05:53:56,065	117375	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334836107,"INFO	2025-10-13T05:53:56,107	117417	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334836107,"INFO	2025-10-13T05:53:56,107	117417	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 1365094b-14e8-49e4-855a-d15bfb80b737)
"
1760334836108,"INFO	2025-10-13T05:53:56,107	117417	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 23 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334838466,"INFO	2025-10-13T05:53:58,466	119776	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334838467,"INFO	2025-10-13T05:53:58,466	119776	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 24, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334838467,"INFO	2025-10-13T05:53:58,467	119777	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 24; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_24_a_spark-application-1760334728567_p_1
"
1760334838467,"INFO	2025-10-13T05:53:58,467	119777	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334838495,"INFO	2025-10-13T05:53:58,495	119805	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334838496,"INFO	2025-10-13T05:53:58,495	119805	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: f8faa8ec-a9aa-4723-a9ac-0d5a94dba43c)
"
1760334838496,"INFO	2025-10-13T05:53:58,496	119806	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 24 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334839936,"INFO	2025-10-13T05:53:59,935	121245	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 51.0 in stage 0.0 (TID 51) (172.34.249.48, executor 17, partition 51, PROCESS_LOCAL, 29316 bytes) 
"
1760334839936,"INFO	2025-10-13T05:53:59,936	121246	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 22.0 in stage 0.0 (TID 22) in 20027 ms on 172.34.249.48 (executor 17) (14/590)
"
1760334840053,"INFO	2025-10-13T05:54:00,052	121362	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 52.0 in stage 0.0 (TID 52) (172.35.230.30, executor 7, partition 52, PROCESS_LOCAL, 29316 bytes) 
"
1760334840053,"INFO	2025-10-13T05:54:00,053	121363	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 12.0 in stage 0.0 (TID 12) in 34849 ms on 172.35.230.30 (executor 7) (15/590)
"
1760334842034,"INFO	2025-10-13T05:54:02,033	123343	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 53.0 in stage 0.0 (TID 53) (172.35.115.9, executor 10, partition 53, PROCESS_LOCAL, 29316 bytes) 
"
1760334842034,"INFO	2025-10-13T05:54:02,034	123344	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 15.0 in stage 0.0 (TID 15) in 32260 ms on 172.35.115.9 (executor 10) (16/590)
"
1760334842036,"INFO	2025-10-13T05:54:02,035	123345	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 54.0 in stage 0.0 (TID 54) (172.35.115.9, executor 10, partition 54, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:54:02,035	123345	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 14.0 in stage 0.0 (TID 14) in 32262 ms on 172.35.115.9 (executor 10) (17/590)
"
1760334843150,"INFO	2025-10-13T05:54:03,149	124459	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 55.0 in stage 0.0 (TID 55) (172.35.230.30, executor 7, partition 55, PROCESS_LOCAL, 29316 bytes) 
"
1760334843151,"INFO	2025-10-13T05:54:03,150	124460	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 11.0 in stage 0.0 (TID 11) in 37947 ms on 172.35.230.30 (executor 7) (18/590)
"
1760334844041,"INFO	2025-10-13T05:54:04,040	125350	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 56.0 in stage 0.0 (TID 56) (172.35.30.152, executor 1, partition 56, PROCESS_LOCAL, 29316 bytes) 
"
1760334844042,"INFO	2025-10-13T05:54:04,041	125351	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 27.0 in stage 0.0 (TID 27) in 23791 ms on 172.35.30.152 (executor 1) (19/590)
"
1760334846875,"INFO	2025-10-13T05:54:06,875	128185	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 57.0 in stage 0.0 (TID 57) (172.35.34.68, executor 9, partition 57, PROCESS_LOCAL, 29316 bytes) 
"
1760334846876,"INFO	2025-10-13T05:54:06,875	128185	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 16.0 in stage 0.0 (TID 16) in 31773 ms on 172.35.34.68 (executor 9) (20/590)
"
1760334846877,"INFO	2025-10-13T05:54:06,876	128186	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 58.0 in stage 0.0 (TID 58) (172.35.34.68, executor 9, partition 58, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:54:06,877	128187	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 17.0 in stage 0.0 (TID 17) in 31774 ms on 172.35.34.68 (executor 9) (21/590)
"
1760334848692,"INFO	2025-10-13T05:54:08,691	130001	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334848692,"INFO	2025-10-13T05:54:08,691	130001	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760334849807,"INFO	2025-10-13T05:54:09,806	131116	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 59.0 in stage 0.0 (TID 59) (172.34.145.94, executor 3, partition 59, PROCESS_LOCAL, 29316 bytes) 
"
1760334849807,"INFO	2025-10-13T05:54:09,807	131117	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 18.0 in stage 0.0 (TID 18) in 32246 ms on 172.34.145.94 (executor 3) (22/590)
"
1760334849975,"INFO	2025-10-13T05:54:09,975	131285	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 60.0 in stage 0.0 (TID 60) (172.34.145.94, executor 3, partition 60, PROCESS_LOCAL, 29316 bytes) 
"
1760334849976,"INFO	2025-10-13T05:54:09,975	131285	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 19.0 in stage 0.0 (TID 19) in 32413 ms on 172.34.145.94 (executor 3) (23/590)
"
1760334853037,"INFO	2025-10-13T05:54:13,036	134346	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334853037,"INFO	2025-10-13T05:54:13,037	134347	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 25, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334853037,"INFO	2025-10-13T05:54:13,037	134347	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 25; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_25_a_spark-application-1760334728567_p_1
"
1760334853038,"INFO	2025-10-13T05:54:13,038	134348	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334853084,"INFO	2025-10-13T05:54:13,084	134394	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334853084,"INFO	2025-10-13T05:54:13,084	134394	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: c0ffc9ac-2766-45ab-abfe-5d20c048fa43)
"
1760334853084,"INFO	2025-10-13T05:54:13,084	134394	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 25 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334854193,"INFO	2025-10-13T05:54:14,193	135503	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 61.0 in stage 0.0 (TID 61) (172.34.249.48, executor 17, partition 61, PROCESS_LOCAL, 29316 bytes) 
"
1760334854194,"INFO	2025-10-13T05:54:14,194	135504	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 21.0 in stage 0.0 (TID 21) in 34286 ms on 172.34.249.48 (executor 17) (24/590)
"
1760334854899,"INFO	2025-10-13T05:54:14,898	136208	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 62.0 in stage 0.0 (TID 62) (172.34.158.2, executor 2, partition 62, PROCESS_LOCAL, 29316 bytes) 
"
1760334854899,"INFO	2025-10-13T05:54:14,899	136209	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 33.0 in stage 0.0 (TID 33) in 33382 ms on 172.34.158.2 (executor 2) (25/590)
"
1760334856111,"INFO	2025-10-13T05:54:16,111	137421	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 63.0 in stage 0.0 (TID 63) (172.34.158.2, executor 2, partition 63, PROCESS_LOCAL, 29316 bytes) 
"
1760334856112,"INFO	2025-10-13T05:54:16,111	137421	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 32.0 in stage 0.0 (TID 32) in 34977 ms on 172.34.158.2 (executor 2) (26/590)
"
1760334857433,"INFO	2025-10-13T05:54:17,433	138743	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 64.0 in stage 0.0 (TID 64) (172.35.30.152, executor 1, partition 64, PROCESS_LOCAL, 29316 bytes) 
"
1760334857434,"INFO	2025-10-13T05:54:17,434	138744	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 48.0 in stage 0.0 (TID 48) in 25157 ms on 172.35.30.152 (executor 1) (27/590)
"
1760334863179,"INFO	2025-10-13T05:54:23,179	144489	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334863179,"INFO	2025-10-13T05:54:23,179	144489	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 26, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334863180,"INFO	2025-10-13T05:54:23,179	144489	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 26; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_26_a_spark-application-1760334728567_p_1
"
1760334863180,"INFO	2025-10-13T05:54:23,180	144490	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334863209,"INFO	2025-10-13T05:54:23,209	144519	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334863209,"INFO	2025-10-13T05:54:23,209	144519	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 945230ed-5517-4dcd-9522-a7c9f631f61a)
"
1760334863210,"INFO	2025-10-13T05:54:23,209	144519	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 26 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334865365,"INFO	2025-10-13T05:54:25,364	146674	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 65.0 in stage 0.0 (TID 65) (172.35.116.46, executor 4, partition 65, PROCESS_LOCAL, 29316 bytes) 
"
1760334865366,"INFO	2025-10-13T05:54:25,365	146675	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 49.0 in stage 0.0 (TID 49) in 31087 ms on 172.35.116.46 (executor 4) (28/590)
"
1760334865798,"INFO	2025-10-13T05:54:25,798	147108	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 66.0 in stage 0.0 (TID 66) (172.35.116.46, executor 4, partition 66, PROCESS_LOCAL, 29316 bytes) 
"
1760334865799,"INFO	2025-10-13T05:54:25,799	147109	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 50.0 in stage 0.0 (TID 50) in 30877 ms on 172.35.116.46 (executor 4) (29/590)
"
1760334868479,"INFO	2025-10-13T05:54:28,479	149789	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 67.0 in stage 0.0 (TID 67) (172.35.30.152, executor 1, partition 67, PROCESS_LOCAL, 29316 bytes) 
"
1760334868480,"INFO	2025-10-13T05:54:28,479	149789	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 56.0 in stage 0.0 (TID 56) in 24439 ms on 172.35.30.152 (executor 1) (30/590)
"
1760334870106,"INFO	2025-10-13T05:54:30,106	151416	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 68.0 in stage 0.0 (TID 68) (172.35.53.249, executor 8, partition 68, PROCESS_LOCAL, 29316 bytes) 
"
1760334870107,"INFO	2025-10-13T05:54:30,107	151417	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 28.0 in stage 0.0 (TID 28) in 49791 ms on 172.35.53.249 (executor 8) (31/590)
"
1760334870830,"INFO	2025-10-13T05:54:30,830	152140	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 69.0 in stage 0.0 (TID 69) (172.34.249.48, executor 17, partition 69, PROCESS_LOCAL, 29316 bytes) 
"
1760334870831,"INFO	2025-10-13T05:54:30,830	152140	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 51.0 in stage 0.0 (TID 51) in 30895 ms on 172.34.249.48 (executor 17) (32/590)
"
1760334871343,"INFO	2025-10-13T05:54:31,343	152653	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 70.0 in stage 0.0 (TID 70) (172.34.117.91, executor 13, partition 70, PROCESS_LOCAL, 29316 bytes) 
"
1760334871344,"INFO	2025-10-13T05:54:31,343	152653	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 37.0 in stage 0.0 (TID 37) in 48490 ms on 172.34.117.91 (executor 13) (33/590)
"
1760334871345,"INFO	2025-10-13T05:54:31,344	152654	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 71.0 in stage 0.0 (TID 71) (172.34.117.91, executor 13, partition 71, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:54:31,345	152655	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 36.0 in stage 0.0 (TID 36) in 48493 ms on 172.34.117.91 (executor 13) (34/590)
"
1760334871550,"INFO	2025-10-13T05:54:31,550	152860	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 72.0 in stage 0.0 (TID 72) (172.35.53.249, executor 8, partition 72, PROCESS_LOCAL, 29316 bytes) 
"
1760334871551,"INFO	2025-10-13T05:54:31,550	152860	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 29.0 in stage 0.0 (TID 29) in 51233 ms on 172.35.53.249 (executor 8) (35/590)
"
1760334872257,"INFO	2025-10-13T05:54:32,257	153567	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 73.0 in stage 0.0 (TID 73) (172.34.233.198, executor 5, partition 73, PROCESS_LOCAL, 29316 bytes) 
"
1760334872258,"INFO	2025-10-13T05:54:32,258	153568	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 25.0 in stage 0.0 (TID 25) in 52070 ms on 172.34.233.198 (executor 5) (36/590)
"
1760334872260,"INFO	2025-10-13T05:54:32,259	153569	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 74.0 in stage 0.0 (TID 74) (172.34.233.198, executor 5, partition 74, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:54:32,259	153569	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 26.0 in stage 0.0 (TID 26) in 52070 ms on 172.34.233.198 (executor 5) (37/590)
"
1760334873710,"INFO	2025-10-13T05:54:33,709	155019	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 75.0 in stage 0.0 (TID 75) (172.34.1.110, executor 14, partition 75, PROCESS_LOCAL, 29316 bytes) 
"
1760334873710,"INFO	2025-10-13T05:54:33,710	155020	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 38.0 in stage 0.0 (TID 38) in 50590 ms on 172.34.1.110 (executor 14) (38/590)
"
1760334873712,"INFO	2025-10-13T05:54:33,712	155022	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 76.0 in stage 0.0 (TID 76) (172.34.1.110, executor 14, partition 76, PROCESS_LOCAL, 29316 bytes) 
"
1760334873713,"INFO	2025-10-13T05:54:33,713	155023	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 39.0 in stage 0.0 (TID 39) in 50592 ms on 172.34.1.110 (executor 14) (39/590)
"
1760334874027,"INFO	2025-10-13T05:54:34,026	155336	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 77.0 in stage 0.0 (TID 77) (172.34.76.221, executor 11, partition 77, PROCESS_LOCAL, 29316 bytes) 
"
1760334874028,"INFO	2025-10-13T05:54:34,027	155337	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 34.0 in stage 0.0 (TID 34) in 51280 ms on 172.34.76.221 (executor 11) (40/590)
"
1760334874029,"INFO	2025-10-13T05:54:34,028	155338	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 78.0 in stage 0.0 (TID 78) (172.34.76.221, executor 11, partition 78, PROCESS_LOCAL, 29316 bytes) 
"
1760334874029,"INFO	2025-10-13T05:54:34,029	155339	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 35.0 in stage 0.0 (TID 35) in 51281 ms on 172.34.76.221 (executor 11) (41/590)
"
1760334874666,"INFO	2025-10-13T05:54:34,666	155976	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 79.0 in stage 0.0 (TID 79) (172.34.78.80, executor 12, partition 79, PROCESS_LOCAL, 29316 bytes) 
"
1760334874667,"INFO	2025-10-13T05:54:34,667	155977	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 24.0 in stage 0.0 (TID 24) in 54644 ms on 172.34.78.80 (executor 12) (42/590)
"
1760334874669,"INFO	2025-10-13T05:54:34,669	155979	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 80.0 in stage 0.0 (TID 80) (172.34.78.80, executor 12, partition 80, PROCESS_LOCAL, 29316 bytes) 
"
1760334874670,"INFO	2025-10-13T05:54:34,669	155979	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 23.0 in stage 0.0 (TID 23) in 54647 ms on 172.34.78.80 (executor 12) (43/590)
"
1760334874909,"INFO	2025-10-13T05:54:34,909	156219	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 81.0 in stage 0.0 (TID 81) (172.34.59.71, executor 19, partition 81, PROCESS_LOCAL, 29316 bytes) 
"
1760334874910,"INFO	2025-10-13T05:54:34,910	156220	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 30.0 in stage 0.0 (TID 30) in 54070 ms on 172.34.59.71 (executor 19) (44/590)
"
1760334874911,"INFO	2025-10-13T05:54:34,911	156221	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 82.0 in stage 0.0 (TID 82) (172.34.59.71, executor 19, partition 82, PROCESS_LOCAL, 29316 bytes) 
"
1760334874912,"INFO	2025-10-13T05:54:34,912	156222	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 31.0 in stage 0.0 (TID 31) in 54071 ms on 172.34.59.71 (executor 19) (45/590)
"
1760334874975,"INFO	2025-10-13T05:54:34,975	156285	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 83.0 in stage 0.0 (TID 83) (172.34.89.92, executor 16, partition 83, PROCESS_LOCAL, 29316 bytes) 
"
1760334874976,"INFO	2025-10-13T05:54:34,975	156285	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 41.0 in stage 0.0 (TID 41) in 51409 ms on 172.34.89.92 (executor 16) (46/590)
"
1760334875058,"INFO	2025-10-13T05:54:35,058	156368	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 84.0 in stage 0.0 (TID 84) (172.34.89.92, executor 16, partition 84, PROCESS_LOCAL, 29316 bytes) 
"
1760334875059,"INFO	2025-10-13T05:54:35,059	156369	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 40.0 in stage 0.0 (TID 40) in 51494 ms on 172.34.89.92 (executor 16) (47/590)
"
1760334875446,"INFO	2025-10-13T05:54:35,445	156755	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 85.0 in stage 0.0 (TID 85) (172.35.230.30, executor 7, partition 85, PROCESS_LOCAL, 29316 bytes) 
"
1760334875446,"INFO	2025-10-13T05:54:35,446	156756	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 52.0 in stage 0.0 (TID 52) in 35394 ms on 172.35.230.30 (executor 7) (48/590)
"
1760334876558,"INFO	2025-10-13T05:54:36,558	157868	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 86.0 in stage 0.0 (TID 86) (172.35.115.9, executor 10, partition 86, PROCESS_LOCAL, 29316 bytes) 
"
1760334876559,"INFO	2025-10-13T05:54:36,559	157869	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 54.0 in stage 0.0 (TID 54) in 34524 ms on 172.35.115.9 (executor 10) (49/590)
"
1760334877343,"INFO	2025-10-13T05:54:37,342	158652	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 87.0 in stage 0.0 (TID 87) (172.34.247.5, executor 6, partition 87, PROCESS_LOCAL, 29316 bytes) 
"
1760334877343,"INFO	2025-10-13T05:54:37,343	158653	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 42.0 in stage 0.0 (TID 42) in 53725 ms on 172.34.247.5 (executor 6) (50/590)
"
1760334877447,"INFO	2025-10-13T05:54:37,447	158757	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 88.0 in stage 0.0 (TID 88) (172.35.115.9, executor 10, partition 88, PROCESS_LOCAL, 29316 bytes) 
"
1760334877448,"INFO	2025-10-13T05:54:37,448	158758	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 53.0 in stage 0.0 (TID 53) in 35415 ms on 172.35.115.9 (executor 10) (51/590)
"
1760334877450,"INFO	2025-10-13T05:54:37,449	158759	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 89.0 in stage 0.0 (TID 89) (172.34.102.82, executor 18, partition 89, PROCESS_LOCAL, 29316 bytes) 
"
1760334877451,"INFO	2025-10-13T05:54:37,450	158760	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 46.0 in stage 0.0 (TID 46) in 53114 ms on 172.34.102.82 (executor 18) (52/590)
"
1760334877451,"INFO	2025-10-13T05:54:37,451	158761	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 90.0 in stage 0.0 (TID 90) (172.34.102.82, executor 18, partition 90, PROCESS_LOCAL, 29316 bytes) 
"
1760334877452,"INFO	2025-10-13T05:54:37,451	158761	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 47.0 in stage 0.0 (TID 47) in 53115 ms on 172.34.102.82 (executor 18) (53/590)
"
1760334877939,"INFO	2025-10-13T05:54:37,938	159248	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 91.0 in stage 0.0 (TID 91) (172.35.230.30, executor 7, partition 91, PROCESS_LOCAL, 29316 bytes) 
"
1760334877939,"INFO	2025-10-13T05:54:37,939	159249	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 55.0 in stage 0.0 (TID 55) in 34790 ms on 172.35.230.30 (executor 7) (54/590)
"
1760334878095,"INFO	2025-10-13T05:54:38,095	159405	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334878096,"INFO	2025-10-13T05:54:38,095	159405	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 27, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334878096,"INFO	2025-10-13T05:54:38,096	159406	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 27; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_27_a_spark-application-1760334728567_p_1
INFO	2025-10-13T05:54:38,096	159406	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334878097,"INFO	2025-10-13T05:54:38,096	159406	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 92.0 in stage 0.0 (TID 92) (172.34.247.5, executor 6, partition 92, PROCESS_LOCAL, 29316 bytes) 
"
1760334878097,"INFO	2025-10-13T05:54:38,097	159407	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 43.0 in stage 0.0 (TID 43) in 54478 ms on 172.34.247.5 (executor 6) (55/590)
"
1760334878125,"INFO	2025-10-13T05:54:38,125	159435	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334878126,"INFO	2025-10-13T05:54:38,125	159435	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 0ab1ffaf-2be2-4e03-90ad-ab3a8c50521b)
"
1760334878126,"INFO	2025-10-13T05:54:38,125	159435	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 27 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334878200,"INFO	2025-10-13T05:54:38,199	159509	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 93.0 in stage 0.0 (TID 93) (172.34.139.155, executor 15, partition 93, PROCESS_LOCAL, 29316 bytes) 
"
1760334878201,"INFO	2025-10-13T05:54:38,200	159510	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 45.0 in stage 0.0 (TID 45) in 54519 ms on 172.34.139.155 (executor 15) (56/590)
"
1760334878242,"INFO	2025-10-13T05:54:38,241	159551	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 94.0 in stage 0.0 (TID 94) (172.34.139.155, executor 15, partition 94, PROCESS_LOCAL, 29316 bytes) 
"
1760334878242,"INFO	2025-10-13T05:54:38,242	159552	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 44.0 in stage 0.0 (TID 44) in 54562 ms on 172.34.139.155 (executor 15) (57/590)
"
1760334880981,"INFO	2025-10-13T05:54:40,981	162291	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 95.0 in stage 0.0 (TID 95) (172.35.34.68, executor 9, partition 95, PROCESS_LOCAL, 29316 bytes) 
"
1760334880982,"INFO	2025-10-13T05:54:40,982	162292	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 58.0 in stage 0.0 (TID 58) in 34105 ms on 172.35.34.68 (executor 9) (58/590)
"
1760334881821,"INFO	2025-10-13T05:54:41,821	163131	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 96.0 in stage 0.0 (TID 96) (172.34.145.94, executor 3, partition 96, PROCESS_LOCAL, 29316 bytes) 
"
1760334881822,"INFO	2025-10-13T05:54:41,821	163131	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 59.0 in stage 0.0 (TID 59) in 32015 ms on 172.34.145.94 (executor 3) (59/590)
"
1760334881862,"INFO	2025-10-13T05:54:41,861	163171	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 97.0 in stage 0.0 (TID 97) (172.35.34.68, executor 9, partition 97, PROCESS_LOCAL, 29316 bytes) 
"
1760334881862,"INFO	2025-10-13T05:54:41,862	163172	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 57.0 in stage 0.0 (TID 57) in 34988 ms on 172.35.34.68 (executor 9) (60/590)
"
1760334881924,"INFO	2025-10-13T05:54:41,923	163233	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 98.0 in stage 0.0 (TID 98) (172.35.30.152, executor 1, partition 98, PROCESS_LOCAL, 29316 bytes) 
"
1760334881924,"INFO	2025-10-13T05:54:41,924	163234	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 64.0 in stage 0.0 (TID 64) in 24491 ms on 172.35.30.152 (executor 1) (61/590)
"
1760334882801,"INFO	2025-10-13T05:54:42,800	164110	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 99.0 in stage 0.0 (TID 99) (172.34.249.48, executor 17, partition 99, PROCESS_LOCAL, 29316 bytes) 
"
1760334882802,"INFO	2025-10-13T05:54:42,801	164111	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 61.0 in stage 0.0 (TID 61) in 28609 ms on 172.34.249.48 (executor 17) (62/590)
"
1760334883463,"INFO	2025-10-13T05:54:43,463	164773	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 100.0 in stage 0.0 (TID 100) (172.34.145.94, executor 3, partition 100, PROCESS_LOCAL, 29316 bytes) 
"
1760334883464,"INFO	2025-10-13T05:54:43,464	164774	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 60.0 in stage 0.0 (TID 60) in 33490 ms on 172.34.145.94 (executor 3) (63/590)
"
1760334887749,"INFO	2025-10-13T05:54:47,749	169059	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 101.0 in stage 0.0 (TID 101) (172.34.158.2, executor 2, partition 101, PROCESS_LOCAL, 29316 bytes) 
"
1760334887750,"INFO	2025-10-13T05:54:47,750	169060	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 62.0 in stage 0.0 (TID 62) in 32852 ms on 172.34.158.2 (executor 2) (64/590)
"
1760334889262,"INFO	2025-10-13T05:54:49,262	170572	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 102.0 in stage 0.0 (TID 102) (172.34.158.2, executor 2, partition 102, PROCESS_LOCAL, 29316 bytes) 
"
1760334889263,"INFO	2025-10-13T05:54:49,262	170572	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 63.0 in stage 0.0 (TID 63) in 33152 ms on 172.34.158.2 (executor 2) (65/590)
"
1760334891963,"INFO	2025-10-13T05:54:51,963	173273	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334891964,"INFO	2025-10-13T05:54:51,963	173273	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 28, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334891964,"INFO	2025-10-13T05:54:51,964	173274	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 28; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_28_a_spark-application-1760334728567_p_1
"
1760334891964,"INFO	2025-10-13T05:54:51,964	173274	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334892010,"INFO	2025-10-13T05:54:52,010	173320	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334892010,"INFO	2025-10-13T05:54:52,010	173320	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 52e0bc0b-1abe-46af-9464-d6e125a8978f)
INFO	2025-10-13T05:54:52,010	173320	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 28 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334892461,"INFO	2025-10-13T05:54:52,460	173770	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 103.0 in stage 0.0 (TID 103) (172.35.30.152, executor 1, partition 103, PROCESS_LOCAL, 29316 bytes) 
"
1760334892461,"INFO	2025-10-13T05:54:52,461	173771	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 67.0 in stage 0.0 (TID 67) in 23983 ms on 172.35.30.152 (executor 1) (66/590)
"
1760334895474,"INFO	2025-10-13T05:54:55,473	176783	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 104.0 in stage 0.0 (TID 104) (172.34.249.48, executor 17, partition 104, PROCESS_LOCAL, 29316 bytes) 
"
1760334895474,"INFO	2025-10-13T05:54:55,474	176784	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 69.0 in stage 0.0 (TID 69) in 24645 ms on 172.34.249.48 (executor 17) (67/590)
"
1760334897144,"INFO	2025-10-13T05:54:57,144	178454	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 105.0 in stage 0.0 (TID 105) (172.35.116.46, executor 4, partition 105, PROCESS_LOCAL, 29316 bytes) 
"
1760334897145,"INFO	2025-10-13T05:54:57,144	178454	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 65.0 in stage 0.0 (TID 65) in 31780 ms on 172.35.116.46 (executor 4) (68/590)
"
1760334897989,"INFO	2025-10-13T05:54:57,988	179298	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 106.0 in stage 0.0 (TID 106) (172.35.116.46, executor 4, partition 106, PROCESS_LOCAL, 29316 bytes) 
"
1760334897989,"INFO	2025-10-13T05:54:57,989	179299	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 66.0 in stage 0.0 (TID 66) in 32192 ms on 172.35.116.46 (executor 4) (69/590)
"
1760334902025,"INFO	2025-10-13T05:55:02,024	183334	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 107.0 in stage 0.0 (TID 107) (172.34.117.91, executor 13, partition 107, PROCESS_LOCAL, 29316 bytes) 
"
1760334902025,"INFO	2025-10-13T05:55:02,025	183335	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 70.0 in stage 0.0 (TID 70) in 30683 ms on 172.34.117.91 (executor 13) (70/590)
"
1760334902381,"INFO	2025-10-13T05:55:02,380	183690	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 108.0 in stage 0.0 (TID 108) (172.34.117.91, executor 13, partition 108, PROCESS_LOCAL, 29316 bytes) 
"
1760334902381,"INFO	2025-10-13T05:55:02,381	183691	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 71.0 in stage 0.0 (TID 71) in 31037 ms on 172.34.117.91 (executor 13) (71/590)
"
1760334904178,"INFO	2025-10-13T05:55:04,177	185487	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 109.0 in stage 0.0 (TID 109) (172.35.53.249, executor 8, partition 109, PROCESS_LOCAL, 29316 bytes) 
"
1760334904178,"INFO	2025-10-13T05:55:04,178	185488	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 72.0 in stage 0.0 (TID 72) in 32628 ms on 172.35.53.249 (executor 8) (72/590)
"
1760334904255,"INFO	2025-10-13T05:55:04,255	185565	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334904255,"INFO	2025-10-13T05:55:04,255	185565	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 29, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334904255,"INFO	2025-10-13T05:55:04,255	185565	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 29; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_29_a_spark-application-1760334728567_p_1
"
1760334904256,"INFO	2025-10-13T05:55:04,256	185566	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334904298,"INFO	2025-10-13T05:55:04,298	185608	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334904298,"INFO	2025-10-13T05:55:04,298	185608	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: e9c0465a-bae6-42bb-90ca-a1da08c0f530)
INFO	2025-10-13T05:55:04,298	185608	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 29 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334904358,"INFO	2025-10-13T05:55:04,358	185668	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 110.0 in stage 0.0 (TID 110) (172.34.233.198, executor 5, partition 110, PROCESS_LOCAL, 29316 bytes) 
"
1760334904359,"INFO	2025-10-13T05:55:04,358	185668	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 74.0 in stage 0.0 (TID 74) in 32100 ms on 172.34.233.198 (executor 5) (73/590)
"
1760334904485,"INFO	2025-10-13T05:55:04,485	185795	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 111.0 in stage 0.0 (TID 111) (172.35.53.249, executor 8, partition 111, PROCESS_LOCAL, 29316 bytes) 
"
1760334904486,"INFO	2025-10-13T05:55:04,485	185795	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 68.0 in stage 0.0 (TID 68) in 34379 ms on 172.35.53.249 (executor 8) (74/590)
"
1760334904529,"INFO	2025-10-13T05:55:04,529	185839	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 112.0 in stage 0.0 (TID 112) (172.34.233.198, executor 5, partition 112, PROCESS_LOCAL, 29316 bytes) 
"
1760334904530,"INFO	2025-10-13T05:55:04,530	185840	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 73.0 in stage 0.0 (TID 73) in 32272 ms on 172.34.233.198 (executor 5) (75/590)
"
1760334905595,"INFO	2025-10-13T05:55:05,594	186904	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334905595,"INFO	2025-10-13T05:55:05,595	186905	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 30, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334905595,"INFO	2025-10-13T05:55:05,595	186905	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 30; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_30_a_spark-application-1760334728567_p_1
"
1760334905595,"INFO	2025-10-13T05:55:05,595	186905	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334905631,"INFO	2025-10-13T05:55:05,631	186941	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334905632,"INFO	2025-10-13T05:55:05,631	186941	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: fe690c87-4858-4d46-a082-b85f205f0b5a)
INFO	2025-10-13T05:55:05,631	186941	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 30 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334905637,"INFO	2025-10-13T05:55:05,637	186947	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 113.0 in stage 0.0 (TID 113) (172.35.30.152, executor 1, partition 113, PROCESS_LOCAL, 29316 bytes) 
"
1760334905638,"INFO	2025-10-13T05:55:05,638	186948	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 98.0 in stage 0.0 (TID 98) in 23715 ms on 172.35.30.152 (executor 1) (76/590)
"
1760334906210,"INFO	2025-10-13T05:55:06,210	187520	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 114.0 in stage 0.0 (TID 114) (172.34.1.110, executor 14, partition 114, PROCESS_LOCAL, 29316 bytes) 
"
1760334906211,"INFO	2025-10-13T05:55:06,211	187521	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 75.0 in stage 0.0 (TID 75) in 32502 ms on 172.34.1.110 (executor 14) (77/590)
"
1760334906221,"INFO	2025-10-13T05:55:06,221	187531	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 115.0 in stage 0.0 (TID 115) (172.34.1.110, executor 14, partition 115, PROCESS_LOCAL, 29316 bytes) 
"
1760334906222,"INFO	2025-10-13T05:55:06,222	187532	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 76.0 in stage 0.0 (TID 76) in 32510 ms on 172.34.1.110 (executor 14) (78/590)
"
1760334907045,"INFO	2025-10-13T05:55:07,045	188355	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 116.0 in stage 0.0 (TID 116) (172.34.59.71, executor 19, partition 116, PROCESS_LOCAL, 29316 bytes) 
"
1760334907046,"INFO	2025-10-13T05:55:07,046	188356	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 81.0 in stage 0.0 (TID 81) in 32138 ms on 172.34.59.71 (executor 19) (79/590)
"
1760334907057,"INFO	2025-10-13T05:55:07,056	188366	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 117.0 in stage 0.0 (TID 117) (172.34.76.221, executor 11, partition 117, PROCESS_LOCAL, 29316 bytes) 
"
1760334907057,"INFO	2025-10-13T05:55:07,057	188367	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 78.0 in stage 0.0 (TID 78) in 33029 ms on 172.34.76.221 (executor 11) (80/590)
"
1760334907070,"INFO	2025-10-13T05:55:07,069	188379	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 118.0 in stage 0.0 (TID 118) (172.34.89.92, executor 16, partition 118, PROCESS_LOCAL, 29316 bytes) 
"
1760334907070,"INFO	2025-10-13T05:55:07,070	188380	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 84.0 in stage 0.0 (TID 84) in 32012 ms on 172.34.89.92 (executor 16) (81/590)
"
1760334907117,"INFO	2025-10-13T05:55:07,116	188426	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 119.0 in stage 0.0 (TID 119) (172.35.230.30, executor 7, partition 119, PROCESS_LOCAL, 29316 bytes) 
"
1760334907117,"INFO	2025-10-13T05:55:07,117	188427	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 85.0 in stage 0.0 (TID 85) in 31672 ms on 172.35.230.30 (executor 7) (82/590)
"
1760334907173,"INFO	2025-10-13T05:55:07,173	188483	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 120.0 in stage 0.0 (TID 120) (172.34.249.48, executor 17, partition 120, PROCESS_LOCAL, 29316 bytes) 
"
1760334907173,"INFO	2025-10-13T05:55:07,173	188483	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 99.0 in stage 0.0 (TID 99) in 24373 ms on 172.34.249.48 (executor 17) (83/590)
"
1760334907258,"INFO	2025-10-13T05:55:07,258	188568	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 121.0 in stage 0.0 (TID 121) (172.34.59.71, executor 19, partition 121, PROCESS_LOCAL, 29316 bytes) 
"
1760334907258,"INFO	2025-10-13T05:55:07,258	188568	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 82.0 in stage 0.0 (TID 82) in 32348 ms on 172.34.59.71 (executor 19) (84/590)
"
1760334907273,"INFO	2025-10-13T05:55:07,273	188583	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 122.0 in stage 0.0 (TID 122) (172.34.78.80, executor 12, partition 122, PROCESS_LOCAL, 29316 bytes) 
"
1760334907274,"INFO	2025-10-13T05:55:07,274	188584	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 80.0 in stage 0.0 (TID 80) in 32606 ms on 172.34.78.80 (executor 12) (85/590)
"
1760334907353,"INFO	2025-10-13T05:55:07,352	188662	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 123.0 in stage 0.0 (TID 123) (172.34.76.221, executor 11, partition 123, PROCESS_LOCAL, 29316 bytes) 
"
1760334907353,"INFO	2025-10-13T05:55:07,353	188663	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 77.0 in stage 0.0 (TID 77) in 33327 ms on 172.34.76.221 (executor 11) (86/590)
"
1760334907495,"INFO	2025-10-13T05:55:07,495	188805	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 124.0 in stage 0.0 (TID 124) (172.34.89.92, executor 16, partition 124, PROCESS_LOCAL, 29316 bytes) 
"
1760334907496,"INFO	2025-10-13T05:55:07,495	188805	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 83.0 in stage 0.0 (TID 83) in 32521 ms on 172.34.89.92 (executor 16) (87/590)
"
1760334907579,"INFO	2025-10-13T05:55:07,579	188889	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 125.0 in stage 0.0 (TID 125) (172.34.78.80, executor 12, partition 125, PROCESS_LOCAL, 29316 bytes) 
"
1760334907579,"INFO	2025-10-13T05:55:07,579	188889	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 79.0 in stage 0.0 (TID 79) in 32913 ms on 172.34.78.80 (executor 12) (88/590)
"
1760334908692,"INFO	2025-10-13T05:55:08,692	190002	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334908692,"INFO	2025-10-13T05:55:08,692	190002	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760334909282,"INFO	2025-10-13T05:55:09,281	190591	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 126.0 in stage 0.0 (TID 126) (172.35.115.9, executor 10, partition 126, PROCESS_LOCAL, 29316 bytes) 
"
1760334909282,"INFO	2025-10-13T05:55:09,282	190592	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 86.0 in stage 0.0 (TID 86) in 32725 ms on 172.35.115.9 (executor 10) (89/590)
"
1760334909844,"INFO	2025-10-13T05:55:09,844	191154	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 127.0 in stage 0.0 (TID 127) (172.34.102.82, executor 18, partition 127, PROCESS_LOCAL, 29316 bytes) 
"
1760334909845,"INFO	2025-10-13T05:55:09,844	191154	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 90.0 in stage 0.0 (TID 90) in 32394 ms on 172.34.102.82 (executor 18) (90/590)
"
1760334909978,"INFO	2025-10-13T05:55:09,978	191288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 128.0 in stage 0.0 (TID 128) (172.34.102.82, executor 18, partition 128, PROCESS_LOCAL, 29316 bytes) 
"
1760334909979,"INFO	2025-10-13T05:55:09,978	191288	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 89.0 in stage 0.0 (TID 89) in 32529 ms on 172.34.102.82 (executor 18) (91/590)
"
1760334910065,"INFO	2025-10-13T05:55:10,065	191375	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 129.0 in stage 0.0 (TID 129) (172.35.230.30, executor 7, partition 129, PROCESS_LOCAL, 29316 bytes) 
"
1760334910066,"INFO	2025-10-13T05:55:10,065	191375	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 91.0 in stage 0.0 (TID 91) in 32127 ms on 172.35.230.30 (executor 7) (92/590)
"
1760334910378,"INFO	2025-10-13T05:55:10,377	191687	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 130.0 in stage 0.0 (TID 130) (172.35.115.9, executor 10, partition 130, PROCESS_LOCAL, 29316 bytes) 
"
1760334910378,"INFO	2025-10-13T05:55:10,378	191688	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 88.0 in stage 0.0 (TID 88) in 32932 ms on 172.35.115.9 (executor 10) (93/590)
"
1760334910580,"INFO	2025-10-13T05:55:10,579	191889	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 131.0 in stage 0.0 (TID 131) (172.34.139.155, executor 15, partition 131, PROCESS_LOCAL, 29316 bytes) 
"
1760334910580,"INFO	2025-10-13T05:55:10,580	191890	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 94.0 in stage 0.0 (TID 94) in 32339 ms on 172.34.139.155 (executor 15) (94/590)
"
1760334910702,"INFO	2025-10-13T05:55:10,702	192012	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 132.0 in stage 0.0 (TID 132) (172.34.139.155, executor 15, partition 132, PROCESS_LOCAL, 29316 bytes) 
"
1760334910703,"INFO	2025-10-13T05:55:10,703	192013	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 93.0 in stage 0.0 (TID 93) in 32503 ms on 172.34.139.155 (executor 15) (95/590)
"
1760334910768,"INFO	2025-10-13T05:55:10,768	192078	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334910768,"INFO	2025-10-13T05:55:10,768	192078	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 31, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334910769,"INFO	2025-10-13T05:55:10,768	192078	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 31; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_31_a_spark-application-1760334728567_p_1
"
1760334910769,"INFO	2025-10-13T05:55:10,769	192079	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334910778,"INFO	2025-10-13T05:55:10,778	192088	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 133.0 in stage 0.0 (TID 133) (172.34.247.5, executor 6, partition 133, PROCESS_LOCAL, 29316 bytes) 
"
1760334910778,"INFO	2025-10-13T05:55:10,778	192088	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 87.0 in stage 0.0 (TID 87) in 33436 ms on 172.34.247.5 (executor 6) (96/590)
"
1760334910810,"INFO	2025-10-13T05:55:10,810	192120	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334910810,"INFO	2025-10-13T05:55:10,810	192120	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 0f392472-edff-4124-9957-31a825dbef46)
"
1760334910810,"INFO	2025-10-13T05:55:10,810	192120	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 31 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334912452,"INFO	2025-10-13T05:55:12,452	193762	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 134.0 in stage 0.0 (TID 134) (172.34.247.5, executor 6, partition 134, PROCESS_LOCAL, 29316 bytes) 
"
1760334912453,"INFO	2025-10-13T05:55:12,452	193762	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 92.0 in stage 0.0 (TID 92) in 34356 ms on 172.34.247.5 (executor 6) (97/590)
"
1760334912972,"INFO	2025-10-13T05:55:12,971	194281	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 135.0 in stage 0.0 (TID 135) (172.35.34.68, executor 9, partition 135, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:55:12,972	194282	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 95.0 in stage 0.0 (TID 95) in 31991 ms on 172.35.34.68 (executor 9) (98/590)
"
1760334913740,"INFO	2025-10-13T05:55:13,740	195050	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 136.0 in stage 0.0 (TID 136) (172.34.145.94, executor 3, partition 136, PROCESS_LOCAL, 29316 bytes) 
"
1760334913741,"INFO	2025-10-13T05:55:13,741	195051	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 96.0 in stage 0.0 (TID 96) in 31920 ms on 172.34.145.94 (executor 3) (99/590)
"
1760334913901,"INFO	2025-10-13T05:55:13,900	195210	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 137.0 in stage 0.0 (TID 137) (172.35.34.68, executor 9, partition 137, PROCESS_LOCAL, 29316 bytes) 
"
1760334913901,"INFO	2025-10-13T05:55:13,901	195211	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 97.0 in stage 0.0 (TID 97) in 32040 ms on 172.35.34.68 (executor 9) (100/590)
"
1760334915414,"INFO	2025-10-13T05:55:15,413	196723	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 138.0 in stage 0.0 (TID 138) (172.34.145.94, executor 3, partition 138, PROCESS_LOCAL, 29316 bytes) 
"
1760334915415,"INFO	2025-10-13T05:55:15,414	196724	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 100.0 in stage 0.0 (TID 100) in 31952 ms on 172.34.145.94 (executor 3) (101/590)
"
1760334916214,"INFO	2025-10-13T05:55:16,214	197524	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 139.0 in stage 0.0 (TID 139) (172.35.30.152, executor 1, partition 139, PROCESS_LOCAL, 29316 bytes) 
"
1760334916215,"INFO	2025-10-13T05:55:16,214	197524	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 103.0 in stage 0.0 (TID 103) in 23754 ms on 172.35.30.152 (executor 1) (102/590)
"
1760334919963,"INFO	2025-10-13T05:55:19,963	201273	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 140.0 in stage 0.0 (TID 140) (172.34.249.48, executor 17, partition 140, PROCESS_LOCAL, 29316 bytes) 
"
1760334919963,"INFO	2025-10-13T05:55:19,963	201273	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 104.0 in stage 0.0 (TID 104) in 24490 ms on 172.34.249.48 (executor 17) (103/590)
"
1760334920725,"INFO	2025-10-13T05:55:20,724	202034	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 141.0 in stage 0.0 (TID 141) (172.34.158.2, executor 2, partition 141, PROCESS_LOCAL, 29316 bytes) 
"
1760334920725,"INFO	2025-10-13T05:55:20,725	202035	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 101.0 in stage 0.0 (TID 101) in 32976 ms on 172.34.158.2 (executor 2) (104/590)
"
1760334921295,"INFO	2025-10-13T05:55:21,294	202604	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334921295,"INFO	2025-10-13T05:55:21,295	202605	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 32, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334921295,"INFO	2025-10-13T05:55:21,295	202605	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 32; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_32_a_spark-application-1760334728567_p_1
"
1760334921296,"INFO	2025-10-13T05:55:21,295	202605	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334921331,"INFO	2025-10-13T05:55:21,331	202641	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334921331,"INFO	2025-10-13T05:55:21,331	202641	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 8fb3aefd-fccd-47cf-97cd-7ad52b0cca0d)
"
1760334921332,"INFO	2025-10-13T05:55:21,331	202641	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 32 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334922663,"INFO	2025-10-13T05:55:22,662	203972	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 142.0 in stage 0.0 (TID 142) (172.34.158.2, executor 2, partition 142, PROCESS_LOCAL, 29316 bytes) 
"
1760334922663,"INFO	2025-10-13T05:55:22,663	203973	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 102.0 in stage 0.0 (TID 102) in 33402 ms on 172.34.158.2 (executor 2) (105/590)
"
1760334929020,"INFO	2025-10-13T05:55:29,020	210330	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 143.0 in stage 0.0 (TID 143) (172.35.116.46, executor 4, partition 143, PROCESS_LOCAL, 29316 bytes) 
"
1760334929020,"INFO	2025-10-13T05:55:29,020	210330	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 105.0 in stage 0.0 (TID 105) in 31877 ms on 172.35.116.46 (executor 4) (106/590)
"
1760334929672,"INFO	2025-10-13T05:55:29,671	210981	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 144.0 in stage 0.0 (TID 144) (172.35.30.152, executor 1, partition 144, PROCESS_LOCAL, 29316 bytes) 
"
1760334929672,"INFO	2025-10-13T05:55:29,672	210982	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 113.0 in stage 0.0 (TID 113) in 24035 ms on 172.35.30.152 (executor 1) (107/590)
"
1760334930272,"INFO	2025-10-13T05:55:30,272	211582	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 145.0 in stage 0.0 (TID 145) (172.35.116.46, executor 4, partition 145, PROCESS_LOCAL, 29316 bytes) 
"
1760334930273,"INFO	2025-10-13T05:55:30,273	211583	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 106.0 in stage 0.0 (TID 106) in 32285 ms on 172.35.116.46 (executor 4) (108/590)
"
1760334931660,"INFO	2025-10-13T05:55:31,660	212970	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 146.0 in stage 0.0 (TID 146) (172.34.117.91, executor 13, partition 146, PROCESS_LOCAL, 29316 bytes) 
"
1760334931661,"INFO	2025-10-13T05:55:31,661	212971	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 107.0 in stage 0.0 (TID 107) in 29636 ms on 172.34.117.91 (executor 13) (109/590)
"
1760334931761,"INFO	2025-10-13T05:55:31,760	213070	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 147.0 in stage 0.0 (TID 147) (172.34.249.48, executor 17, partition 147, PROCESS_LOCAL, 29316 bytes) 
"
1760334931761,"INFO	2025-10-13T05:55:31,761	213071	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 120.0 in stage 0.0 (TID 120) in 24589 ms on 172.34.249.48 (executor 17) (110/590)
"
1760334932585,"INFO	2025-10-13T05:55:32,585	213895	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 148.0 in stage 0.0 (TID 148) (172.34.117.91, executor 13, partition 148, PROCESS_LOCAL, 29316 bytes) 
"
1760334932586,"INFO	2025-10-13T05:55:32,585	213895	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 108.0 in stage 0.0 (TID 108) in 30205 ms on 172.34.117.91 (executor 13) (111/590)
"
1760334935809,"INFO	2025-10-13T05:55:35,809	217119	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334935809,"INFO	2025-10-13T05:55:35,809	217119	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 33, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334935810,"INFO	2025-10-13T05:55:35,809	217119	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 33; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_33_a_spark-application-1760334728567_p_1
"
1760334935810,"INFO	2025-10-13T05:55:35,810	217120	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334935842,"INFO	2025-10-13T05:55:35,842	217152	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334935842,"INFO	2025-10-13T05:55:35,842	217152	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5c858b53-d6fc-4fa8-a3ae-b3ce41005e1e)
"
1760334935842,"INFO	2025-10-13T05:55:35,842	217152	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 33 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334936805,"INFO	2025-10-13T05:55:36,805	218115	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 149.0 in stage 0.0 (TID 149) (172.35.53.249, executor 8, partition 149, PROCESS_LOCAL, 29316 bytes) 
"
1760334936806,"INFO	2025-10-13T05:55:36,805	218115	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 109.0 in stage 0.0 (TID 109) in 32628 ms on 172.35.53.249 (executor 8) (112/590)
"
1760334937150,"INFO	2025-10-13T05:55:37,149	218459	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 150.0 in stage 0.0 (TID 150) (172.35.53.249, executor 8, partition 150, PROCESS_LOCAL, 29316 bytes) 
"
1760334937151,"INFO	2025-10-13T05:55:37,150	218460	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 111.0 in stage 0.0 (TID 111) in 32665 ms on 172.35.53.249 (executor 8) (113/590)
"
1760334937809,"INFO	2025-10-13T05:55:37,809	219119	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 151.0 in stage 0.0 (TID 151) (172.34.233.198, executor 5, partition 151, PROCESS_LOCAL, 29316 bytes) 
"
1760334937810,"INFO	2025-10-13T05:55:37,809	219119	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 110.0 in stage 0.0 (TID 110) in 33452 ms on 172.34.233.198 (executor 5) (114/590)
"
1760334938032,"INFO	2025-10-13T05:55:38,031	219341	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334938032,"INFO	2025-10-13T05:55:38,032	219342	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 34, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334938032,"INFO	2025-10-13T05:55:38,032	219342	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 34; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_34_a_spark-application-1760334728567_p_1
"
1760334938032,"INFO	2025-10-13T05:55:38,032	219342	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334938070,"INFO	2025-10-13T05:55:38,070	219380	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334938071,"INFO	2025-10-13T05:55:38,070	219380	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: f2f55dd5-9f75-4c1a-9378-b09cbde42224)
"
1760334938071,"INFO	2025-10-13T05:55:38,070	219380	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 34 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334938119,"INFO	2025-10-13T05:55:38,119	219429	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 152.0 in stage 0.0 (TID 152) (172.34.233.198, executor 5, partition 152, PROCESS_LOCAL, 29316 bytes) 
"
1760334938120,"INFO	2025-10-13T05:55:38,120	219430	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 112.0 in stage 0.0 (TID 112) in 33591 ms on 172.34.233.198 (executor 5) (115/590)
"
1760334939077,"INFO	2025-10-13T05:55:39,077	220387	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 153.0 in stage 0.0 (TID 153) (172.35.230.30, executor 7, partition 153, PROCESS_LOCAL, 29316 bytes) 
"
1760334939078,"INFO	2025-10-13T05:55:39,078	220388	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 119.0 in stage 0.0 (TID 119) in 31962 ms on 172.35.230.30 (executor 7) (116/590)
"
1760334939502,"INFO	2025-10-13T05:55:39,501	220811	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 154.0 in stage 0.0 (TID 154) (172.34.89.92, executor 16, partition 154, PROCESS_LOCAL, 29316 bytes) 
"
1760334939503,"INFO	2025-10-13T05:55:39,502	220812	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 118.0 in stage 0.0 (TID 118) in 32433 ms on 172.34.89.92 (executor 16) (117/590)
"
1760334939517,"INFO	2025-10-13T05:55:39,517	220827	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 155.0 in stage 0.0 (TID 155) (172.34.1.110, executor 14, partition 155, PROCESS_LOCAL, 29316 bytes) 
"
1760334939518,"INFO	2025-10-13T05:55:39,517	220827	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 115.0 in stage 0.0 (TID 115) in 33296 ms on 172.34.1.110 (executor 14) (118/590)
"
1760334940188,"INFO	2025-10-13T05:55:40,187	221497	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 156.0 in stage 0.0 (TID 156) (172.34.89.92, executor 16, partition 156, PROCESS_LOCAL, 29316 bytes) 
"
1760334940188,"INFO	2025-10-13T05:55:40,188	221498	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 124.0 in stage 0.0 (TID 124) in 32693 ms on 172.34.89.92 (executor 16) (119/590)
"
1760334940337,"INFO	2025-10-13T05:55:40,337	221647	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 157.0 in stage 0.0 (TID 157) (172.35.30.152, executor 1, partition 157, PROCESS_LOCAL, 29316 bytes) 
"
1760334940337,"INFO	2025-10-13T05:55:40,337	221647	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 139.0 in stage 0.0 (TID 139) in 24124 ms on 172.35.30.152 (executor 1) (120/590)
"
1760334940371,"INFO	2025-10-13T05:55:40,370	221680	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 158.0 in stage 0.0 (TID 158) (172.34.1.110, executor 14, partition 158, PROCESS_LOCAL, 29316 bytes) 
"
1760334940371,"INFO	2025-10-13T05:55:40,371	221681	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 114.0 in stage 0.0 (TID 114) in 34162 ms on 172.34.1.110 (executor 14) (121/590)
"
1760334940817,"INFO	2025-10-13T05:55:40,817	222127	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 159.0 in stage 0.0 (TID 159) (172.34.78.80, executor 12, partition 159, PROCESS_LOCAL, 29316 bytes) 
"
1760334940818,"INFO	2025-10-13T05:55:40,818	222128	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 122.0 in stage 0.0 (TID 122) in 33545 ms on 172.34.78.80 (executor 12) (122/590)
"
1760334940921,"INFO	2025-10-13T05:55:40,921	222231	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 160.0 in stage 0.0 (TID 160) (172.34.78.80, executor 12, partition 160, PROCESS_LOCAL, 29316 bytes) 
"
1760334940922,"INFO	2025-10-13T05:55:40,921	222231	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 125.0 in stage 0.0 (TID 125) in 33343 ms on 172.34.78.80 (executor 12) (123/590)
"
1760334940935,"INFO	2025-10-13T05:55:40,935	222245	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 161.0 in stage 0.0 (TID 161) (172.34.76.221, executor 11, partition 161, PROCESS_LOCAL, 29316 bytes) 
"
1760334940936,"INFO	2025-10-13T05:55:40,936	222246	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 117.0 in stage 0.0 (TID 117) in 33880 ms on 172.34.76.221 (executor 11) (124/590)
"
1760334941892,"INFO	2025-10-13T05:55:41,892	223202	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 162.0 in stage 0.0 (TID 162) (172.34.59.71, executor 19, partition 162, PROCESS_LOCAL, 29316 bytes) 
"
1760334941893,"INFO	2025-10-13T05:55:41,893	223203	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 121.0 in stage 0.0 (TID 121) in 34636 ms on 172.34.59.71 (executor 19) (125/590)
"
1760334941994,"INFO	2025-10-13T05:55:41,994	223304	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 163.0 in stage 0.0 (TID 163) (172.35.230.30, executor 7, partition 163, PROCESS_LOCAL, 29316 bytes) 
"
1760334941994,"INFO	2025-10-13T05:55:41,994	223304	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 129.0 in stage 0.0 (TID 129) in 31930 ms on 172.35.230.30 (executor 7) (126/590)
"
1760334942117,"INFO	2025-10-13T05:55:42,117	223427	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 164.0 in stage 0.0 (TID 164) (172.35.115.9, executor 10, partition 164, PROCESS_LOCAL, 29316 bytes) 
"
1760334942118,"INFO	2025-10-13T05:55:42,118	223428	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 126.0 in stage 0.0 (TID 126) in 32837 ms on 172.35.115.9 (executor 10) (127/590)
"
1760334942256,"INFO	2025-10-13T05:55:42,256	223566	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 165.0 in stage 0.0 (TID 165) (172.34.59.71, executor 19, partition 165, PROCESS_LOCAL, 29316 bytes) 
"
1760334942257,"INFO	2025-10-13T05:55:42,257	223567	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 116.0 in stage 0.0 (TID 116) in 35213 ms on 172.34.59.71 (executor 19) (128/590)
"
1760334942698,"INFO	2025-10-13T05:55:42,698	224008	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 166.0 in stage 0.0 (TID 166) (172.34.76.221, executor 11, partition 166, PROCESS_LOCAL, 29316 bytes) 
"
1760334942699,"INFO	2025-10-13T05:55:42,699	224009	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 123.0 in stage 0.0 (TID 123) in 35347 ms on 172.34.76.221 (executor 11) (129/590)
"
1760334942826,"INFO	2025-10-13T05:55:42,826	224136	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 167.0 in stage 0.0 (TID 167) (172.34.102.82, executor 18, partition 167, PROCESS_LOCAL, 29316 bytes) 
"
1760334942827,"INFO	2025-10-13T05:55:42,826	224136	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 127.0 in stage 0.0 (TID 127) in 32983 ms on 172.34.102.82 (executor 18) (130/590)
"
1760334943047,"INFO	2025-10-13T05:55:43,047	224357	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 168.0 in stage 0.0 (TID 168) (172.34.102.82, executor 18, partition 168, PROCESS_LOCAL, 29316 bytes) 
"
1760334943048,"INFO	2025-10-13T05:55:43,047	224357	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 128.0 in stage 0.0 (TID 128) in 33070 ms on 172.34.102.82 (executor 18) (131/590)
"
1760334943315,"INFO	2025-10-13T05:55:43,314	224624	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 169.0 in stage 0.0 (TID 169) (172.34.139.155, executor 15, partition 169, PROCESS_LOCAL, 29316 bytes) 
"
1760334943315,"INFO	2025-10-13T05:55:43,315	224625	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 131.0 in stage 0.0 (TID 131) in 32736 ms on 172.34.139.155 (executor 15) (132/590)
"
1760334943770,"INFO	2025-10-13T05:55:43,770	225080	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 170.0 in stage 0.0 (TID 170) (172.35.115.9, executor 10, partition 170, PROCESS_LOCAL, 29316 bytes) 
"
1760334943771,"INFO	2025-10-13T05:55:43,771	225081	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 130.0 in stage 0.0 (TID 130) in 33394 ms on 172.35.115.9 (executor 10) (133/590)
"
1760334944157,"INFO	2025-10-13T05:55:44,156	225466	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 171.0 in stage 0.0 (TID 171) (172.34.139.155, executor 15, partition 171, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:55:44,156	225466	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 132.0 in stage 0.0 (TID 132) in 33454 ms on 172.34.139.155 (executor 15) (134/590)
"
1760334944355,"INFO	2025-10-13T05:55:44,354	225664	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 172.0 in stage 0.0 (TID 172) (172.34.249.48, executor 17, partition 172, PROCESS_LOCAL, 29316 bytes) 
"
1760334944355,"INFO	2025-10-13T05:55:44,355	225665	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 140.0 in stage 0.0 (TID 140) in 24393 ms on 172.34.249.48 (executor 17) (135/590)
"
1760334945043,"INFO	2025-10-13T05:55:45,042	226352	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 173.0 in stage 0.0 (TID 173) (172.34.247.5, executor 6, partition 173, PROCESS_LOCAL, 29316 bytes) 
"
1760334945044,"INFO	2025-10-13T05:55:45,043	226353	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 133.0 in stage 0.0 (TID 133) in 34266 ms on 172.34.247.5 (executor 6) (136/590)
"
1760334945428,"INFO	2025-10-13T05:55:45,427	226737	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 174.0 in stage 0.0 (TID 174) (172.34.145.94, executor 3, partition 174, PROCESS_LOCAL, 29316 bytes) 
"
1760334945428,"INFO	2025-10-13T05:55:45,428	226738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 136.0 in stage 0.0 (TID 136) in 31689 ms on 172.34.145.94 (executor 3) (137/590)
"
1760334945567,"INFO	2025-10-13T05:55:45,566	226876	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 175.0 in stage 0.0 (TID 175) (172.35.34.68, executor 9, partition 175, PROCESS_LOCAL, 29316 bytes) 
"
1760334945567,"INFO	2025-10-13T05:55:45,567	226877	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 135.0 in stage 0.0 (TID 135) in 32596 ms on 172.35.34.68 (executor 9) (138/590)
"
1760334946848,"INFO	2025-10-13T05:55:46,848	228158	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 176.0 in stage 0.0 (TID 176) (172.35.34.68, executor 9, partition 176, PROCESS_LOCAL, 29316 bytes) 
"
1760334946848,"INFO	2025-10-13T05:55:46,848	228158	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 137.0 in stage 0.0 (TID 137) in 32948 ms on 172.35.34.68 (executor 9) (139/590)
"
1760334947641,"INFO	2025-10-13T05:55:47,640	228950	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 177.0 in stage 0.0 (TID 177) (172.34.247.5, executor 6, partition 177, PROCESS_LOCAL, 29316 bytes) 
"
1760334947641,"INFO	2025-10-13T05:55:47,641	228951	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 134.0 in stage 0.0 (TID 134) in 35190 ms on 172.34.247.5 (executor 6) (140/590)
"
1760334947813,"INFO	2025-10-13T05:55:47,812	229122	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 178.0 in stage 0.0 (TID 178) (172.34.145.94, executor 3, partition 178, PROCESS_LOCAL, 29316 bytes) 
"
1760334947813,"INFO	2025-10-13T05:55:47,813	229123	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 138.0 in stage 0.0 (TID 138) in 32400 ms on 172.34.145.94 (executor 3) (141/590)
"
1760334953009,"INFO	2025-10-13T05:55:53,008	234318	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 179.0 in stage 0.0 (TID 179) (172.34.158.2, executor 2, partition 179, PROCESS_LOCAL, 29316 bytes) 
"
1760334953009,"INFO	2025-10-13T05:55:53,009	234319	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 141.0 in stage 0.0 (TID 141) in 32285 ms on 172.34.158.2 (executor 2) (142/590)
"
1760334953084,"INFO	2025-10-13T05:55:53,083	234393	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 180.0 in stage 0.0 (TID 180) (172.35.30.152, executor 1, partition 180, PROCESS_LOCAL, 29316 bytes) 
"
1760334953084,"INFO	2025-10-13T05:55:53,084	234394	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 144.0 in stage 0.0 (TID 144) in 23413 ms on 172.35.30.152 (executor 1) (143/590)
"
1760334953380,"INFO	2025-10-13T05:55:53,380	234690	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334953381,"INFO	2025-10-13T05:55:53,380	234690	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 35, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334953381,"INFO	2025-10-13T05:55:53,381	234691	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 35; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_35_a_spark-application-1760334728567_p_1
"
1760334953381,"INFO	2025-10-13T05:55:53,381	234691	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334953430,"INFO	2025-10-13T05:55:53,430	234740	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334953430,"INFO	2025-10-13T05:55:53,430	234740	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 37519683-e771-4654-acad-923da1e9e8ee)
"
1760334953430,"INFO	2025-10-13T05:55:53,430	234740	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 35 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334956086,"INFO	2025-10-13T05:55:56,086	237396	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 181.0 in stage 0.0 (TID 181) (172.34.158.2, executor 2, partition 181, PROCESS_LOCAL, 29316 bytes) 
"
1760334956086,"INFO	2025-10-13T05:55:56,086	237396	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 142.0 in stage 0.0 (TID 142) in 33424 ms on 172.34.158.2 (executor 2) (144/590)
"
1760334956123,"INFO	2025-10-13T05:55:56,122	237432	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 182.0 in stage 0.0 (TID 182) (172.34.249.48, executor 17, partition 182, PROCESS_LOCAL, 29316 bytes) 
"
1760334956123,"INFO	2025-10-13T05:55:56,123	237433	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 147.0 in stage 0.0 (TID 147) in 24363 ms on 172.34.249.48 (executor 17) (145/590)
"
1760334961656,"INFO	2025-10-13T05:56:01,655	242965	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 183.0 in stage 0.0 (TID 183) (172.35.116.46, executor 4, partition 183, PROCESS_LOCAL, 29316 bytes) 
"
1760334961657,"INFO	2025-10-13T05:56:01,656	242966	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 143.0 in stage 0.0 (TID 143) in 32637 ms on 172.35.116.46 (executor 4) (146/590)
"
1760334962259,"INFO	2025-10-13T05:56:02,258	243568	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334962259,"INFO	2025-10-13T05:56:02,259	243569	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 36, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334962259,"INFO	2025-10-13T05:56:02,259	243569	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 36; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_36_a_spark-application-1760334728567_p_1
"
1760334962260,"INFO	2025-10-13T05:56:02,259	243569	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334962302,"INFO	2025-10-13T05:56:02,301	243611	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334962302,"INFO	2025-10-13T05:56:02,301	243611	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 6acbf992-8083-45c0-b17d-d70502525db4)
"
1760334962302,"INFO	2025-10-13T05:56:02,302	243612	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 36 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334962863,"INFO	2025-10-13T05:56:02,863	244173	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 184.0 in stage 0.0 (TID 184) (172.34.117.91, executor 13, partition 184, PROCESS_LOCAL, 29316 bytes) 
"
1760334962864,"INFO	2025-10-13T05:56:02,863	244173	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 146.0 in stage 0.0 (TID 146) in 31204 ms on 172.34.117.91 (executor 13) (147/590)
"
1760334963332,"INFO	2025-10-13T05:56:03,332	244642	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 185.0 in stage 0.0 (TID 185) (172.35.116.46, executor 4, partition 185, PROCESS_LOCAL, 29316 bytes) 
"
1760334963333,"INFO	2025-10-13T05:56:03,333	244643	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 145.0 in stage 0.0 (TID 145) in 33061 ms on 172.35.116.46 (executor 4) (148/590)
"
1760334963780,"INFO	2025-10-13T05:56:03,780	245090	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 186.0 in stage 0.0 (TID 186) (172.34.117.91, executor 13, partition 186, PROCESS_LOCAL, 29316 bytes) 
"
1760334963781,"INFO	2025-10-13T05:56:03,781	245091	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 148.0 in stage 0.0 (TID 148) in 31196 ms on 172.34.117.91 (executor 13) (149/590)
"
1760334964494,"INFO	2025-10-13T05:56:04,493	245803	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 187.0 in stage 0.0 (TID 187) (172.35.30.152, executor 1, partition 187, PROCESS_LOCAL, 29316 bytes) 
"
1760334964494,"INFO	2025-10-13T05:56:04,494	245804	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 157.0 in stage 0.0 (TID 157) in 24158 ms on 172.35.30.152 (executor 1) (150/590)
"
1760334968653,"INFO	2025-10-13T05:56:08,652	249962	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 188.0 in stage 0.0 (TID 188) (172.34.249.48, executor 17, partition 188, PROCESS_LOCAL, 29316 bytes) 
"
1760334968654,"INFO	2025-10-13T05:56:08,653	249963	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 172.0 in stage 0.0 (TID 172) in 24299 ms on 172.34.249.48 (executor 17) (151/590)
"
1760334968693,"INFO	2025-10-13T05:56:08,692	250002	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760334968693,"INFO	2025-10-13T05:56:08,693	250003	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760334969224,"INFO	2025-10-13T05:56:09,224	250534	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 189.0 in stage 0.0 (TID 189) (172.35.53.249, executor 8, partition 189, PROCESS_LOCAL, 29316 bytes) 
"
1760334969225,"INFO	2025-10-13T05:56:09,225	250535	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 149.0 in stage 0.0 (TID 149) in 32421 ms on 172.35.53.249 (executor 8) (152/590)
"
1760334969745,"INFO	2025-10-13T05:56:09,744	251054	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 190.0 in stage 0.0 (TID 190) (172.35.53.249, executor 8, partition 190, PROCESS_LOCAL, 29316 bytes) 
"
1760334969745,"INFO	2025-10-13T05:56:09,745	251055	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 150.0 in stage 0.0 (TID 150) in 32596 ms on 172.35.53.249 (executor 8) (153/590)
"
1760334970117,"INFO	2025-10-13T05:56:10,117	251427	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 191.0 in stage 0.0 (TID 191) (172.34.233.198, executor 5, partition 191, PROCESS_LOCAL, 29316 bytes) 
"
1760334970118,"INFO	2025-10-13T05:56:10,117	251427	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 152.0 in stage 0.0 (TID 152) in 31998 ms on 172.34.233.198 (executor 5) (154/590)
"
1760334970125,"INFO	2025-10-13T05:56:10,124	251434	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 192.0 in stage 0.0 (TID 192) (172.34.233.198, executor 5, partition 192, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:56:10,125	251435	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 151.0 in stage 0.0 (TID 151) in 32316 ms on 172.34.233.198 (executor 5) (155/590)
"
1760334970776,"INFO	2025-10-13T05:56:10,776	252086	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 193.0 in stage 0.0 (TID 193) (172.35.230.30, executor 7, partition 193, PROCESS_LOCAL, 29316 bytes) 
"
1760334970777,"INFO	2025-10-13T05:56:10,776	252086	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 153.0 in stage 0.0 (TID 153) in 31699 ms on 172.35.230.30 (executor 7) (156/590)
"
1760334971610,"INFO	2025-10-13T05:56:11,610	252920	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 194.0 in stage 0.0 (TID 194) (172.34.89.92, executor 16, partition 194, PROCESS_LOCAL, 29316 bytes) 
"
1760334971611,"INFO	2025-10-13T05:56:11,610	252920	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 154.0 in stage 0.0 (TID 154) in 32109 ms on 172.34.89.92 (executor 16) (157/590)
"
1760334972198,"INFO	2025-10-13T05:56:12,198	253508	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 195.0 in stage 0.0 (TID 195) (172.34.89.92, executor 16, partition 195, PROCESS_LOCAL, 29316 bytes) 
"
1760334972199,"INFO	2025-10-13T05:56:12,199	253509	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 156.0 in stage 0.0 (TID 156) in 32011 ms on 172.34.89.92 (executor 16) (158/590)
"
1760334972577,"INFO	2025-10-13T05:56:12,576	253886	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 196.0 in stage 0.0 (TID 196) (172.34.1.110, executor 14, partition 196, PROCESS_LOCAL, 29316 bytes) 
"
1760334972577,"INFO	2025-10-13T05:56:12,577	253887	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 155.0 in stage 0.0 (TID 155) in 33060 ms on 172.34.1.110 (executor 14) (159/590)
"
1760334972648,"INFO	2025-10-13T05:56:12,648	253958	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 197.0 in stage 0.0 (TID 197) (172.34.76.221, executor 11, partition 197, PROCESS_LOCAL, 29316 bytes) 
"
1760334972648,"INFO	2025-10-13T05:56:12,648	253958	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 161.0 in stage 0.0 (TID 161) in 31713 ms on 172.34.76.221 (executor 11) (160/590)
"
1760334973634,"INFO	2025-10-13T05:56:13,633	254943	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 198.0 in stage 0.0 (TID 198) (172.34.78.80, executor 12, partition 198, PROCESS_LOCAL, 29316 bytes) 
"
1760334973634,"INFO	2025-10-13T05:56:13,634	254944	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 159.0 in stage 0.0 (TID 159) in 32817 ms on 172.34.78.80 (executor 12) (161/590)
"
1760334973826,"INFO	2025-10-13T05:56:13,826	255136	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 199.0 in stage 0.0 (TID 199) (172.34.78.80, executor 12, partition 199, PROCESS_LOCAL, 29316 bytes) 
"
1760334973827,"INFO	2025-10-13T05:56:13,826	255136	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 160.0 in stage 0.0 (TID 160) in 32906 ms on 172.34.78.80 (executor 12) (162/590)
"
1760334974002,"INFO	2025-10-13T05:56:14,001	255311	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 200.0 in stage 0.0 (TID 200) (172.35.230.30, executor 7, partition 200, PROCESS_LOCAL, 29316 bytes) 
"
1760334974002,"INFO	2025-10-13T05:56:14,002	255312	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 163.0 in stage 0.0 (TID 163) in 32009 ms on 172.35.230.30 (executor 7) (163/590)
"
1760334974106,"INFO	2025-10-13T05:56:14,105	255415	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 201.0 in stage 0.0 (TID 201) (172.34.1.110, executor 14, partition 201, PROCESS_LOCAL, 29316 bytes) 
"
1760334974106,"INFO	2025-10-13T05:56:14,106	255416	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 158.0 in stage 0.0 (TID 158) in 33736 ms on 172.34.1.110 (executor 14) (164/590)
"
1760334974635,"INFO	2025-10-13T05:56:14,635	255945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 202.0 in stage 0.0 (TID 202) (172.34.59.71, executor 19, partition 202, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:56:14,635	255945	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 162.0 in stage 0.0 (TID 162) in 32743 ms on 172.34.59.71 (executor 19) (165/590)
"
1760334974742,"INFO	2025-10-13T05:56:14,742	256052	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 203.0 in stage 0.0 (TID 203) (172.34.59.71, executor 19, partition 203, PROCESS_LOCAL, 29316 bytes) 
"
1760334974742,"INFO	2025-10-13T05:56:14,742	256052	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 165.0 in stage 0.0 (TID 165) in 32486 ms on 172.34.59.71 (executor 19) (166/590)
"
1760334975321,"INFO	2025-10-13T05:56:15,321	256631	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 204.0 in stage 0.0 (TID 204) (172.35.115.9, executor 10, partition 204, PROCESS_LOCAL, 29316 bytes) 
"
1760334975322,"INFO	2025-10-13T05:56:15,321	256631	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 164.0 in stage 0.0 (TID 164) in 33204 ms on 172.35.115.9 (executor 10) (167/590)
"
1760334975885,"INFO	2025-10-13T05:56:15,884	257194	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 205.0 in stage 0.0 (TID 205) (172.34.102.82, executor 18, partition 205, PROCESS_LOCAL, 29316 bytes) 
"
1760334975885,"INFO	2025-10-13T05:56:15,885	257195	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 168.0 in stage 0.0 (TID 168) in 32838 ms on 172.34.102.82 (executor 18) (168/590)
"
1760334976313,"INFO	2025-10-13T05:56:16,313	257623	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 206.0 in stage 0.0 (TID 206) (172.34.247.5, executor 6, partition 206, PROCESS_LOCAL, 29316 bytes) 
"
1760334976314,"INFO	2025-10-13T05:56:16,314	257624	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 173.0 in stage 0.0 (TID 173) in 31272 ms on 172.34.247.5 (executor 6) (169/590)
"
1760334976334,"INFO	2025-10-13T05:56:16,334	257644	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 207.0 in stage 0.0 (TID 207) (172.34.139.155, executor 15, partition 207, PROCESS_LOCAL, 29316 bytes) 
"
1760334976335,"INFO	2025-10-13T05:56:16,335	257645	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 169.0 in stage 0.0 (TID 169) in 33021 ms on 172.34.139.155 (executor 15) (170/590)
"
1760334976583,"INFO	2025-10-13T05:56:16,583	257893	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 208.0 in stage 0.0 (TID 208) (172.34.145.94, executor 3, partition 208, PROCESS_LOCAL, 29316 bytes) 
"
1760334976583,"INFO	2025-10-13T05:56:16,583	257893	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 174.0 in stage 0.0 (TID 174) in 31156 ms on 172.34.145.94 (executor 3) (171/590)
"
1760334976865,"INFO	2025-10-13T05:56:16,864	258174	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 209.0 in stage 0.0 (TID 209) (172.35.115.9, executor 10, partition 209, PROCESS_LOCAL, 29316 bytes) 
"
1760334976865,"INFO	2025-10-13T05:56:16,865	258175	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 170.0 in stage 0.0 (TID 170) in 33095 ms on 172.35.115.9 (executor 10) (172/590)
"
1760334976869,"INFO	2025-10-13T05:56:16,869	258179	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 210.0 in stage 0.0 (TID 210) (172.34.76.221, executor 11, partition 210, PROCESS_LOCAL, 29316 bytes) 
"
1760334976870,"INFO	2025-10-13T05:56:16,869	258179	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 166.0 in stage 0.0 (TID 166) in 34171 ms on 172.34.76.221 (executor 11) (173/590)
"
1760334977053,"INFO	2025-10-13T05:56:17,052	258362	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 211.0 in stage 0.0 (TID 211) (172.35.30.152, executor 1, partition 211, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:56:17,052	258362	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 180.0 in stage 0.0 (TID 180) in 23969 ms on 172.35.30.152 (executor 1) (174/590)
"
1760334977467,"INFO	2025-10-13T05:56:17,467	258777	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 212.0 in stage 0.0 (TID 212) (172.35.34.68, executor 9, partition 212, PROCESS_LOCAL, 29316 bytes) 
"
1760334977467,"INFO	2025-10-13T05:56:17,467	258777	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 175.0 in stage 0.0 (TID 175) in 31901 ms on 172.35.34.68 (executor 9) (175/590)
"
1760334977542,"INFO	2025-10-13T05:56:17,542	258852	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 213.0 in stage 0.0 (TID 213) (172.34.102.82, executor 18, partition 213, PROCESS_LOCAL, 29316 bytes) 
"
1760334977542,"INFO	2025-10-13T05:56:17,542	258852	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 167.0 in stage 0.0 (TID 167) in 34716 ms on 172.34.102.82 (executor 18) (176/590)
"
1760334977619,"INFO	2025-10-13T05:56:17,619	258929	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334977620,"INFO	2025-10-13T05:56:17,619	258929	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 37, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334977620,"INFO	2025-10-13T05:56:17,620	258930	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 37; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_37_a_spark-application-1760334728567_p_1
"
1760334977620,"INFO	2025-10-13T05:56:17,620	258930	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334977655,"INFO	2025-10-13T05:56:17,654	258964	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334977655,"INFO	2025-10-13T05:56:17,655	258965	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: a47cbfc1-d2ff-41ca-b1c2-9fc1d0be742d)
"
1760334977655,"INFO	2025-10-13T05:56:17,655	258965	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 37 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334978072,"INFO	2025-10-13T05:56:18,072	259382	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 214.0 in stage 0.0 (TID 214) (172.34.139.155, executor 15, partition 214, PROCESS_LOCAL, 29316 bytes) 
"
1760334978073,"INFO	2025-10-13T05:56:18,073	259383	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 171.0 in stage 0.0 (TID 171) in 33918 ms on 172.34.139.155 (executor 15) (177/590)
"
1760334979289,"INFO	2025-10-13T05:56:19,289	260599	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 215.0 in stage 0.0 (TID 215) (172.35.34.68, executor 9, partition 215, PROCESS_LOCAL, 29316 bytes) 
"
1760334979289,"INFO	2025-10-13T05:56:19,289	260599	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 176.0 in stage 0.0 (TID 176) in 32442 ms on 172.35.34.68 (executor 9) (178/590)
"
1760334979304,"INFO	2025-10-13T05:56:19,303	260613	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 216.0 in stage 0.0 (TID 216) (172.34.145.94, executor 3, partition 216, PROCESS_LOCAL, 29316 bytes) 
"
1760334979304,"INFO	2025-10-13T05:56:19,304	260614	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 178.0 in stage 0.0 (TID 178) in 31492 ms on 172.34.145.94 (executor 3) (179/590)
"
1760334980650,"INFO	2025-10-13T05:56:20,650	261960	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 217.0 in stage 0.0 (TID 217) (172.34.247.5, executor 6, partition 217, PROCESS_LOCAL, 29316 bytes) 
"
1760334980651,"INFO	2025-10-13T05:56:20,650	261960	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 177.0 in stage 0.0 (TID 177) in 33010 ms on 172.34.247.5 (executor 6) (180/590)
"
1760334980770,"INFO	2025-10-13T05:56:20,769	262079	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 218.0 in stage 0.0 (TID 218) (172.34.249.48, executor 17, partition 218, PROCESS_LOCAL, 29316 bytes) 
"
1760334980770,"INFO	2025-10-13T05:56:20,770	262080	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 182.0 in stage 0.0 (TID 182) in 24648 ms on 172.34.249.48 (executor 17) (181/590)
"
1760334984033,"INFO	2025-10-13T05:56:24,033	265343	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 219.0 in stage 0.0 (TID 219) (172.34.158.2, executor 2, partition 219, PROCESS_LOCAL, 29316 bytes) 
"
1760334984034,"INFO	2025-10-13T05:56:24,034	265344	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 179.0 in stage 0.0 (TID 179) in 31026 ms on 172.34.158.2 (executor 2) (182/590)
"
1760334988040,"INFO	2025-10-13T05:56:28,039	269349	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334988040,"INFO	2025-10-13T05:56:28,040	269350	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 38, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334988040,"INFO	2025-10-13T05:56:28,040	269350	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 38; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_38_a_spark-application-1760334728567_p_1
"
1760334988040,"INFO	2025-10-13T05:56:28,040	269350	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334988070,"INFO	2025-10-13T05:56:28,070	269380	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334988070,"INFO	2025-10-13T05:56:28,070	269380	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 32ec5585-98be-4ac3-8f34-65b49bec31a9)
INFO	2025-10-13T05:56:28,070	269380	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 38 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760334988453,"INFO	2025-10-13T05:56:28,453	269763	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 220.0 in stage 0.0 (TID 220) (172.34.158.2, executor 2, partition 220, PROCESS_LOCAL, 29316 bytes) 
"
1760334988453,"INFO	2025-10-13T05:56:28,453	269763	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 181.0 in stage 0.0 (TID 181) in 32368 ms on 172.34.158.2 (executor 2) (183/590)
"
1760334988820,"INFO	2025-10-13T05:56:28,820	270130	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 221.0 in stage 0.0 (TID 221) (172.35.30.152, executor 1, partition 221, PROCESS_LOCAL, 29316 bytes) 
"
1760334988821,"INFO	2025-10-13T05:56:28,820	270130	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 187.0 in stage 0.0 (TID 187) in 24327 ms on 172.35.30.152 (executor 1) (184/590)
"
1760334994023,"INFO	2025-10-13T05:56:34,023	275333	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 222.0 in stage 0.0 (TID 222) (172.34.117.91, executor 13, partition 222, PROCESS_LOCAL, 29316 bytes) 
"
1760334994024,"INFO	2025-10-13T05:56:34,023	275333	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 184.0 in stage 0.0 (TID 184) in 31160 ms on 172.34.117.91 (executor 13) (185/590)
"
1760334994243,"INFO	2025-10-13T05:56:34,243	275553	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 223.0 in stage 0.0 (TID 223) (172.35.116.46, executor 4, partition 223, PROCESS_LOCAL, 29316 bytes) 
"
1760334994243,"INFO	2025-10-13T05:56:34,243	275553	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 183.0 in stage 0.0 (TID 183) in 32588 ms on 172.35.116.46 (executor 4) (186/590)
"
1760334994408,"INFO	2025-10-13T05:56:34,408	275718	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 224.0 in stage 0.0 (TID 224) (172.34.249.48, executor 17, partition 224, PROCESS_LOCAL, 29316 bytes) 
"
1760334994408,"INFO	2025-10-13T05:56:34,408	275718	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 188.0 in stage 0.0 (TID 188) in 25756 ms on 172.34.249.48 (executor 17) (187/590)
"
1760334994875,"INFO	2025-10-13T05:56:34,875	276185	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 225.0 in stage 0.0 (TID 225) (172.34.117.91, executor 13, partition 225, PROCESS_LOCAL, 29316 bytes) 
"
1760334994876,"INFO	2025-10-13T05:56:34,875	276185	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 186.0 in stage 0.0 (TID 186) in 31095 ms on 172.34.117.91 (executor 13) (188/590)
"
1760334995974,"INFO	2025-10-13T05:56:35,973	277283	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 226.0 in stage 0.0 (TID 226) (172.35.116.46, executor 4, partition 226, PROCESS_LOCAL, 29316 bytes) 
"
1760334995974,"INFO	2025-10-13T05:56:35,973	277283	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 185.0 in stage 0.0 (TID 185) in 32641 ms on 172.35.116.46 (executor 4) (189/590)
"
1760334998482,"INFO	2025-10-13T05:56:38,481	279791	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760334998482,"INFO	2025-10-13T05:56:38,482	279792	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 39, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760334998482,"INFO	2025-10-13T05:56:38,482	279792	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 39; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_39_a_spark-application-1760334728567_p_1
"
1760334998482,"INFO	2025-10-13T05:56:38,482	279792	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760334998511,"INFO	2025-10-13T05:56:38,511	279821	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760334998512,"INFO	2025-10-13T05:56:38,511	279821	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 1917900e-a359-46b0-a306-75e8cbb62857)
"
1760334998512,"INFO	2025-10-13T05:56:38,512	279822	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 39 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335001153,"INFO	2025-10-13T05:56:41,153	282463	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335001154,"INFO	2025-10-13T05:56:41,153	282463	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 40, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335001154,"INFO	2025-10-13T05:56:41,154	282464	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 40; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_40_a_spark-application-1760334728567_p_1
"
1760335001154,"INFO	2025-10-13T05:56:41,154	282464	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335001188,"INFO	2025-10-13T05:56:41,188	282498	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 227.0 in stage 0.0 (TID 227) (172.35.30.152, executor 1, partition 227, PROCESS_LOCAL, 29316 bytes) 
"
1760335001188,"INFO	2025-10-13T05:56:41,188	282498	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 211.0 in stage 0.0 (TID 211) in 24136 ms on 172.35.30.152 (executor 1) (190/590)
"
1760335001190,"INFO	2025-10-13T05:56:41,190	282500	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335001190,"INFO	2025-10-13T05:56:41,190	282500	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 8d8cc142-162d-49d4-a53e-39a9f62e009b)
"
1760335001190,"INFO	2025-10-13T05:56:41,190	282500	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 40 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335003048,"INFO	2025-10-13T05:56:43,048	284358	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 228.0 in stage 0.0 (TID 228) (172.35.53.249, executor 8, partition 228, PROCESS_LOCAL, 29316 bytes) 
"
1760335003049,"INFO	2025-10-13T05:56:43,048	284358	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 189.0 in stage 0.0 (TID 189) in 33824 ms on 172.35.53.249 (executor 8) (191/590)
"
1760335003406,"INFO	2025-10-13T05:56:43,406	284716	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 229.0 in stage 0.0 (TID 229) (172.35.53.249, executor 8, partition 229, PROCESS_LOCAL, 29316 bytes) 
"
1760335003406,"INFO	2025-10-13T05:56:43,406	284716	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 190.0 in stage 0.0 (TID 190) in 33662 ms on 172.35.53.249 (executor 8) (192/590)
"
1760335003749,"INFO	2025-10-13T05:56:43,749	285059	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 230.0 in stage 0.0 (TID 230) (172.35.230.30, executor 7, partition 230, PROCESS_LOCAL, 29316 bytes) 
"
1760335003750,"INFO	2025-10-13T05:56:43,749	285059	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 193.0 in stage 0.0 (TID 193) in 32973 ms on 172.35.230.30 (executor 7) (193/590)
"
1760335003936,"INFO	2025-10-13T05:56:43,936	285246	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 231.0 in stage 0.0 (TID 231) (172.34.233.198, executor 5, partition 231, PROCESS_LOCAL, 29316 bytes) 
"
1760335003936,"INFO	2025-10-13T05:56:43,936	285246	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 192.0 in stage 0.0 (TID 192) in 33812 ms on 172.34.233.198 (executor 5) (194/590)
"
1760335004086,"INFO	2025-10-13T05:56:44,086	285396	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 232.0 in stage 0.0 (TID 232) (172.34.233.198, executor 5, partition 232, PROCESS_LOCAL, 29316 bytes) 
"
1760335004087,"INFO	2025-10-13T05:56:44,087	285397	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 191.0 in stage 0.0 (TID 191) in 33971 ms on 172.34.233.198 (executor 5) (195/590)
"
1760335004825,"INFO	2025-10-13T05:56:44,825	286135	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 233.0 in stage 0.0 (TID 233) (172.34.89.92, executor 16, partition 233, PROCESS_LOCAL, 29316 bytes) 
"
1760335004825,"INFO	2025-10-13T05:56:44,825	286135	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 194.0 in stage 0.0 (TID 194) in 33216 ms on 172.34.89.92 (executor 16) (196/590)
"
1760335005421,"INFO	2025-10-13T05:56:45,421	286731	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 234.0 in stage 0.0 (TID 234) (172.34.89.92, executor 16, partition 234, PROCESS_LOCAL, 29316 bytes) 
"
1760335005421,"INFO	2025-10-13T05:56:45,421	286731	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 195.0 in stage 0.0 (TID 195) in 33223 ms on 172.34.89.92 (executor 16) (197/590)
"
1760335005490,"INFO	2025-10-13T05:56:45,490	286800	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 235.0 in stage 0.0 (TID 235) (172.34.249.48, executor 17, partition 235, PROCESS_LOCAL, 29316 bytes) 
"
1760335005490,"INFO	2025-10-13T05:56:45,490	286800	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 218.0 in stage 0.0 (TID 218) in 24721 ms on 172.34.249.48 (executor 17) (198/590)
"
1760335005813,"INFO	2025-10-13T05:56:45,813	287123	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 236.0 in stage 0.0 (TID 236) (172.34.1.110, executor 14, partition 236, PROCESS_LOCAL, 29316 bytes) 
"
1760335005813,"INFO	2025-10-13T05:56:45,813	287123	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 196.0 in stage 0.0 (TID 196) in 33237 ms on 172.34.1.110 (executor 14) (199/590)
"
1760335006390,"INFO	2025-10-13T05:56:46,389	287699	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335006390,"INFO	2025-10-13T05:56:46,390	287700	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 41, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335006390,"INFO	2025-10-13T05:56:46,390	287700	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 41; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_41_a_spark-application-1760334728567_p_1
"
1760335006391,"INFO	2025-10-13T05:56:46,390	287700	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335006430,"INFO	2025-10-13T05:56:46,430	287740	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335006430,"INFO	2025-10-13T05:56:46,430	287740	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: e359d052-34aa-4876-8e9b-9d9e31b445e6)
"
1760335006430,"INFO	2025-10-13T05:56:46,430	287740	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 41 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335006540,"INFO	2025-10-13T05:56:46,539	287849	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 237.0 in stage 0.0 (TID 237) (172.34.76.221, executor 11, partition 237, PROCESS_LOCAL, 29316 bytes) 
"
1760335006540,"INFO	2025-10-13T05:56:46,540	287850	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 197.0 in stage 0.0 (TID 197) in 33893 ms on 172.34.76.221 (executor 11) (200/590)
"
1760335007028,"INFO	2025-10-13T05:56:47,028	288338	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 238.0 in stage 0.0 (TID 238) (172.35.230.30, executor 7, partition 238, PROCESS_LOCAL, 29316 bytes) 
"
1760335007029,"INFO	2025-10-13T05:56:47,029	288339	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 200.0 in stage 0.0 (TID 200) in 33028 ms on 172.35.230.30 (executor 7) (201/590)
"
1760335007265,"INFO	2025-10-13T05:56:47,265	288575	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 239.0 in stage 0.0 (TID 239) (172.34.247.5, executor 6, partition 239, PROCESS_LOCAL, 29316 bytes) 
"
1760335007265,"INFO	2025-10-13T05:56:47,265	288575	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 206.0 in stage 0.0 (TID 206) in 30952 ms on 172.34.247.5 (executor 6) (202/590)
"
1760335007602,"INFO	2025-10-13T05:56:47,601	288911	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 240.0 in stage 0.0 (TID 240) (172.34.78.80, executor 12, partition 240, PROCESS_LOCAL, 29316 bytes) 
"
1760335007602,"INFO	2025-10-13T05:56:47,602	288912	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 198.0 in stage 0.0 (TID 198) in 33969 ms on 172.34.78.80 (executor 12) (203/590)
"
1760335007731,"INFO	2025-10-13T05:56:47,731	289041	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 241.0 in stage 0.0 (TID 241) (172.34.59.71, executor 19, partition 241, PROCESS_LOCAL, 29316 bytes) 
"
1760335007731,"INFO	2025-10-13T05:56:47,731	289041	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 202.0 in stage 0.0 (TID 202) in 33097 ms on 172.34.59.71 (executor 19) (204/590)
"
1760335007746,"INFO	2025-10-13T05:56:47,746	289056	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 242.0 in stage 0.0 (TID 242) (172.34.78.80, executor 12, partition 242, PROCESS_LOCAL, 29316 bytes) 
"
1760335007747,"INFO	2025-10-13T05:56:47,746	289056	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 199.0 in stage 0.0 (TID 199) in 33920 ms on 172.34.78.80 (executor 12) (205/590)
"
1760335007877,"INFO	2025-10-13T05:56:47,876	289186	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335007877,"INFO	2025-10-13T05:56:47,877	289187	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 42, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335007877,"INFO	2025-10-13T05:56:47,877	289187	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 42; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_42_a_spark-application-1760334728567_p_1
"
1760335007877,"INFO	2025-10-13T05:56:47,877	289187	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335007909,"INFO	2025-10-13T05:56:47,909	289219	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335007909,"INFO	2025-10-13T05:56:47,909	289219	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 4c239423-07d6-427f-9481-a1cdbd3ddf99)
"
1760335007909,"INFO	2025-10-13T05:56:47,909	289219	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 42 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335007967,"INFO	2025-10-13T05:56:47,967	289277	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 243.0 in stage 0.0 (TID 243) (172.34.145.94, executor 3, partition 243, PROCESS_LOCAL, 29316 bytes) 
"
1760335007967,"INFO	2025-10-13T05:56:47,967	289277	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 208.0 in stage 0.0 (TID 208) in 31385 ms on 172.34.145.94 (executor 3) (206/590)
"
1760335008312,"INFO	2025-10-13T05:56:48,312	289622	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 244.0 in stage 0.0 (TID 244) (172.35.115.9, executor 10, partition 244, PROCESS_LOCAL, 29316 bytes) 
"
1760335008313,"INFO	2025-10-13T05:56:48,313	289623	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 204.0 in stage 0.0 (TID 204) in 32992 ms on 172.35.115.9 (executor 10) (207/590)
"
1760335008314,"INFO	2025-10-13T05:56:48,314	289624	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 245.0 in stage 0.0 (TID 245) (172.34.1.110, executor 14, partition 245, PROCESS_LOCAL, 29316 bytes) 
"
1760335008314,"INFO	2025-10-13T05:56:48,314	289624	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 201.0 in stage 0.0 (TID 201) in 34209 ms on 172.34.1.110 (executor 14) (208/590)
"
1760335008533,"INFO	2025-10-13T05:56:48,532	289842	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 246.0 in stage 0.0 (TID 246) (172.34.102.82, executor 18, partition 246, PROCESS_LOCAL, 29316 bytes) 
"
1760335008533,"INFO	2025-10-13T05:56:48,533	289843	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 205.0 in stage 0.0 (TID 205) in 32649 ms on 172.34.102.82 (executor 18) (209/590)
"
1760335008643,"INFO	2025-10-13T05:56:48,643	289953	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 247.0 in stage 0.0 (TID 247) (172.34.59.71, executor 19, partition 247, PROCESS_LOCAL, 29316 bytes) 
"
1760335008644,"INFO	2025-10-13T05:56:48,643	289953	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 203.0 in stage 0.0 (TID 203) in 33901 ms on 172.34.59.71 (executor 19) (210/590)
"
1760335009387,"INFO	2025-10-13T05:56:49,386	290696	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 248.0 in stage 0.0 (TID 248) (172.35.34.68, executor 9, partition 248, PROCESS_LOCAL, 29316 bytes) 
"
1760335009387,"INFO	2025-10-13T05:56:49,387	290697	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 212.0 in stage 0.0 (TID 212) in 31921 ms on 172.35.34.68 (executor 9) (211/590)
"
1760335010315,"INFO	2025-10-13T05:56:50,314	291624	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 249.0 in stage 0.0 (TID 249) (172.34.139.155, executor 15, partition 249, PROCESS_LOCAL, 29316 bytes) 
"
1760335010315,"INFO	2025-10-13T05:56:50,315	291625	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 207.0 in stage 0.0 (TID 207) in 33981 ms on 172.34.139.155 (executor 15) (212/590)
"
1760335010362,"INFO	2025-10-13T05:56:50,362	291672	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 250.0 in stage 0.0 (TID 250) (172.34.102.82, executor 18, partition 250, PROCESS_LOCAL, 29316 bytes) 
"
1760335010363,"INFO	2025-10-13T05:56:50,362	291672	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 213.0 in stage 0.0 (TID 213) in 32821 ms on 172.34.102.82 (executor 18) (213/590)
"
1760335010425,"INFO	2025-10-13T05:56:50,425	291735	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 251.0 in stage 0.0 (TID 251) (172.35.115.9, executor 10, partition 251, PROCESS_LOCAL, 29316 bytes) 
"
1760335010426,"INFO	2025-10-13T05:56:50,425	291735	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 209.0 in stage 0.0 (TID 209) in 33561 ms on 172.35.115.9 (executor 10) (214/590)
"
1760335011537,"INFO	2025-10-13T05:56:51,536	292846	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 252.0 in stage 0.0 (TID 252) (172.34.145.94, executor 3, partition 252, PROCESS_LOCAL, 29316 bytes) 
"
1760335011537,"INFO	2025-10-13T05:56:51,536	292846	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 216.0 in stage 0.0 (TID 216) in 32233 ms on 172.34.145.94 (executor 3) (215/590)
"
1760335012009,"INFO	2025-10-13T05:56:52,008	293318	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 253.0 in stage 0.0 (TID 253) (172.34.76.221, executor 11, partition 253, PROCESS_LOCAL, 29316 bytes) 
"
1760335012009,"INFO	2025-10-13T05:56:52,009	293319	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 210.0 in stage 0.0 (TID 210) in 35141 ms on 172.34.76.221 (executor 11) (216/590)
"
1760335012088,"INFO	2025-10-13T05:56:52,087	293397	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 254.0 in stage 0.0 (TID 254) (172.35.34.68, executor 9, partition 254, PROCESS_LOCAL, 29316 bytes) 
"
1760335012088,"INFO	2025-10-13T05:56:52,088	293398	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 215.0 in stage 0.0 (TID 215) in 32800 ms on 172.35.34.68 (executor 9) (217/590)
"
1760335012764,"INFO	2025-10-13T05:56:52,764	294074	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 255.0 in stage 0.0 (TID 255) (172.34.139.155, executor 15, partition 255, PROCESS_LOCAL, 29316 bytes) 
"
1760335012765,"INFO	2025-10-13T05:56:52,764	294074	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 214.0 in stage 0.0 (TID 214) in 34692 ms on 172.34.139.155 (executor 15) (218/590)
"
1760335012878,"INFO	2025-10-13T05:56:52,878	294188	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 256.0 in stage 0.0 (TID 256) (172.35.30.152, executor 1, partition 256, PROCESS_LOCAL, 29316 bytes) 
"
1760335012879,"INFO	2025-10-13T05:56:52,879	294189	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 221.0 in stage 0.0 (TID 221) in 24060 ms on 172.35.30.152 (executor 1) (219/590)
"
1760335013153,"INFO	2025-10-13T05:56:53,152	294462	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335013153,"INFO	2025-10-13T05:56:53,153	294463	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 43, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335013153,"INFO	2025-10-13T05:56:53,153	294463	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 43; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_43_a_spark-application-1760334728567_p_1
"
1760335013153,"INFO	2025-10-13T05:56:53,153	294463	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335013195,"INFO	2025-10-13T05:56:53,195	294505	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335013195,"INFO	2025-10-13T05:56:53,195	294505	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: af566e82-c4d3-4978-86ae-4d8b32c5f44c)
"
1760335013195,"INFO	2025-10-13T05:56:53,195	294505	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 43 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335013601,"INFO	2025-10-13T05:56:53,601	294911	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 257.0 in stage 0.0 (TID 257) (172.34.247.5, executor 6, partition 257, PROCESS_LOCAL, 29316 bytes) 
"
1760335013601,"INFO	2025-10-13T05:56:53,601	294911	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 217.0 in stage 0.0 (TID 217) in 32952 ms on 172.34.247.5 (executor 6) (220/590)
"
1760335014472,"INFO	2025-10-13T05:56:54,471	295781	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 258.0 in stage 0.0 (TID 258) (172.34.158.2, executor 2, partition 258, PROCESS_LOCAL, 29316 bytes) 
"
1760335014473,"INFO	2025-10-13T05:56:54,472	295782	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 219.0 in stage 0.0 (TID 219) in 30439 ms on 172.34.158.2 (executor 2) (221/590)
"
1760335019242,"INFO	2025-10-13T05:56:59,241	300551	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 259.0 in stage 0.0 (TID 259) (172.34.249.48, executor 17, partition 259, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:56:59,242	300552	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 224.0 in stage 0.0 (TID 224) in 24834 ms on 172.34.249.48 (executor 17) (222/590)
"
1760335019959,"INFO	2025-10-13T05:56:59,958	301268	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 260.0 in stage 0.0 (TID 260) (172.34.158.2, executor 2, partition 260, PROCESS_LOCAL, 29316 bytes) 
"
1760335019959,"INFO	2025-10-13T05:56:59,958	301268	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 220.0 in stage 0.0 (TID 220) in 31506 ms on 172.34.158.2 (executor 2) (223/590)
"
1760335023236,"INFO	2025-10-13T05:57:03,236	304546	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 261.0 in stage 0.0 (TID 261) (172.34.117.91, executor 13, partition 261, PROCESS_LOCAL, 29316 bytes) 
"
1760335023237,"INFO	2025-10-13T05:57:03,236	304546	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 222.0 in stage 0.0 (TID 222) in 29213 ms on 172.34.117.91 (executor 13) (224/590)
"
1760335025032,"INFO	2025-10-13T05:57:05,032	306342	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 262.0 in stage 0.0 (TID 262) (172.34.117.91, executor 13, partition 262, PROCESS_LOCAL, 29316 bytes) 
"
1760335025032,"INFO	2025-10-13T05:57:05,032	306342	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 225.0 in stage 0.0 (TID 225) in 30158 ms on 172.34.117.91 (executor 13) (225/590)
"
1760335025190,"INFO	2025-10-13T05:57:05,189	306499	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 263.0 in stage 0.0 (TID 263) (172.35.30.152, executor 1, partition 263, PROCESS_LOCAL, 29316 bytes) 
"
1760335025190,"INFO	2025-10-13T05:57:05,190	306500	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 227.0 in stage 0.0 (TID 227) in 24003 ms on 172.35.30.152 (executor 1) (226/590)
"
1760335025635,"INFO	2025-10-13T05:57:05,635	306945	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 264.0 in stage 0.0 (TID 264) (172.35.116.46, executor 4, partition 264, PROCESS_LOCAL, 29316 bytes) 
"
1760335025636,"INFO	2025-10-13T05:57:05,635	306945	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 223.0 in stage 0.0 (TID 223) in 31393 ms on 172.35.116.46 (executor 4) (227/590)
"
1760335027860,"INFO	2025-10-13T05:57:07,859	309169	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 265.0 in stage 0.0 (TID 265) (172.35.116.46, executor 4, partition 265, PROCESS_LOCAL, 29316 bytes) 
"
1760335027860,"INFO	2025-10-13T05:57:07,860	309170	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 226.0 in stage 0.0 (TID 226) in 31887 ms on 172.35.116.46 (executor 4) (228/590)
"
1760335028693,"INFO	2025-10-13T05:57:08,693	310003	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760335028694,"INFO	2025-10-13T05:57:08,693	310003	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760335029108,"INFO	2025-10-13T05:57:09,107	310417	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335029108,"INFO	2025-10-13T05:57:09,108	310418	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 44, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335029108,"INFO	2025-10-13T05:57:09,108	310418	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 44; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_44_a_spark-application-1760334728567_p_1
"
1760335029108,"INFO	2025-10-13T05:57:09,108	310418	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335029157,"INFO	2025-10-13T05:57:09,157	310467	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335029158,"INFO	2025-10-13T05:57:09,157	310467	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 1cadddde-0224-4f2d-b9fa-f0d8e707a22e)
"
1760335029158,"INFO	2025-10-13T05:57:09,157	310467	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 44 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335030067,"INFO	2025-10-13T05:57:10,066	311376	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 266.0 in stage 0.0 (TID 266) (172.34.249.48, executor 17, partition 266, PROCESS_LOCAL, 29316 bytes) 
"
1760335030067,"INFO	2025-10-13T05:57:10,067	311377	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 235.0 in stage 0.0 (TID 235) in 24578 ms on 172.34.249.48 (executor 17) (229/590)
"
1760335034429,"INFO	2025-10-13T05:57:14,429	315739	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335034429,"INFO	2025-10-13T05:57:14,429	315739	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 45, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335034430,"INFO	2025-10-13T05:57:14,429	315739	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 45; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_45_a_spark-application-1760334728567_p_1
"
1760335034430,"INFO	2025-10-13T05:57:14,430	315740	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335034489,"INFO	2025-10-13T05:57:14,489	315799	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335034490,"INFO	2025-10-13T05:57:14,489	315799	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: ef76597c-f244-42be-abef-dc308efc7fff)
"
1760335034490,"INFO	2025-10-13T05:57:14,489	315799	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 45 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335034673,"INFO	2025-10-13T05:57:14,672	315982	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 267.0 in stage 0.0 (TID 267) (172.35.230.30, executor 7, partition 267, PROCESS_LOCAL, 29316 bytes) 
"
1760335034673,"INFO	2025-10-13T05:57:14,673	315983	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 230.0 in stage 0.0 (TID 230) in 30923 ms on 172.35.230.30 (executor 7) (230/590)
"
1760335035192,"INFO	2025-10-13T05:57:15,191	316501	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 268.0 in stage 0.0 (TID 268) (172.34.76.221, executor 11, partition 268, PROCESS_LOCAL, 29316 bytes) 
"
1760335035193,"INFO	2025-10-13T05:57:15,192	316502	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 237.0 in stage 0.0 (TID 237) in 28653 ms on 172.34.76.221 (executor 11) (231/590)
"
1760335035903,"INFO	2025-10-13T05:57:15,903	317213	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 269.0 in stage 0.0 (TID 269) (172.35.53.249, executor 8, partition 269, PROCESS_LOCAL, 29316 bytes) 
"
1760335035904,"INFO	2025-10-13T05:57:15,903	317213	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 228.0 in stage 0.0 (TID 228) in 32856 ms on 172.35.53.249 (executor 8) (232/590)
"
1760335036127,"INFO	2025-10-13T05:57:16,127	317437	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 270.0 in stage 0.0 (TID 270) (172.35.53.249, executor 8, partition 270, PROCESS_LOCAL, 29316 bytes) 
"
1760335036128,"INFO	2025-10-13T05:57:16,127	317437	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 229.0 in stage 0.0 (TID 229) in 32722 ms on 172.35.53.249 (executor 8) (233/590)
"
1760335036293,"INFO	2025-10-13T05:57:16,293	317603	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 271.0 in stage 0.0 (TID 271) (172.34.233.198, executor 5, partition 271, PROCESS_LOCAL, 29316 bytes) 
"
1760335036293,"INFO	2025-10-13T05:57:16,293	317603	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 231.0 in stage 0.0 (TID 231) in 32358 ms on 172.34.233.198 (executor 5) (234/590)
"
1760335036741,"INFO	2025-10-13T05:57:16,741	318051	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 272.0 in stage 0.0 (TID 272) (172.34.233.198, executor 5, partition 272, PROCESS_LOCAL, 29316 bytes) 
"
1760335036741,"INFO	2025-10-13T05:57:16,741	318051	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 232.0 in stage 0.0 (TID 232) in 32655 ms on 172.34.233.198 (executor 5) (235/590)
"
1760335036978,"INFO	2025-10-13T05:57:16,978	318288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 273.0 in stage 0.0 (TID 273) (172.35.30.152, executor 1, partition 273, PROCESS_LOCAL, 29316 bytes) 
"
1760335036978,"INFO	2025-10-13T05:57:16,978	318288	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 256.0 in stage 0.0 (TID 256) in 24100 ms on 172.35.30.152 (executor 1) (236/590)
"
1760335037094,"INFO	2025-10-13T05:57:17,094	318404	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 274.0 in stage 0.0 (TID 274) (172.34.247.5, executor 6, partition 274, PROCESS_LOCAL, 29316 bytes) 
"
1760335037094,"INFO	2025-10-13T05:57:17,094	318404	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 239.0 in stage 0.0 (TID 239) in 29830 ms on 172.34.247.5 (executor 6) (237/590)
"
1760335037244,"INFO	2025-10-13T05:57:17,244	318554	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 275.0 in stage 0.0 (TID 275) (172.34.1.110, executor 14, partition 275, PROCESS_LOCAL, 29316 bytes) 
"
1760335037244,"INFO	2025-10-13T05:57:17,244	318554	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 236.0 in stage 0.0 (TID 236) in 31432 ms on 172.34.1.110 (executor 14) (238/590)
"
1760335037280,"INFO	2025-10-13T05:57:17,280	318590	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 276.0 in stage 0.0 (TID 276) (172.34.89.92, executor 16, partition 276, PROCESS_LOCAL, 29316 bytes) 
"
1760335037280,"INFO	2025-10-13T05:57:17,280	318590	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 233.0 in stage 0.0 (TID 233) in 32456 ms on 172.34.89.92 (executor 16) (239/590)
"
1760335037950,"INFO	2025-10-13T05:57:17,949	319259	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 277.0 in stage 0.0 (TID 277) (172.34.89.92, executor 16, partition 277, PROCESS_LOCAL, 29316 bytes) 
"
1760335037950,"INFO	2025-10-13T05:57:17,950	319260	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 234.0 in stage 0.0 (TID 234) in 32530 ms on 172.34.89.92 (executor 16) (240/590)
"
1760335038471,"INFO	2025-10-13T05:57:18,471	319781	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 278.0 in stage 0.0 (TID 278) (172.34.145.94, executor 3, partition 278, PROCESS_LOCAL, 29316 bytes) 
"
1760335038472,"INFO	2025-10-13T05:57:18,471	319781	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 243.0 in stage 0.0 (TID 243) in 30505 ms on 172.34.145.94 (executor 3) (241/590)
"
1760335038962,"INFO	2025-10-13T05:57:18,962	320272	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335038962,"INFO	2025-10-13T05:57:18,962	320272	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 46, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335038963,"INFO	2025-10-13T05:57:18,962	320272	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 46; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_46_a_spark-application-1760334728567_p_1
"
1760335038963,"INFO	2025-10-13T05:57:18,963	320273	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335038999,"INFO	2025-10-13T05:57:18,999	320309	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335039000,"INFO	2025-10-13T05:57:18,999	320309	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 002b538e-a0a7-4ca1-abcc-e6adb5494c01)
"
1760335039000,"INFO	2025-10-13T05:57:18,999	320309	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 46 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335039546,"INFO	2025-10-13T05:57:19,545	320855	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 279.0 in stage 0.0 (TID 279) (172.35.230.30, executor 7, partition 279, PROCESS_LOCAL, 29316 bytes) 
"
1760335039546,"INFO	2025-10-13T05:57:19,546	320856	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 238.0 in stage 0.0 (TID 238) in 32518 ms on 172.35.230.30 (executor 7) (242/590)
"
1760335039867,"INFO	2025-10-13T05:57:19,866	321176	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 280.0 in stage 0.0 (TID 280) (172.35.115.9, executor 10, partition 280, PROCESS_LOCAL, 29316 bytes) 
"
1760335039867,"INFO	2025-10-13T05:57:19,867	321177	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 244.0 in stage 0.0 (TID 244) in 31555 ms on 172.35.115.9 (executor 10) (243/590)
"
1760335040075,"INFO	2025-10-13T05:57:20,074	321384	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 281.0 in stage 0.0 (TID 281) (172.35.34.68, executor 9, partition 281, PROCESS_LOCAL, 29316 bytes) 
"
1760335040075,"INFO	2025-10-13T05:57:20,075	321385	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 248.0 in stage 0.0 (TID 248) in 30689 ms on 172.35.34.68 (executor 9) (244/590)
"
1760335040259,"INFO	2025-10-13T05:57:20,258	321568	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 282.0 in stage 0.0 (TID 282) (172.34.59.71, executor 19, partition 282, PROCESS_LOCAL, 29316 bytes) 
"
1760335040259,"INFO	2025-10-13T05:57:20,259	321569	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 241.0 in stage 0.0 (TID 241) in 32529 ms on 172.34.59.71 (executor 19) (245/590)
"
1760335040640,"INFO	2025-10-13T05:57:20,640	321950	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 283.0 in stage 0.0 (TID 283) (172.34.78.80, executor 12, partition 283, PROCESS_LOCAL, 29316 bytes) 
"
1760335040641,"INFO	2025-10-13T05:57:20,641	321951	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 242.0 in stage 0.0 (TID 242) in 32895 ms on 172.34.78.80 (executor 12) (246/590)
"
1760335040648,"INFO	2025-10-13T05:57:20,648	321958	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 284.0 in stage 0.0 (TID 284) (172.34.102.82, executor 18, partition 284, PROCESS_LOCAL, 29316 bytes) 
"
1760335040648,"INFO	2025-10-13T05:57:20,648	321958	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 246.0 in stage 0.0 (TID 246) in 32116 ms on 172.34.102.82 (executor 18) (247/590)
"
1760335040799,"INFO	2025-10-13T05:57:20,798	322108	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 285.0 in stage 0.0 (TID 285) (172.34.59.71, executor 19, partition 285, PROCESS_LOCAL, 29316 bytes) 
"
1760335040799,"INFO	2025-10-13T05:57:20,799	322109	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 247.0 in stage 0.0 (TID 247) in 32156 ms on 172.34.59.71 (executor 19) (248/590)
"
1760335040846,"INFO	2025-10-13T05:57:20,845	322155	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 286.0 in stage 0.0 (TID 286) (172.34.78.80, executor 12, partition 286, PROCESS_LOCAL, 29316 bytes) 
"
1760335040846,"INFO	2025-10-13T05:57:20,846	322156	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 240.0 in stage 0.0 (TID 240) in 33245 ms on 172.34.78.80 (executor 12) (249/590)
"
1760335041385,"INFO	2025-10-13T05:57:21,385	322695	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 287.0 in stage 0.0 (TID 287) (172.34.1.110, executor 14, partition 287, PROCESS_LOCAL, 29316 bytes) 
"
1760335041386,"INFO	2025-10-13T05:57:21,385	322695	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 245.0 in stage 0.0 (TID 245) in 33072 ms on 172.34.1.110 (executor 14) (250/590)
"
1760335041763,"INFO	2025-10-13T05:57:21,762	323072	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 288.0 in stage 0.0 (TID 288) (172.34.139.155, executor 15, partition 288, PROCESS_LOCAL, 29316 bytes) 
"
1760335041763,"INFO	2025-10-13T05:57:21,763	323073	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 249.0 in stage 0.0 (TID 249) in 31449 ms on 172.34.139.155 (executor 15) (251/590)
"
1760335043119,"INFO	2025-10-13T05:57:23,119	324429	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 289.0 in stage 0.0 (TID 289) (172.34.76.221, executor 11, partition 289, PROCESS_LOCAL, 29316 bytes) 
"
1760335043120,"INFO	2025-10-13T05:57:23,119	324429	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 253.0 in stage 0.0 (TID 253) in 31111 ms on 172.34.76.221 (executor 11) (252/590)
"
1760335043213,"INFO	2025-10-13T05:57:23,213	324523	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 290.0 in stage 0.0 (TID 290) (172.34.145.94, executor 3, partition 290, PROCESS_LOCAL, 29316 bytes) 
"
1760335043213,"INFO	2025-10-13T05:57:23,213	324523	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 252.0 in stage 0.0 (TID 252) in 31677 ms on 172.34.145.94 (executor 3) (253/590)
"
1760335043386,"INFO	2025-10-13T05:57:23,386	324696	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 291.0 in stage 0.0 (TID 291) (172.34.102.82, executor 18, partition 291, PROCESS_LOCAL, 29316 bytes) 
"
1760335043387,"INFO	2025-10-13T05:57:23,386	324696	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 250.0 in stage 0.0 (TID 250) in 33024 ms on 172.34.102.82 (executor 18) (254/590)
"
1760335043392,"INFO	2025-10-13T05:57:23,392	324702	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 292.0 in stage 0.0 (TID 292) (172.35.115.9, executor 10, partition 292, PROCESS_LOCAL, 29316 bytes) 
"
1760335043393,"INFO	2025-10-13T05:57:23,393	324703	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 251.0 in stage 0.0 (TID 251) in 32969 ms on 172.35.115.9 (executor 10) (255/590)
"
1760335043415,"INFO	2025-10-13T05:57:23,414	324724	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 293.0 in stage 0.0 (TID 293) (172.35.34.68, executor 9, partition 293, PROCESS_LOCAL, 29316 bytes) 
"
1760335043415,"INFO	2025-10-13T05:57:23,415	324725	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 254.0 in stage 0.0 (TID 254) in 31328 ms on 172.35.34.68 (executor 9) (256/590)
"
1760335043553,"INFO	2025-10-13T05:57:23,553	324863	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 294.0 in stage 0.0 (TID 294) (172.34.249.48, executor 17, partition 294, PROCESS_LOCAL, 29316 bytes) 
"
1760335043553,"INFO	2025-10-13T05:57:23,553	324863	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 259.0 in stage 0.0 (TID 259) in 24312 ms on 172.34.249.48 (executor 17) (257/590)
"
1760335044621,"INFO	2025-10-13T05:57:24,621	325931	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 295.0 in stage 0.0 (TID 295) (172.34.247.5, executor 6, partition 295, PROCESS_LOCAL, 29316 bytes) 
"
1760335044621,"INFO	2025-10-13T05:57:24,621	325931	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 257.0 in stage 0.0 (TID 257) in 31021 ms on 172.34.247.5 (executor 6) (258/590)
"
1760335045220,"INFO	2025-10-13T05:57:25,219	326529	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 296.0 in stage 0.0 (TID 296) (172.34.158.2, executor 2, partition 296, PROCESS_LOCAL, 29316 bytes) 
"
1760335045220,"INFO	2025-10-13T05:57:25,220	326530	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 258.0 in stage 0.0 (TID 258) in 30749 ms on 172.34.158.2 (executor 2) (259/590)
"
1760335045310,"INFO	2025-10-13T05:57:25,310	326620	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 297.0 in stage 0.0 (TID 297) (172.34.139.155, executor 15, partition 297, PROCESS_LOCAL, 29316 bytes) 
"
1760335045310,"INFO	2025-10-13T05:57:25,310	326620	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 255.0 in stage 0.0 (TID 255) in 32547 ms on 172.34.139.155 (executor 15) (260/590)
"
1760335049043,"INFO	2025-10-13T05:57:29,043	330353	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 298.0 in stage 0.0 (TID 298) (172.35.30.152, executor 1, partition 298, PROCESS_LOCAL, 29316 bytes) 
"
1760335049044,"INFO	2025-10-13T05:57:29,044	330354	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 263.0 in stage 0.0 (TID 263) in 23855 ms on 172.35.30.152 (executor 1) (261/590)
"
1760335050295,"INFO	2025-10-13T05:57:30,295	331605	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335050295,"INFO	2025-10-13T05:57:30,295	331605	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 47, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335050296,"INFO	2025-10-13T05:57:30,295	331605	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 47; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_47_a_spark-application-1760334728567_p_1
"
1760335050296,"INFO	2025-10-13T05:57:30,296	331606	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335050334,"INFO	2025-10-13T05:57:30,333	331643	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335050334,"INFO	2025-10-13T05:57:30,333	331643	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5e9d08de-e06b-479b-81b1-9cb283d5dc43)
"
1760335050334,"INFO	2025-10-13T05:57:30,334	331644	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 47 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335051616,"INFO	2025-10-13T05:57:31,615	332925	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 299.0 in stage 0.0 (TID 299) (172.34.158.2, executor 2, partition 299, PROCESS_LOCAL, 29316 bytes) 
"
1760335051616,"INFO	2025-10-13T05:57:31,616	332926	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 260.0 in stage 0.0 (TID 260) in 31658 ms on 172.34.158.2 (executor 2) (262/590)
"
1760335053462,"INFO	2025-10-13T05:57:33,462	334772	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 300.0 in stage 0.0 (TID 300) (172.34.117.91, executor 13, partition 300, PROCESS_LOCAL, 29316 bytes) 
"
1760335053463,"INFO	2025-10-13T05:57:33,462	334772	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 261.0 in stage 0.0 (TID 261) in 30227 ms on 172.34.117.91 (executor 13) (263/590)
"
1760335055177,"INFO	2025-10-13T05:57:35,176	336486	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 301.0 in stage 0.0 (TID 301) (172.34.117.91, executor 13, partition 301, PROCESS_LOCAL, 29316 bytes) 
"
1760335055177,"INFO	2025-10-13T05:57:35,177	336487	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 262.0 in stage 0.0 (TID 262) in 30146 ms on 172.34.117.91 (executor 13) (264/590)
"
1760335055246,"INFO	2025-10-13T05:57:35,245	336555	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 302.0 in stage 0.0 (TID 302) (172.34.249.48, executor 17, partition 302, PROCESS_LOCAL, 29316 bytes) 
"
1760335055246,"INFO	2025-10-13T05:57:35,246	336556	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 266.0 in stage 0.0 (TID 266) in 25180 ms on 172.34.249.48 (executor 17) (265/590)
"
1760335056655,"INFO	2025-10-13T05:57:36,654	337964	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 303.0 in stage 0.0 (TID 303) (172.35.116.46, executor 4, partition 303, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:57:36,655	337965	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 264.0 in stage 0.0 (TID 264) in 31020 ms on 172.35.116.46 (executor 4) (266/590)
"
1760335057246,"INFO	2025-10-13T05:57:37,246	338556	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335057247,"INFO	2025-10-13T05:57:37,246	338556	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 48, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335057247,"INFO	2025-10-13T05:57:37,247	338557	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 48; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_48_a_spark-application-1760334728567_p_1
"
1760335057247,"INFO	2025-10-13T05:57:37,247	338557	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335057283,"INFO	2025-10-13T05:57:37,283	338593	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335057283,"INFO	2025-10-13T05:57:37,283	338593	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 949819d6-82e4-4659-8279-38dae77586c2)
"
1760335057283,"INFO	2025-10-13T05:57:37,283	338593	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 48 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335058681,"INFO	2025-10-13T05:57:38,680	339990	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 304.0 in stage 0.0 (TID 304) (172.34.76.221, executor 11, partition 304, PROCESS_LOCAL, 29316 bytes) 
"
1760335058681,"INFO	2025-10-13T05:57:38,681	339991	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 268.0 in stage 0.0 (TID 268) in 23490 ms on 172.34.76.221 (executor 11) (267/590)
"
1760335059351,"INFO	2025-10-13T05:57:39,351	340661	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 305.0 in stage 0.0 (TID 305) (172.35.116.46, executor 4, partition 305, PROCESS_LOCAL, 29316 bytes) 
"
1760335059351,"INFO	2025-10-13T05:57:39,351	340661	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 265.0 in stage 0.0 (TID 265) in 31492 ms on 172.35.116.46 (executor 4) (268/590)
"
1760335060989,"INFO	2025-10-13T05:57:40,988	342298	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 306.0 in stage 0.0 (TID 306) (172.35.30.152, executor 1, partition 306, PROCESS_LOCAL, 29316 bytes) 
"
1760335060989,"INFO	2025-10-13T05:57:40,989	342299	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 273.0 in stage 0.0 (TID 273) in 24012 ms on 172.35.30.152 (executor 1) (269/590)
"
1760335064072,"INFO	2025-10-13T05:57:44,071	345381	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 307.0 in stage 0.0 (TID 307) (172.35.230.30, executor 7, partition 307, PROCESS_LOCAL, 29316 bytes) 
"
1760335064072,"INFO	2025-10-13T05:57:44,072	345382	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 267.0 in stage 0.0 (TID 267) in 29400 ms on 172.35.230.30 (executor 7) (270/590)
"
1760335064420,"INFO	2025-10-13T05:57:44,419	345729	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 308.0 in stage 0.0 (TID 308) (172.34.247.5, executor 6, partition 308, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:57:44,420	345730	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 274.0 in stage 0.0 (TID 274) in 27326 ms on 172.34.247.5 (executor 6) (271/590)
"
1760335066624,"INFO	2025-10-13T05:57:46,624	347934	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 309.0 in stage 0.0 (TID 309) (172.34.1.110, executor 14, partition 309, PROCESS_LOCAL, 29316 bytes) 
"
1760335066625,"INFO	2025-10-13T05:57:46,624	347934	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 275.0 in stage 0.0 (TID 275) in 29381 ms on 172.34.1.110 (executor 14) (272/590)
"
1760335068259,"INFO	2025-10-13T05:57:48,259	349569	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 310.0 in stage 0.0 (TID 310) (172.35.53.249, executor 8, partition 310, PROCESS_LOCAL, 29316 bytes) 
"
1760335068259,"INFO	2025-10-13T05:57:48,259	349569	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 269.0 in stage 0.0 (TID 269) in 32356 ms on 172.35.53.249 (executor 8) (273/590)
"
1760335068397,"INFO	2025-10-13T05:57:48,397	349707	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 311.0 in stage 0.0 (TID 311) (172.34.249.48, executor 17, partition 311, PROCESS_LOCAL, 29316 bytes) 
"
1760335068397,"INFO	2025-10-13T05:57:48,397	349707	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 294.0 in stage 0.0 (TID 294) in 24845 ms on 172.34.249.48 (executor 17) (274/590)
"
1760335068598,"INFO	2025-10-13T05:57:48,598	349908	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 312.0 in stage 0.0 (TID 312) (172.34.145.94, executor 3, partition 312, PROCESS_LOCAL, 29316 bytes) 
"
1760335068599,"INFO	2025-10-13T05:57:48,598	349908	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 278.0 in stage 0.0 (TID 278) in 30128 ms on 172.34.145.94 (executor 3) (275/590)
"
1760335068727,"INFO	2025-10-13T05:57:48,726	350036	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 313.0 in stage 0.0 (TID 313) (172.35.53.249, executor 8, partition 313, PROCESS_LOCAL, 29316 bytes) 
"
1760335068727,"INFO	2025-10-13T05:57:48,727	350037	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 270.0 in stage 0.0 (TID 270) in 32600 ms on 172.35.53.249 (executor 8) (276/590)
"
1760335068996,"INFO	2025-10-13T05:57:48,996	350306	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 314.0 in stage 0.0 (TID 314) (172.34.233.198, executor 5, partition 314, PROCESS_LOCAL, 29316 bytes) 
"
1760335068997,"INFO	2025-10-13T05:57:48,996	350306	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 271.0 in stage 0.0 (TID 271) in 32704 ms on 172.34.233.198 (executor 5) (277/590)
"
1760335069033,"INFO	2025-10-13T05:57:49,032	350342	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 315.0 in stage 0.0 (TID 315) (172.34.89.92, executor 16, partition 315, PROCESS_LOCAL, 29316 bytes) 
"
1760335069033,"INFO	2025-10-13T05:57:49,033	350343	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 276.0 in stage 0.0 (TID 276) in 31753 ms on 172.34.89.92 (executor 16) (278/590)
"
1760335069214,"INFO	2025-10-13T05:57:49,214	350524	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335069214,"INFO	2025-10-13T05:57:49,214	350524	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 49, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335069214,"INFO	2025-10-13T05:57:49,214	350524	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 49; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_49_a_spark-application-1760334728567_p_1
"
1760335069214,"INFO	2025-10-13T05:57:49,214	350524	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335069243,"INFO	2025-10-13T05:57:49,243	350553	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335069243,"INFO	2025-10-13T05:57:49,243	350553	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 2db3991e-460d-4d41-abb4-6d171efe4c1f)
"
1760335069243,"INFO	2025-10-13T05:57:49,243	350553	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 49 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335069282,"INFO	2025-10-13T05:57:49,282	350592	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 316.0 in stage 0.0 (TID 316) (172.34.233.198, executor 5, partition 316, PROCESS_LOCAL, 29316 bytes) 
"
1760335069282,"INFO	2025-10-13T05:57:49,282	350592	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 272.0 in stage 0.0 (TID 272) in 32542 ms on 172.34.233.198 (executor 5) (279/590)
"
1760335069970,"INFO	2025-10-13T05:57:49,969	351279	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 317.0 in stage 0.0 (TID 317) (172.34.89.92, executor 16, partition 317, PROCESS_LOCAL, 29316 bytes) 
"
1760335069970,"INFO	2025-10-13T05:57:49,970	351280	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 277.0 in stage 0.0 (TID 277) in 32021 ms on 172.34.89.92 (executor 16) (280/590)
"
1760335070078,"INFO	2025-10-13T05:57:50,077	351387	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 318.0 in stage 0.0 (TID 318) (172.34.76.221, executor 11, partition 318, PROCESS_LOCAL, 29316 bytes) 
"
1760335070078,"INFO	2025-10-13T05:57:50,077	351387	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 289.0 in stage 0.0 (TID 289) in 26958 ms on 172.34.76.221 (executor 11) (281/590)
"
1760335070545,"INFO	2025-10-13T05:57:50,545	351855	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 319.0 in stage 0.0 (TID 319) (172.35.230.30, executor 7, partition 319, PROCESS_LOCAL, 29316 bytes) 
"
1760335070546,"INFO	2025-10-13T05:57:50,545	351855	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 279.0 in stage 0.0 (TID 279) in 31000 ms on 172.35.230.30 (executor 7) (282/590)
"
1760335070579,"INFO	2025-10-13T05:57:50,579	351889	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 320.0 in stage 0.0 (TID 320) (172.35.34.68, executor 9, partition 320, PROCESS_LOCAL, 29316 bytes) 
"
1760335070579,"INFO	2025-10-13T05:57:50,579	351889	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 281.0 in stage 0.0 (TID 281) in 30505 ms on 172.35.34.68 (executor 9) (283/590)
"
1760335071460,"INFO	2025-10-13T05:57:51,460	352770	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 321.0 in stage 0.0 (TID 321) (172.35.115.9, executor 10, partition 321, PROCESS_LOCAL, 29316 bytes) 
"
1760335071461,"INFO	2025-10-13T05:57:51,460	352770	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 280.0 in stage 0.0 (TID 280) in 31594 ms on 172.35.115.9 (executor 10) (284/590)
"
1760335071577,"INFO	2025-10-13T05:57:51,576	352886	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 322.0 in stage 0.0 (TID 322) (172.34.102.82, executor 18, partition 322, PROCESS_LOCAL, 29316 bytes) 
"
1760335071577,"INFO	2025-10-13T05:57:51,576	352886	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 284.0 in stage 0.0 (TID 284) in 30928 ms on 172.34.102.82 (executor 18) (285/590)
"
1760335071969,"INFO	2025-10-13T05:57:51,969	353279	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 323.0 in stage 0.0 (TID 323) (172.34.1.110, executor 14, partition 323, PROCESS_LOCAL, 29316 bytes) 
"
1760335071970,"INFO	2025-10-13T05:57:51,970	353280	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 287.0 in stage 0.0 (TID 287) in 30586 ms on 172.34.1.110 (executor 14) (286/590)
"
1760335072202,"INFO	2025-10-13T05:57:52,201	353511	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 324.0 in stage 0.0 (TID 324) (172.34.139.155, executor 15, partition 324, PROCESS_LOCAL, 29316 bytes) 
"
1760335072202,"INFO	2025-10-13T05:57:52,202	353512	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 288.0 in stage 0.0 (TID 288) in 30440 ms on 172.34.139.155 (executor 15) (287/590)
"
1760335072447,"INFO	2025-10-13T05:57:52,447	353757	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 325.0 in stage 0.0 (TID 325) (172.34.59.71, executor 19, partition 325, PROCESS_LOCAL, 29316 bytes) 
"
1760335072448,"INFO	2025-10-13T05:57:52,447	353757	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 282.0 in stage 0.0 (TID 282) in 32189 ms on 172.34.59.71 (executor 19) (288/590)
"
1760335072916,"INFO	2025-10-13T05:57:52,915	354225	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 326.0 in stage 0.0 (TID 326) (172.35.30.152, executor 1, partition 326, PROCESS_LOCAL, 29316 bytes) 
"
1760335072916,"INFO	2025-10-13T05:57:52,916	354226	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 298.0 in stage 0.0 (TID 298) in 23873 ms on 172.35.30.152 (executor 1) (289/590)
"
1760335073232,"INFO	2025-10-13T05:57:53,231	354541	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 327.0 in stage 0.0 (TID 327) (172.34.59.71, executor 19, partition 327, PROCESS_LOCAL, 29316 bytes) 
"
1760335073232,"INFO	2025-10-13T05:57:53,232	354542	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 285.0 in stage 0.0 (TID 285) in 32434 ms on 172.34.59.71 (executor 19) (290/590)
"
1760335073821,"INFO	2025-10-13T05:57:53,821	355131	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 328.0 in stage 0.0 (TID 328) (172.34.78.80, executor 12, partition 328, PROCESS_LOCAL, 29316 bytes) 
"
1760335073822,"INFO	2025-10-13T05:57:53,821	355131	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 283.0 in stage 0.0 (TID 283) in 33181 ms on 172.34.78.80 (executor 12) (291/590)
"
1760335074092,"INFO	2025-10-13T05:57:54,091	355401	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 329.0 in stage 0.0 (TID 329) (172.34.247.5, executor 6, partition 329, PROCESS_LOCAL, 29316 bytes) 
"
1760335074092,"INFO	2025-10-13T05:57:54,091	355401	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 295.0 in stage 0.0 (TID 295) in 29471 ms on 172.34.247.5 (executor 6) (292/590)
"
1760335074114,"INFO	2025-10-13T05:57:54,113	355423	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 330.0 in stage 0.0 (TID 330) (172.34.78.80, executor 12, partition 330, PROCESS_LOCAL, 29316 bytes) 
"
1760335074114,"INFO	2025-10-13T05:57:54,114	355424	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 286.0 in stage 0.0 (TID 286) in 33269 ms on 172.34.78.80 (executor 12) (293/590)
"
1760335074165,"INFO	2025-10-13T05:57:54,164	355474	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 331.0 in stage 0.0 (TID 331) (172.34.158.2, executor 2, partition 331, PROCESS_LOCAL, 29316 bytes) 
"
1760335074165,"INFO	2025-10-13T05:57:54,165	355475	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 296.0 in stage 0.0 (TID 296) in 28946 ms on 172.34.158.2 (executor 2) (294/590)
"
1760335074883,"INFO	2025-10-13T05:57:54,883	356193	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 332.0 in stage 0.0 (TID 332) (172.34.145.94, executor 3, partition 332, PROCESS_LOCAL, 29316 bytes) 
"
1760335074884,"INFO	2025-10-13T05:57:54,883	356193	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 290.0 in stage 0.0 (TID 290) in 31671 ms on 172.34.145.94 (executor 3) (295/590)
"
1760335075032,"INFO	2025-10-13T05:57:55,031	356341	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 333.0 in stage 0.0 (TID 333) (172.35.34.68, executor 9, partition 333, PROCESS_LOCAL, 29316 bytes) 
"
1760335075032,"INFO	2025-10-13T05:57:55,032	356342	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 293.0 in stage 0.0 (TID 293) in 31618 ms on 172.35.34.68 (executor 9) (296/590)
"
1760335075398,"INFO	2025-10-13T05:57:55,397	356707	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 334.0 in stage 0.0 (TID 334) (172.34.102.82, executor 18, partition 334, PROCESS_LOCAL, 29316 bytes) 
"
1760335075398,"INFO	2025-10-13T05:57:55,398	356708	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 291.0 in stage 0.0 (TID 291) in 32012 ms on 172.34.102.82 (executor 18) (297/590)
"
1760335075912,"INFO	2025-10-13T05:57:55,912	357222	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 335.0 in stage 0.0 (TID 335) (172.35.115.9, executor 10, partition 335, PROCESS_LOCAL, 29316 bytes) 
"
1760335075913,"INFO	2025-10-13T05:57:55,912	357222	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 292.0 in stage 0.0 (TID 292) in 32520 ms on 172.35.115.9 (executor 10) (298/590)
"
1760335076955,"INFO	2025-10-13T05:57:56,954	358264	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 336.0 in stage 0.0 (TID 336) (172.34.139.155, executor 15, partition 336, PROCESS_LOCAL, 29316 bytes) 
"
1760335076955,"INFO	2025-10-13T05:57:56,955	358265	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 297.0 in stage 0.0 (TID 297) in 31645 ms on 172.34.139.155 (executor 15) (299/590)
"
1760335080106,"INFO	2025-10-13T05:58:00,105	361415	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 337.0 in stage 0.0 (TID 337) (172.34.249.48, executor 17, partition 337, PROCESS_LOCAL, 29307 bytes) 
"
1760335080106,"INFO	2025-10-13T05:58:00,105	361415	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 302.0 in stage 0.0 (TID 302) in 24860 ms on 172.34.249.48 (executor 17) (300/590)
"
1760335081801,"INFO	2025-10-13T05:58:01,800	363110	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335081801,"INFO	2025-10-13T05:58:01,801	363111	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 50, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335081801,"INFO	2025-10-13T05:58:01,801	363111	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 50; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_50_a_spark-application-1760334728567_p_1
"
1760335081802,"INFO	2025-10-13T05:58:01,801	363111	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335081848,"INFO	2025-10-13T05:58:01,848	363158	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335081848,"INFO	2025-10-13T05:58:01,848	363158	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 4310d84c-b125-4038-a94c-3e3251032a7c)
"
1760335081848,"INFO	2025-10-13T05:58:01,848	363158	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 50 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335082261,"INFO	2025-10-13T05:58:02,260	363570	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 338.0 in stage 0.0 (TID 338) (172.34.158.2, executor 2, partition 338, PROCESS_LOCAL, 29316 bytes) 
"
1760335082261,"INFO	2025-10-13T05:58:02,261	363571	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 299.0 in stage 0.0 (TID 299) in 30646 ms on 172.34.158.2 (executor 2) (301/590)
"
1760335082433,"INFO	2025-10-13T05:58:02,432	363742	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 339.0 in stage 0.0 (TID 339) (172.34.76.221, executor 11, partition 339, PROCESS_LOCAL, 29316 bytes) 
"
1760335082433,"INFO	2025-10-13T05:58:02,433	363743	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 304.0 in stage 0.0 (TID 304) in 23753 ms on 172.34.76.221 (executor 11) (302/590)
"
1760335083331,"INFO	2025-10-13T05:58:03,331	364641	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 340.0 in stage 0.0 (TID 340) (172.34.117.91, executor 13, partition 340, PROCESS_LOCAL, 29316 bytes) 
"
1760335083332,"INFO	2025-10-13T05:58:03,331	364641	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 300.0 in stage 0.0 (TID 300) in 29869 ms on 172.34.117.91 (executor 13) (303/590)
"
1760335084728,"INFO	2025-10-13T05:58:04,728	366038	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 341.0 in stage 0.0 (TID 341) (172.35.30.152, executor 1, partition 341, PROCESS_LOCAL, 29316 bytes) 
"
1760335084729,"INFO	2025-10-13T05:58:04,729	366039	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 306.0 in stage 0.0 (TID 306) in 23741 ms on 172.35.30.152 (executor 1) (304/590)
"
1760335085434,"INFO	2025-10-13T05:58:05,434	366744	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 342.0 in stage 0.0 (TID 342) (172.34.117.91, executor 13, partition 342, PROCESS_LOCAL, 29316 bytes) 
"
1760335085435,"INFO	2025-10-13T05:58:05,434	366744	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 301.0 in stage 0.0 (TID 301) in 30258 ms on 172.34.117.91 (executor 13) (305/590)
"
1760335086773,"INFO	2025-10-13T05:58:06,772	368082	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335086773,"INFO	2025-10-13T05:58:06,773	368083	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 51, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335086773,"INFO	2025-10-13T05:58:06,773	368083	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 51; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_51_a_spark-application-1760334728567_p_1
"
1760335086773,"INFO	2025-10-13T05:58:06,773	368083	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335086817,"INFO	2025-10-13T05:58:06,817	368127	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335086817,"INFO	2025-10-13T05:58:06,817	368127	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: fbac63bd-1164-4fe2-a461-349c5293dd47)
INFO	2025-10-13T05:58:06,817	368127	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 51 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335087318,"INFO	2025-10-13T05:58:07,318	368628	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 343.0 in stage 0.0 (TID 343) (172.35.116.46, executor 4, partition 343, PROCESS_LOCAL, 29316 bytes) 
"
1760335087318,"INFO	2025-10-13T05:58:07,318	368628	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 303.0 in stage 0.0 (TID 303) in 30664 ms on 172.35.116.46 (executor 4) (306/590)
"
1760335088694,"INFO	2025-10-13T05:58:08,694	370004	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760335088694,"INFO	2025-10-13T05:58:08,694	370004	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760335089428,"INFO	2025-10-13T05:58:09,428	370738	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 344.0 in stage 0.0 (TID 344) (172.34.247.5, executor 6, partition 344, PROCESS_LOCAL, 29316 bytes) 
"
1760335089429,"INFO	2025-10-13T05:58:09,428	370738	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 308.0 in stage 0.0 (TID 308) in 25009 ms on 172.34.247.5 (executor 6) (307/590)
"
1760335090153,"INFO	2025-10-13T05:58:10,152	371462	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 345.0 in stage 0.0 (TID 345) (172.35.230.30, executor 7, partition 345, PROCESS_LOCAL, 29316 bytes) 
"
1760335090153,"INFO	2025-10-13T05:58:10,153	371463	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 307.0 in stage 0.0 (TID 307) in 26082 ms on 172.35.230.30 (executor 7) (308/590)
"
1760335090559,"INFO	2025-10-13T05:58:10,558	371868	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 346.0 in stage 0.0 (TID 346) (172.35.116.46, executor 4, partition 346, PROCESS_LOCAL, 29316 bytes) 
"
1760335090559,"INFO	2025-10-13T05:58:10,559	371869	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 305.0 in stage 0.0 (TID 305) in 31209 ms on 172.35.116.46 (executor 4) (309/590)
"
1760335093175,"INFO	2025-10-13T05:58:13,174	374484	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 347.0 in stage 0.0 (TID 347) (172.34.249.48, executor 17, partition 347, PROCESS_LOCAL, 29316 bytes) 
"
1760335093175,"INFO	2025-10-13T05:58:13,175	374485	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 311.0 in stage 0.0 (TID 311) in 24779 ms on 172.34.249.48 (executor 17) (310/590)
"
1760335094187,"INFO	2025-10-13T05:58:14,186	375496	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 348.0 in stage 0.0 (TID 348) (172.34.76.221, executor 11, partition 348, PROCESS_LOCAL, 29316 bytes) 
"
1760335094187,"INFO	2025-10-13T05:58:14,187	375497	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 318.0 in stage 0.0 (TID 318) in 24110 ms on 172.34.76.221 (executor 11) (311/590)
"
1760335095436,"INFO	2025-10-13T05:58:15,436	376746	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 349.0 in stage 0.0 (TID 349) (172.34.1.110, executor 14, partition 349, PROCESS_LOCAL, 29316 bytes) 
"
1760335095436,"INFO	2025-10-13T05:58:15,436	376746	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 309.0 in stage 0.0 (TID 309) in 28812 ms on 172.34.1.110 (executor 14) (312/590)
"
1760335096779,"INFO	2025-10-13T05:58:16,779	378089	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 350.0 in stage 0.0 (TID 350) (172.35.30.152, executor 1, partition 350, PROCESS_LOCAL, 29316 bytes) 
"
1760335096780,"INFO	2025-10-13T05:58:16,779	378089	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 326.0 in stage 0.0 (TID 326) in 23864 ms on 172.35.30.152 (executor 1) (313/590)
"
1760335098247,"INFO	2025-10-13T05:58:18,246	379556	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 351.0 in stage 0.0 (TID 351) (172.34.145.94, executor 3, partition 351, PROCESS_LOCAL, 29316 bytes) 
"
1760335098247,"INFO	2025-10-13T05:58:18,247	379557	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 312.0 in stage 0.0 (TID 312) in 29649 ms on 172.34.145.94 (executor 3) (314/590)
"
1760335099904,"INFO	2025-10-13T05:58:19,903	381213	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 352.0 in stage 0.0 (TID 352) (172.35.230.30, executor 7, partition 352, PROCESS_LOCAL, 29316 bytes) 
"
1760335099904,"INFO	2025-10-13T05:58:19,904	381214	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 319.0 in stage 0.0 (TID 319) in 29360 ms on 172.35.230.30 (executor 7) (315/590)
"
1760335099922,"INFO	2025-10-13T05:58:19,922	381232	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 353.0 in stage 0.0 (TID 353) (172.35.34.68, executor 9, partition 353, PROCESS_LOCAL, 29316 bytes) 
"
1760335099922,"INFO	2025-10-13T05:58:19,922	381232	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 320.0 in stage 0.0 (TID 320) in 29344 ms on 172.35.34.68 (executor 9) (316/590)
"
1760335100340,"INFO	2025-10-13T05:58:20,339	381649	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 354.0 in stage 0.0 (TID 354) (172.34.158.2, executor 2, partition 354, PROCESS_LOCAL, 29316 bytes) 
"
1760335100340,"INFO	2025-10-13T05:58:20,340	381650	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 331.0 in stage 0.0 (TID 331) in 26176 ms on 172.34.158.2 (executor 2) (317/590)
"
1760335100801,"INFO	2025-10-13T05:58:20,800	382110	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 355.0 in stage 0.0 (TID 355) (172.34.247.5, executor 6, partition 355, PROCESS_LOCAL, 29316 bytes) 
"
1760335100801,"INFO	2025-10-13T05:58:20,801	382111	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 329.0 in stage 0.0 (TID 329) in 26710 ms on 172.34.247.5 (executor 6) (318/590)
"
1760335100915,"INFO	2025-10-13T05:58:20,914	382224	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 356.0 in stage 0.0 (TID 356) (172.35.53.249, executor 8, partition 356, PROCESS_LOCAL, 29316 bytes) 
"
1760335100915,"INFO	2025-10-13T05:58:20,915	382225	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 310.0 in stage 0.0 (TID 310) in 32657 ms on 172.35.53.249 (executor 8) (319/590)
"
1760335101120,"INFO	2025-10-13T05:58:21,120	382430	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 357.0 in stage 0.0 (TID 357) (172.34.89.92, executor 16, partition 357, PROCESS_LOCAL, 29316 bytes) 
"
1760335101120,"INFO	2025-10-13T05:58:21,120	382430	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 315.0 in stage 0.0 (TID 315) in 32088 ms on 172.34.89.92 (executor 16) (320/590)
"
1760335101456,"INFO	2025-10-13T05:58:21,456	382766	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 358.0 in stage 0.0 (TID 358) (172.34.102.82, executor 18, partition 358, PROCESS_LOCAL, 29316 bytes) 
"
1760335101457,"INFO	2025-10-13T05:58:21,456	382766	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 322.0 in stage 0.0 (TID 322) in 29881 ms on 172.34.102.82 (executor 18) (321/590)
"
1760335101579,"INFO	2025-10-13T05:58:21,579	382889	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 359.0 in stage 0.0 (TID 359) (172.35.115.9, executor 10, partition 359, PROCESS_LOCAL, 29316 bytes) 
"
1760335101580,"INFO	2025-10-13T05:58:21,580	382890	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 321.0 in stage 0.0 (TID 321) in 30120 ms on 172.35.115.9 (executor 10) (322/590)
"
1760335101612,"INFO	2025-10-13T05:58:21,612	382922	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 360.0 in stage 0.0 (TID 360) (172.34.233.198, executor 5, partition 360, PROCESS_LOCAL, 29316 bytes) 
"
1760335101613,"INFO	2025-10-13T05:58:21,612	382922	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 314.0 in stage 0.0 (TID 314) in 32617 ms on 172.34.233.198 (executor 5) (323/590)
"
1760335101743,"INFO	2025-10-13T05:58:21,743	383053	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 361.0 in stage 0.0 (TID 361) (172.35.53.249, executor 8, partition 361, PROCESS_LOCAL, 29316 bytes) 
"
1760335101743,"INFO	2025-10-13T05:58:21,743	383053	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 313.0 in stage 0.0 (TID 313) in 33017 ms on 172.35.53.249 (executor 8) (324/590)
"
1760335101937,"INFO	2025-10-13T05:58:21,937	383247	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 362.0 in stage 0.0 (TID 362) (172.34.139.155, executor 15, partition 362, PROCESS_LOCAL, 29316 bytes) 
"
1760335101938,"INFO	2025-10-13T05:58:21,937	383247	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 324.0 in stage 0.0 (TID 324) in 29736 ms on 172.34.139.155 (executor 15) (325/590)
"
1760335101973,"INFO	2025-10-13T05:58:21,972	383282	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 363.0 in stage 0.0 (TID 363) (172.34.1.110, executor 14, partition 363, PROCESS_LOCAL, 29316 bytes) 
"
1760335101973,"INFO	2025-10-13T05:58:21,973	383283	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 323.0 in stage 0.0 (TID 323) in 30004 ms on 172.34.1.110 (executor 14) (326/590)
"
1760335102113,"INFO	2025-10-13T05:58:22,112	383422	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 364.0 in stage 0.0 (TID 364) (172.34.89.92, executor 16, partition 364, PROCESS_LOCAL, 29316 bytes) 
"
1760335102113,"INFO	2025-10-13T05:58:22,113	383423	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 317.0 in stage 0.0 (TID 317) in 32144 ms on 172.34.89.92 (executor 16) (327/590)
"
1760335102193,"INFO	2025-10-13T05:58:22,192	383502	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 365.0 in stage 0.0 (TID 365) (172.34.233.198, executor 5, partition 365, PROCESS_LOCAL, 29316 bytes) 
"
1760335102193,"INFO	2025-10-13T05:58:22,193	383503	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 316.0 in stage 0.0 (TID 316) in 32911 ms on 172.34.233.198 (executor 5) (328/590)
"
1760335102204,"INFO	2025-10-13T05:58:22,203	383513	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335102204,"INFO	2025-10-13T05:58:22,204	383514	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 52, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335102204,"INFO	2025-10-13T05:58:22,204	383514	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 52; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_52_a_spark-application-1760334728567_p_1
"
1760335102204,"INFO	2025-10-13T05:58:22,204	383514	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335102242,"INFO	2025-10-13T05:58:22,241	383551	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335102242,"INFO	2025-10-13T05:58:22,241	383551	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: c2de16fa-6163-4405-af34-b85b0e986f5f)
"
1760335102242,"INFO	2025-10-13T05:58:22,242	383552	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 52 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335104552,"INFO	2025-10-13T05:58:24,551	385861	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 366.0 in stage 0.0 (TID 366) (172.34.59.71, executor 19, partition 366, PROCESS_LOCAL, 29316 bytes) 
"
1760335104552,"INFO	2025-10-13T05:58:24,551	385861	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 325.0 in stage 0.0 (TID 325) in 32104 ms on 172.34.59.71 (executor 19) (329/590)
"
1760335105025,"INFO	2025-10-13T05:58:25,025	386335	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 367.0 in stage 0.0 (TID 367) (172.34.249.48, executor 17, partition 367, PROCESS_LOCAL, 29307 bytes) 
"
1760335105026,"INFO	2025-10-13T05:58:25,025	386335	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 337.0 in stage 0.0 (TID 337) in 24920 ms on 172.34.249.48 (executor 17) (330/590)
"
1760335105263,"INFO	2025-10-13T05:58:25,263	386573	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335105264,"INFO	2025-10-13T05:58:25,263	386573	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 53, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335105264,"INFO	2025-10-13T05:58:25,264	386574	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 53; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_53_a_spark-application-1760334728567_p_1
"
1760335105264,"INFO	2025-10-13T05:58:25,264	386574	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335105300,"INFO	2025-10-13T05:58:25,300	386610	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335105300,"INFO	2025-10-13T05:58:25,300	386610	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: c960b72b-9c7e-461c-b1f2-f6b8ba596eb2)
"
1760335105300,"INFO	2025-10-13T05:58:25,300	386610	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 53 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335105759,"INFO	2025-10-13T05:58:25,758	387068	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 368.0 in stage 0.0 (TID 368) (172.34.59.71, executor 19, partition 368, PROCESS_LOCAL, 29316 bytes) 
"
1760335105759,"INFO	2025-10-13T05:58:25,759	387069	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 327.0 in stage 0.0 (TID 327) in 32528 ms on 172.34.59.71 (executor 19) (331/590)
"
1760335105927,"INFO	2025-10-13T05:58:25,927	387237	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 369.0 in stage 0.0 (TID 369) (172.34.145.94, executor 3, partition 369, PROCESS_LOCAL, 29316 bytes) 
"
1760335105928,"INFO	2025-10-13T05:58:25,927	387237	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 332.0 in stage 0.0 (TID 332) in 31044 ms on 172.34.145.94 (executor 3) (332/590)
"
1760335106111,"INFO	2025-10-13T05:58:26,110	387420	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 370.0 in stage 0.0 (TID 370) (172.35.34.68, executor 9, partition 370, PROCESS_LOCAL, 29316 bytes) 
"
1760335106111,"INFO	2025-10-13T05:58:26,111	387421	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 333.0 in stage 0.0 (TID 333) in 31080 ms on 172.35.34.68 (executor 9) (333/590)
"
1760335106507,"INFO	2025-10-13T05:58:26,507	387817	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 371.0 in stage 0.0 (TID 371) (172.34.76.221, executor 11, partition 371, PROCESS_LOCAL, 29316 bytes) 
"
1760335106507,"INFO	2025-10-13T05:58:26,507	387817	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 339.0 in stage 0.0 (TID 339) in 24075 ms on 172.34.76.221 (executor 11) (334/590)
"
1760335106752,"INFO	2025-10-13T05:58:26,752	388062	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 372.0 in stage 0.0 (TID 372) (172.34.78.80, executor 12, partition 372, PROCESS_LOCAL, 29316 bytes) 
"
1760335106753,"INFO	2025-10-13T05:58:26,753	388063	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 328.0 in stage 0.0 (TID 328) in 32933 ms on 172.34.78.80 (executor 12) (335/590)
"
1760335107110,"INFO	2025-10-13T05:58:27,109	388419	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 373.0 in stage 0.0 (TID 373) (172.34.102.82, executor 18, partition 373, PROCESS_LOCAL, 29316 bytes) 
"
1760335107110,"INFO	2025-10-13T05:58:27,110	388420	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 334.0 in stage 0.0 (TID 334) in 31713 ms on 172.34.102.82 (executor 18) (336/590)
"
1760335107380,"INFO	2025-10-13T05:58:27,380	388690	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 374.0 in stage 0.0 (TID 374) (172.34.78.80, executor 12, partition 374, PROCESS_LOCAL, 29316 bytes) 
"
1760335107381,"INFO	2025-10-13T05:58:27,380	388690	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 330.0 in stage 0.0 (TID 330) in 33267 ms on 172.34.78.80 (executor 12) (337/590)
"
1760335107868,"INFO	2025-10-13T05:58:27,868	389178	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 375.0 in stage 0.0 (TID 375) (172.35.115.9, executor 10, partition 375, PROCESS_LOCAL, 29316 bytes) 
"
1760335107868,"INFO	2025-10-13T05:58:27,868	389178	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 335.0 in stage 0.0 (TID 335) in 31957 ms on 172.35.115.9 (executor 10) (338/590)
"
1760335108237,"INFO	2025-10-13T05:58:28,237	389547	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 376.0 in stage 0.0 (TID 376) (172.34.139.155, executor 15, partition 376, PROCESS_LOCAL, 29316 bytes) 
"
1760335108238,"INFO	2025-10-13T05:58:28,238	389548	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 336.0 in stage 0.0 (TID 336) in 31284 ms on 172.34.139.155 (executor 15) (339/590)
"
1760335108769,"INFO	2025-10-13T05:58:28,768	390078	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 377.0 in stage 0.0 (TID 377) (172.35.30.152, executor 1, partition 377, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:58:28,769	390079	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 341.0 in stage 0.0 (TID 341) in 24041 ms on 172.35.30.152 (executor 1) (340/590)
"
1760335111004,"INFO	2025-10-13T05:58:31,004	392314	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 378.0 in stage 0.0 (TID 378) (172.34.158.2, executor 2, partition 378, PROCESS_LOCAL, 29316 bytes) 
"
1760335111004,"INFO	2025-10-13T05:58:31,004	392314	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 338.0 in stage 0.0 (TID 338) in 28744 ms on 172.34.158.2 (executor 2) (341/590)
"
1760335113450,"INFO	2025-10-13T05:58:33,450	394760	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 379.0 in stage 0.0 (TID 379) (172.34.117.91, executor 13, partition 379, PROCESS_LOCAL, 29316 bytes) 
"
1760335113451,"INFO	2025-10-13T05:58:33,450	394760	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 340.0 in stage 0.0 (TID 340) in 30120 ms on 172.34.117.91 (executor 13) (342/590)
"
1760335114777,"INFO	2025-10-13T05:58:34,777	396087	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 380.0 in stage 0.0 (TID 380) (172.35.230.30, executor 7, partition 380, PROCESS_LOCAL, 29316 bytes) 
"
1760335114778,"INFO	2025-10-13T05:58:34,777	396087	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 345.0 in stage 0.0 (TID 345) in 24625 ms on 172.35.230.30 (executor 7) (343/590)
"
1760335114957,"INFO	2025-10-13T05:58:34,957	396267	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 381.0 in stage 0.0 (TID 381) (172.34.247.5, executor 6, partition 381, PROCESS_LOCAL, 29316 bytes) 
"
1760335114958,"INFO	2025-10-13T05:58:34,957	396267	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 344.0 in stage 0.0 (TID 344) in 25530 ms on 172.34.247.5 (executor 6) (344/590)
"
1760335115787,"INFO	2025-10-13T05:58:35,787	397097	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 382.0 in stage 0.0 (TID 382) (172.34.117.91, executor 13, partition 382, PROCESS_LOCAL, 29307 bytes) 
"
1760335115787,"INFO	2025-10-13T05:58:35,787	397097	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 342.0 in stage 0.0 (TID 342) in 30353 ms on 172.34.117.91 (executor 13) (345/590)
"
1760335117475,"INFO	2025-10-13T05:58:37,475	398785	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 383.0 in stage 0.0 (TID 383) (172.34.249.48, executor 17, partition 383, PROCESS_LOCAL, 29316 bytes) 
"
1760335117476,"INFO	2025-10-13T05:58:37,475	398785	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 347.0 in stage 0.0 (TID 347) in 24301 ms on 172.34.249.48 (executor 17) (346/590)
"
1760335118755,"INFO	2025-10-13T05:58:38,754	400064	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 384.0 in stage 0.0 (TID 384) (172.35.116.46, executor 4, partition 384, PROCESS_LOCAL, 29316 bytes) 
"
1760335118755,"INFO	2025-10-13T05:58:38,755	400065	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 343.0 in stage 0.0 (TID 343) in 31438 ms on 172.35.116.46 (executor 4) (347/590)
"
1760335118871,"INFO	2025-10-13T05:58:38,871	400181	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 385.0 in stage 0.0 (TID 385) (172.34.76.221, executor 11, partition 385, PROCESS_LOCAL, 29316 bytes) 
"
1760335118871,"INFO	2025-10-13T05:58:38,871	400181	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 348.0 in stage 0.0 (TID 348) in 24685 ms on 172.34.76.221 (executor 11) (348/590)
"
1760335119689,"INFO	2025-10-13T05:58:39,688	400998	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335119689,"INFO	2025-10-13T05:58:39,689	400999	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 54, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335119689,"INFO	2025-10-13T05:58:39,689	400999	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 54; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_54_a_spark-application-1760334728567_p_1
"
1760335119690,"INFO	2025-10-13T05:58:39,689	400999	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335119727,"INFO	2025-10-13T05:58:39,727	401037	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335119727,"INFO	2025-10-13T05:58:39,727	401037	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 3cdd6007-bade-4ef6-bc79-1d1de11d3e2e)
"
1760335119727,"INFO	2025-10-13T05:58:39,727	401037	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 54 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335120393,"INFO	2025-10-13T05:58:40,392	401702	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 386.0 in stage 0.0 (TID 386) (172.35.30.152, executor 1, partition 386, PROCESS_LOCAL, 29316 bytes) 
"
1760335120393,"INFO	2025-10-13T05:58:40,393	401703	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 350.0 in stage 0.0 (TID 350) in 23615 ms on 172.35.30.152 (executor 1) (349/590)
"
1760335121009,"INFO	2025-10-13T05:58:41,008	402318	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 387.0 in stage 0.0 (TID 387) (172.34.1.110, executor 14, partition 387, PROCESS_LOCAL, 29316 bytes) 
"
1760335121009,"INFO	2025-10-13T05:58:41,009	402319	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 349.0 in stage 0.0 (TID 349) in 25574 ms on 172.34.1.110 (executor 14) (350/590)
"
1760335121899,"INFO	2025-10-13T05:58:41,898	403208	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 388.0 in stage 0.0 (TID 388) (172.35.116.46, executor 4, partition 388, PROCESS_LOCAL, 29316 bytes) 
"
1760335121899,"INFO	2025-10-13T05:58:41,899	403209	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 346.0 in stage 0.0 (TID 346) in 31341 ms on 172.35.116.46 (executor 4) (351/590)
"
1760335126381,"INFO	2025-10-13T05:58:46,380	407690	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335126381,"INFO	2025-10-13T05:58:46,381	407691	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 55, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335126381,"INFO	2025-10-13T05:58:46,381	407691	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 55; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_55_a_spark-application-1760334728567_p_1
"
1760335126381,"INFO	2025-10-13T05:58:46,381	407691	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335126424,"INFO	2025-10-13T05:58:46,424	407734	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335126424,"INFO	2025-10-13T05:58:46,424	407734	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 40be0eeb-dc01-4662-a501-1d223f12f126)
INFO	2025-10-13T05:58:46,424	407734	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 55 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335127004,"INFO	2025-10-13T05:58:47,004	408314	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 389.0 in stage 0.0 (TID 389) (172.34.145.94, executor 3, partition 389, PROCESS_LOCAL, 29316 bytes) 
"
1760335127005,"INFO	2025-10-13T05:58:47,004	408314	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 351.0 in stage 0.0 (TID 351) in 28758 ms on 172.34.145.94 (executor 3) (352/590)
"
1760335127115,"INFO	2025-10-13T05:58:47,115	408425	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 390.0 in stage 0.0 (TID 390) (172.35.230.30, executor 7, partition 390, PROCESS_LOCAL, 29316 bytes) 
"
1760335127116,"INFO	2025-10-13T05:58:47,115	408425	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 352.0 in stage 0.0 (TID 352) in 27212 ms on 172.35.230.30 (executor 7) (353/590)
"
1760335127204,"INFO	2025-10-13T05:58:47,204	408514	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 391.0 in stage 0.0 (TID 391) (172.34.158.2, executor 2, partition 391, PROCESS_LOCAL, 29316 bytes) 
"
1760335127204,"INFO	2025-10-13T05:58:47,204	408514	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 354.0 in stage 0.0 (TID 354) in 26865 ms on 172.34.158.2 (executor 2) (354/590)
"
1760335127689,"INFO	2025-10-13T05:58:47,689	408999	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 392.0 in stage 0.0 (TID 392) (172.34.247.5, executor 6, partition 392, PROCESS_LOCAL, 29316 bytes) 
"
1760335127689,"INFO	2025-10-13T05:58:47,689	408999	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 355.0 in stage 0.0 (TID 355) in 26889 ms on 172.34.247.5 (executor 6) (355/590)
"
1760335129478,"INFO	2025-10-13T05:58:49,478	410788	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 393.0 in stage 0.0 (TID 393) (172.35.34.68, executor 9, partition 393, PROCESS_LOCAL, 29316 bytes) 
"
1760335129479,"INFO	2025-10-13T05:58:49,478	410788	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 353.0 in stage 0.0 (TID 353) in 29557 ms on 172.35.34.68 (executor 9) (356/590)
"
1760335129766,"INFO	2025-10-13T05:58:49,765	411075	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 394.0 in stage 0.0 (TID 394) (172.34.249.48, executor 17, partition 394, PROCESS_LOCAL, 29316 bytes) 
"
1760335129766,"INFO	2025-10-13T05:58:49,766	411076	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 367.0 in stage 0.0 (TID 367) in 24741 ms on 172.34.249.48 (executor 17) (357/590)
"
1760335130179,"INFO	2025-10-13T05:58:50,179	411489	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 395.0 in stage 0.0 (TID 395) (172.34.1.110, executor 14, partition 395, PROCESS_LOCAL, 29316 bytes) 
"
1760335130180,"INFO	2025-10-13T05:58:50,179	411489	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 363.0 in stage 0.0 (TID 363) in 28207 ms on 172.34.1.110 (executor 14) (358/590)
"
1760335131488,"INFO	2025-10-13T05:58:51,487	412797	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 396.0 in stage 0.0 (TID 396) (172.34.102.82, executor 18, partition 396, PROCESS_LOCAL, 29316 bytes) 
"
1760335131488,"INFO	2025-10-13T05:58:51,488	412798	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 358.0 in stage 0.0 (TID 358) in 30033 ms on 172.34.102.82 (executor 18) (359/590)
"
1760335131816,"INFO	2025-10-13T05:58:51,816	413126	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 397.0 in stage 0.0 (TID 397) (172.35.30.152, executor 1, partition 397, PROCESS_LOCAL, 29307 bytes) 
"
1760335131817,"INFO	2025-10-13T05:58:51,816	413126	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 377.0 in stage 0.0 (TID 377) in 23048 ms on 172.35.30.152 (executor 1) (360/590)
"
1760335132031,"INFO	2025-10-13T05:58:52,031	413341	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 398.0 in stage 0.0 (TID 398) (172.34.76.221, executor 11, partition 398, PROCESS_LOCAL, 29316 bytes) 
"
1760335132032,"INFO	2025-10-13T05:58:52,031	413341	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 371.0 in stage 0.0 (TID 371) in 25525 ms on 172.34.76.221 (executor 11) (361/590)
"
1760335132116,"INFO	2025-10-13T05:58:52,115	413425	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 399.0 in stage 0.0 (TID 399) (172.35.115.9, executor 10, partition 399, PROCESS_LOCAL, 29316 bytes) 
"
1760335132116,"INFO	2025-10-13T05:58:52,116	413426	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 359.0 in stage 0.0 (TID 359) in 30537 ms on 172.35.115.9 (executor 10) (362/590)
"
1760335132434,"INFO	2025-10-13T05:58:52,434	413744	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 400.0 in stage 0.0 (TID 400) (172.34.139.155, executor 15, partition 400, PROCESS_LOCAL, 29316 bytes) 
"
1760335132434,"INFO	2025-10-13T05:58:52,434	413744	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 362.0 in stage 0.0 (TID 362) in 30497 ms on 172.34.139.155 (executor 15) (363/590)
"
1760335133036,"INFO	2025-10-13T05:58:53,036	414346	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 401.0 in stage 0.0 (TID 401) (172.34.89.92, executor 16, partition 401, PROCESS_LOCAL, 29316 bytes) 
"
1760335133037,"INFO	2025-10-13T05:58:53,036	414346	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 357.0 in stage 0.0 (TID 357) in 31917 ms on 172.34.89.92 (executor 16) (364/590)
"
1760335133258,"INFO	2025-10-13T05:58:53,258	414568	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 402.0 in stage 0.0 (TID 402) (172.35.53.249, executor 8, partition 402, PROCESS_LOCAL, 29316 bytes) 
"
1760335133259,"INFO	2025-10-13T05:58:53,258	414568	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 356.0 in stage 0.0 (TID 356) in 32344 ms on 172.35.53.249 (executor 8) (365/590)
"
1760335133828,"INFO	2025-10-13T05:58:53,828	415138	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 403.0 in stage 0.0 (TID 403) (172.34.233.198, executor 5, partition 403, PROCESS_LOCAL, 29316 bytes) 
"
1760335133828,"INFO	2025-10-13T05:58:53,828	415138	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 360.0 in stage 0.0 (TID 360) in 32216 ms on 172.34.233.198 (executor 5) (366/590)
"
1760335134145,"INFO	2025-10-13T05:58:54,144	415454	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 404.0 in stage 0.0 (TID 404) (172.34.89.92, executor 16, partition 404, PROCESS_LOCAL, 29316 bytes) 
"
1760335134145,"INFO	2025-10-13T05:58:54,145	415455	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 364.0 in stage 0.0 (TID 364) in 32033 ms on 172.34.89.92 (executor 16) (367/590)
"
1760335134245,"INFO	2025-10-13T05:58:54,245	415555	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 405.0 in stage 0.0 (TID 405) (172.34.233.198, executor 5, partition 405, PROCESS_LOCAL, 29316 bytes) 
"
1760335134245,"INFO	2025-10-13T05:58:54,245	415555	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 365.0 in stage 0.0 (TID 365) in 32053 ms on 172.34.233.198 (executor 5) (368/590)
"
1760335134351,"INFO	2025-10-13T05:58:54,350	415660	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 406.0 in stage 0.0 (TID 406) (172.35.53.249, executor 8, partition 406, PROCESS_LOCAL, 29316 bytes) 
"
1760335134351,"INFO	2025-10-13T05:58:54,351	415661	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 361.0 in stage 0.0 (TID 361) in 32608 ms on 172.35.53.249 (executor 8) (369/590)
"
1760335136100,"INFO	2025-10-13T05:58:56,100	417410	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335136100,"INFO	2025-10-13T05:58:56,100	417410	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 56, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335136100,"INFO	2025-10-13T05:58:56,100	417410	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 56; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_56_a_spark-application-1760334728567_p_1
"
1760335136100,"INFO	2025-10-13T05:58:56,100	417410	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335136140,"INFO	2025-10-13T05:58:56,139	417449	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335136140,"INFO	2025-10-13T05:58:56,140	417450	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: ccc4693a-64db-4c8e-a3f7-03035706bfce)
"
1760335136140,"INFO	2025-10-13T05:58:56,140	417450	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 56 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335136375,"INFO	2025-10-13T05:58:56,374	417684	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 407.0 in stage 0.0 (TID 407) (172.34.145.94, executor 3, partition 407, PROCESS_LOCAL, 29316 bytes) 
"
1760335136375,"INFO	2025-10-13T05:58:56,375	417685	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 369.0 in stage 0.0 (TID 369) in 30449 ms on 172.34.145.94 (executor 3) (370/590)
"
1760335136574,"INFO	2025-10-13T05:58:56,574	417884	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 408.0 in stage 0.0 (TID 408) (172.34.59.71, executor 19, partition 408, PROCESS_LOCAL, 29316 bytes) 
"
1760335136575,"INFO	2025-10-13T05:58:56,575	417885	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 366.0 in stage 0.0 (TID 366) in 32024 ms on 172.34.59.71 (executor 19) (371/590)
"
1760335137284,"INFO	2025-10-13T05:58:57,283	418593	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 409.0 in stage 0.0 (TID 409) (172.35.34.68, executor 9, partition 409, PROCESS_LOCAL, 29316 bytes) 
"
1760335137284,"INFO	2025-10-13T05:58:57,284	418594	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 370.0 in stage 0.0 (TID 370) in 31174 ms on 172.35.34.68 (executor 9) (372/590)
"
1760335137477,"INFO	2025-10-13T05:58:57,476	418786	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 410.0 in stage 0.0 (TID 410) (172.34.102.82, executor 18, partition 410, PROCESS_LOCAL, 29316 bytes) 
"
1760335137477,"INFO	2025-10-13T05:58:57,477	418787	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 373.0 in stage 0.0 (TID 373) in 30368 ms on 172.34.102.82 (executor 18) (373/590)
"
1760335138072,"INFO	2025-10-13T05:58:58,072	419382	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 411.0 in stage 0.0 (TID 411) (172.34.158.2, executor 2, partition 411, PROCESS_LOCAL, 29316 bytes) 
"
1760335138073,"INFO	2025-10-13T05:58:58,072	419382	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 378.0 in stage 0.0 (TID 378) in 27069 ms on 172.34.158.2 (executor 2) (374/590)
"
1760335138137,"INFO	2025-10-13T05:58:58,137	419447	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 412.0 in stage 0.0 (TID 412) (172.35.115.9, executor 10, partition 412, PROCESS_LOCAL, 29316 bytes) 
"
1760335138137,"INFO	2025-10-13T05:58:58,137	419447	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 375.0 in stage 0.0 (TID 375) in 30270 ms on 172.35.115.9 (executor 10) (375/590)
"
1760335138730,"INFO	2025-10-13T05:58:58,730	420040	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 413.0 in stage 0.0 (TID 413) (172.34.139.155, executor 15, partition 413, PROCESS_LOCAL, 29316 bytes) 
"
1760335138731,"INFO	2025-10-13T05:58:58,730	420040	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 376.0 in stage 0.0 (TID 376) in 30493 ms on 172.34.139.155 (executor 15) (376/590)
"
1760335138818,"INFO	2025-10-13T05:58:58,817	420127	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 414.0 in stage 0.0 (TID 414) (172.35.230.30, executor 7, partition 414, PROCESS_LOCAL, 29316 bytes) 
"
1760335138818,"INFO	2025-10-13T05:58:58,818	420128	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 380.0 in stage 0.0 (TID 380) in 24041 ms on 172.35.230.30 (executor 7) (377/590)
"
1760335138903,"INFO	2025-10-13T05:58:58,902	420212	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 415.0 in stage 0.0 (TID 415) (172.34.247.5, executor 6, partition 415, PROCESS_LOCAL, 29316 bytes) 
"
1760335138903,"INFO	2025-10-13T05:58:58,903	420213	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 381.0 in stage 0.0 (TID 381) in 23946 ms on 172.34.247.5 (executor 6) (378/590)
"
1760335138908,"INFO	2025-10-13T05:58:58,908	420218	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 416.0 in stage 0.0 (TID 416) (172.34.78.80, executor 12, partition 416, PROCESS_LOCAL, 29316 bytes) 
"
1760335138908,"INFO	2025-10-13T05:58:58,908	420218	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 372.0 in stage 0.0 (TID 372) in 32156 ms on 172.34.78.80 (executor 12) (379/590)
"
1760335139163,"INFO	2025-10-13T05:58:59,163	420473	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 417.0 in stage 0.0 (TID 417) (172.34.59.71, executor 19, partition 417, PROCESS_LOCAL, 29316 bytes) 
"
1760335139163,"INFO	2025-10-13T05:58:59,163	420473	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 368.0 in stage 0.0 (TID 368) in 33405 ms on 172.34.59.71 (executor 19) (380/590)
"
1760335139513,"INFO	2025-10-13T05:58:59,513	420823	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 418.0 in stage 0.0 (TID 418) (172.34.78.80, executor 12, partition 418, PROCESS_LOCAL, 29316 bytes) 
"
1760335139514,"INFO	2025-10-13T05:58:59,513	420823	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 374.0 in stage 0.0 (TID 374) in 32133 ms on 172.34.78.80 (executor 12) (381/590)
"
1760335140640,"INFO	2025-10-13T05:59:00,639	421949	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 419.0 in stage 0.0 (TID 419) (172.34.249.48, executor 17, partition 419, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:59:00,639	421949	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 383.0 in stage 0.0 (TID 383) in 23165 ms on 172.34.249.48 (executor 17) (382/590)
"
1760335144189,"INFO	2025-10-13T05:59:04,189	425499	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335144190,"INFO	2025-10-13T05:59:04,189	425499	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 57, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335144190,"INFO	2025-10-13T05:59:04,190	425500	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 57; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_57_a_spark-application-1760334728567_p_1
"
1760335144190,"INFO	2025-10-13T05:59:04,190	425500	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335144237,"INFO	2025-10-13T05:59:04,237	425547	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335144237,"INFO	2025-10-13T05:59:04,237	425547	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 9a0bcc3b-4d73-43eb-9d68-82f37c757f33)
INFO	2025-10-13T05:59:04,237	425547	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 57 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335144575,"INFO	2025-10-13T05:59:04,575	425885	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 420.0 in stage 0.0 (TID 420) (172.34.76.221, executor 11, partition 420, PROCESS_LOCAL, 29316 bytes) 
"
1760335144575,"INFO	2025-10-13T05:59:04,575	425885	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 385.0 in stage 0.0 (TID 385) in 25705 ms on 172.34.76.221 (executor 11) (383/590)
"
1760335144784,"INFO	2025-10-13T05:59:04,784	426094	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 421.0 in stage 0.0 (TID 421) (172.34.1.110, executor 14, partition 421, PROCESS_LOCAL, 29316 bytes) 
"
1760335144785,"INFO	2025-10-13T05:59:04,784	426094	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 387.0 in stage 0.0 (TID 387) in 23776 ms on 172.34.1.110 (executor 14) (384/590)
"
1760335145184,"INFO	2025-10-13T05:59:05,184	426494	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 422.0 in stage 0.0 (TID 422) (172.35.30.152, executor 1, partition 422, PROCESS_LOCAL, 29316 bytes) 
"
1760335145185,"INFO	2025-10-13T05:59:05,184	426494	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 386.0 in stage 0.0 (TID 386) in 24792 ms on 172.35.30.152 (executor 1) (385/590)
"
1760335145938,"INFO	2025-10-13T05:59:05,938	427248	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 423.0 in stage 0.0 (TID 423) (172.34.117.91, executor 13, partition 423, PROCESS_LOCAL, 29316 bytes) 
"
1760335145939,"INFO	2025-10-13T05:59:05,938	427248	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 379.0 in stage 0.0 (TID 379) in 32488 ms on 172.34.117.91 (executor 13) (386/590)
"
1760335146087,"INFO	2025-10-13T05:59:06,087	427397	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 424.0 in stage 0.0 (TID 424) (172.34.117.91, executor 13, partition 424, PROCESS_LOCAL, 29316 bytes) 
"
1760335146088,"INFO	2025-10-13T05:59:06,088	427398	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 382.0 in stage 0.0 (TID 382) in 30301 ms on 172.34.117.91 (executor 13) (387/590)
"
1760335147458,"INFO	2025-10-13T05:59:07,458	428768	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 425.0 in stage 0.0 (TID 425) (172.35.116.46, executor 4, partition 425, PROCESS_LOCAL, 29316 bytes) 
"
1760335147459,"INFO	2025-10-13T05:59:07,459	428769	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 384.0 in stage 0.0 (TID 384) in 28704 ms on 172.35.116.46 (executor 4) (388/590)
"
1760335148694,"INFO	2025-10-13T05:59:08,694	430004	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
INFO	2025-10-13T05:59:08,694	430004	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760335151936,"INFO	2025-10-13T05:59:11,935	433245	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 426.0 in stage 0.0 (TID 426) (172.35.230.30, executor 7, partition 426, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:59:11,936	433246	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 390.0 in stage 0.0 (TID 390) in 24821 ms on 172.35.230.30 (executor 7) (389/590)
"
1760335153898,"INFO	2025-10-13T05:59:13,898	435208	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 427.0 in stage 0.0 (TID 427) (172.34.247.5, executor 6, partition 427, PROCESS_LOCAL, 29316 bytes) 
"
1760335153898,"INFO	2025-10-13T05:59:13,898	435208	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 392.0 in stage 0.0 (TID 392) in 26210 ms on 172.34.247.5 (executor 6) (390/590)
"
1760335153942,"INFO	2025-10-13T05:59:13,942	435252	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 428.0 in stage 0.0 (TID 428) (172.34.145.94, executor 3, partition 428, PROCESS_LOCAL, 29316 bytes) 
"
1760335153943,"INFO	2025-10-13T05:59:13,942	435252	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 389.0 in stage 0.0 (TID 389) in 26938 ms on 172.34.145.94 (executor 3) (391/590)
"
1760335154168,"INFO	2025-10-13T05:59:14,168	435478	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 429.0 in stage 0.0 (TID 429) (172.35.116.46, executor 4, partition 429, PROCESS_LOCAL, 29316 bytes) 
"
1760335154168,"INFO	2025-10-13T05:59:14,168	435478	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 388.0 in stage 0.0 (TID 388) in 32270 ms on 172.35.116.46 (executor 4) (392/590)
"
1760335154442,"INFO	2025-10-13T05:59:14,442	435752	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 430.0 in stage 0.0 (TID 430) (172.34.158.2, executor 2, partition 430, PROCESS_LOCAL, 29316 bytes) 
"
1760335154443,"INFO	2025-10-13T05:59:14,442	435752	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 391.0 in stage 0.0 (TID 391) in 27239 ms on 172.34.158.2 (executor 2) (393/590)
"
1760335155258,"INFO	2025-10-13T05:59:15,258	436568	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 431.0 in stage 0.0 (TID 431) (172.34.76.221, executor 11, partition 431, PROCESS_LOCAL, 29316 bytes) 
"
1760335155258,"INFO	2025-10-13T05:59:15,258	436568	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 398.0 in stage 0.0 (TID 398) in 23227 ms on 172.34.76.221 (executor 11) (394/590)
"
1760335155374,"INFO	2025-10-13T05:59:15,373	436683	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 432.0 in stage 0.0 (TID 432) (172.34.249.48, executor 17, partition 432, PROCESS_LOCAL, 29316 bytes) 
"
1760335155374,"INFO	2025-10-13T05:59:15,374	436684	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 394.0 in stage 0.0 (TID 394) in 25609 ms on 172.34.249.48 (executor 17) (395/590)
"
1760335156737,"INFO	2025-10-13T05:59:16,736	438046	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 433.0 in stage 0.0 (TID 433) (172.34.1.110, executor 14, partition 433, PROCESS_LOCAL, 29316 bytes) 
"
1760335156737,"INFO	2025-10-13T05:59:16,737	438047	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 395.0 in stage 0.0 (TID 395) in 26559 ms on 172.34.1.110 (executor 14) (396/590)
"
1760335157224,"INFO	2025-10-13T05:59:17,224	438534	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 434.0 in stage 0.0 (TID 434) (172.35.30.152, executor 1, partition 434, PROCESS_LOCAL, 29316 bytes) 
"
1760335157225,"INFO	2025-10-13T05:59:17,224	438534	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 397.0 in stage 0.0 (TID 397) in 25408 ms on 172.35.30.152 (executor 1) (397/590)
"
1760335158679,"INFO	2025-10-13T05:59:18,678	439988	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 435.0 in stage 0.0 (TID 435) (172.35.34.68, executor 9, partition 435, PROCESS_LOCAL, 29316 bytes) 
"
1760335158679,"INFO	2025-10-13T05:59:18,679	439989	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 393.0 in stage 0.0 (TID 393) in 29202 ms on 172.35.34.68 (executor 9) (398/590)
"
1760335159406,"INFO	2025-10-13T05:59:19,405	440715	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335159406,"INFO	2025-10-13T05:59:19,406	440716	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 58, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335159406,"INFO	2025-10-13T05:59:19,406	440716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 58; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_58_a_spark-application-1760334728567_p_1
"
1760335159406,"INFO	2025-10-13T05:59:19,406	440716	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335159696,"INFO	2025-10-13T05:59:19,696	441006	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335159696,"INFO	2025-10-13T05:59:19,696	441006	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 62fd6494-6c9b-45db-89d7-5e3fed0afabf)
INFO	2025-10-13T05:59:19,696	441006	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 58 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335160545,"INFO	2025-10-13T05:59:20,545	441855	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 436.0 in stage 0.0 (TID 436) (172.34.139.155, executor 15, partition 436, PROCESS_LOCAL, 29316 bytes) 
"
1760335160546,"INFO	2025-10-13T05:59:20,545	441855	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 400.0 in stage 0.0 (TID 400) in 28112 ms on 172.34.139.155 (executor 15) (399/590)
"
1760335162676,"INFO	2025-10-13T05:59:22,676	443986	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 437.0 in stage 0.0 (TID 437) (172.34.102.82, executor 18, partition 437, PROCESS_LOCAL, 29316 bytes) 
"
1760335162677,"INFO	2025-10-13T05:59:22,676	443986	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 396.0 in stage 0.0 (TID 396) in 31189 ms on 172.34.102.82 (executor 18) (400/590)
"
1760335163350,"INFO	2025-10-13T05:59:23,349	444659	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335163350,"INFO	2025-10-13T05:59:23,350	444660	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 59, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335163350,"INFO	2025-10-13T05:59:23,350	444660	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 59; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_59_a_spark-application-1760334728567_p_1
"
1760335163350,"INFO	2025-10-13T05:59:23,350	444660	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335163385,"INFO	2025-10-13T05:59:23,385	444695	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335163385,"INFO	2025-10-13T05:59:23,385	444695	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 368b7f9a-b9c9-4058-987d-94b10d878080)
INFO	2025-10-13T05:59:23,385	444695	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 59 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335163737,"INFO	2025-10-13T05:59:23,737	445047	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 438.0 in stage 0.0 (TID 438) (172.35.230.30, executor 7, partition 438, PROCESS_LOCAL, 29316 bytes) 
"
1760335163737,"INFO	2025-10-13T05:59:23,737	445047	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 414.0 in stage 0.0 (TID 414) in 24920 ms on 172.35.230.30 (executor 7) (401/590)
"
1760335164136,"INFO	2025-10-13T05:59:24,136	445446	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 439.0 in stage 0.0 (TID 439) (172.34.89.92, executor 16, partition 439, PROCESS_LOCAL, 29316 bytes) 
"
1760335164136,"INFO	2025-10-13T05:59:24,136	445446	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 401.0 in stage 0.0 (TID 401) in 31101 ms on 172.34.89.92 (executor 16) (402/590)
"
1760335164251,"INFO	2025-10-13T05:59:24,250	445560	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 440.0 in stage 0.0 (TID 440) (172.34.145.94, executor 3, partition 440, PROCESS_LOCAL, 29316 bytes) 
"
1760335164251,"INFO	2025-10-13T05:59:24,250	445560	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 407.0 in stage 0.0 (TID 407) in 27876 ms on 172.34.145.94 (executor 3) (403/590)
"
1760335164279,"INFO	2025-10-13T05:59:24,279	445589	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 441.0 in stage 0.0 (TID 441) (172.35.115.9, executor 10, partition 441, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:59:24,279	445589	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 399.0 in stage 0.0 (TID 399) in 32164 ms on 172.35.115.9 (executor 10) (404/590)
"
1760335164441,"INFO	2025-10-13T05:59:24,441	445751	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335164442,"INFO	2025-10-13T05:59:24,441	445751	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 60, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335164442,"INFO	2025-10-13T05:59:24,442	445752	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 60; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_60_a_spark-application-1760334728567_p_1
"
1760335164442,"INFO	2025-10-13T05:59:24,442	445752	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335164471,"INFO	2025-10-13T05:59:24,471	445781	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335164471,"INFO	2025-10-13T05:59:24,471	445781	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 5e9b1748-3e11-4cc8-b074-7631d91d2068)
"
1760335164471,"INFO	2025-10-13T05:59:24,471	445781	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 60 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335165104,"INFO	2025-10-13T05:59:25,103	446413	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 442.0 in stage 0.0 (TID 442) (172.34.233.198, executor 5, partition 442, PROCESS_LOCAL, 29316 bytes) 
"
1760335165104,"INFO	2025-10-13T05:59:25,104	446414	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 405.0 in stage 0.0 (TID 405) in 30860 ms on 172.34.233.198 (executor 5) (405/590)
"
1760335165325,"INFO	2025-10-13T05:59:25,325	446635	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 443.0 in stage 0.0 (TID 443) (172.34.158.2, executor 2, partition 443, PROCESS_LOCAL, 29316 bytes) 
"
1760335165325,"INFO	2025-10-13T05:59:25,325	446635	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 411.0 in stage 0.0 (TID 411) in 27253 ms on 172.34.158.2 (executor 2) (406/590)
"
1760335165381,"INFO	2025-10-13T05:59:25,381	446691	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 444.0 in stage 0.0 (TID 444) (172.34.89.92, executor 16, partition 444, PROCESS_LOCAL, 29316 bytes) 
"
1760335165382,"INFO	2025-10-13T05:59:25,381	446691	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 404.0 in stage 0.0 (TID 404) in 31237 ms on 172.34.89.92 (executor 16) (407/590)
"
1760335165458,"INFO	2025-10-13T05:59:25,458	446768	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 445.0 in stage 0.0 (TID 445) (172.34.247.5, executor 6, partition 445, PROCESS_LOCAL, 29316 bytes) 
"
1760335165459,"INFO	2025-10-13T05:59:25,458	446768	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 415.0 in stage 0.0 (TID 415) in 26556 ms on 172.34.247.5 (executor 6) (408/590)
"
1760335166267,"INFO	2025-10-13T05:59:26,266	447576	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 446.0 in stage 0.0 (TID 446) (172.35.53.249, executor 8, partition 446, PROCESS_LOCAL, 29316 bytes) 
"
1760335166267,"INFO	2025-10-13T05:59:26,267	447577	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 406.0 in stage 0.0 (TID 406) in 31917 ms on 172.35.53.249 (executor 8) (409/590)
"
1760335166723,"INFO	2025-10-13T05:59:26,723	448033	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 447.0 in stage 0.0 (TID 447) (172.35.34.68, executor 9, partition 447, PROCESS_LOCAL, 29316 bytes) 
"
1760335166724,"INFO	2025-10-13T05:59:26,724	448034	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 409.0 in stage 0.0 (TID 409) in 29441 ms on 172.35.34.68 (executor 9) (410/590)
"
1760335166830,"INFO	2025-10-13T05:59:26,830	448140	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 448.0 in stage 0.0 (TID 448) (172.34.59.71, executor 19, partition 448, PROCESS_LOCAL, 29316 bytes) 
"
1760335166831,"INFO	2025-10-13T05:59:26,830	448140	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 408.0 in stage 0.0 (TID 408) in 30256 ms on 172.34.59.71 (executor 19) (411/590)
"
1760335167083,"INFO	2025-10-13T05:59:27,082	448392	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 449.0 in stage 0.0 (TID 449) (172.34.249.48, executor 17, partition 449, PROCESS_LOCAL, 29316 bytes) 
"
1760335167083,"INFO	2025-10-13T05:59:27,083	448393	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 419.0 in stage 0.0 (TID 419) in 26445 ms on 172.34.249.48 (executor 17) (412/590)
"
1760335167153,"INFO	2025-10-13T05:59:27,153	448463	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 450.0 in stage 0.0 (TID 450) (172.34.233.198, executor 5, partition 450, PROCESS_LOCAL, 29316 bytes) 
"
1760335167153,"INFO	2025-10-13T05:59:27,153	448463	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 403.0 in stage 0.0 (TID 403) in 33326 ms on 172.34.233.198 (executor 5) (413/590)
"
1760335167519,"INFO	2025-10-13T05:59:27,519	448829	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 451.0 in stage 0.0 (TID 451) (172.34.76.221, executor 11, partition 451, PROCESS_LOCAL, 29316 bytes) 
"
1760335167520,"INFO	2025-10-13T05:59:27,519	448829	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 420.0 in stage 0.0 (TID 420) in 22945 ms on 172.34.76.221 (executor 11) (414/590)
"
1760335167715,"INFO	2025-10-13T05:59:27,715	449025	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 452.0 in stage 0.0 (TID 452) (172.35.53.249, executor 8, partition 452, PROCESS_LOCAL, 29316 bytes) 
"
1760335167716,"INFO	2025-10-13T05:59:27,715	449025	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 402.0 in stage 0.0 (TID 402) in 34457 ms on 172.35.53.249 (executor 8) (415/590)
"
1760335167801,"INFO	2025-10-13T05:59:27,800	449110	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 453.0 in stage 0.0 (TID 453) (172.34.102.82, executor 18, partition 453, PROCESS_LOCAL, 29316 bytes) 
"
1760335167801,"INFO	2025-10-13T05:59:27,801	449111	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 410.0 in stage 0.0 (TID 410) in 30325 ms on 172.34.102.82 (executor 18) (416/590)
"
1760335168250,"INFO	2025-10-13T05:59:28,250	449560	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 454.0 in stage 0.0 (TID 454) (172.34.1.110, executor 14, partition 454, PROCESS_LOCAL, 29316 bytes) 
"
1760335168250,"INFO	2025-10-13T05:59:28,250	449560	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 421.0 in stage 0.0 (TID 421) in 23467 ms on 172.34.1.110 (executor 14) (417/590)
"
1760335168294,"INFO	2025-10-13T05:59:28,293	449603	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 455.0 in stage 0.0 (TID 455) (172.34.139.155, executor 15, partition 455, PROCESS_LOCAL, 29316 bytes) 
"
1760335168294,"INFO	2025-10-13T05:59:28,294	449604	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 413.0 in stage 0.0 (TID 413) in 29564 ms on 172.34.139.155 (executor 15) (418/590)
"
1760335168548,"INFO	2025-10-13T05:59:28,548	449858	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 456.0 in stage 0.0 (TID 456) (172.35.30.152, executor 1, partition 456, PROCESS_LOCAL, 29316 bytes) 
"
1760335168549,"INFO	2025-10-13T05:59:28,548	449858	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 422.0 in stage 0.0 (TID 422) in 23364 ms on 172.35.30.152 (executor 1) (419/590)
"
1760335168900,"INFO	2025-10-13T05:59:28,900	450210	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 457.0 in stage 0.0 (TID 457) (172.35.115.9, executor 10, partition 457, PROCESS_LOCAL, 29316 bytes) 
"
1760335168900,"INFO	2025-10-13T05:59:28,900	450210	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 412.0 in stage 0.0 (TID 412) in 30763 ms on 172.35.115.9 (executor 10) (420/590)
"
1760335170204,"INFO	2025-10-13T05:59:30,203	451513	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 458.0 in stage 0.0 (TID 458) (172.34.59.71, executor 19, partition 458, PROCESS_LOCAL, 29316 bytes) 
"
1760335170204,"INFO	2025-10-13T05:59:30,204	451514	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 417.0 in stage 0.0 (TID 417) in 31042 ms on 172.34.59.71 (executor 19) (421/590)
"
1760335170648,"INFO	2025-10-13T05:59:30,648	451958	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 459.0 in stage 0.0 (TID 459) (172.34.78.80, executor 12, partition 459, PROCESS_LOCAL, 29316 bytes) 
"
1760335170649,"INFO	2025-10-13T05:59:30,649	451959	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 416.0 in stage 0.0 (TID 416) in 31741 ms on 172.34.78.80 (executor 12) (422/590)
"
1760335171009,"INFO	2025-10-13T05:59:31,009	452319	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 460.0 in stage 0.0 (TID 460) (172.34.78.80, executor 12, partition 460, PROCESS_LOCAL, 29316 bytes) 
"
1760335171009,"INFO	2025-10-13T05:59:31,009	452319	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 418.0 in stage 0.0 (TID 418) in 31496 ms on 172.34.78.80 (executor 12) (423/590)
"
1760335172968,"INFO	2025-10-13T05:59:32,968	454278	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335172968,"INFO	2025-10-13T05:59:32,968	454278	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 61, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335172968,"INFO	2025-10-13T05:59:32,968	454278	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 61; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_61_a_spark-application-1760334728567_p_1
"
1760335172969,"INFO	2025-10-13T05:59:32,968	454278	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335172999,"INFO	2025-10-13T05:59:32,999	454309	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335172999,"INFO	2025-10-13T05:59:32,999	454309	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 84ee28e2-7f65-4e24-a0bb-4531133586c5)
"
1760335172999,"INFO	2025-10-13T05:59:32,999	454309	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 61 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335174247,"INFO	2025-10-13T05:59:34,246	455556	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 461.0 in stage 0.0 (TID 461) (172.35.116.46, executor 4, partition 461, PROCESS_LOCAL, 29316 bytes) 
"
1760335174247,"INFO	2025-10-13T05:59:34,247	455557	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 425.0 in stage 0.0 (TID 425) in 26789 ms on 172.35.116.46 (executor 4) (424/590)
"
1760335175264,"INFO	2025-10-13T05:59:35,263	456573	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 462.0 in stage 0.0 (TID 462) (172.35.230.30, executor 7, partition 462, PROCESS_LOCAL, 29316 bytes) 
"
1760335175264,"INFO	2025-10-13T05:59:35,264	456574	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 426.0 in stage 0.0 (TID 426) in 23329 ms on 172.35.230.30 (executor 7) (425/590)
"
1760335176663,"INFO	2025-10-13T05:59:36,662	457972	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 463.0 in stage 0.0 (TID 463) (172.34.117.91, executor 13, partition 463, PROCESS_LOCAL, 29316 bytes) 
"
1760335176663,"INFO	2025-10-13T05:59:36,663	457973	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 423.0 in stage 0.0 (TID 423) in 30725 ms on 172.34.117.91 (executor 13) (426/590)
"
1760335176826,"INFO	2025-10-13T05:59:36,825	458135	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 464.0 in stage 0.0 (TID 464) (172.34.117.91, executor 13, partition 464, PROCESS_LOCAL, 29316 bytes) 
"
1760335176826,"INFO	2025-10-13T05:59:36,826	458136	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 424.0 in stage 0.0 (TID 424) in 30739 ms on 172.34.117.91 (executor 13) (427/590)
"
1760335177586,"INFO	2025-10-13T05:59:37,586	458896	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 465.0 in stage 0.0 (TID 465) (172.34.145.94, executor 3, partition 465, PROCESS_LOCAL, 29316 bytes) 
"
1760335177587,"INFO	2025-10-13T05:59:37,586	458896	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 428.0 in stage 0.0 (TID 428) in 23644 ms on 172.34.145.94 (executor 3) (428/590)
"
1760335177886,"INFO	2025-10-13T05:59:37,885	459195	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 466.0 in stage 0.0 (TID 466) (172.34.247.5, executor 6, partition 466, PROCESS_LOCAL, 29316 bytes) 
"
1760335177886,"INFO	2025-10-13T05:59:37,886	459196	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 427.0 in stage 0.0 (TID 427) in 23989 ms on 172.34.247.5 (executor 6) (429/590)
"
1760335177909,"INFO	2025-10-13T05:59:37,909	459219	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 467.0 in stage 0.0 (TID 467) (172.34.158.2, executor 2, partition 467, PROCESS_LOCAL, 29316 bytes) 
"
1760335177909,"INFO	2025-10-13T05:59:37,909	459219	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 430.0 in stage 0.0 (TID 430) in 23468 ms on 172.34.158.2 (executor 2) (430/590)
"
1760335178811,"INFO	2025-10-13T05:59:38,810	460120	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 468.0 in stage 0.0 (TID 468) (172.34.76.221, executor 11, partition 468, PROCESS_LOCAL, 29316 bytes) 
"
1760335178811,"INFO	2025-10-13T05:59:38,811	460121	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 431.0 in stage 0.0 (TID 431) in 23554 ms on 172.34.76.221 (executor 11) (431/590)
"
1760335178847,"INFO	2025-10-13T05:59:38,847	460157	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 469.0 in stage 0.0 (TID 469) (172.34.249.48, executor 17, partition 469, PROCESS_LOCAL, 29316 bytes) 
"
1760335178848,"INFO	2025-10-13T05:59:38,848	460158	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 432.0 in stage 0.0 (TID 432) in 23475 ms on 172.34.249.48 (executor 17) (432/590)
"
1760335179284,"INFO	2025-10-13T05:59:39,284	460594	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 470.0 in stage 0.0 (TID 470) (172.34.1.110, executor 14, partition 470, PROCESS_LOCAL, 29316 bytes) 
"
1760335179284,"INFO	2025-10-13T05:59:39,284	460594	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 433.0 in stage 0.0 (TID 433) in 22548 ms on 172.34.1.110 (executor 14) (433/590)
"
1760335179980,"INFO	2025-10-13T05:59:39,980	461290	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 471.0 in stage 0.0 (TID 471) (172.35.30.152, executor 1, partition 471, PROCESS_LOCAL, 29316 bytes) 
"
1760335179981,"INFO	2025-10-13T05:59:39,980	461290	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 434.0 in stage 0.0 (TID 434) in 22757 ms on 172.35.30.152 (executor 1) (434/590)
"
1760335181996,"INFO	2025-10-13T05:59:41,996	463306	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 472.0 in stage 0.0 (TID 472) (172.35.34.68, executor 9, partition 472, PROCESS_LOCAL, 29316 bytes) 
"
1760335181997,"INFO	2025-10-13T05:59:41,997	463307	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 435.0 in stage 0.0 (TID 435) in 23318 ms on 172.35.34.68 (executor 9) (435/590)
"
1760335183012,"INFO	2025-10-13T05:59:43,011	464321	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 473.0 in stage 0.0 (TID 473) (172.35.116.46, executor 4, partition 473, PROCESS_LOCAL, 29316 bytes) 
"
1760335183012,"INFO	2025-10-13T05:59:43,011	464321	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 429.0 in stage 0.0 (TID 429) in 28844 ms on 172.35.116.46 (executor 4) (436/590)
"
1760335184811,"INFO	2025-10-13T05:59:44,810	466120	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 474.0 in stage 0.0 (TID 474) (172.34.139.155, executor 15, partition 474, PROCESS_LOCAL, 29316 bytes) 
"
1760335184811,"INFO	2025-10-13T05:59:44,811	466121	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 436.0 in stage 0.0 (TID 436) in 24267 ms on 172.34.139.155 (executor 15) (437/590)
"
1760335185364,"INFO	2025-10-13T05:59:45,364	466674	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335185364,"INFO	2025-10-13T05:59:45,364	466674	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 62, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335185366,"INFO	2025-10-13T05:59:45,364	466674	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 62; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_62_a_spark-application-1760334728567_p_1
INFO	2025-10-13T05:59:45,364	466674	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335185394,"INFO	2025-10-13T05:59:45,394	466704	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335185395,"INFO	2025-10-13T05:59:45,394	466704	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: cb651bf6-0b0a-41a5-ac84-9de8229daa3a)
"
1760335185395,"INFO	2025-10-13T05:59:45,394	466704	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 62 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335186896,"INFO	2025-10-13T05:59:46,895	468205	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 475.0 in stage 0.0 (TID 475) (172.35.230.30, executor 7, partition 475, PROCESS_LOCAL, 29316 bytes) 
"
1760335186896,"INFO	2025-10-13T05:59:46,896	468206	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 438.0 in stage 0.0 (TID 438) in 23160 ms on 172.35.230.30 (executor 7) (438/590)
"
1760335189351,"INFO	2025-10-13T05:59:49,350	470660	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 476.0 in stage 0.0 (TID 476) (172.34.145.94, executor 3, partition 476, PROCESS_LOCAL, 29316 bytes) 
"
1760335189351,"INFO	2025-10-13T05:59:49,351	470661	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 440.0 in stage 0.0 (TID 440) in 25101 ms on 172.34.145.94 (executor 3) (439/590)
"
1760335190094,"INFO	2025-10-13T05:59:50,094	471404	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 477.0 in stage 0.0 (TID 477) (172.34.158.2, executor 2, partition 477, PROCESS_LOCAL, 29316 bytes) 
"
1760335190094,"INFO	2025-10-13T05:59:50,094	471404	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 443.0 in stage 0.0 (TID 443) in 24770 ms on 172.34.158.2 (executor 2) (440/590)
"
1760335190910,"INFO	2025-10-13T05:59:50,910	472220	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 478.0 in stage 0.0 (TID 478) (172.34.247.5, executor 6, partition 478, PROCESS_LOCAL, 29316 bytes) 
"
1760335190911,"INFO	2025-10-13T05:59:50,910	472220	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 445.0 in stage 0.0 (TID 445) in 25452 ms on 172.34.247.5 (executor 6) (441/590)
"
1760335191430,"INFO	2025-10-13T05:59:51,429	472739	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 479.0 in stage 0.0 (TID 479) (172.34.1.110, executor 14, partition 479, PROCESS_LOCAL, 29316 bytes) 
"
1760335191430,"INFO	2025-10-13T05:59:51,430	472740	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 454.0 in stage 0.0 (TID 454) in 23181 ms on 172.34.1.110 (executor 14) (442/590)
"
1760335191432,"INFO	2025-10-13T05:59:51,432	472742	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 480.0 in stage 0.0 (TID 480) (172.34.102.82, executor 18, partition 480, PROCESS_LOCAL, 29316 bytes) 
"
1760335191432,"INFO	2025-10-13T05:59:51,432	472742	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 437.0 in stage 0.0 (TID 437) in 28757 ms on 172.34.102.82 (executor 18) (443/590)
"
1760335191782,"INFO	2025-10-13T05:59:51,782	473092	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 481.0 in stage 0.0 (TID 481) (172.34.76.221, executor 11, partition 481, PROCESS_LOCAL, 29316 bytes) 
"
1760335191783,"INFO	2025-10-13T05:59:51,782	473092	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 451.0 in stage 0.0 (TID 451) in 24263 ms on 172.34.76.221 (executor 11) (444/590)
"
1760335191803,"INFO	2025-10-13T05:59:51,803	473113	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 482.0 in stage 0.0 (TID 482) (172.34.249.48, executor 17, partition 482, PROCESS_LOCAL, 29316 bytes) 
"
1760335191803,"INFO	2025-10-13T05:59:51,803	473113	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 449.0 in stage 0.0 (TID 449) in 24721 ms on 172.34.249.48 (executor 17) (445/590)
"
1760335192236,"INFO	2025-10-13T05:59:52,236	473546	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335192236,"INFO	2025-10-13T05:59:52,236	473546	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 63, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335192237,"INFO	2025-10-13T05:59:52,236	473546	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 63; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_63_a_spark-application-1760334728567_p_1
"
1760335192237,"INFO	2025-10-13T05:59:52,237	473547	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335192266,"INFO	2025-10-13T05:59:52,266	473576	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335192266,"INFO	2025-10-13T05:59:52,266	473576	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: ed248371-8a4c-436c-a38f-5ebc041a48a0)
"
1760335192266,"INFO	2025-10-13T05:59:52,266	473576	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 63 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335192716,"INFO	2025-10-13T05:59:52,715	474025	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 483.0 in stage 0.0 (TID 483) (172.35.30.152, executor 1, partition 483, PROCESS_LOCAL, 29316 bytes) 
"
1760335192716,"INFO	2025-10-13T05:59:52,716	474026	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 456.0 in stage 0.0 (TID 456) in 24168 ms on 172.35.30.152 (executor 1) (446/590)
"
1760335193318,"INFO	2025-10-13T05:59:53,318	474628	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 484.0 in stage 0.0 (TID 484) (172.35.34.68, executor 9, partition 484, PROCESS_LOCAL, 29316 bytes) 
"
1760335193319,"INFO	2025-10-13T05:59:53,319	474629	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 447.0 in stage 0.0 (TID 447) in 26596 ms on 172.35.34.68 (executor 9) (447/590)
"
1760335195281,"INFO	2025-10-13T05:59:55,280	476590	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 485.0 in stage 0.0 (TID 485) (172.34.89.92, executor 16, partition 485, PROCESS_LOCAL, 29316 bytes) 
INFO	2025-10-13T05:59:55,280	476590	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 439.0 in stage 0.0 (TID 439) in 31145 ms on 172.34.89.92 (executor 16) (448/590)
"
1760335195363,"INFO	2025-10-13T05:59:55,363	476673	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 486.0 in stage 0.0 (TID 486) (172.35.115.9, executor 10, partition 486, PROCESS_LOCAL, 29316 bytes) 
"
1760335195364,"INFO	2025-10-13T05:59:55,364	476674	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 441.0 in stage 0.0 (TID 441) in 31084 ms on 172.35.115.9 (executor 10) (449/590)
"
1760335195781,"INFO	2025-10-13T05:59:55,781	477091	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 487.0 in stage 0.0 (TID 487) (172.34.139.155, executor 15, partition 487, PROCESS_LOCAL, 29316 bytes) 
"
1760335195782,"INFO	2025-10-13T05:59:55,782	477092	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 455.0 in stage 0.0 (TID 455) in 27489 ms on 172.34.139.155 (executor 15) (450/590)
"
1760335196587,"INFO	2025-10-13T05:59:56,587	477897	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 488.0 in stage 0.0 (TID 488) (172.35.116.46, executor 4, partition 488, PROCESS_LOCAL, 29316 bytes) 
"
1760335196587,"INFO	2025-10-13T05:59:56,587	477897	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 461.0 in stage 0.0 (TID 461) in 22341 ms on 172.35.116.46 (executor 4) (451/590)
"
1760335197536,"INFO	2025-10-13T05:59:57,536	478846	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 489.0 in stage 0.0 (TID 489) (172.34.233.198, executor 5, partition 489, PROCESS_LOCAL, 29316 bytes) 
"
1760335197537,"INFO	2025-10-13T05:59:57,537	478847	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 442.0 in stage 0.0 (TID 442) in 32434 ms on 172.34.233.198 (executor 5) (452/590)
"
1760335197753,"INFO	2025-10-13T05:59:57,753	479063	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 490.0 in stage 0.0 (TID 490) (172.34.89.92, executor 16, partition 490, PROCESS_LOCAL, 29316 bytes) 
"
1760335197753,"INFO	2025-10-13T05:59:57,753	479063	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 444.0 in stage 0.0 (TID 444) in 32372 ms on 172.34.89.92 (executor 16) (453/590)
"
1760335197978,"INFO	2025-10-13T05:59:57,978	479288	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 491.0 in stage 0.0 (TID 491) (172.34.59.71, executor 19, partition 491, PROCESS_LOCAL, 29316 bytes) 
"
1760335197978,"INFO	2025-10-13T05:59:57,978	479288	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 448.0 in stage 0.0 (TID 448) in 31148 ms on 172.34.59.71 (executor 19) (454/590)
"
1760335198395,"INFO	2025-10-13T05:59:58,394	479704	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 492.0 in stage 0.0 (TID 492) (172.34.102.82, executor 18, partition 492, PROCESS_LOCAL, 29316 bytes) 
"
1760335198395,"INFO	2025-10-13T05:59:58,394	479704	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 453.0 in stage 0.0 (TID 453) in 30594 ms on 172.34.102.82 (executor 18) (455/590)
"
1760335198461,"INFO	2025-10-13T05:59:58,461	479771	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 493.0 in stage 0.0 (TID 493) (172.35.230.30, executor 7, partition 493, PROCESS_LOCAL, 29316 bytes) 
"
1760335198462,"INFO	2025-10-13T05:59:58,461	479771	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 462.0 in stage 0.0 (TID 462) in 23198 ms on 172.35.230.30 (executor 7) (456/590)
"
1760335199215,"INFO	2025-10-13T05:59:59,215	480525	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 494.0 in stage 0.0 (TID 494) (172.35.53.249, executor 8, partition 494, PROCESS_LOCAL, 29316 bytes) 
"
1760335199215,"INFO	2025-10-13T05:59:59,215	480525	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 446.0 in stage 0.0 (TID 446) in 32949 ms on 172.35.53.249 (executor 8) (457/590)
"
1760335199737,"INFO	2025-10-13T05:59:59,736	481046	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 495.0 in stage 0.0 (TID 495) (172.34.233.198, executor 5, partition 495, PROCESS_LOCAL, 29316 bytes) 
"
1760335199737,"INFO	2025-10-13T05:59:59,736	481046	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 450.0 in stage 0.0 (TID 450) in 32583 ms on 172.34.233.198 (executor 5) (458/590)
"
1760335200917,"INFO	2025-10-13T06:00:00,916	482226	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 496.0 in stage 0.0 (TID 496) (172.35.115.9, executor 10, partition 496, PROCESS_LOCAL, 29316 bytes) 
"
1760335200917,"INFO	2025-10-13T06:00:00,917	482227	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 457.0 in stage 0.0 (TID 457) in 32018 ms on 172.35.115.9 (executor 10) (459/590)
"
1760335201236,"INFO	2025-10-13T06:00:01,236	482546	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 497.0 in stage 0.0 (TID 497) (172.35.53.249, executor 8, partition 497, PROCESS_LOCAL, 29316 bytes) 
"
1760335201237,"INFO	2025-10-13T06:00:01,236	482546	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 452.0 in stage 0.0 (TID 452) in 33521 ms on 172.35.53.249 (executor 8) (460/590)
"
1760335201255,"INFO	2025-10-13T06:00:01,255	482565	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 498.0 in stage 0.0 (TID 498) (172.34.145.94, executor 3, partition 498, PROCESS_LOCAL, 29316 bytes) 
"
1760335201256,"INFO	2025-10-13T06:00:01,255	482565	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 465.0 in stage 0.0 (TID 465) in 23669 ms on 172.34.145.94 (executor 3) (461/590)
"
1760335201747,"INFO	2025-10-13T06:00:01,746	483056	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335201747,"INFO	2025-10-13T06:00:01,747	483057	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 64, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335201747,"INFO	2025-10-13T06:00:01,747	483057	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 64; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_64_a_spark-application-1760334728567_p_1
"
1760335201747,"INFO	2025-10-13T06:00:01,747	483057	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335201777,"INFO	2025-10-13T06:00:01,777	483087	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335201777,"INFO	2025-10-13T06:00:01,777	483087	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: b588c099-d308-45e2-a395-831a5c5dbfee)
"
1760335201777,"INFO	2025-10-13T06:00:01,777	483087	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 64 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335202129,"INFO	2025-10-13T06:00:02,128	483438	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 499.0 in stage 0.0 (TID 499) (172.34.59.71, executor 19, partition 499, PROCESS_LOCAL, 29316 bytes) 
"
1760335202129,"INFO	2025-10-13T06:00:02,129	483439	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 458.0 in stage 0.0 (TID 458) in 31926 ms on 172.34.59.71 (executor 19) (462/590)
"
1760335202557,"INFO	2025-10-13T06:00:02,557	483867	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 500.0 in stage 0.0 (TID 500) (172.34.247.5, executor 6, partition 500, PROCESS_LOCAL, 29316 bytes) 
"
1760335202558,"INFO	2025-10-13T06:00:02,558	483868	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 466.0 in stage 0.0 (TID 466) in 24673 ms on 172.34.247.5 (executor 6) (463/590)
"
1760335202622,"INFO	2025-10-13T06:00:02,621	483931	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 501.0 in stage 0.0 (TID 501) (172.34.1.110, executor 14, partition 501, PROCESS_LOCAL, 29316 bytes) 
"
1760335202622,"INFO	2025-10-13T06:00:02,622	483932	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 470.0 in stage 0.0 (TID 470) in 23339 ms on 172.34.1.110 (executor 14) (464/590)
"
1760335202921,"INFO	2025-10-13T06:00:02,920	484230	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 502.0 in stage 0.0 (TID 502) (172.34.158.2, executor 2, partition 502, PROCESS_LOCAL, 29316 bytes) 
"
1760335202921,"INFO	2025-10-13T06:00:02,921	484231	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 467.0 in stage 0.0 (TID 467) in 25013 ms on 172.34.158.2 (executor 2) (465/590)
"
1760335203027,"INFO	2025-10-13T06:00:03,026	484336	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 503.0 in stage 0.0 (TID 503) (172.34.76.221, executor 11, partition 503, PROCESS_LOCAL, 29316 bytes) 
"
1760335203027,"INFO	2025-10-13T06:00:03,027	484337	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 468.0 in stage 0.0 (TID 468) in 24217 ms on 172.34.76.221 (executor 11) (466/590)
"
1760335203961,"INFO	2025-10-13T06:00:03,960	485270	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 504.0 in stage 0.0 (TID 504) (172.34.78.80, executor 12, partition 504, PROCESS_LOCAL, 29316 bytes) 
"
1760335203961,"INFO	2025-10-13T06:00:03,961	485271	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 459.0 in stage 0.0 (TID 459) in 33313 ms on 172.34.78.80 (executor 12) (467/590)
"
1760335203970,"INFO	2025-10-13T06:00:03,970	485280	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 505.0 in stage 0.0 (TID 505) (172.34.249.48, executor 17, partition 505, PROCESS_LOCAL, 29316 bytes) 
"
1760335203971,"INFO	2025-10-13T06:00:03,971	485281	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 469.0 in stage 0.0 (TID 469) in 25124 ms on 172.34.249.48 (executor 17) (468/590)
"
1760335203992,"INFO	2025-10-13T06:00:03,992	485302	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 506.0 in stage 0.0 (TID 506) (172.35.30.152, executor 1, partition 506, PROCESS_LOCAL, 29316 bytes) 
"
1760335203992,"INFO	2025-10-13T06:00:03,992	485302	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 471.0 in stage 0.0 (TID 471) in 24013 ms on 172.35.30.152 (executor 1) (469/590)
"
1760335204286,"INFO	2025-10-13T06:00:04,286	485596	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 507.0 in stage 0.0 (TID 507) (172.34.78.80, executor 12, partition 507, PROCESS_LOCAL, 29316 bytes) 
"
1760335204286,"INFO	2025-10-13T06:00:04,286	485596	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 460.0 in stage 0.0 (TID 460) in 33278 ms on 172.34.78.80 (executor 12) (470/590)
"
1760335206040,"INFO	2025-10-13T06:00:06,039	487349	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 508.0 in stage 0.0 (TID 508) (172.35.34.68, executor 9, partition 508, PROCESS_LOCAL, 29316 bytes) 
"
1760335206040,"INFO	2025-10-13T06:00:06,040	487350	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 472.0 in stage 0.0 (TID 472) in 24044 ms on 172.35.34.68 (executor 9) (471/590)
"
1760335207242,"INFO	2025-10-13T06:00:07,242	488552	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 509.0 in stage 0.0 (TID 509) (172.34.117.91, executor 13, partition 509, PROCESS_LOCAL, 29316 bytes) 
"
1760335207242,"INFO	2025-10-13T06:00:07,242	488552	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 464.0 in stage 0.0 (TID 464) in 30417 ms on 172.34.117.91 (executor 13) (472/590)
"
1760335207257,"INFO	2025-10-13T06:00:07,257	488567	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 510.0 in stage 0.0 (TID 510) (172.34.117.91, executor 13, partition 510, PROCESS_LOCAL, 29316 bytes) 
"
1760335207257,"INFO	2025-10-13T06:00:07,257	488567	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 463.0 in stage 0.0 (TID 463) in 30595 ms on 172.34.117.91 (executor 13) (473/590)
"
1760335208276,"INFO	2025-10-13T06:00:08,276	489586	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 511.0 in stage 0.0 (TID 511) (172.35.116.46, executor 4, partition 511, PROCESS_LOCAL, 29316 bytes) 
"
1760335208277,"INFO	2025-10-13T06:00:08,277	489587	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 473.0 in stage 0.0 (TID 473) in 25266 ms on 172.35.116.46 (executor 4) (474/590)
"
1760335208695,"INFO	2025-10-13T06:00:08,695	490005	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760335208695,"INFO	2025-10-13T06:00:08,695	490005	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760335209270,"INFO	2025-10-13T06:00:09,269	490579	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 512.0 in stage 0.0 (TID 512) (172.34.139.155, executor 15, partition 512, PROCESS_LOCAL, 29316 bytes) 
"
1760335209270,"INFO	2025-10-13T06:00:09,270	490580	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 474.0 in stage 0.0 (TID 474) in 24460 ms on 172.34.139.155 (executor 15) (475/590)
"
1760335211548,"INFO	2025-10-13T06:00:11,548	492858	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 513.0 in stage 0.0 (TID 513) (172.35.230.30, executor 7, partition 513, PROCESS_LOCAL, 29316 bytes) 
"
1760335211548,"INFO	2025-10-13T06:00:11,548	492858	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 475.0 in stage 0.0 (TID 475) in 24653 ms on 172.35.230.30 (executor 7) (476/590)
"
1760335212841,"INFO	2025-10-13T06:00:12,840	494150	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335212841,"INFO	2025-10-13T06:00:12,841	494151	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 65, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335212841,"INFO	2025-10-13T06:00:12,841	494151	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 65; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_65_a_spark-application-1760334728567_p_1
"
1760335212841,"INFO	2025-10-13T06:00:12,841	494151	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335212879,"INFO	2025-10-13T06:00:12,879	494189	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335212879,"INFO	2025-10-13T06:00:12,879	494189	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: e934710c-ea06-4ecf-a431-7a538e059fea)
"
1760335212879,"INFO	2025-10-13T06:00:12,879	494189	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 65 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335213573,"INFO	2025-10-13T06:00:13,573	494883	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 514.0 in stage 0.0 (TID 514) (172.34.145.94, executor 3, partition 514, PROCESS_LOCAL, 29316 bytes) 
"
1760335213574,"INFO	2025-10-13T06:00:13,574	494884	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 476.0 in stage 0.0 (TID 476) in 24224 ms on 172.34.145.94 (executor 3) (477/590)
"
1760335215008,"INFO	2025-10-13T06:00:15,008	496318	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 515.0 in stage 0.0 (TID 515) (172.34.158.2, executor 2, partition 515, PROCESS_LOCAL, 29316 bytes) 
"
1760335215008,"INFO	2025-10-13T06:00:15,008	496318	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 477.0 in stage 0.0 (TID 477) in 24915 ms on 172.34.158.2 (executor 2) (478/590)
"
1760335215256,"INFO	2025-10-13T06:00:15,256	496566	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 516.0 in stage 0.0 (TID 516) (172.34.1.110, executor 14, partition 516, PROCESS_LOCAL, 29316 bytes) 
"
1760335215257,"INFO	2025-10-13T06:00:15,257	496567	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 479.0 in stage 0.0 (TID 479) in 23828 ms on 172.34.1.110 (executor 14) (479/590)
"
1760335216042,"INFO	2025-10-13T06:00:16,042	497352	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 517.0 in stage 0.0 (TID 517) (172.34.76.221, executor 11, partition 517, PROCESS_LOCAL, 29316 bytes) 
"
1760335216043,"INFO	2025-10-13T06:00:16,043	497353	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 481.0 in stage 0.0 (TID 481) in 24261 ms on 172.34.76.221 (executor 11) (480/590)
"
1760335216306,"INFO	2025-10-13T06:00:16,305	497615	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 518.0 in stage 0.0 (TID 518) (172.34.249.48, executor 17, partition 518, PROCESS_LOCAL, 29316 bytes) 
"
1760335216306,"INFO	2025-10-13T06:00:16,306	497616	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 482.0 in stage 0.0 (TID 482) in 24504 ms on 172.34.249.48 (executor 17) (481/590)
"
1760335216698,"INFO	2025-10-13T06:00:16,697	498007	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 519.0 in stage 0.0 (TID 519) (172.34.247.5, executor 6, partition 519, PROCESS_LOCAL, 29316 bytes) 
"
1760335216698,"INFO	2025-10-13T06:00:16,698	498008	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 478.0 in stage 0.0 (TID 478) in 25789 ms on 172.34.247.5 (executor 6) (482/590)
"
1760335216984,"INFO	2025-10-13T06:00:16,984	498294	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 520.0 in stage 0.0 (TID 520) (172.35.30.152, executor 1, partition 520, PROCESS_LOCAL, 29316 bytes) 
"
1760335216984,"INFO	2025-10-13T06:00:16,984	498294	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 483.0 in stage 0.0 (TID 483) in 24269 ms on 172.35.30.152 (executor 1) (483/590)
"
1760335218108,"INFO	2025-10-13T06:00:18,107	499417	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 521.0 in stage 0.0 (TID 521) (172.35.34.68, executor 9, partition 521, PROCESS_LOCAL, 29316 bytes) 
"
1760335218108,"INFO	2025-10-13T06:00:18,108	499418	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 484.0 in stage 0.0 (TID 484) in 24790 ms on 172.35.34.68 (executor 9) (484/590)
"
1760335219012,"INFO	2025-10-13T06:00:19,012	500322	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 522.0 in stage 0.0 (TID 522) (172.34.102.82, executor 18, partition 522, PROCESS_LOCAL, 29316 bytes) 
"
1760335219013,"INFO	2025-10-13T06:00:19,012	500322	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 480.0 in stage 0.0 (TID 480) in 27580 ms on 172.34.102.82 (executor 18) (485/590)
"
1760335219625,"INFO	2025-10-13T06:00:19,624	500934	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 523.0 in stage 0.0 (TID 523) (172.35.116.46, executor 4, partition 523, PROCESS_LOCAL, 29316 bytes) 
"
1760335219625,"INFO	2025-10-13T06:00:19,624	500934	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 488.0 in stage 0.0 (TID 488) in 23038 ms on 172.35.116.46 (executor 4) (486/590)
"
1760335220483,"INFO	2025-10-13T06:00:20,482	501792	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 524.0 in stage 0.0 (TID 524) (172.34.139.155, executor 15, partition 524, PROCESS_LOCAL, 29316 bytes) 
"
1760335220483,"INFO	2025-10-13T06:00:20,483	501793	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 487.0 in stage 0.0 (TID 487) in 24702 ms on 172.34.139.155 (executor 15) (487/590)
"
1760335222765,"INFO	2025-10-13T06:00:22,765	504075	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335222765,"INFO	2025-10-13T06:00:22,765	504075	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 66, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335222765,"INFO	2025-10-13T06:00:22,765	504075	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 66; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_66_a_spark-application-1760334728567_p_1
"
1760335222766,"INFO	2025-10-13T06:00:22,766	504076	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335222805,"INFO	2025-10-13T06:00:22,805	504115	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335222805,"INFO	2025-10-13T06:00:22,805	504115	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: 8800bb5b-25cd-4ad7-a699-ba64a9ee3fa3)
"
1760335222805,"INFO	2025-10-13T06:00:22,805	504115	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 66 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335223105,"INFO	2025-10-13T06:00:23,105	504415	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 525.0 in stage 0.0 (TID 525) (172.35.230.30, executor 7, partition 525, PROCESS_LOCAL, 29316 bytes) 
"
1760335223106,"INFO	2025-10-13T06:00:23,105	504415	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 493.0 in stage 0.0 (TID 493) in 24644 ms on 172.35.230.30 (executor 7) (488/590)
"
1760335224816,"INFO	2025-10-13T06:00:24,816	506126	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 526.0 in stage 0.0 (TID 526) (172.34.145.94, executor 3, partition 526, PROCESS_LOCAL, 29316 bytes) 
"
1760335224817,"INFO	2025-10-13T06:00:24,816	506126	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 498.0 in stage 0.0 (TID 498) in 23561 ms on 172.34.145.94 (executor 3) (489/590)
"
1760335226192,"INFO	2025-10-13T06:00:26,191	507501	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 527.0 in stage 0.0 (TID 527) (172.35.115.9, executor 10, partition 527, PROCESS_LOCAL, 29292 bytes) 
"
1760335226192,"INFO	2025-10-13T06:00:26,192	507502	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 486.0 in stage 0.0 (TID 486) in 30829 ms on 172.35.115.9 (executor 10) (490/590)
"
1760335226391,"INFO	2025-10-13T06:00:26,391	507701	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 528.0 in stage 0.0 (TID 528) (172.34.1.110, executor 14, partition 528, PROCESS_LOCAL, 29292 bytes) 
"
1760335226392,"INFO	2025-10-13T06:00:26,392	507702	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 501.0 in stage 0.0 (TID 501) in 23771 ms on 172.34.1.110 (executor 14) (491/590)
"
1760335227356,"INFO	2025-10-13T06:00:27,356	508666	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 529.0 in stage 0.0 (TID 529) (172.34.89.92, executor 16, partition 529, PROCESS_LOCAL, 29292 bytes) 
"
1760335227357,"INFO	2025-10-13T06:00:27,356	508666	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 485.0 in stage 0.0 (TID 485) in 32076 ms on 172.34.89.92 (executor 16) (492/590)
"
1760335227567,"INFO	2025-10-13T06:00:27,567	508877	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 530.0 in stage 0.0 (TID 530) (172.34.76.221, executor 11, partition 530, PROCESS_LOCAL, 29292 bytes) 
"
1760335227568,"INFO	2025-10-13T06:00:27,567	508877	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 503.0 in stage 0.0 (TID 503) in 24541 ms on 172.34.76.221 (executor 11) (493/590)
"
1760335227956,"INFO	2025-10-13T06:00:27,956	509266	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 531.0 in stage 0.0 (TID 531) (172.34.158.2, executor 2, partition 531, PROCESS_LOCAL, 29292 bytes) 
"
1760335227956,"INFO	2025-10-13T06:00:27,956	509266	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 502.0 in stage 0.0 (TID 502) in 25036 ms on 172.34.158.2 (executor 2) (494/590)
"
1760335228025,"INFO	2025-10-13T06:00:28,025	509335	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 532.0 in stage 0.0 (TID 532) (172.34.102.82, executor 18, partition 532, PROCESS_LOCAL, 29292 bytes) 
"
1760335228025,"INFO	2025-10-13T06:00:28,025	509335	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 492.0 in stage 0.0 (TID 492) in 29632 ms on 172.34.102.82 (executor 18) (495/590)
"
1760335228061,"INFO	2025-10-13T06:00:28,061	509371	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 533.0 in stage 0.0 (TID 533) (172.34.247.5, executor 6, partition 533, PROCESS_LOCAL, 29292 bytes) 
"
1760335228062,"INFO	2025-10-13T06:00:28,061	509371	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 500.0 in stage 0.0 (TID 500) in 25504 ms on 172.34.247.5 (executor 6) (496/590)
"
1760335228504,"INFO	2025-10-13T06:00:28,504	509814	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 534.0 in stage 0.0 (TID 534) (172.35.30.152, executor 1, partition 534, PROCESS_LOCAL, 29292 bytes) 
"
1760335228504,"INFO	2025-10-13T06:00:28,504	509814	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 506.0 in stage 0.0 (TID 506) in 24512 ms on 172.35.30.152 (executor 1) (497/590)
"
1760335228559,"INFO	2025-10-13T06:00:28,559	509869	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 535.0 in stage 0.0 (TID 535) (172.34.249.48, executor 17, partition 535, PROCESS_LOCAL, 29292 bytes) 
"
1760335228559,"INFO	2025-10-13T06:00:28,559	509869	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 505.0 in stage 0.0 (TID 505) in 24589 ms on 172.34.249.48 (executor 17) (498/590)
"
1760335229294,"INFO	2025-10-13T06:00:29,294	510604	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335229294,"INFO	2025-10-13T06:00:29,294	510604	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 67, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335229294,"INFO	2025-10-13T06:00:29,294	510604	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 67; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_67_a_spark-application-1760334728567_p_1
"
1760335229294,"INFO	2025-10-13T06:00:29,294	510604	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335229328,"INFO	2025-10-13T06:00:29,328	510638	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335229328,"INFO	2025-10-13T06:00:29,328	510638	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: fc7d7949-c5d1-408a-8595-2bac9de21b86)
"
1760335229328,"INFO	2025-10-13T06:00:29,328	510638	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 67 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335229548,"INFO	2025-10-13T06:00:29,548	510858	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 536.0 in stage 0.0 (TID 536) (172.34.233.198, executor 5, partition 536, PROCESS_LOCAL, 29292 bytes) 
"
1760335229548,"INFO	2025-10-13T06:00:29,548	510858	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 489.0 in stage 0.0 (TID 489) in 32012 ms on 172.34.233.198 (executor 5) (499/590)
"
1760335229702,"INFO	2025-10-13T06:00:29,702	511012	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 537.0 in stage 0.0 (TID 537) (172.34.59.71, executor 19, partition 537, PROCESS_LOCAL, 29292 bytes) 
"
1760335229702,"INFO	2025-10-13T06:00:29,702	511012	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 491.0 in stage 0.0 (TID 491) in 31724 ms on 172.34.59.71 (executor 19) (500/590)
"
1760335229897,"INFO	2025-10-13T06:00:29,897	511207	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 538.0 in stage 0.0 (TID 538) (172.34.89.92, executor 16, partition 538, PROCESS_LOCAL, 29292 bytes) 
INFO	2025-10-13T06:00:29,897	511207	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 490.0 in stage 0.0 (TID 490) in 32144 ms on 172.34.89.92 (executor 16) (501/590)
"
1760335230236,"INFO	2025-10-13T06:00:30,236	511546	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 539.0 in stage 0.0 (TID 539) (172.35.34.68, executor 9, partition 539, PROCESS_LOCAL, 29292 bytes) 
"
1760335230237,"INFO	2025-10-13T06:00:30,236	511546	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 508.0 in stage 0.0 (TID 508) in 24197 ms on 172.35.34.68 (executor 9) (502/590)
"
1760335231360,"INFO	2025-10-13T06:00:31,360	512670	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 540.0 in stage 0.0 (TID 540) (172.35.116.46, executor 4, partition 540, PROCESS_LOCAL, 29292 bytes) 
"
1760335231361,"INFO	2025-10-13T06:00:31,360	512670	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 511.0 in stage 0.0 (TID 511) in 23085 ms on 172.35.116.46 (executor 4) (503/590)
"
1760335231974,"INFO	2025-10-13T06:00:31,973	513283	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760334728567 with resource profile 0
"
1760335231974,"INFO	2025-10-13T06:00:31,974	513284	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.35.202.190:41007, --executor-id, 68, --app-id, spark-application-1760334728567, --cores, 2, --resourceProfileId, 0)
"
1760335231974,"INFO	2025-10-13T06:00:31,974	513284	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 68; clientToken gr_7243f2da-9517-4f1c-891e-8e368dbfd590_e_68_a_spark-application-1760334728567_p_1
"
1760335231974,"INFO	2025-10-13T06:00:31,974	513284	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
"
1760335232005,"INFO	2025-10-13T06:00:32,004	513314	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
"
1760335232005,"INFO	2025-10-13T06:00:32,005	513315	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 20.0 for groupId 7243f2da-9517-4f1c-891e-8e368dbfd590 (Service: GlueJobExecutor, Status Code: 400, Request ID: cef24e58-c5d4-4be8-82cd-353a13199c62)
"
1760335232005,"INFO	2025-10-13T06:00:32,005	513315	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 68 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
"
1760335232010,"INFO	2025-10-13T06:00:32,010	513320	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 541.0 in stage 0.0 (TID 541) (172.35.115.9, executor 10, partition 541, PROCESS_LOCAL, 29292 bytes) 
"
1760335232010,"INFO	2025-10-13T06:00:32,010	513320	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 496.0 in stage 0.0 (TID 496) in 31094 ms on 172.35.115.9 (executor 10) (504/590)
"
1760335232170,"INFO	2025-10-13T06:00:32,169	513479	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 542.0 in stage 0.0 (TID 542) (172.34.233.198, executor 5, partition 542, PROCESS_LOCAL, 29292 bytes) 
"
1760335232170,"INFO	2025-10-13T06:00:32,170	513480	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 495.0 in stage 0.0 (TID 495) in 32434 ms on 172.34.233.198 (executor 5) (505/590)
"
1760335232803,"INFO	2025-10-13T06:00:32,802	514112	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 543.0 in stage 0.0 (TID 543) (172.35.53.249, executor 8, partition 543, PROCESS_LOCAL, 29292 bytes) 
"
1760335232803,"INFO	2025-10-13T06:00:32,803	514113	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 494.0 in stage 0.0 (TID 494) in 33589 ms on 172.35.53.249 (executor 8) (506/590)
"
1760335233387,"INFO	2025-10-13T06:00:33,386	514696	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 544.0 in stage 0.0 (TID 544) (172.34.59.71, executor 19, partition 544, PROCESS_LOCAL, 29292 bytes) 
"
1760335233387,"INFO	2025-10-13T06:00:33,386	514696	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 499.0 in stage 0.0 (TID 499) in 31258 ms on 172.34.59.71 (executor 19) (507/590)
"
1760335233426,"INFO	2025-10-13T06:00:33,426	514736	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 545.0 in stage 0.0 (TID 545) (172.34.139.155, executor 15, partition 545, PROCESS_LOCAL, 29292 bytes) 
"
1760335233426,"INFO	2025-10-13T06:00:33,426	514736	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 512.0 in stage 0.0 (TID 512) in 24157 ms on 172.34.139.155 (executor 15) (508/590)
"
1760335233924,"INFO	2025-10-13T06:00:33,923	515233	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 546.0 in stage 0.0 (TID 546) (172.35.53.249, executor 8, partition 546, PROCESS_LOCAL, 29292 bytes) 
"
1760335233924,"INFO	2025-10-13T06:00:33,924	515234	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 497.0 in stage 0.0 (TID 497) in 32688 ms on 172.35.53.249 (executor 8) (509/590)
"
1760335236246,"INFO	2025-10-13T06:00:36,245	517555	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 547.0 in stage 0.0 (TID 547) (172.35.230.30, executor 7, partition 547, PROCESS_LOCAL, 29292 bytes) 
"
1760335236246,"INFO	2025-10-13T06:00:36,246	517556	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 513.0 in stage 0.0 (TID 513) in 24699 ms on 172.35.230.30 (executor 7) (510/590)
"
1760335237289,"INFO	2025-10-13T06:00:37,288	518598	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 548.0 in stage 0.0 (TID 548) (172.34.78.80, executor 12, partition 548, PROCESS_LOCAL, 29292 bytes) 
INFO	2025-10-13T06:00:37,288	518598	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 504.0 in stage 0.0 (TID 504) in 33328 ms on 172.34.78.80 (executor 12) (511/590)
"
1760335237682,"INFO	2025-10-13T06:00:37,681	518991	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 549.0 in stage 0.0 (TID 549) (172.34.78.80, executor 12, partition 549, PROCESS_LOCAL, 29292 bytes) 
"
1760335237682,"INFO	2025-10-13T06:00:37,682	518992	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 507.0 in stage 0.0 (TID 507) in 33397 ms on 172.34.78.80 (executor 12) (512/590)
"
1760335237843,"INFO	2025-10-13T06:00:37,842	519152	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 550.0 in stage 0.0 (TID 550) (172.34.145.94, executor 3, partition 550, PROCESS_LOCAL, 29292 bytes) 
"
1760335237843,"INFO	2025-10-13T06:00:37,843	519153	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 514.0 in stage 0.0 (TID 514) in 24270 ms on 172.34.145.94 (executor 3) (513/590)
"
1760335238328,"INFO	2025-10-13T06:00:38,328	519638	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 551.0 in stage 0.0 (TID 551) (172.34.1.110, executor 14, partition 551, PROCESS_LOCAL, 29292 bytes) 
"
1760335238329,"INFO	2025-10-13T06:00:38,329	519639	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 516.0 in stage 0.0 (TID 516) in 23072 ms on 172.34.1.110 (executor 14) (514/590)
"
1760335238332,"INFO	2025-10-13T06:00:38,332	519642	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 19
"
1760335238332,"INFO	2025-10-13T06:00:38,332	519642	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 19
"
1760335238758,"INFO	2025-10-13T06:00:38,757	520067	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 552.0 in stage 0.0 (TID 552) (172.34.117.91, executor 13, partition 552, PROCESS_LOCAL, 29292 bytes) 
"
1760335238758,"INFO	2025-10-13T06:00:38,758	520068	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 509.0 in stage 0.0 (TID 509) in 31517 ms on 172.34.117.91 (executor 13) (515/590)
"
1760335238831,"INFO	2025-10-13T06:00:38,830	520140	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 553.0 in stage 0.0 (TID 553) (172.34.117.91, executor 13, partition 553, PROCESS_LOCAL, 29292 bytes) 
"
1760335238831,"INFO	2025-10-13T06:00:38,831	520141	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 510.0 in stage 0.0 (TID 510) in 31575 ms on 172.34.117.91 (executor 13) (516/590)
"
1760335240217,"INFO	2025-10-13T06:00:40,216	521526	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 554.0 in stage 0.0 (TID 554) (172.34.158.2, executor 2, partition 554, PROCESS_LOCAL, 29292 bytes) 
"
1760335240217,"INFO	2025-10-13T06:00:40,217	521527	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 515.0 in stage 0.0 (TID 515) in 25210 ms on 172.34.158.2 (executor 2) (517/590)
"
1760335240919,"INFO	2025-10-13T06:00:40,918	522228	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 555.0 in stage 0.0 (TID 555) (172.34.76.221, executor 11, partition 555, PROCESS_LOCAL, 29292 bytes) 
"
1760335240919,"INFO	2025-10-13T06:00:40,919	522229	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 517.0 in stage 0.0 (TID 517) in 24877 ms on 172.34.76.221 (executor 11) (518/590)
"
1760335240936,"INFO	2025-10-13T06:00:40,936	522246	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 18
"
1760335240936,"INFO	2025-10-13T06:00:40,936	522246	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 18
"
1760335241173,"INFO	2025-10-13T06:00:41,173	522483	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 556.0 in stage 0.0 (TID 556) (172.34.249.48, executor 17, partition 556, PROCESS_LOCAL, 29292 bytes) 
"
1760335241173,"INFO	2025-10-13T06:00:41,173	522483	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 518.0 in stage 0.0 (TID 518) in 24868 ms on 172.34.249.48 (executor 17) (519/590)
"
1760335241341,"INFO	2025-10-13T06:00:41,340	522650	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 557.0 in stage 0.0 (TID 557) (172.35.30.152, executor 1, partition 557, PROCESS_LOCAL, 29292 bytes) 
"
1760335241341,"INFO	2025-10-13T06:00:41,341	522651	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 520.0 in stage 0.0 (TID 520) in 24358 ms on 172.35.30.152 (executor 1) (520/590)
"
1760335241802,"INFO	2025-10-13T06:00:41,802	523112	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 558.0 in stage 0.0 (TID 558) (172.34.247.5, executor 6, partition 558, PROCESS_LOCAL, 29292 bytes) 
"
1760335241803,"INFO	2025-10-13T06:00:41,803	523113	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 519.0 in stage 0.0 (TID 519) in 25106 ms on 172.34.247.5 (executor 6) (521/590)
"
1760335242438,"INFO	2025-10-13T06:00:42,437	523747	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 559.0 in stage 0.0 (TID 559) (172.35.34.68, executor 9, partition 559, PROCESS_LOCAL, 29292 bytes) 
"
1760335242438,"INFO	2025-10-13T06:00:42,438	523748	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 521.0 in stage 0.0 (TID 521) in 24331 ms on 172.35.34.68 (executor 9) (522/590)
"
1760335242538,"INFO	2025-10-13T06:00:42,538	523848	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 17
"
1760335242538,"INFO	2025-10-13T06:00:42,538	523848	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 17
"
1760335243060,"INFO	2025-10-13T06:00:43,060	524370	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 560.0 in stage 0.0 (TID 560) (172.35.116.46, executor 4, partition 560, PROCESS_LOCAL, 29283 bytes) 
"
1760335243061,"INFO	2025-10-13T06:00:43,061	524371	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 523.0 in stage 0.0 (TID 523) in 23437 ms on 172.35.116.46 (executor 4) (523/590)
"
1760335244157,"INFO	2025-10-13T06:00:44,157	525467	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 561.0 in stage 0.0 (TID 561) (172.34.102.82, executor 18, partition 561, PROCESS_LOCAL, 29292 bytes) 
"
1760335244158,"INFO	2025-10-13T06:00:44,157	525467	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 522.0 in stage 0.0 (TID 522) in 25145 ms on 172.34.102.82 (executor 18) (524/590)
"
1760335245065,"INFO	2025-10-13T06:00:45,064	526374	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 562.0 in stage 0.0 (TID 562) (172.34.139.155, executor 15, partition 562, PROCESS_LOCAL, 29292 bytes) 
"
1760335245065,"INFO	2025-10-13T06:00:45,065	526375	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 524.0 in stage 0.0 (TID 524) in 24583 ms on 172.34.139.155 (executor 15) (525/590)
"
1760335247904,"INFO	2025-10-13T06:00:47,903	529213	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 563.0 in stage 0.0 (TID 563) (172.35.230.30, executor 7, partition 563, PROCESS_LOCAL, 29292 bytes) 
"
1760335247904,"INFO	2025-10-13T06:00:47,904	529214	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 525.0 in stage 0.0 (TID 525) in 24799 ms on 172.35.230.30 (executor 7) (526/590)
"
1760335247945,"INFO	2025-10-13T06:00:47,945	529255	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 16
"
1760335247946,"INFO	2025-10-13T06:00:47,945	529255	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 16
"
1760335249739,"INFO	2025-10-13T06:00:49,739	531049	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 564.0 in stage 0.0 (TID 564) (172.34.145.94, executor 3, partition 564, PROCESS_LOCAL, 29292 bytes) 
"
1760335249739,"INFO	2025-10-13T06:00:49,739	531049	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 526.0 in stage 0.0 (TID 526) in 24923 ms on 172.34.145.94 (executor 3) (527/590)
"
1760335249804,"INFO	2025-10-13T06:00:49,804	531114	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 565.0 in stage 0.0 (TID 565) (172.34.1.110, executor 14, partition 565, PROCESS_LOCAL, 29292 bytes) 
"
1760335249805,"INFO	2025-10-13T06:00:49,804	531114	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 528.0 in stage 0.0 (TID 528) in 23413 ms on 172.34.1.110 (executor 14) (528/590)
"
1760335252424,"INFO	2025-10-13T06:00:52,423	533733	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 566.0 in stage 0.0 (TID 566) (172.34.76.221, executor 11, partition 566, PROCESS_LOCAL, 29292 bytes) 
"
1760335252424,"INFO	2025-10-13T06:00:52,424	533734	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 530.0 in stage 0.0 (TID 530) in 24857 ms on 172.34.76.221 (executor 11) (529/590)
"
1760335252611,"INFO	2025-10-13T06:00:52,611	533921	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 567.0 in stage 0.0 (TID 567) (172.34.158.2, executor 2, partition 567, PROCESS_LOCAL, 29292 bytes) 
"
1760335252612,"INFO	2025-10-13T06:00:52,611	533921	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 531.0 in stage 0.0 (TID 531) in 24656 ms on 172.34.158.2 (executor 2) (530/590)
"
1760335252652,"INFO	2025-10-13T06:00:52,651	533961	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 15
"
1760335252652,"INFO	2025-10-13T06:00:52,651	533961	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 15
"
1760335253345,"INFO	2025-10-13T06:00:53,345	534655	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 568.0 in stage 0.0 (TID 568) (172.34.247.5, executor 6, partition 568, PROCESS_LOCAL, 29292 bytes) 
"
1760335253346,"INFO	2025-10-13T06:00:53,345	534655	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 533.0 in stage 0.0 (TID 533) in 25284 ms on 172.34.247.5 (executor 6) (531/590)
"
1760335253709,"INFO	2025-10-13T06:00:53,709	535019	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 569.0 in stage 0.0 (TID 569) (172.34.249.48, executor 17, partition 569, PROCESS_LOCAL, 29292 bytes) 
"
1760335253710,"INFO	2025-10-13T06:00:53,710	535020	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 535.0 in stage 0.0 (TID 535) in 25151 ms on 172.34.249.48 (executor 17) (532/590)
"
1760335253840,"INFO	2025-10-13T06:00:53,840	535150	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 570.0 in stage 0.0 (TID 570) (172.35.30.152, executor 1, partition 570, PROCESS_LOCAL, 29292 bytes) 
"
1760335253840,"INFO	2025-10-13T06:00:53,840	535150	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 534.0 in stage 0.0 (TID 534) in 25337 ms on 172.35.30.152 (executor 1) (533/590)
"
1760335254924,"INFO	2025-10-13T06:00:54,923	536233	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 571.0 in stage 0.0 (TID 571) (172.35.34.68, executor 9, partition 571, PROCESS_LOCAL, 29292 bytes) 
"
1760335254924,"INFO	2025-10-13T06:00:54,924	536234	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 539.0 in stage 0.0 (TID 539) in 24689 ms on 172.35.34.68 (executor 9) (534/590)
"
1760335254955,"INFO	2025-10-13T06:00:54,954	536264	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 14
"
1760335254955,"INFO	2025-10-13T06:00:54,954	536264	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 14
"
1760335255019,"INFO	2025-10-13T06:00:55,018	536328	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 572.0 in stage 0.0 (TID 572) (172.35.116.46, executor 4, partition 572, PROCESS_LOCAL, 29292 bytes) 
"
1760335255019,"INFO	2025-10-13T06:00:55,019	536329	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 540.0 in stage 0.0 (TID 540) in 23659 ms on 172.35.116.46 (executor 4) (535/590)
"
1760335255810,"INFO	2025-10-13T06:00:55,809	537119	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 573.0 in stage 0.0 (TID 573) (172.34.102.82, executor 18, partition 573, PROCESS_LOCAL, 29292 bytes) 
"
1760335255810,"INFO	2025-10-13T06:00:55,810	537120	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 532.0 in stage 0.0 (TID 532) in 27785 ms on 172.34.102.82 (executor 18) (536/590)
"
1760335257492,"INFO	2025-10-13T06:00:57,491	538801	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 574.0 in stage 0.0 (TID 574) (172.35.115.9, executor 10, partition 574, PROCESS_LOCAL, 29292 bytes) 
"
1760335257492,"INFO	2025-10-13T06:00:57,492	538802	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 527.0 in stage 0.0 (TID 527) in 31301 ms on 172.35.115.9 (executor 10) (537/590)
"
1760335257558,"INFO	2025-10-13T06:00:57,558	538868	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 575.0 in stage 0.0 (TID 575) (172.34.139.155, executor 15, partition 575, PROCESS_LOCAL, 29292 bytes) 
"
1760335257559,"INFO	2025-10-13T06:00:57,558	538868	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 545.0 in stage 0.0 (TID 545) in 24132 ms on 172.34.139.155 (executor 15) (538/590)
"
1760335257659,"INFO	2025-10-13T06:00:57,658	538968	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 13
INFO	2025-10-13T06:00:57,659	538969	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 13
"
1760335260169,"INFO	2025-10-13T06:01:00,168	541478	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 576.0 in stage 0.0 (TID 576) (172.35.230.30, executor 7, partition 576, PROCESS_LOCAL, 29292 bytes) 
"
1760335260169,"INFO	2025-10-13T06:01:00,169	541479	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 547.0 in stage 0.0 (TID 547) in 23924 ms on 172.35.230.30 (executor 7) (539/590)
"
1760335260640,"INFO	2025-10-13T06:01:00,640	541950	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 577.0 in stage 0.0 (TID 577) (172.34.89.92, executor 16, partition 577, PROCESS_LOCAL, 29292 bytes) 
"
1760335260641,"INFO	2025-10-13T06:01:00,640	541950	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 529.0 in stage 0.0 (TID 529) in 33285 ms on 172.34.89.92 (executor 16) (540/590)
"
1760335261880,"INFO	2025-10-13T06:01:01,880	543190	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 578.0 in stage 0.0 (TID 578) (172.34.1.110, executor 14, partition 578, PROCESS_LOCAL, 29292 bytes) 
"
1760335261880,"INFO	2025-10-13T06:01:01,880	543190	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 551.0 in stage 0.0 (TID 551) in 23552 ms on 172.34.1.110 (executor 14) (541/590)
"
1760335262020,"INFO	2025-10-13T06:01:02,019	543329	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 579.0 in stage 0.0 (TID 579) (172.34.145.94, executor 3, partition 579, PROCESS_LOCAL, 29292 bytes) 
"
1760335262020,"INFO	2025-10-13T06:01:02,020	543330	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 550.0 in stage 0.0 (TID 550) in 24178 ms on 172.34.145.94 (executor 3) (542/590)
"
1760335262065,"INFO	2025-10-13T06:01:02,065	543375	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 12
"
1760335262065,"INFO	2025-10-13T06:01:02,065	543375	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 12
"
1760335262626,"INFO	2025-10-13T06:01:02,626	543936	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 580.0 in stage 0.0 (TID 580) (172.34.59.71, executor 19, partition 580, PROCESS_LOCAL, 29292 bytes) 
"
1760335262626,"INFO	2025-10-13T06:01:02,626	543936	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 537.0 in stage 0.0 (TID 537) in 32924 ms on 172.34.59.71 (executor 19) (543/590)
"
1760335262932,"INFO	2025-10-13T06:01:02,931	544241	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 581.0 in stage 0.0 (TID 581) (172.34.233.198, executor 5, partition 581, PROCESS_LOCAL, 29292 bytes) 
"
1760335262932,"INFO	2025-10-13T06:01:02,932	544242	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 536.0 in stage 0.0 (TID 536) in 33385 ms on 172.34.233.198 (executor 5) (544/590)
"
1760335263399,"INFO	2025-10-13T06:01:03,398	544708	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 582.0 in stage 0.0 (TID 582) (172.34.89.92, executor 16, partition 582, PROCESS_LOCAL, 29292 bytes) 
"
1760335263399,"INFO	2025-10-13T06:01:03,399	544709	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 538.0 in stage 0.0 (TID 538) in 33502 ms on 172.34.89.92 (executor 16) (545/590)
"
1760335264320,"INFO	2025-10-13T06:01:04,320	545630	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 583.0 in stage 0.0 (TID 583) (172.35.115.9, executor 10, partition 583, PROCESS_LOCAL, 29292 bytes) 
"
1760335264320,"INFO	2025-10-13T06:01:04,320	545630	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 541.0 in stage 0.0 (TID 541) in 32311 ms on 172.35.115.9 (executor 10) (546/590)
"
1760335264369,"INFO	2025-10-13T06:01:04,368	545678	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 11
"
1760335264369,"INFO	2025-10-13T06:01:04,368	545678	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 11
"
1760335265187,"INFO	2025-10-13T06:01:05,187	546497	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 584.0 in stage 0.0 (TID 584) (172.34.76.221, executor 11, partition 584, PROCESS_LOCAL, 29292 bytes) 
"
1760335265188,"INFO	2025-10-13T06:01:05,187	546497	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 555.0 in stage 0.0 (TID 555) in 24269 ms on 172.34.76.221 (executor 11) (547/590)
"
1760335265351,"INFO	2025-10-13T06:01:05,351	546661	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 585.0 in stage 0.0 (TID 585) (172.34.158.2, executor 2, partition 585, PROCESS_LOCAL, 29292 bytes) 
"
1760335265352,"INFO	2025-10-13T06:01:05,352	546662	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 554.0 in stage 0.0 (TID 554) in 25136 ms on 172.34.158.2 (executor 2) (548/590)
"
1760335265478,"INFO	2025-10-13T06:01:05,478	546788	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 586.0 in stage 0.0 (TID 586) (172.34.233.198, executor 5, partition 586, PROCESS_LOCAL, 29292 bytes) 
"
1760335265479,"INFO	2025-10-13T06:01:05,479	546789	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 542.0 in stage 0.0 (TID 542) in 33310 ms on 172.34.233.198 (executor 5) (549/590)
"
1760335265592,"INFO	2025-10-13T06:01:05,592	546902	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 587.0 in stage 0.0 (TID 587) (172.35.30.152, executor 1, partition 587, PROCESS_LOCAL, 29292 bytes) 
"
1760335265593,"INFO	2025-10-13T06:01:05,592	546902	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 557.0 in stage 0.0 (TID 557) in 24252 ms on 172.35.30.152 (executor 1) (550/590)
"
1760335265671,"INFO	2025-10-13T06:01:05,670	546980	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 10
"
1760335265671,"INFO	2025-10-13T06:01:05,671	546981	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 10
"
1760335265841,"INFO	2025-10-13T06:01:05,841	547151	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 588.0 in stage 0.0 (TID 588) (172.34.249.48, executor 17, partition 588, PROCESS_LOCAL, 29292 bytes) 
"
1760335265841,"INFO	2025-10-13T06:01:05,841	547151	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 556.0 in stage 0.0 (TID 556) in 24669 ms on 172.34.249.48 (executor 17) (551/590)
"
1760335266284,"INFO	2025-10-13T06:01:06,283	547593	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 589.0 in stage 0.0 (TID 589) (172.34.59.71, executor 19, partition 589, PROCESS_LOCAL, 29292 bytes) 
"
1760335266284,"INFO	2025-10-13T06:01:06,284	547594	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 544.0 in stage 0.0 (TID 544) in 32898 ms on 172.34.59.71 (executor 19) (552/590)
"
1760335266328,"INFO	2025-10-13T06:01:06,328	547638	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 543.0 in stage 0.0 (TID 543) in 33526 ms on 172.35.53.249 (executor 8) (553/590)
"
1760335266590,"INFO	2025-10-13T06:01:06,590	547900	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 558.0 in stage 0.0 (TID 558) in 24788 ms on 172.34.247.5 (executor 6) (554/590)
"
1760335266673,"INFO	2025-10-13T06:01:06,672	547982	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 9
INFO	2025-10-13T06:01:06,672	547982	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 9
"
1760335267328,"INFO	2025-10-13T06:01:07,327	548637	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 560.0 in stage 0.0 (TID 560) in 24267 ms on 172.35.116.46 (executor 4) (555/590)
"
1760335267358,"INFO	2025-10-13T06:01:07,357	548667	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 559.0 in stage 0.0 (TID 559) in 24920 ms on 172.35.34.68 (executor 9) (556/590)
"
1760335267486,"INFO	2025-10-13T06:01:07,486	548796	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 546.0 in stage 0.0 (TID 546) in 33563 ms on 172.35.53.249 (executor 8) (557/590)
"
1760335268302,"INFO	2025-10-13T06:01:08,302	549612	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 561.0 in stage 0.0 (TID 561) in 24146 ms on 172.34.102.82 (executor 18) (558/590)
"
1760335268375,"INFO	2025-10-13T06:01:08,375	549685	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 8
"
1760335268375,"INFO	2025-10-13T06:01:08,375	549685	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 8
"
1760335268696,"INFO	2025-10-13T06:01:08,695	550005	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorStatus-poller]	60	polling for JES executor task status
"
1760335268696,"INFO	2025-10-13T06:01:08,695	550005	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorStatus-poller]	60	polling for 19 executor task status
"
1760335269286,"INFO	2025-10-13T06:01:09,285	550595	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 562.0 in stage 0.0 (TID 562) in 24221 ms on 172.34.139.155 (executor 15) (559/590)
"
1760335270875,"INFO	2025-10-13T06:01:10,874	552184	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 553.0 in stage 0.0 (TID 553) in 32044 ms on 172.34.117.91 (executor 13) (560/590)
"
1760335270958,"INFO	2025-10-13T06:01:10,957	552267	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 552.0 in stage 0.0 (TID 552) in 32200 ms on 172.34.117.91 (executor 13) (561/590)
"
1760335271417,"INFO	2025-10-13T06:01:11,416	552726	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 548.0 in stage 0.0 (TID 548) in 34128 ms on 172.34.78.80 (executor 12) (562/590)
"
1760335271479,"INFO	2025-10-13T06:01:11,478	552788	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 7
INFO	2025-10-13T06:01:11,479	552789	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 7
"
1760335271656,"INFO	2025-10-13T06:01:11,656	552966	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 549.0 in stage 0.0 (TID 549) in 33975 ms on 172.34.78.80 (executor 12) (563/590)
"
1760335271953,"INFO	2025-10-13T06:01:11,953	553263	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 563.0 in stage 0.0 (TID 563) in 24050 ms on 172.35.230.30 (executor 7) (564/590)
"
1760335274175,"INFO	2025-10-13T06:01:14,175	555485	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 565.0 in stage 0.0 (TID 565) in 24371 ms on 172.34.1.110 (executor 14) (565/590)
"
1760335274702,"INFO	2025-10-13T06:01:14,701	556011	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 564.0 in stage 0.0 (TID 564) in 24963 ms on 172.34.145.94 (executor 3) (566/590)
"
1760335274782,"INFO	2025-10-13T06:01:14,782	556092	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 6
"
1760335274782,"INFO	2025-10-13T06:01:14,782	556092	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 6
"
1760335276674,"INFO	2025-10-13T06:01:16,673	557983	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 566.0 in stage 0.0 (TID 566) in 24250 ms on 172.34.76.221 (executor 11) (567/590)
"
1760335277271,"INFO	2025-10-13T06:01:17,270	558580	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 570.0 in stage 0.0 (TID 570) in 23431 ms on 172.35.30.152 (executor 1) (568/590)
"
1760335277889,"INFO	2025-10-13T06:01:17,889	559199	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 567.0 in stage 0.0 (TID 567) in 25278 ms on 172.34.158.2 (executor 2) (569/590)
"
1760335278057,"INFO	2025-10-13T06:01:18,057	559367	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 568.0 in stage 0.0 (TID 568) in 24712 ms on 172.34.247.5 (executor 6) (570/590)
"
1760335278087,"INFO	2025-10-13T06:01:18,086	559396	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 5
"
1760335278087,"INFO	2025-10-13T06:01:18,087	559397	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 5
"
1760335278718,"INFO	2025-10-13T06:01:18,718	560028	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 569.0 in stage 0.0 (TID 569) in 25009 ms on 172.34.249.48 (executor 17) (571/590)
"
1760335279314,"INFO	2025-10-13T06:01:19,314	560624	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 571.0 in stage 0.0 (TID 571) in 24391 ms on 172.35.34.68 (executor 9) (572/590)
"
1760335280153,"INFO	2025-10-13T06:01:20,153	561463	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 573.0 in stage 0.0 (TID 573) in 24344 ms on 172.34.102.82 (executor 18) (573/590)
"
1760335280871,"INFO	2025-10-13T06:01:20,870	562180	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 572.0 in stage 0.0 (TID 572) in 25852 ms on 172.35.116.46 (executor 4) (574/590)
"
1760335280891,"INFO	2025-10-13T06:01:20,891	562201	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 4
"
1760335280891,"INFO	2025-10-13T06:01:20,891	562201	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 4
"
1760335280918,"INFO	2025-10-13T06:01:20,918	562228	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 575.0 in stage 0.0 (TID 575) in 23360 ms on 172.34.139.155 (executor 15) (575/590)
"
1760335284068,"INFO	2025-10-13T06:01:24,067	565377	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 576.0 in stage 0.0 (TID 576) in 23899 ms on 172.35.230.30 (executor 7) (576/590)
"
1760335286395,"INFO	2025-10-13T06:01:26,395	567705	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 579.0 in stage 0.0 (TID 579) in 24376 ms on 172.34.145.94 (executor 3) (577/590)
"
1760335287008,"INFO	2025-10-13T06:01:27,007	568317	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 578.0 in stage 0.0 (TID 578) in 25128 ms on 172.34.1.110 (executor 14) (578/590)
"
1760335287080,"INFO	2025-10-13T06:01:27,080	568390	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 574.0 in stage 0.0 (TID 574) in 29589 ms on 172.35.115.9 (executor 10) (579/590)
"
1760335287099,"INFO	2025-10-13T06:01:27,098	568408	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 3
INFO	2025-10-13T06:01:27,098	568408	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 3
"
1760335288375,"INFO	2025-10-13T06:01:28,375	569685	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 584.0 in stage 0.0 (TID 584) in 23188 ms on 172.34.76.221 (executor 11) (580/590)
"
1760335288941,"WARN	2025-10-13T06:01:28,940	570250	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	72	Lost task 587.0 in stage 0.0 (TID 587) (172.35.30.152 executor 1): java.io.IOException: No space left on device
	at java.base/java.io.FileOutputStream.writeBytes(Native Method)
	at java.base/java.io.FileOutputStream.write(FileOutputStream.java:349)
	at org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:59)
	at org.apache.spark.io.MutableCheckedOutputStream.write(MutableCheckedOutputStream.scala:43)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:127)
	at net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:225)
	at net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:178)
	at org.apache.commons.io.output.ProxyOutputStream.write(ProxyOutputStream.java:147)
	at org.apache.spark.io.UnsafeBufferedOutputStream.flushBuffer(UnsafeBufferedOutputStream.java:165)
	at org.apache.spark.io.UnsafeBufferedOutputStream.write(UnsafeBufferedOutputStream.java:112)
	at org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeByteArrayBaseObjectToStream(UnsafeRow.java:589)
	at org.apache.spark.sql.catalyst.expressions.UnsafeRow.writeToStream(UnsafeRow.java:581)
	at org.apache.spark.sql.execution.UnsafeBufferedOutputStreamWriter.writeRow(UnsafeBufferedOutputStreamWriter.scala:37)
	at org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2.writeValue(UnsafeRowSerializer.scala:262)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:350)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:186)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)
	at org.apache.spark.scheduler.Task.run(Task.scala:152)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)

"
1760335288944,"INFO	2025-10-13T06:01:28,942	570252	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 587.1 in stage 0.0 (TID 590) (172.35.230.30, executor 7, partition 587, PROCESS_LOCAL, 29292 bytes) 
"
1760335288950,"ERROR	2025-10-13T06:01:28,950	570260	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisTaskFailed"",""Timestamp"":1760335288946,""Failure Reason"":""No space left on device"",""Stack Trace"":[{""Declaring Class"":""java.io.FileOutputStream"",""Method Name"":""writeBytes"",""File Name"":""FileOutputStream.java"",""Line Number"":-2},{""Declaring Class"":""java.io.FileOutputStream"",""Method Name"":""write"",""File Name"":""FileOutputStream.java"",""Line Number"":349},{""Declaring Class"":""org.apache.spark.storage.TimeTrackingOutputStream"",""Method Name"":""write"",""File Name"":""TimeTrackingOutputStream.java"",""Line Number"":59},{""Declaring Class"":""org.apache.spark.io.MutableCheckedOutputStream"",""Method Name"":""write"",""File Name"":""MutableCheckedOutputStream.scala"",""Line Number"":43},{""Declaring Class"":""java.io.BufferedOutputStream"",""Method Name"":""flushBuffer"",""File Name"":""BufferedOutputStream.java"",""Line Number"":81},{""Declaring Class"":""java.io.BufferedOutputStream"",""Method Name"":""write"",""File Name"":""BufferedOutputStream.java"",""Line Number"":127},{""Declaring Class"":""net.jpountz.lz4.LZ4BlockOutputStream"",""Method Name"":""flushBufferedData"",""File Name"":""LZ4BlockOutputStream.java"",""Line Number"":225},{""Declaring Class"":""net.jpountz.lz4.LZ4BlockOutputStream"",""Method Name"":""write"",""File Name"":""LZ4BlockOutputStream.java"",""Line Number"":178},{""Declaring Class"":""org.apache.commons.io.output.ProxyOutputStream"",""Method Name"":""write"",""File Name"":""ProxyOutputStream.java"",""Line Number"":147},{""Declaring Class"":""org.apache.spark.io.UnsafeBufferedOutputStream"",""Method Name"":""flushBuffer"",""File Name"":""UnsafeBufferedOutputStream.java"",""Line Number"":165},{""Declaring Class"":""org.apache.spark.io.UnsafeBufferedOutputStream"",""Method Name"":""write"",""File Name"":""UnsafeBufferedOutputStream.java"",""Line Number"":112},{""Declaring Class"":""org.apache.spark.sql.catalyst.expressions.UnsafeRow"",""Method Name"":""writeByteArrayBaseObjectToStream"",""File Name"":""UnsafeRow.java"",""Line Number"":589},{""Declaring Class"":""org.apache.spark.sql.catalyst.expressions.UnsafeRow"",""Method Name"":""writeToStream"",""File Name"":""UnsafeRow.java"",""Line Number"":581},{""Declaring Class"":""org.apache.spark.sql.execution.UnsafeBufferedOutputStreamWriter"",""Method Name"":""writeRow"",""File Name"":""UnsafeBufferedOutputStreamWriter.scala"",""Line Number"":37},{""Declaring Class"":""org.apache.spark.sql.execution.UnsafeRowSerializerInstance$$anon$2"",""Method Name"":""writeValue"",""File Name"":""UnsafeRowSerializer.scala"",""Line Number"":262},{""Declaring Class"":""org.apache.spark.storage.DiskBlockObjectWriter"",""Method Name"":""write"",""File Name"":""DiskBlockObjectWriter.scala"",""Line Number"":350},{""Declaring Class"":""org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter"",""Method Name"":""write"",""File Name"":""BypassMergeSortShuffleWriter.java"",""Line Number"":186},{""Declaring Class"":""org.apache.spark.shuffle.ShuffleWriteProcessor"",""Method Name"":""doWrite"",""File Name"":""ShuffleWriteProcessor.scala"",""Line Number"":45},{""Declaring Class"":""org.apache.spark.shuffle.ShuffleWriteProcessor"",""Method Name"":""write"",""File Name"":""ShuffleWriteProcessor.scala"",""Line Number"":69},{""Declaring Class"":""org.apache.spark.scheduler.ShuffleMapTask"",""Method Name"":""runTask"",""File Name"":""ShuffleMapTask.scala"",""Line Number"":104},{""Declaring Class"":""org.apache.spark.scheduler.ShuffleMapTask"",""Method Name"":""runTask"",""File Name"":""ShuffleMapTask.scala"",""Line Number"":54},{""Declaring Class"":""org.apache.spark.TaskContext"",""Method Name"":""runTaskWithListeners"",""File Name"":""TaskContext.scala"",""Line Number"":174},{""Declaring Class"":""org.apache.spark.scheduler.Task"",""Method Name"":""run"",""File Name"":""Task.scala"",""Line Number"":152},{""Declaring Class"":""org.apache.spark.executor.Executor$TaskRunner"",""Method Name"":""$anonfun$run$4"",""File Name"":""Executor.scala"",""Line Number"":632},{""Declaring Class"":""org.apache.spark.util.SparkErrorUtils"",""Method Name"":""tryWithSafeFinally"",""File Name"":""SparkErrorUtils.scala"",""Line Number"":64},{""Declaring Class"":""org.apache.spark.util.SparkErrorUtils"",""Method Name"":""tryWithSafeFinally$"",""File Name"":""SparkErrorUtils.scala"",""Line Number"":61},{""Declaring Class"":""org.apache.spark.util.Utils$"",""Method Name"":""tryWithSafeFinally"",""File Name"":""Utils.scala"",""Line Number"":96},{""Declaring Class"":""org.apache.spark.executor.Executor$TaskRunner"",""Method Name"":""run"",""File Name"":""Executor.scala"",""Line Number"":635},{""Declaring Class"":""java.util.concurrent.ThreadPoolExecutor"",""Method Name"":""runWorker"",""File Name"":""ThreadPoolExecutor.java"",""Line Number"":1136},{""Declaring Class"":""java.util.concurrent.ThreadPoolExecutor$Worker"",""Method Name"":""run"",""File Name"":""ThreadPoolExecutor.java"",""Line Number"":635},{""Declaring Class"":""java.lang.Thread"",""Method Name"":""run"",""File Name"":""Thread.java"",""Line Number"":840}],""Task Launch Time"":1760335265592,""Stage ID"":0,""Stage Attempt ID"":0,""Task Type"":""ShuffleMapTask"",""Executor ID"":""1"",""Task ID"":587}
"
1760335289664,"INFO	2025-10-13T06:01:29,663	570973	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 585.0 in stage 0.0 (TID 585) in 24312 ms on 172.34.158.2 (executor 2) (581/590)
"
1760335290425,"INFO	2025-10-13T06:01:30,425	571735	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 588.0 in stage 0.0 (TID 588) in 24585 ms on 172.34.249.48 (executor 17) (582/590)
"
1760335290503,"INFO	2025-10-13T06:01:30,503	571813	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
"
1760335290503,"INFO	2025-10-13T06:01:30,503	571813	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
"
1760335293097,"INFO	2025-10-13T06:01:33,096	574406	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-3]	60	Finished task 577.0 in stage 0.0 (TID 577) in 32456 ms on 172.34.89.92 (executor 16) (583/590)
"
1760335295460,"INFO	2025-10-13T06:01:35,459	576769	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 583.0 in stage 0.0 (TID 583) in 31140 ms on 172.35.115.9 (executor 10) (584/590)
"
1760335295634,"INFO	2025-10-13T06:01:35,634	576944	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 580.0 in stage 0.0 (TID 580) in 33008 ms on 172.34.59.71 (executor 19) (585/590)
"
1760335296053,"INFO	2025-10-13T06:01:36,053	577363	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-2]	60	Finished task 582.0 in stage 0.0 (TID 582) in 32655 ms on 172.34.89.92 (executor 16) (586/590)
"
1760335296109,"INFO	2025-10-13T06:01:36,109	577419	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 1
"
1760335296110,"INFO	2025-10-13T06:01:36,109	577419	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 1
"
1760335296406,"ERROR	2025-10-13T06:01:36,406	577716	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	76	threshold for consecutive executor task creation reached
"
1760335296409,"INFO	2025-10-13T06:01:36,409	577719	org.apache.spark.SparkContext	[shutdown-hook-0]	60	Invoking stop() from shutdown hook
"
1760335296412,"INFO	2025-10-13T06:01:36,409	577719	org.apache.spark.SparkContext	[shutdown-hook-0]	60	SparkContext is stopping with exitCode 0.
"
1760335296417,"INFO	2025-10-13T06:01:36,417	577727	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[spark-listener-group-shared]	70	Logs, events processed and insights are written to file /tmp/glue-exception-analysis-logs/spark-application-1760334728567
"
1760335296419,"INFO	2025-10-13T06:01:36,419	577729	org.apache.spark.scheduler.DAGScheduler	[shutdown-hook-0]	60	ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0) failed in 556.616 s due to Stage cancelled because SparkContext was shut down
"
1760335296421,"INFO	2025-10-13T06:01:36,421	577731	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[shutdown-hook-0]	60	Stopping JES Scheduler Backend.
"
1760335296422,"INFO	2025-10-13T06:01:36,422	577732	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[shutdown-hook-0]	60	Shutting down all executors
"
1760335296424,"INFO	2025-10-13T06:01:36,424	577734	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Asking each executor to shut down
"
1760335296426,"ERROR	2025-10-13T06:01:36,426	577736	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisStageFailed"",""Timestamp"":1760335296418,""Failure Reason"":""Stage cancelled because SparkContext was shut down"",""Stack Trace"":[],""Stage ID"":0,""Stage Attempt ID"":0,""Number of Tasks"":590}
"
1760335296434,"ERROR	2025-10-13T06:01:36,434	577744	com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener	[spark-listener-group-shared]	9	[Glue Exception Analysis] {""Event"":""GlueExceptionAnalysisJobFailed"",""Timestamp"":1760335296431,""Failure Reason"":""org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down"",""Stack Trace"":[{""Declaring Class"":""org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down)"",""Method Name"":""TopLevelFailedReason"",""File Name"":""TopLevelFailedReason"",""Line Number"":-1}],""Job Id"":0,""Job Result"":""JobFailed"",""Failed Stage Id"":-1}
"
1760335296441,"INFO	2025-10-13T06:01:36,440	577750	org.apache.spark.MapOutputTrackerMasterEndpoint	[dispatcher-event-loop-1]	60	MapOutputTrackerMasterEndpoint stopped!
"
1760335296442,"INFO	2025-10-13T06:01:36,442	577752	org.apache.spark.sql.execution.SQLExecution	[Thread-7]	60	Skipped SparkListenerSQLExecutionObfuscatedInfo event due to NON_EMPTY_ERROR.
"
1760335296452,"INFO	2025-10-13T06:01:36,452	577762	org.apache.spark.storage.memory.MemoryStore	[shutdown-hook-0]	60	MemoryStore cleared
"
1760335296453,"INFO	2025-10-13T06:01:36,452	577762	org.apache.spark.storage.BlockManager	[shutdown-hook-0]	60	BlockManager stopped
"
1760335296457,"INFO	2025-10-13T06:01:36,457	577767	org.apache.spark.storage.BlockManagerMaster	[shutdown-hook-0]	60	BlockManagerMaster stopped
"
1760335296459,"INFO	2025-10-13T06:01:36,459	577769	org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint	[dispatcher-event-loop-1]	60	OutputCommitCoordinator stopped!
"
1760335296535,"INFO	2025-10-13T06:01:36,535	577845	org.apache.spark.SparkContext	[shutdown-hook-0]	60	Successfully stopped SparkContext
"
1760335296536,"INFO	2025-10-13T06:01:36,536	577846	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Shutdown hook called
"
1760335296547,"INFO	2025-10-13T06:01:36,536	577846	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-d3c2de48-694d-42d2-aed3-82a2c5b5822d/pyspark-f189a6cd-aae1-4078-93f4-30f08d5ee6e7
"
1760335296556,"INFO	2025-10-13T06:01:36,556	577866	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-d768328c-c5fd-414d-b03a-43b98c4f3acd
"
1760335296566,"INFO	2025-10-13T06:01:36,566	577876	org.apache.spark.util.ShutdownHookManager	[shutdown-hook-0]	60	Deleting directory /tmp/spark-d3c2de48-694d-42d2-aed3-82a2c5b5822d
"