INFO	2025-10-12T19:10:52,629	59899	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.33.234:34335, --executor-id, 3, --app-id, spark-application-1760296205636, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-12T19:10:52,628	59898	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760296205636 with resource profile 0
INFO	2025-10-12T19:10:49,701	56971	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task creation failed for executor 2 in resource profile 0, restarting within 15 secs. restart reason: Executor task resource limit has been temporarily hit..
INFO	2025-10-12T19:10:49,701	56971	org.apache.spark.scheduler.cluster.glue.util.ExceptionWrapper	[executorAllocator]	60	Exception thrown: software.amazon.awssdk.services.gluejobexecutor.model.ResourceNumberLimitExceededException: Number of ChildTask has reached the maximum limit of 2.0 for groupId f61d0483-d788-4d8b-8021-5bdbf69866e8 (Service: GlueJobExecutor, Status Code: 400, Request ID: a3cca326-dc1a-43d2-b4a0-92bd4f5ec7f8)
INFO	2025-10-12T19:10:49,699	56969	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	81	Exception thrown while creating child task 
INFO	2025-10-12T19:10:49,649	56919	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.33.234:34335, --executor-id, 2, --app-id, spark-application-1760296205636, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-12T19:10:49,650	56920	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 2; clientToken gr_f61d0483-d788-4d8b-8021-5bdbf69866e8_e_2_a_spark-application-1760296205636_p_1
INFO	2025-10-12T19:10:49,650	56920	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
INFO	2025-10-12T19:10:49,649	56919	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760296205636 with resource profile 0
INFO	2025-10-12T19:10:49,418	56688	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 1 new executor because tasks are backlogged (new desired total will be 2 for resource profile id: 0)
INFO	2025-10-12T19:10:49,416	56686	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
INFO	2025-10-12T19:10:49,416	56686	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
INFO	2025-10-12T19:10:43,567	50837	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 1.0 in stage 0.0 (TID 1) in 23997 ms on 172.34.28.133 (executor 1) (2/32)
INFO	2025-10-12T19:10:43,565	50835	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 3.0 in stage 0.0 (TID 3) (172.34.28.133, executor 1, partition 3, PROCESS_LOCAL, 16810 bytes) 
INFO	2025-10-12T19:10:43,548	50818	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 0.0 in stage 0.0 (TID 0) in 24013 ms on 172.34.28.133 (executor 1) (1/32)
INFO	2025-10-12T19:10:43,537	50807	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 2.0 in stage 0.0 (TID 2) (172.34.28.133, executor 1, partition 2, PROCESS_LOCAL, 16810 bytes) 
INFO	2025-10-12T19:10:22,664	29934	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.28.133:45661 (size: 3.4 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:10:20,514	27784	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.28.133:45661 (size: 13.4 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:10:19,571	26841	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 1.0 in stage 0.0 (TID 1) (172.34.28.133, executor 1, partition 1, PROCESS_LOCAL, 16810 bytes) 
INFO	2025-10-12T19:10:19,566	26836	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 0.0 in stage 0.0 (TID 0) (172.34.28.133, executor 1, partition 0, PROCESS_LOCAL, 16810 bytes) 
INFO	2025-10-12T19:10:19,519	26789	org.apache.spark.scheduler.TaskSchedulerImpl	[dag-scheduler-event-loop]	60	Adding task set 0.0 with 32 tasks resource profile 0
INFO	2025-10-12T19:10:19,514	26784	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting 32 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
INFO	2025-10-12T19:10:19,489	26759	org.apache.spark.SparkContext	[dag-scheduler-event-loop]	60	Created broadcast 2 from broadcast at DAGScheduler.scala:1664
INFO	2025-10-12T19:10:19,487	26757	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.33.234:43981 (size: 13.4 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:10:19,486	26756	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.4 KiB, actual size: 13.4 KiB, free 5.8 GiB)
INFO	2025-10-12T19:10:19,462	26732	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2 stored as values in memory (estimated size 30.4 KiB, free 5.8 GiB)
INFO	2025-10-12T19:10:19,319	26589	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
INFO	2025-10-12T19:10:19,316	26586	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Missing parents: List()
INFO	2025-10-12T19:10:19,315	26585	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Parents of final stage: List()
INFO	2025-10-12T19:10:19,314	26584	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Got map stage job 0 (save at NativeMethodAccessorImpl.java:0) with 32 output partitions
INFO	2025-10-12T19:10:19,314	26584	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Final stage: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0)
INFO	2025-10-12T19:10:19,309	26579	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Registering RDD 5 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
INFO	2025-10-12T19:10:19,091	26361	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 1 from broadcast at SparkBatch.java:85
INFO	2025-10-12T19:10:19,089	26359	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.33.234:43981 (size: 3.4 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:10:19,089	26359	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KiB, actual size: 3.4 KiB, free 5.8 GiB)
INFO	2025-10-12T19:10:19,077	26347	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1 stored as values in memory (estimated size 32.0 KiB, free 5.8 GiB)
INFO	2025-10-12T19:10:18,715	25985	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 0 from broadcast at SparkBatch.java:85
INFO	2025-10-12T19:10:18,709	25979	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_0_piece0 in memory on 172.34.33.234:43981 (size: 3.4 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:10:18,706	25976	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KiB, actual size: 3.4 KiB, free 5.8 GiB)
INFO	2025-10-12T19:10:18,560	25830	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 5.8 GiB)
INFO	2025-10-12T19:10:18,505	25775	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,503	25773	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,498	25768	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,491	25761	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,477	25747	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,473	25743	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,451	25721	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:10:18,158	25428	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	150	Requesting [] as write ordering for table glue_catalog.maximo_dq.relatedrecord
INFO	2025-10-12T19:10:18,156	25426	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	157	Requesting 0 bytes advisory partition size for table glue_catalog.maximo_dq.relatedrecord
INFO	2025-10-12T19:10:18,156	25426	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	138	Requesting UnspecifiedDistribution as write distribution for table glue_catalog.maximo_dq.relatedrecord
INFO	2025-10-12T19:10:18,121	25391	org.apache.iceberg.spark.source.SparkPartitioningAwareScan	[Thread-7]	119	Reporting UnknownPartitioning with 32 partition(s) for table glue_catalog.maximo_raw.relatedrecord
INFO	2025-10-12T19:10:17,868	25138	org.apache.iceberg.BaseDistributedDataScan	[Thread-7]	278	Planning file tasks locally for table glue_catalog.maximo_raw.relatedrecord
INFO	2025-10-12T19:10:17,572	24842	org.apache.iceberg.SnapshotScan	[Thread-7]	124	Scanning table glue_catalog.maximo_raw.relatedrecord snapshot 3779443845899496993 created at 2025-10-12T18:54:47.380+00:00 with filter true
INFO	2025-10-12T19:10:17,564	24834	org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown	[Thread-7]	60	
Output: recordkey#0, class#1, relatedreckey#2, relatedrecclass#3, relatedrecsiteid#4, relatedrecorgid#5, siteid#6, orgid#7, relatetype#8, relatedrecordid#9, rowstamp#10, plusrelatestatus#11, pluscacontrol#12, etrcrrelatetype#13, etrecapprreq#14, etrecwoclose#15, etrrelatetype#16, etrpmttask#17, pk_hash#18, edl_load_date#19
        
INFO	2025-10-12T19:10:17,059	24329	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.relatedrecord loaded Spark schema: StructType(StructField(recordkey,StringType,true),StructField(class,StringType,true),StructField(relatedreckey,StringType,true),StructField(relatedrecclass,StringType,true),StructField(relatedrecsiteid,StringType,true),StructField(relatedrecorgid,StringType,true),StructField(siteid,StringType,true),StructField(orgid,StringType,true),StructField(relatetype,StringType,true),StructField(relatedrecordid,DecimalType(38,10),true),StructField(rowstamp,StringType,true),StructField(plusrelatestatus,StringType,true),StructField(pluscacontrol,DecimalType(38,10),true),StructField(etrcrrelatetype,StringType,true),StructField(etrecapprreq,DecimalType(38,10),true),StructField(etrecwoclose,DecimalType(38,10),true),StructField(etrrelatetype,StringType,true),StructField(etrpmttask,StringType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
INFO	2025-10-12T19:10:16,574	23844	org.opensearch.hadoop.util.Version	[Thread-7]	143	OpenSearch Hadoop v1.2.0 [2a4148055f]
INFO	2025-10-12T19:10:14,501	21771	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.28.133:45661 with 5.8 GiB RAM, BlockManagerId(1, 172.34.28.133, 45661, None)
INFO	2025-10-12T19:10:14,459	21729	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.relatedrecord loaded Spark schema: StructType(StructField(recordkey,StringType,true),StructField(class,StringType,true),StructField(relatedreckey,StringType,true),StructField(relatedrecclass,StringType,true),StructField(relatedrecsiteid,StringType,true),StructField(relatedrecorgid,StringType,true),StructField(siteid,StringType,true),StructField(orgid,StringType,true),StructField(relatetype,StringType,true),StructField(relatedrecordid,DecimalType(38,10),true),StructField(rowstamp,StringType,true),StructField(plusrelatestatus,StringType,true),StructField(pluscacontrol,DecimalType(38,10),true),StructField(etrcrrelatetype,StringType,true),StructField(etrecapprreq,DecimalType(38,10),true),StructField(etrecwoclose,DecimalType(38,10),true),StructField(etrrelatetype,StringType,true),StructField(etrpmttask,StringType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
INFO	2025-10-12T19:10:14,456	21726	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_dq.relatedrecord
INFO	2025-10-12T19:10:14,353	21623	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-dq-dev/maximo_dq.db/relatedrecord/metadata/00012-b4d1c377-ce61-4c8f-88a0-fbb7ab87f440.metadata.json
INFO	2025-10-12T19:10:14,341	21611	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 1 has registered (new total is 1)
INFO	2025-10-12T19:10:14,341	21611	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 1
INFO	2025-10-12T19:10:14,337	21607	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 1 @ 1760296214336
INFO	2025-10-12T19:10:14,335	21605	org.apache.spark.executor.ExecutorLogUrlHandler	[dispatcher-CoarseGrainedScheduler]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
INFO	2025-10-12T19:10:14,333	21603	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.28.133:57430) with ID 1,  ResourceProfileId 0
INFO	2025-10-12T19:10:14,269	21539	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
WARN	2025-10-12T19:10:14,269	21539	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
INFO	2025-10-12T19:10:14,155	21425	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
INFO	2025-10-12T19:10:13,429	20699	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_raw.relatedrecord loaded Spark schema: StructType(StructField(recordkey,StringType,true),StructField(class,StringType,true),StructField(relatedreckey,StringType,true),StructField(relatedrecclass,StringType,true),StructField(relatedrecsiteid,StringType,true),StructField(relatedrecorgid,StringType,true),StructField(siteid,StringType,true),StructField(orgid,StringType,true),StructField(relatetype,StringType,true),StructField(relatedrecordid,DecimalType(38,10),true),StructField(rowstamp,StringType,true),StructField(plusrelatestatus,StringType,true),StructField(pluscacontrol,DecimalType(38,10),true),StructField(etrcrrelatetype,StringType,true),StructField(etrecapprreq,DecimalType(38,10),true),StructField(etrecwoclose,DecimalType(38,10),true),StructField(etrrelatetype,StringType,true),StructField(etrpmttask,StringType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
INFO	2025-10-12T19:10:13,407	20677	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_raw.relatedrecord
INFO	2025-10-12T19:10:12,982	20252	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-raw-dev/maximo_raw.db/relatedrecord/metadata/00015-63c6f6fb-a679-4719-bedf-6f49d321e336.metadata.json
INFO	2025-10-12T19:10:12,864	20134	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
WARN	2025-10-12T19:10:12,864	20134	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
INFO	2025-10-12T19:10:11,888	19158	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
INFO	2025-10-12T19:10:08,091	15361	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Warehouse path is 'file:/home/hadoop/spark-warehouse'.
INFO	2025-10-12T19:10:08,088	15358	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Setting hive.metastore.warehouse.dir ('/tmp/spark-warehouse') to the value of spark.sql.warehouse.dir.
INFO	2025-10-12T19:10:06,640	13910	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-d5d02bd2709d7d6fe0ba9b6680597d5427ab97e1 created for executor 1 in resource profile 0
INFO	2025-10-12T19:10:06,639	13909	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
INFO	2025-10-12T19:10:06,243	13513	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
INFO	2025-10-12T19:10:06,235	13505	org.apache.spark.executor.ExecutorLogUrlHandler	[Thread-7]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
INFO	2025-10-12T19:10:06,230	13500	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	getDriverLogUrls Map()
INFO	2025-10-12T19:10:06,194	13464	org.apache.spark.SparkContext	[Thread-7]	60	Registered listener com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener
INFO	2025-10-12T19:10:06,183	13453	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[Thread-7]	51	Started file writer for com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter
INFO	2025-10-12T19:10:06,122	13392	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Requested total executors are 1
INFO	2025-10-12T19:10:06,121	13391	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
INFO	2025-10-12T19:10:06,099	13369	org.apache.spark.ExecutorAllocationManager	[Thread-7]	60	Dynamic allocation is enabled without a shuffle service.
INFO	2025-10-12T19:10:06,093	13363	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
INFO	2025-10-12T19:10:05,933	13203	org.apache.spark.deploy.history.SingleEventLogFileWriter	[Thread-7]	60	Logging events to file:/var/log/spark/apps/spark-application-1760296205636.inprogress
INFO	2025-10-12T19:10:05,745	13015	org.apache.spark.storage.BlockManager	[Thread-7]	60	Initialized BlockManager: BlockManagerId(driver, 172.34.33.234, 43981, None)
INFO	2025-10-12T19:10:05,744	13014	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registered BlockManager BlockManagerId(driver, 172.34.33.234, 43981, None)
INFO	2025-10-12T19:10:05,739	13009	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.33.234:43981 with 5.8 GiB RAM, BlockManagerId(driver, 172.34.33.234, 43981, None)
INFO	2025-10-12T19:10:05,735	13005	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registering BlockManager BlockManagerId(driver, 172.34.33.234, 43981, None)
INFO	2025-10-12T19:10:05,724	12994	org.apache.spark.storage.BlockManager	[Thread-7]	60	Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
INFO	2025-10-12T19:10:05,719	12989	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43981.
INFO	2025-10-12T19:10:05,720	12990	org.apache.spark.network.netty.NettyBlockTransferService	[Thread-7]	88	Server created on 172.34.33.234:43981
INFO	2025-10-12T19:10:05,718	12988	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
INFO	2025-10-12T19:10:05,703	12973	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 1; clientToken gr_f61d0483-d788-4d8b-8021-5bdbf69866e8_e_1_a_spark-application-1760296205636_p_1
INFO	2025-10-12T19:10:05,702	12972	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.33.234:34335, --executor-id, 1, --app-id, spark-application-1760296205636, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-12T19:10:05,699	12969	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760296205636 with resource profile 0
INFO	2025-10-12T19:10:05,689	12959	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Initial executors are 1
INFO	2025-10-12T19:10:05,689	12959	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
INFO	2025-10-12T19:10:05,687	12957	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Starting JES Scheduler Backend.
INFO	2025-10-12T19:10:05,645	12915	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
INFO	2025-10-12T19:10:05,642	12912	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	JESSchedulerBackend
INFO	2025-10-12T19:10:04,750	12020	org.apache.spark.deploy.glue.client.GlueRMClientFactory	[Thread-7]	60	JESClusterManager: Initializing JES client with endpoint: https://glue-jes.us-gov-west-1.amazonaws.com
INFO	2025-10-12T19:10:04,748	12018	org.apache.spark.scheduler.cluster.glue.JESClusterManager	[Thread-7]	121	Python path for executors: mosaic.zip:yaml.zip:sqlglot.zip:python_environment
INFO	2025-10-12T19:10:04,151	11421	org.apache.spark.SparkContext	[Thread-7]	60	Unpacking an archive /tmp/glue-job-6959303791097702753_glue_venv.zip#python_environment from /tmp/spark-d829ff7e-d6c3-438d-8ce1-934d61b2aa96/glue-job-6959303791097702753_glue_venv.zip to /tmp/spark-785c78cd-2c2c-4662-9238-bb830d681dae/userFiles-f07ec01e-e260-4326-85e2-030dd51df8a4/python_environment
INFO	2025-10-12T19:10:04,137	11407	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-6959303791097702753_glue_venv.zip to /tmp/spark-d829ff7e-d6c3-438d-8ce1-934d61b2aa96/glue-job-6959303791097702753_glue_venv.zip
INFO	2025-10-12T19:10:04,137	11407	org.apache.spark.SparkContext	[Thread-7]	60	Added archive /tmp/glue-job-6959303791097702753_glue_venv.zip#python_environment at spark://172.34.33.234:34335/files/glue-job-6959303791097702753_glue_venv.zip with timestamp 1760296202757
INFO	2025-10-12T19:10:03,991	11261	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-6959303791097702753/extra-py-files/sqlglot.zip at spark://172.34.33.234:34335/files/sqlglot.zip with timestamp 1760296202757
INFO	2025-10-12T19:10:03,992	11262	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-6959303791097702753/extra-py-files/sqlglot.zip to /tmp/spark-785c78cd-2c2c-4662-9238-bb830d681dae/userFiles-f07ec01e-e260-4326-85e2-030dd51df8a4/sqlglot.zip
INFO	2025-10-12T19:10:03,986	11256	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-6959303791097702753/extra-py-files/yaml.zip to /tmp/spark-785c78cd-2c2c-4662-9238-bb830d681dae/userFiles-f07ec01e-e260-4326-85e2-030dd51df8a4/yaml.zip
INFO	2025-10-12T19:10:03,986	11256	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-6959303791097702753/extra-py-files/yaml.zip at spark://172.34.33.234:34335/files/yaml.zip with timestamp 1760296202757
INFO	2025-10-12T19:10:03,974	11244	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-6959303791097702753/extra-py-files/mosaic.zip to /tmp/spark-785c78cd-2c2c-4662-9238-bb830d681dae/userFiles-f07ec01e-e260-4326-85e2-030dd51df8a4/mosaic.zip
INFO	2025-10-12T19:10:03,972	11242	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-6959303791097702753/extra-py-files/mosaic.zip at spark://172.34.33.234:34335/files/mosaic.zip with timestamp 1760296202757
INFO	2025-10-12T19:10:03,819	11089	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-6959303791097702753/jars/dj5xOe-AwsGlueMLLibs.jar at spark://172.34.33.234:34335/jars/dj5xOe-AwsGlueMLLibs.jar with timestamp 1760296202757
INFO	2025-10-12T19:10:03,817	11087	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-6959303791097702753/jars/odvJng-aws-glue-di-package-5.0.704.jar at spark://172.34.33.234:34335/jars/odvJng-aws-glue-di-package-5.0.704.jar with timestamp 1760296202757
INFO	2025-10-12T19:10:03,742	11012	org.apache.spark.subresultcache.SubResultCacheManager	[Thread-7]	60	Sub-result caches are disabled.
INFO	2025-10-12T19:10:03,737	11007	org.apache.spark.SparkEnv	[Thread-7]	60	Registering OutputCommitCoordinator
INFO	2025-10-12T19:10:03,722	10992	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	MemoryStore started with capacity 5.8 GiB
INFO	2025-10-12T19:10:03,707	10977	org.apache.spark.storage.DiskBlockManager	[Thread-7]	60	Created local directory at /tmp/blockmgr-f8c7f80d-5672-4858-b3d3-3d2707aef044
INFO	2025-10-12T19:10:03,682	10952	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMasterHeartbeat
INFO	2025-10-12T19:10:03,677	10947	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	BlockManagerMasterEndpoint up
INFO	2025-10-12T19:10:03,676	10946	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
INFO	2025-10-12T19:10:03,647	10917	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMaster
INFO	2025-10-12T19:10:03,600	10870	org.apache.spark.SparkEnv	[Thread-7]	60	Registering MapOutputTracker
INFO	2025-10-12T19:10:03,548	10818	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'sparkDriver' on port 34335.
INFO	2025-10-12T19:10:03,198	10468	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls groups to: 
INFO	2025-10-12T19:10:03,199	10469	org.apache.spark.SecurityManager	[Thread-7]	60	SecurityManager: authentication enabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
INFO	2025-10-12T19:10:03,197	10467	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls to: hadoop
INFO	2025-10-12T19:10:03,198	10468	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls groups to: 
INFO	2025-10-12T19:10:03,197	10467	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls to: hadoop
INFO	2025-10-12T19:10:03,025	10295	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
INFO	2025-10-12T19:10:03,026	10296	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 1
INFO	2025-10-12T19:10:03,025	10295	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	User executor ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
INFO	2025-10-12T19:10:03,021	10291	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 0
INFO	2025-10-12T19:10:03,019	10289	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
INFO	2025-10-12T19:10:03,011	10281	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Default ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
INFO	2025-10-12T19:10:02,981	10251	org.apache.spark.SparkContext	[Thread-7]	60	Submitted application: maximo_dq_relatedrecord
INFO	2025-10-12T19:10:02,979	10249	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	No custom resources configured for spark.driver.
INFO	2025-10-12T19:10:02,980	10250	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
INFO	2025-10-12T19:10:02,978	10248	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
INFO	2025-10-12T19:10:02,767	10037	org.apache.spark.SparkContext	[Thread-7]	60	OS info Linux, 5.10.240-238.966.amzn2.x86_64, amd64
INFO	2025-10-12T19:10:02,768	10038	org.apache.spark.SparkContext	[Thread-7]	60	Java version 17.0.16
INFO	2025-10-12T19:10:02,767	10037	org.apache.spark.SparkContext	[Thread-7]	60	Running Spark version 3.5.4-amzn-0
INFO	2025-10-12T19:10:02,755	10025	org.apache.spark.emr.EMRParamSideChannel	[Thread-7]	177	Setting FGAC mode to false
INFO	2025-10-12T19:09:55,405	2675	com.amazonaws.services.glue.SafeLogging	[main]	60	Initializing logging subsystem
INFO	2025-10-12T19:09:55,228	2498	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
INFO	2025-10-12T19:09:54,926	2196	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
Sun Oct 12 19:09:52 UTC 2025
Launching ...
INFO	2025-10-12T19:09:52,212	31728	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	76	shutdownAsyncProcessing has been completed
INFO	2025-10-12T19:09:52,211	31727	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	50	shutdownAsyncProcessing has been Started
INFO	2025-10-12T19:09:52,201	31717	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	39	Setting Up Virtual Env and Application Python Modules has been completed in async mode
INFO	2025-10-12T19:09:52,024	31540	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-6959303791097702753/pythonmodules/createvenvzip.sh /tmp/glue_venv /tmp/glue-job-6959303791097702753_glue_venv.zip
INFO	2025-10-12T19:09:43,500	23016	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-6959303791097702753/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-6959303791097702753/python/3CvvA4-AwsGlueMLLibs/amzn_awsgluemlpythonlibs-1.0-py3-none-any.whl
INFO	2025-10-12T19:09:43,495	23011	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-6959303791097702753/python/3CvvA4-AwsGlueMLLibs.py.zip -d /tmp/glue-job-6959303791097702753/python/3CvvA4-AwsGlueMLLibs
INFO	2025-10-12T19:09:39,455	18971	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-6959303791097702753/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-6959303791097702753/python/ufak9W-AWSGlueDataplanePython-5.0.704/amzn_awsgluelibs-5.0.704-py3-none-any.whl
INFO	2025-10-12T19:09:39,394	18910	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-6959303791097702753/python/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip -d /tmp/glue-job-6959303791097702753/python/ufak9W-AWSGlueDataplanePython-5.0.704
INFO	2025-10-12T19:09:32,270	11786	com.amazonaws.services.glue.launch.helpers.FileManager	[main]	119	Script should be downloaded at /tmp/glue-job-6959303791097702753/raw_dq_load.py 
INFO	2025-10-12T19:09:32,270	11786	com.amazonaws.services.glue.FileDownloader	[sdk-async-response-2-0]	145	Object downloaded. Details: GetObjectResponse(AcceptRanges=bytes, LastModified=2025-10-10T16:51:03Z, ContentLength=453, ETag="3f516bac98ff6f23cf7791a839a72cc0", ContentType=binary/octet-stream, ServerSideEncryption=AES256, Metadata={})
INFO	2025-10-12T19:09:31,401	10917	com.amazonaws.services.glue.FileDownloader	[main]	138	Download bucket: entergy-govdatacore-dataeng-code-repo-dev key: entergy-gov-data-core-code/scripts/raw_dq_load.py to /tmp/glue-job-6959303791097702753/raw_dq_load.py with usingProxy: false and isProxyDisabled: true
INFO	2025-10-12T19:09:31,391	10907	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	37	Encoded S3 URI to s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
INFO	2025-10-12T19:09:31,391	10907	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	32	Encoding S3 URI s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
INFO	2025-10-12T19:09:31,185	10701	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py file to destination location: /tmp/glue-job-6959303791097702753/raw_dq_load.py
INFO	2025-10-12T19:09:31,183	10699	com.amazonaws.services.glue.PrepareLaunch	[main]	194	list of connectors to be added in classpath: List()
INFO	2025-10-12T19:09:30,856	10372	com.amazonaws.services.glue.launch.helpers.ConnectionsManager	[main]	78	GLUE_CONNECTIVITY: attached connection types: ListBuffer()
INFO	2025-10-12T19:09:30,741	10257	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/aws_glue_connectors/selected/native
INFO	2025-10-12T19:09:30,741	10257	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/aws_glue_connectors/marketplace
INFO	2025-10-12T19:09:30,740	10256	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/aws_glue_connectors/selected
INFO	2025-10-12T19:09:30,741	10257	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/exception_catch
INFO	2025-10-12T19:09:30,741	10257	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/amazon
INFO	2025-10-12T19:09:30,741	10257	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/amazon/certs
INFO	2025-10-12T19:09:30,740	10256	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-6959303791097702753/aws_glue_connectors
INFO	2025-10-12T19:09:30,728	10244	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	78	setting up the log4j.configurationFile=/tmp/glue-job-6959303791097702753/glue-380291413387046264log4j2.properties
INFO	2025-10-12T19:09:29,660	9176	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading /tmp/glue-380291413387046264log4j2.properties file to destination location: /tmp/glue-job-6959303791097702753/glue-380291413387046264log4j2.properties
WARN	2025-10-12T19:09:29,656	9172	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	60	Logger setup failed for exception analysis: Cannot invoke "java.net.URL.toURI()" because the return value of "java.lang.Class.getResource(String)" is null
INFO	2025-10-12T19:09:29,654	9170	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	31	setupLoggerProperties...
INFO	2025-10-12T19:09:29,653	9169	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	59	glue.etl.telemetry.runtimeImproveFeature.autoscaling, jr_7cfdb218791a318a0a6c4e0f1efe0df749c9a0d6aa88d5dbf8d5cc48d670d4da_attempt_3
INFO	2025-10-12T19:09:29,646	9162	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	113	optimizeParallelismConfigs started 
INFO	2025-10-12T19:09:29,016	8532	com.amazonaws.services.glue.utils.AWSClientUtils$	[main]	98	AWSClientUtils: create aws sts client with conf: proxy hostnull, proxy port 0
INFO	2025-10-12T19:09:28,976	8492	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
INFO	2025-10-12T19:09:28,739	8255	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
INFO	2025-10-12T19:09:28,734	8250	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	99	
proxy {
  host = null
  port = -1
}
INFO	2025-10-12T19:09:28,697	8213	com.amazonaws.services.glue.launch.helpers.PrepareLaunchProperties	[main]	89	Get job script: raw_dq_load.py.
INFO	2025-10-12T19:09:28,691	8207	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute python3.11 -m venv --clear /tmp/glue_venv
INFO	2025-10-12T19:09:28,688	8204	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	25	Setting Up Virtual Env and Application/Customer Provided Python Modules started in async mode
1760296166008
25/10/12 19:09:25 INFO GlueLibsDownloader: Elapsed time: 1672 millis
25/10/12 19:09:25 INFO GlueLibsDownloader: Elapsed time: 1297 millis
25/10/12 19:09:22 WARN VersionInfoUtils: The AWS SDK for Java 1.x entered maintenance mode starting July 31, 2024 and will reach end of support on December 31, 2025. For more information, see https://aws.amazon.com/blogs/developer/the-aws-sdk-for-java-1-x-is-in-maintenance-mode-effective-july-31-2024/
You can print where on the file system the AWS SDK for Java 1.x core runtime is located by setting the AWS_JAVA_V1_PRINT_LOCATION environment variable or aws.java.v1.printLocation system property to 'true'.
This message can be disabled by setting the AWS_JAVA_V1_DISABLE_DEPRECATION_ANNOUNCEMENT environment variable or aws.java.v1.disableDeprecationAnnouncement system property to 'true'.
The AWS SDK for Java 1.x is being used here:
at java.base/java.lang.Thread.getStackTrace(Thread.java:1619)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.printDeprecationAnnouncement(VersionInfoUtils.java:81)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.<clinit>(VersionInfoUtils.java:59)
at glue.shaded.com.amazonaws.internal.EC2ResourceFetcher.<clinit>(EC2ResourceFetcher.java:44)
at glue.shaded.com.amazonaws.auth.InstanceMetadataServiceCredentialsFetcher.<init>(InstanceMetadataServiceCredentialsFetcher.java:38)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:111)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:91)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:75)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<clinit>(InstanceProfileCredentialsProvider.java:58)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.initializeProvider(EC2ContainerCredentialsProviderWrapper.java:66)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.<init>(EC2ContainerCredentialsProviderWrapper.java:55)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<init>(DefaultAWSCredentialsProviderChain.java:60)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<clinit>(DefaultAWSCredentialsProviderChain.java:54)
at glue.shaded.com.amazonaws.services.s3.AmazonS3ClientBuilder.standard(AmazonS3ClientBuilder.java:46)
at glue.shaded.com.amazonaws.services.s3.AmazonS3Client.builder(AmazonS3Client.java:740)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.getS3Client(GlueLibsDownloader.java:289)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.build(GlueLibsDownloader.java:281)
at com.amazonaws.services.glue.GlueBootstrap.downloadGlueLibs(GlueBootstrap.java:373)
at com.amazonaws.services.glue.GlueBootstrap.lambda$setUpGlueAndUserLibs$1(GlueBootstrap.java:124)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
at java.base/java.lang.Thread.run(Thread.java:840)
25/10/12 19:09:21 INFO GlueBootstrap: Downloading customer supplied extra files...
25/10/12 19:09:21 INFO GlueBootstrap: Downloading Glue libs...
25/10/12 19:09:21 INFO GlueBootstrap: Glue Bootstrapping the driver...
25/10/12 19:09:21 INFO GlueBootstrap: Glue Bootstrapping...
openjdk version "17.0.16" 2025-07-15 LTS
OpenJDK Runtime Environment Corretto-17.0.16.8.1 (build 17.0.16+8-LTS)
OpenJDK 64-Bit Server VM Corretto-17.0.16.8.1 (build 17.0.16+8-LTS, mixed mode, sharing)
/etc/alternatives/jre/bin/java --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions -Djavax.net.ssl.trustStore=/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -Djavax.net.ssl.trustStoreType=JKS -Djavax.net.ssl.trustStorePassword=amazon -DRDS_ROOT_CERT_PATH=/opt/amazon/certs/rds-combined-ca-bundle.pem -DREDSHIFT_ROOT_CERT_PATH=/opt/amazon/certs/redshift-ssl-ca-cert.pem -DRDS_TRUSTSTORE_URL=file:/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -cp /usr/share/aws/aws-glue-shuffle/*:/usr/share/aws/emr-glue-bootstrap/*:/usr/lib/spark/jars/*:/usr/lib/spark/conf:/usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/aws/hmclient/lib/*:/usr/share/aws/iceberg/lib/*:/usr/share/aws/delta/lib/*:/usr/lib/hudi/*:/usr/share/aws/redshift/jdbc/*:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/glue-connectors/lib/*:/usr/share/aws/glue-pii-dependencies/lib/*:/usr/share/aws/datazone-openlineage-spark/lib/*:/usr/lib/hadoop/lib/*::/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/cloudwatch-sink/lib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/lib/hadoop/*:/etc/hadoop/conf:/usr/share/java/Hive-JSON-Serde/* -Dlog4j2.configurationFile=/etc/spark/conf.dist/log4j2.properties com.amazonaws.services.glue.GlueBootstrap --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.maxExecutors=1 --conf spark.executor.memory=10g --conf spark.driver.memory=10g --conf spark.network.timeout=600 --app_name maximo_dq_relatedrecord    --glue-di-packages-correlation-ids 20250828-143656_,20250828-143656_,6376818366,6376818366 --TempDir s3://aws-glue-assets-331875467123-us-gov-west-1/entergy-gov-data-core-code/temporary/ --internal-lib-urls https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/006/Glue5.0/aws-glue-dataplane-python/java17/5.0.704/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip?X-Amz-Security-Token=FwoDYXdzEDIaDORPOBwnSmdXlcCnpiKuAdbrMvLu6jqym3J2Jztm3ePt0sll1dZAhg3ZUH5jDcgpYii5BxzBvA43o1QhP%2FIxKU4zAz7ZemIN%2Bq%2F9BE7kx%2FDzats4O1xmtRSFnk6xOKA%2BEnPMAmFr8wKOZEpz7VJAlP4OZOIMkkXU4mhw0mVzAyk%2BkvvdsZ%2F8%2FeeIRp%2Fw4rYMVA9VqE6nOVOrTdtZf5B%2BdZX1prek5Sn5XnwQBI82G5wcljynWDpDROzyrSMy%2FyjZ%2Ba%2FHBjIfCHP9JNYxmxEoUOOOFU%2Fj52EZvoNF%2BFDcoCokveRlkg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T190913Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3K2OG3FFQ%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=eb93723bd06cb2ca665230fe0c6859a060eebff96422ee4afe53be03438e5585,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/006/Glue5.0/aws-glue-di-libs/java17/5.0.704/odvJng-aws-glue-di-package-5.0.704.jar?X-Amz-Security-Token=FwoDYXdzEDIaDORPOBwnSmdXlcCnpiKuAdbrMvLu6jqym3J2Jztm3ePt0sll1dZAhg3ZUH5jDcgpYii5BxzBvA43o1QhP%2FIxKU4zAz7ZemIN%2Bq%2F9BE7kx%2FDzats4O1xmtRSFnk6xOKA%2BEnPMAmFr8wKOZEpz7VJAlP4OZOIMkkXU4mhw0mVzAyk%2BkvvdsZ%2F8%2FeeIRp%2Fw4rYMVA9VqE6nOVOrTdtZf5B%2BdZX1prek5Sn5XnwQBI82G5wcljynWDpDROzyrSMy%2FyjZ%2Ba%2FHBjIfCHP9JNYxmxEoUOOOFU%2Fj52EZvoNF%2BFDcoCokveRlkg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T190913Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3K2OG3FFQ%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=13dc002305296cfdff5a74962c25c8d2c3b98cc0431d9fe323d662d957c1ec76,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/006/Glue5.0/AwsGlueMLLibsPython/java17/5.0.380/3CvvA4-AwsGlueMLLibs.py.zip?X-Amz-Security-Token=FwoDYXdzEDIaDORPOBwnSmdXlcCnpiKuAdbrMvLu6jqym3J2Jztm3ePt0sll1dZAhg3ZUH5jDcgpYii5BxzBvA43o1QhP%2FIxKU4zAz7ZemIN%2Bq%2F9BE7kx%2FDzats4O1xmtRSFnk6xOKA%2BEnPMAmFr8wKOZEpz7VJAlP4OZOIMkkXU4mhw0mVzAyk%2BkvvdsZ%2F8%2FeeIRp%2Fw4rYMVA9VqE6nOVOrTdtZf5B%2BdZX1prek5Sn5XnwQBI82G5wcljynWDpDROzyrSMy%2FyjZ%2Ba%2FHBjIfCHP9JNYxmxEoUOOOFU%2Fj52EZvoNF%2BFDcoCokveRlkg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T190913Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3K2OG3FFQ%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=ef5e00cc654a0356183c25b623d69899ff57a046257ca2f485a86de3a32c5ec1,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/006/Glue5.0/AwsGlueMLLibs/java17/5.0.380/dj5xOe-AwsGlueMLLibs.jar?X-Amz-Security-Token=FwoDYXdzEDIaDORPOBwnSmdXlcCnpiKuAdbrMvLu6jqym3J2Jztm3ePt0sll1dZAhg3ZUH5jDcgpYii5BxzBvA43o1QhP%2FIxKU4zAz7ZemIN%2Bq%2F9BE7kx%2FDzats4O1xmtRSFnk6xOKA%2BEnPMAmFr8wKOZEpz7VJAlP4OZOIMkkXU4mhw0mVzAyk%2BkvvdsZ%2F8%2FeeIRp%2Fw4rYMVA9VqE6nOVOrTdtZf5B%2BdZX1prek5Sn5XnwQBI82G5wcljynWDpDROzyrSMy%2FyjZ%2Ba%2FHBjIfCHP9JNYxmxEoUOOOFU%2Fj52EZvoNF%2BFDcoCokveRlkg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T190913Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3K2OG3FFQ%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=fc7d01156f3e1051a9d5a46787a280224703c9f1497a8e4f7539027a5f0ebc51 --config s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/config/maximo/dq/relatedrecord.yaml  --job_type data_quality --JOB_ID j_93a164e33afc70c883e5becadc30496b912ef0b2897167ec7bca8553cb79941a --extra-py-files s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/mosaic.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/sqlglot.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/yaml.zip   --JOB_RUN_ID jr_7cfdb218791a318a0a6c4e0f1efe0df749c9a0d6aa88d5dbf8d5cc48d670d4da_attempt_3 --scriptLocation s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py  --tenant-internal glue --enable-auto-scaling true --JOB_NAME maximo_dq_relatedrecord
Sun Oct 12 19:09:20 UTC 2025
Preparing ...