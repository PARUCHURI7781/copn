Driver logs
Driver and executor log streams 

INFO	2025-10-12T19:38:56,444	53171	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 2 @ 1760297936444
INFO	2025-10-12T19:38:56,445	53172	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 2
INFO	2025-10-12T19:38:56,444	53171	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 2 has registered (new total is 2)
INFO	2025-10-12T19:38:56,443	53170	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.34.94.226:34564) with ID 2,  ResourceProfileId 0
INFO	2025-10-12T19:38:51,675	48402	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-1]	60	Finished task 1.0 in stage 0.0 (TID 1) in 26697 ms on 172.35.125.91 (executor 1) (2/132)
INFO	2025-10-12T19:38:51,673	48400	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 3.0 in stage 0.0 (TID 3) (172.35.125.91, executor 1, partition 3, PROCESS_LOCAL, 28579 bytes) 
INFO	2025-10-12T19:38:49,744	46471	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-9018d802ad5faabf8e70ad005b06c2318b00d6d7 created for executor 2 in resource profile 0
INFO	2025-10-12T19:38:49,744	46471	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
INFO	2025-10-12T19:38:49,581	46308	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
INFO	2025-10-12T19:38:49,580	46307	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760297890741 with resource profile 0
INFO	2025-10-12T19:38:49,581	46308	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.33.242:46479, --executor-id, 2, --app-id, spark-application-1760297890741, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-12T19:38:49,581	46308	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 2; clientToken gr_639dbdb6-8b5a-4bff-be50-3c10681f32f3_e_2_a_spark-application-1760297890741_p_1
INFO	2025-10-12T19:38:49,463	46190	org.apache.spark.ExecutorAllocationManager	[spark-dynamic-executor-allocation]	60	Requesting 1 new executor because tasks are backlogged (new desired total will be 2 for resource profile id: 0)
INFO	2025-10-12T19:38:49,461	46188	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Set total expected executors: rpId: 0, numExecs: 2
INFO	2025-10-12T19:38:49,462	46189	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[spark-dynamic-executor-allocation]	60	Requested total executors are 2
INFO	2025-10-12T19:38:40,962	37689	org.apache.spark.scheduler.TaskSetManager	[task-result-getter-0]	60	Finished task 0.0 in stage 0.0 (TID 0) in 16012 ms on 172.35.125.91 (executor 1) (1/132)
INFO	2025-10-12T19:38:40,952	37679	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 2.0 in stage 0.0 (TID 2) (172.35.125.91, executor 1, partition 2, PROCESS_LOCAL, 29145 bytes) 
INFO	2025-10-12T19:38:27,514	24241	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.35.125.91:34679 (size: 4.6 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:38:25,925	22652	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.35.125.91:34679 (size: 16.1 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:38:24,979	21706	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 1.0 in stage 0.0 (TID 1) (172.35.125.91, executor 1, partition 1, PROCESS_LOCAL, 30268 bytes) 
INFO	2025-10-12T19:38:24,975	21702	org.apache.spark.scheduler.TaskSetManager	[dispatcher-CoarseGrainedScheduler]	60	Starting task 0.0 in stage 0.0 (TID 0) (172.35.125.91, executor 1, partition 0, PROCESS_LOCAL, 40203 bytes) 
INFO	2025-10-12T19:38:22,890	19617	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.35.125.91:34679 with 5.8 GiB RAM, BlockManagerId(1, 172.35.125.91, 34679, None)
INFO	2025-10-12T19:38:22,728	19455	org.apache.spark.scheduler.dynalloc.ExecutorMonitor	[spark-listener-group-executorManagement]	60	New executor 1 has registered (new total is 1)
INFO	2025-10-12T19:38:22,723	19450	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[spark-listener-group-shared]	60	connected executor 1
INFO	2025-10-12T19:38:22,722	19449	org.apache.spark.scheduler.cluster.glue.ExecutorEventListener	[spark-listener-group-shared]	60	Got executor added event for 1 @ 1760297902721
INFO	2025-10-12T19:38:22,721	19448	org.apache.spark.executor.ExecutorLogUrlHandler	[dispatcher-CoarseGrainedScheduler]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
INFO	2025-10-12T19:38:22,719	19446	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend$JESAsSchedulerBackendEndpoint	[dispatcher-CoarseGrainedScheduler]	60	Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.35.125.91:37838) with ID 1,  ResourceProfileId 0
INFO	2025-10-12T19:38:19,593	16320	org.apache.spark.scheduler.TaskSchedulerImpl	[dag-scheduler-event-loop]	60	Adding task set 0.0 with 132 tasks resource profile 0
INFO	2025-10-12T19:38:19,591	16318	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting 132 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
INFO	2025-10-12T19:38:19,572	16299	org.apache.spark.SparkContext	[dag-scheduler-event-loop]	60	Created broadcast 2 from broadcast at DAGScheduler.scala:1664
INFO	2025-10-12T19:38:19,571	16298	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_2_piece0 in memory on 172.34.33.242:39187 (size: 16.1 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:38:19,570	16297	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.1 KiB, actual size: 16.1 KiB, free 5.8 GiB)
INFO	2025-10-12T19:38:19,567	16294	org.apache.spark.storage.memory.MemoryStore	[dag-scheduler-event-loop]	60	Block broadcast_2 stored as values in memory (estimated size 37.8 KiB, free 5.8 GiB)
INFO	2025-10-12T19:38:19,393	16120	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at save at NativeMethodAccessorImpl.java:0), which has no missing parents
INFO	2025-10-12T19:38:19,378	16105	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Missing parents: List()
INFO	2025-10-12T19:38:19,376	16103	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Parents of final stage: List()
INFO	2025-10-12T19:38:19,375	16102	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Got map stage job 0 (save at NativeMethodAccessorImpl.java:0) with 132 output partitions
INFO	2025-10-12T19:38:19,376	16103	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Final stage: ShuffleMapStage 0 (save at NativeMethodAccessorImpl.java:0)
INFO	2025-10-12T19:38:19,371	16098	org.apache.spark.scheduler.DAGScheduler	[dag-scheduler-event-loop]	60	Registering RDD 5 (save at NativeMethodAccessorImpl.java:0) as input to shuffle 0
INFO	2025-10-12T19:38:19,137	15864	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 1 from broadcast at SparkBatch.java:85
INFO	2025-10-12T19:38:19,134	15861	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KiB, actual size: 4.6 KiB, free 5.8 GiB)
INFO	2025-10-12T19:38:19,135	15862	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_1_piece0 in memory on 172.34.33.242:39187 (size: 4.6 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:38:19,130	15857	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_1 stored as values in memory (estimated size 32.0 KiB, free 5.8 GiB)
INFO	2025-10-12T19:38:18,736	15463	org.apache.spark.SparkContext	[Thread-7]	60	Created broadcast 0 from broadcast at SparkBatch.java:85
INFO	2025-10-12T19:38:18,731	15458	org.apache.spark.storage.BlockManagerInfo	[dispatcher-BlockManagerMaster]	60	Added broadcast_0_piece0 in memory on 172.34.33.242:39187 (size: 4.6 KiB, free: 5.8 GiB)
INFO	2025-10-12T19:38:18,728	15455	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KiB, actual size: 4.6 KiB, free 5.8 GiB)
INFO	2025-10-12T19:38:18,638	15365	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 5.8 GiB)
INFO	2025-10-12T19:38:18,576	15303	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,574	15301	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,569	15296	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,563	15290	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,545	15272	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,541	15268	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,519	15246	software.amazon.glue.spark.redshift.pushdown.RedshiftStrategy	[Thread-7]	49	No redshift relations, skip push down
INFO	2025-10-12T19:38:18,275	15002	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	150	Requesting [] as write ordering for table glue_catalog.maximo_dq.mrline
INFO	2025-10-12T19:38:18,272	14999	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	157	Requesting 0 bytes advisory partition size for table glue_catalog.maximo_dq.mrline
INFO	2025-10-12T19:38:18,272	14999	org.apache.iceberg.spark.source.SparkWrite	[Thread-7]	138	Requesting UnspecifiedDistribution as write distribution for table glue_catalog.maximo_dq.mrline
INFO	2025-10-12T19:38:18,229	14956	org.apache.iceberg.spark.source.SparkPartitioningAwareScan	[Thread-7]	119	Reporting UnknownPartitioning with 132 partition(s) for table glue_catalog.maximo_raw.mrline
INFO	2025-10-12T19:38:17,887	14614	org.apache.iceberg.BaseDistributedDataScan	[Thread-7]	278	Planning file tasks locally for table glue_catalog.maximo_raw.mrline
INFO	2025-10-12T19:38:17,632	14359	org.apache.iceberg.SnapshotScan	[Thread-7]	124	Scanning table glue_catalog.maximo_raw.mrline snapshot 3593989126089821319 created at 2025-10-12T19:04:36.036+00:00 with filter true
INFO	2025-10-12T19:38:17,623	14350	org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown	[Thread-7]	60	
Output: mrnum#0, mrlinenum#1, mrlineid#2, itemnum#3, description#4, storeloc#5, qty#6, unitcost#7, linecost#8, directreq#9, assetnum#10, location#11, gldebitacct#12, requireddate#13, availdate#14, vendor#15, manufacturer#16, modelnum#17, catalogcode#18, droppoint#19, remarks#20, complete#21, prnum#22, partialissue#23, category#24, mrlin1#25, mrlin2#26, mrlin3#27, mrlin4#28, mrlin5#29, orderunit#30, chargestore#31, mrlaln1#32, mrlaln2#33, mrlaln3#34, mrlaln4#35, mrlaln5#36, pcardnum#37, pcardtype#38, pcardexpdate#39, classificationid#40, fincntrlid#41, pcardverification#42, vendorpackcode#43, vendorpackquantity#44, vendorwarehouse#45, currencycode#46, linecost1#47, linecost2#48, exchangerate#49, exchangerate2#50, inspectionrequired#51, siteid#52, orgid#53, isdistributed#54, refwo#55, enteredastask#56, linetype#57, itemsetid#58, conditioncode#59, commoditygroup#60, commodity#61, contractrefnum#62, contractrefrev#63, contractrefid#64, langcode#65, conversion#66, storelocsite#67, hasld#68, mktplcitem#69, classstructureid#70, rowstamp#71, restype#72, contact#73, etraimmunique#74, etraimmwrnum#75, etrcip13#76, etrexternalrefid#77, etrextmrlineid#78, etrextobjname#79, etrextrefid#80, etrextsysname#81, etrhardpending#82, etrhardresqty#83, etritemid#84, etrlotnum#85, etrmatlcostperc#86, etrpartnum#87, etrpendingqty#88, etrpurchaseagent#89, etrreference#90, etrservicelocat#91, etrservicetype#92, etrtdwonum#93, etrreceiver#94, pk_hash#95, edl_load_date#96
        
WARN	2025-10-12T19:38:17,124	13851	org.apache.spark.sql.catalyst.util.SparkStringUtils	[Thread-7]	72	Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
INFO	2025-10-12T19:38:17,082	13809	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.mrline loaded Spark schema: StructType(StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(mrlineid,DecimalType(38,10),true),StructField(itemnum,StringType,true),StructField(description,StringType,true),StructField(storeloc,StringType,true),StructField(qty,DecimalType(15,2),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(directreq,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(gldebitacct,StringType,true),StructField(requireddate,TimestampType,true),StructField(availdate,TimestampType,true),StructField(vendor,StringType,true),StructField(manufacturer,StringType,true),StructField(modelnum,StringType,true),StructField(catalogcode,StringType,true),StructField(droppoint,StringType,true),StructField(remarks,StringType,true),StructField(complete,DecimalType(38,10),true),StructField(prnum,StringType,true),StructField(partialissue,DecimalType(38,10),true),StructField(category,StringType,true),StructField(mrlin1,StringType,true),StructField(mrlin2,StringType,true),StructField(mrlin3,StringType,true),StructField(mrlin4,StringType,true),StructField(mrlin5,StringType,true),StructField(orderunit,StringType,true),StructField(chargestore,DecimalType(38,10),true),StructField(mrlaln1,StringType,true),StructField(mrlaln2,StringType,true),StructField(mrlaln3,StringType,true),StructField(mrlaln4,StringType,true),StructField(mrlaln5,StringType,true),StructField(pcardnum,StringType,true),StructField(pcardtype,StringType,true),StructField(pcardexpdate,StringType,true),StructField(classificationid,StringType,true),StructField(fincntrlid,StringType,true),StructField(pcardverification,StringType,true),StructField(vendorpackcode,StringType,true),StructField(vendorpackquantity,StringType,true),StructField(vendorwarehouse,StringType,true),StructField(currencycode,StringType,true),StructField(linecost1,DecimalType(18,6),true),StructField(linecost2,DecimalType(18,6),true),StructField(exchangerate,DecimalType(14,7),true),StructField(exchangerate2,DecimalType(14,7),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(siteid,StringType,true),StructField(orgid,StringType,true),StructField(isdistributed,DecimalType(38,10),true),StructField(refwo,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(linetype,StringType,true),StructField(itemsetid,StringType,true),StructField(conditioncode,StringType,true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(contractrefnum,StringType,true),StructField(contractrefrev,DecimalType(38,10),true),StructField(contractrefid,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(conversion,DecimalType(19,6),true),StructField(storelocsite,StringType,true),StructField(hasld,DecimalType(38,10),true),StructField(mktplcitem,DecimalType(38,10),true),StructField(classstructureid,StringType,true),StructField(rowstamp,StringType,true),StructField(restype,StringType,true),StructField(contact,StringType,true),StructField(etraimmunique,StringType,true),StructField(etraimmwrnum,DecimalType(38,10),true),StructField(etrcip13,DecimalType(38,10),true),StructField(etrexternalrefid,StringType,true),StructField(etrextmrlineid,StringType,true),StructField(etrextobjname,StringType,true),StructField(etrextrefid,StringType,true),StructField(etrextsysname,StringType,true),StructField(etrhardpending,DecimalType(38,10),true),StructField(etrhardresqty,DecimalType(15,2),true),StructField(etritemid,StringType,true),StructField(etrlotnum,StringType,true),StructField(etrmatlcostperc,DecimalType(10,2),true),StructField(etrpartnum,StringType,true),StructField(etrpendingqty,DecimalType(16,2),true),StructField(etrpurchaseagent,StringType,true),StructField(etrreference,StringType,true),StructField(etrservicelocat,StringType,true),StructField(etrservicetype,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrreceiver,StringType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
INFO	2025-10-12T19:38:16,868	13595	org.opensearch.hadoop.util.Version	[Thread-7]	143	OpenSearch Hadoop v1.2.0 [2a4148055f]
INFO	2025-10-12T19:38:15,770	12497	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_dq.mrline loaded Spark schema: StructType(StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(mrlineid,DecimalType(38,10),true),StructField(itemnum,StringType,true),StructField(description,StringType,true),StructField(storeloc,StringType,true),StructField(qty,DecimalType(15,2),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(directreq,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(gldebitacct,StringType,true),StructField(requireddate,TimestampType,true),StructField(availdate,TimestampType,true),StructField(vendor,StringType,true),StructField(manufacturer,StringType,true),StructField(modelnum,StringType,true),StructField(catalogcode,StringType,true),StructField(droppoint,StringType,true),StructField(remarks,StringType,true),StructField(complete,DecimalType(38,10),true),StructField(prnum,StringType,true),StructField(partialissue,DecimalType(38,10),true),StructField(category,StringType,true),StructField(mrlin1,StringType,true),StructField(mrlin2,StringType,true),StructField(mrlin3,StringType,true),StructField(mrlin4,StringType,true),StructField(mrlin5,StringType,true),StructField(orderunit,StringType,true),StructField(chargestore,DecimalType(38,10),true),StructField(mrlaln1,StringType,true),StructField(mrlaln2,StringType,true),StructField(mrlaln3,StringType,true),StructField(mrlaln4,StringType,true),StructField(mrlaln5,StringType,true),StructField(pcardnum,StringType,true),StructField(pcardtype,StringType,true),StructField(pcardexpdate,StringType,true),StructField(classificationid,StringType,true),StructField(fincntrlid,StringType,true),StructField(pcardverification,StringType,true),StructField(vendorpackcode,StringType,true),StructField(vendorpackquantity,StringType,true),StructField(vendorwarehouse,StringType,true),StructField(currencycode,StringType,true),StructField(linecost1,DecimalType(18,6),true),StructField(linecost2,DecimalType(18,6),true),StructField(exchangerate,DecimalType(14,7),true),StructField(exchangerate2,DecimalType(14,7),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(siteid,StringType,true),StructField(orgid,StringType,true),StructField(isdistributed,DecimalType(38,10),true),StructField(refwo,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(linetype,StringType,true),StructField(itemsetid,StringType,true),StructField(conditioncode,StringType,true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(contractrefnum,StringType,true),StructField(contractrefrev,DecimalType(38,10),true),StructField(contractrefid,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(conversion,DecimalType(19,6),true),StructField(storelocsite,StringType,true),StructField(hasld,DecimalType(38,10),true),StructField(mktplcitem,DecimalType(38,10),true),StructField(classstructureid,StringType,true),StructField(rowstamp,StringType,true),StructField(restype,StringType,true),StructField(contact,StringType,true),StructField(etraimmunique,StringType,true),StructField(etraimmwrnum,DecimalType(38,10),true),StructField(etrcip13,DecimalType(38,10),true),StructField(etrexternalrefid,StringType,true),StructField(etrextmrlineid,StringType,true),StructField(etrextobjname,StringType,true),StructField(etrextrefid,StringType,true),StructField(etrextsysname,StringType,true),StructField(etrhardpending,DecimalType(38,10),true),StructField(etrhardresqty,DecimalType(15,2),true),StructField(etritemid,StringType,true),StructField(etrlotnum,StringType,true),StructField(etrmatlcostperc,DecimalType(10,2),true),StructField(etrpartnum,StringType,true),StructField(etrpendingqty,DecimalType(16,2),true),StructField(etrpurchaseagent,StringType,true),StructField(etrreference,StringType,true),StructField(etrservicelocat,StringType,true),StructField(etrservicetype,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrreceiver,StringType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
INFO	2025-10-12T19:38:15,767	12494	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_dq.mrline
INFO	2025-10-12T19:38:15,608	12335	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-dq-dev/maximo_dq.db/mrline/metadata/00005-2a7ddc62-d7de-4343-99f8-d74a0d30c41a.metadata.json
INFO	2025-10-12T19:38:15,512	12239	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
WARN	2025-10-12T19:38:15,512	12239	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
INFO	2025-10-12T19:38:15,369	12096	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
INFO	2025-10-12T19:38:14,555	11282	org.apache.iceberg.spark.source.SparkTable	[Thread-7]	206	Table glue_catalog.maximo_raw.mrline loaded Spark schema: StructType(StructField(mrnum,StringType,true),StructField(mrlinenum,DecimalType(38,10),true),StructField(mrlineid,DecimalType(38,10),true),StructField(itemnum,StringType,true),StructField(description,StringType,true),StructField(storeloc,StringType,true),StructField(qty,DecimalType(15,2),true),StructField(unitcost,DecimalType(18,6),true),StructField(linecost,DecimalType(18,6),true),StructField(directreq,DecimalType(38,10),true),StructField(assetnum,StringType,true),StructField(location,StringType,true),StructField(gldebitacct,StringType,true),StructField(requireddate,TimestampType,true),StructField(availdate,TimestampType,true),StructField(vendor,StringType,true),StructField(manufacturer,StringType,true),StructField(modelnum,StringType,true),StructField(catalogcode,StringType,true),StructField(droppoint,StringType,true),StructField(remarks,StringType,true),StructField(complete,DecimalType(38,10),true),StructField(prnum,StringType,true),StructField(partialissue,DecimalType(38,10),true),StructField(category,StringType,true),StructField(mrlin1,StringType,true),StructField(mrlin2,StringType,true),StructField(mrlin3,StringType,true),StructField(mrlin4,StringType,true),StructField(mrlin5,StringType,true),StructField(orderunit,StringType,true),StructField(chargestore,DecimalType(38,10),true),StructField(mrlaln1,StringType,true),StructField(mrlaln2,StringType,true),StructField(mrlaln3,StringType,true),StructField(mrlaln4,StringType,true),StructField(mrlaln5,StringType,true),StructField(pcardnum,StringType,true),StructField(pcardtype,StringType,true),StructField(pcardexpdate,StringType,true),StructField(classificationid,StringType,true),StructField(fincntrlid,StringType,true),StructField(pcardverification,StringType,true),StructField(vendorpackcode,StringType,true),StructField(vendorpackquantity,StringType,true),StructField(vendorwarehouse,StringType,true),StructField(currencycode,StringType,true),StructField(linecost1,DecimalType(18,6),true),StructField(linecost2,DecimalType(18,6),true),StructField(exchangerate,DecimalType(14,7),true),StructField(exchangerate2,DecimalType(14,7),true),StructField(inspectionrequired,DecimalType(38,10),true),StructField(siteid,StringType,true),StructField(orgid,StringType,true),StructField(isdistributed,DecimalType(38,10),true),StructField(refwo,StringType,true),StructField(enteredastask,DecimalType(38,10),true),StructField(linetype,StringType,true),StructField(itemsetid,StringType,true),StructField(conditioncode,StringType,true),StructField(commoditygroup,StringType,true),StructField(commodity,StringType,true),StructField(contractrefnum,StringType,true),StructField(contractrefrev,DecimalType(38,10),true),StructField(contractrefid,DecimalType(38,10),true),StructField(langcode,StringType,true),StructField(conversion,DecimalType(19,6),true),StructField(storelocsite,StringType,true),StructField(hasld,DecimalType(38,10),true),StructField(mktplcitem,DecimalType(38,10),true),StructField(classstructureid,StringType,true),StructField(rowstamp,StringType,true),StructField(restype,StringType,true),StructField(contact,StringType,true),StructField(etraimmunique,StringType,true),StructField(etraimmwrnum,DecimalType(38,10),true),StructField(etrcip13,DecimalType(38,10),true),StructField(etrexternalrefid,StringType,true),StructField(etrextmrlineid,StringType,true),StructField(etrextobjname,StringType,true),StructField(etrextrefid,StringType,true),StructField(etrextsysname,StringType,true),StructField(etrhardpending,DecimalType(38,10),true),StructField(etrhardresqty,DecimalType(15,2),true),StructField(etritemid,StringType,true),StructField(etrlotnum,StringType,true),StructField(etrmatlcostperc,DecimalType(10,2),true),StructField(etrpartnum,StringType,true),StructField(etrpendingqty,DecimalType(16,2),true),StructField(etrpurchaseagent,StringType,true),StructField(etrreference,StringType,true),StructField(etrservicelocat,StringType,true),StructField(etrservicetype,StringType,true),StructField(etrtdwonum,StringType,true),StructField(etrreceiver,StringType,true),StructField(pk_hash,StringType,true),StructField(edl_load_date,TimestampType,true))
INFO	2025-10-12T19:38:14,534	11261	org.apache.iceberg.aws.glue.GlueCatalog	[Thread-7]	855	Table loaded by catalog: glue_catalog.maximo_raw.mrline
INFO	2025-10-12T19:38:14,135	10862	org.apache.iceberg.BaseMetastoreTableOperations	[Thread-7]	189	Refreshing table metadata from new version: s3://entergy-govdatacore-raw-dev/maximo_raw.db/mrline/metadata/00015-b4f07afe-b354-44fb-a1e9-41aafbe4f0bf.metadata.json
WARN	2025-10-12T19:38:14,012	10739	software.amazon.glue.GlueCatalogSessionExtensions	[Thread-7]	174	Fail to load catalog v1/catalogs/:: Forbidden: 331875467123 is not allowlisted to call GetCatalogExtension
INFO	2025-10-12T19:38:14,013	10740	software.amazon.glue.GlueUtil	[Thread-7]	264	Not use extensions: no catalog info
INFO	2025-10-12T19:38:13,391	10118	org.apache.iceberg.CatalogUtil	[Thread-7]	354	Loading custom FileIO implementation: org.apache.iceberg.aws.s3.S3FileIO
INFO	2025-10-12T19:38:11,661	8388	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Warehouse path is 'file:/home/hadoop/spark-warehouse'.
INFO	2025-10-12T19:38:11,657	8384	org.apache.spark.sql.internal.SharedState	[Thread-7]	60	Setting hive.metastore.warehouse.dir ('/tmp/spark-warehouse') to the value of spark.sql.warehouse.dir.
INFO	2025-10-12T19:38:11,571	8298	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	createChildTask API response code 200
INFO	2025-10-12T19:38:11,572	8299	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	executor task g-668250a10448158bb3b1d24405b2d29bdbc56c2f created for executor 1 in resource profile 0
INFO	2025-10-12T19:38:11,333	8060	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
INFO	2025-10-12T19:38:11,328	8055	org.apache.spark.executor.ExecutorLogUrlHandler	[Thread-7]	60	Fail to renew executor log urls: some of required attributes are missing in app's event log.. Required: Set(CONTAINER_ID) / available: Set(). Falling back to show app's original log urls.
INFO	2025-10-12T19:38:11,323	8050	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	getDriverLogUrls Map()
INFO	2025-10-12T19:38:11,273	8000	org.apache.spark.SparkContext	[Thread-7]	60	Registered listener com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener
INFO	2025-10-12T19:38:11,259	7986	com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter	[Thread-7]	51	Started file writer for com.amazonaws.services.glueexceptionanalysis.EventLogFileWriter
INFO	2025-10-12T19:38:11,197	7924	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Requested total executors are 1
INFO	2025-10-12T19:38:11,165	7892	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
INFO	2025-10-12T19:38:11,143	7870	org.apache.spark.ExecutorAllocationManager	[Thread-7]	60	Dynamic allocation is enabled without a shuffle service.
INFO	2025-10-12T19:38:11,142	7869	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
INFO	2025-10-12T19:38:11,031	7758	org.apache.spark.deploy.history.SingleEventLogFileWriter	[Thread-7]	60	Logging events to file:/var/log/spark/apps/spark-application-1760297890741.inprogress
INFO	2025-10-12T19:38:10,846	7573	org.apache.spark.storage.BlockManager	[Thread-7]	60	Initialized BlockManager: BlockManagerId(driver, 172.34.33.242, 39187, None)
INFO	2025-10-12T19:38:10,846	7573	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registered BlockManager BlockManagerId(driver, 172.34.33.242, 39187, None)
INFO	2025-10-12T19:38:10,843	7570	org.apache.spark.storage.BlockManagerMasterEndpoint	[dispatcher-BlockManagerMaster]	60	Registering block manager 172.34.33.242:39187 with 5.8 GiB RAM, BlockManagerId(driver, 172.34.33.242, 39187, None)
INFO	2025-10-12T19:38:10,839	7566	org.apache.spark.storage.BlockManagerMaster	[Thread-7]	60	Registering BlockManager BlockManagerId(driver, 172.34.33.242, 39187, None)
INFO	2025-10-12T19:38:10,829	7556	org.apache.spark.storage.BlockManager	[Thread-7]	60	Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
INFO	2025-10-12T19:38:10,826	7553	org.apache.spark.network.netty.NettyBlockTransferService	[Thread-7]	88	Server created on 172.34.33.242:39187
INFO	2025-10-12T19:38:10,827	7554	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	Sending request to JES
INFO	2025-10-12T19:38:10,826	7553	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39187.
INFO	2025-10-12T19:38:10,807	7534	org.apache.spark.deploy.glue.client.GlueTaskGroupRMClient	[executorAllocator]	60	creating executor task for executor 1; clientToken gr_639dbdb6-8b5a-4bff-be50-3c10681f32f3_e_1_a_spark-application-1760297890741_p_1
INFO	2025-10-12T19:38:10,806	7533	org.apache.spark.scheduler.cluster.glue.allocator.ExecutorTaskAllocator	[executorAllocator]	60	Creating new task with arguments List(--driver-url, spark://CoarseGrainedScheduler@172.34.33.242:46479, --executor-id, 1, --app-id, spark-application-1760297890741, --cores, 2, --resourceProfileId, 0)
INFO	2025-10-12T19:38:10,802	7529	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[executorAllocator]	60	Creating executors task for application spark-application-1760297890741 with resource profile 0
INFO	2025-10-12T19:38:10,796	7523	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Initial executors are 1
INFO	2025-10-12T19:38:10,795	7522	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Set total expected executors: rpId: 0, numExecs: 1
INFO	2025-10-12T19:38:10,793	7520	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	Starting JES Scheduler Backend.
INFO	2025-10-12T19:38:10,749	7476	org.apache.spark.util.Utils	[Thread-7]	60	Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
INFO	2025-10-12T19:38:10,746	7473	org.apache.spark.scheduler.cluster.glue.JESSchedulerBackend	[Thread-7]	60	JESSchedulerBackend
INFO	2025-10-12T19:38:10,191	6918	org.apache.spark.deploy.glue.client.GlueRMClientFactory	[Thread-7]	60	JESClusterManager: Initializing JES client with endpoint: https://glue-jes.us-gov-west-1.amazonaws.com
INFO	2025-10-12T19:38:10,188	6915	org.apache.spark.scheduler.cluster.glue.JESClusterManager	[Thread-7]	121	Python path for executors: sqlglot.zip:mosaic.zip:yaml.zip:python_environment
INFO	2025-10-12T19:38:09,712	6439	org.apache.spark.SparkContext	[Thread-7]	60	Unpacking an archive /tmp/glue-job-12535296226656668579_glue_venv.zip#python_environment from /tmp/spark-66b70c7a-043d-439c-8162-6507c025a5eb/glue-job-12535296226656668579_glue_venv.zip to /tmp/spark-f110d5d5-0a06-454e-9350-3d6826378884/userFiles-cbd6d235-3f65-49b0-906b-1212234f66dc/python_environment
INFO	2025-10-12T19:38:09,698	6425	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12535296226656668579_glue_venv.zip to /tmp/spark-66b70c7a-043d-439c-8162-6507c025a5eb/glue-job-12535296226656668579_glue_venv.zip
INFO	2025-10-12T19:38:09,697	6424	org.apache.spark.SparkContext	[Thread-7]	60	Added archive /tmp/glue-job-12535296226656668579_glue_venv.zip#python_environment at spark://172.34.33.242:46479/files/glue-job-12535296226656668579_glue_venv.zip with timestamp 1760297888568
INFO	2025-10-12T19:38:09,652	6379	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-12535296226656668579/extra-py-files/yaml.zip at spark://172.34.33.242:46479/files/yaml.zip with timestamp 1760297888568
INFO	2025-10-12T19:38:09,653	6380	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12535296226656668579/extra-py-files/yaml.zip to /tmp/spark-f110d5d5-0a06-454e-9350-3d6826378884/userFiles-cbd6d235-3f65-49b0-906b-1212234f66dc/yaml.zip
INFO	2025-10-12T19:38:09,647	6374	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-12535296226656668579/extra-py-files/mosaic.zip at spark://172.34.33.242:46479/files/mosaic.zip with timestamp 1760297888568
INFO	2025-10-12T19:38:09,647	6374	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12535296226656668579/extra-py-files/mosaic.zip to /tmp/spark-f110d5d5-0a06-454e-9350-3d6826378884/userFiles-cbd6d235-3f65-49b0-906b-1212234f66dc/mosaic.zip
INFO	2025-10-12T19:38:09,634	6361	org.apache.spark.util.Utils	[Thread-7]	60	Copying /tmp/glue-job-12535296226656668579/extra-py-files/sqlglot.zip to /tmp/spark-f110d5d5-0a06-454e-9350-3d6826378884/userFiles-cbd6d235-3f65-49b0-906b-1212234f66dc/sqlglot.zip
INFO	2025-10-12T19:38:09,632	6359	org.apache.spark.SparkContext	[Thread-7]	60	Added file /tmp/glue-job-12535296226656668579/extra-py-files/sqlglot.zip at spark://172.34.33.242:46479/files/sqlglot.zip with timestamp 1760297888568
INFO	2025-10-12T19:38:09,466	6193	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-12535296226656668579/jars/dj5xOe-AwsGlueMLLibs.jar at spark://172.34.33.242:46479/jars/dj5xOe-AwsGlueMLLibs.jar with timestamp 1760297888568
INFO	2025-10-12T19:38:09,465	6192	org.apache.spark.SparkContext	[Thread-7]	60	Added JAR /tmp/glue-job-12535296226656668579/jars/odvJng-aws-glue-di-package-5.0.704.jar at spark://172.34.33.242:46479/jars/odvJng-aws-glue-di-package-5.0.704.jar with timestamp 1760297888568
INFO	2025-10-12T19:38:09,428	6155	org.apache.spark.subresultcache.SubResultCacheManager	[Thread-7]	60	Sub-result caches are disabled.
INFO	2025-10-12T19:38:09,423	6150	org.apache.spark.SparkEnv	[Thread-7]	60	Registering OutputCommitCoordinator
INFO	2025-10-12T19:38:09,403	6130	org.apache.spark.storage.memory.MemoryStore	[Thread-7]	60	MemoryStore started with capacity 5.8 GiB
INFO	2025-10-12T19:38:09,382	6109	org.apache.spark.storage.DiskBlockManager	[Thread-7]	60	Created local directory at /tmp/blockmgr-5a069022-3230-46d6-b183-8e1ab86fcce9
INFO	2025-10-12T19:38:09,331	6058	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMasterHeartbeat
INFO	2025-10-12T19:38:09,326	6053	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
INFO	2025-10-12T19:38:09,327	6054	org.apache.spark.storage.BlockManagerMasterEndpoint	[Thread-7]	60	BlockManagerMasterEndpoint up
INFO	2025-10-12T19:38:09,304	6031	org.apache.spark.SparkEnv	[Thread-7]	60	Registering BlockManagerMaster
INFO	2025-10-12T19:38:09,267	5994	org.apache.spark.SparkEnv	[Thread-7]	60	Registering MapOutputTracker
INFO	2025-10-12T19:38:09,222	5949	org.apache.spark.util.Utils	[Thread-7]	60	Successfully started service 'sparkDriver' on port 46479.
INFO	2025-10-12T19:38:08,887	5614	org.apache.spark.SecurityManager	[Thread-7]	60	SecurityManager: authentication enabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
INFO	2025-10-12T19:38:08,886	5613	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls groups to: 
INFO	2025-10-12T19:38:08,887	5614	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls groups to: 
INFO	2025-10-12T19:38:08,885	5612	org.apache.spark.SecurityManager	[Thread-7]	60	Changing view acls to: hadoop
INFO	2025-10-12T19:38:08,886	5613	org.apache.spark.SecurityManager	[Thread-7]	60	Changing modify acls to: hadoop
INFO	2025-10-12T19:38:08,809	5536	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 1
INFO	2025-10-12T19:38:08,809	5536	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	User executor ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
INFO	2025-10-12T19:38:08,809	5536	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
INFO	2025-10-12T19:38:08,805	5532	org.apache.spark.resource.ResourceProfileManager	[Thread-7]	60	Added ResourceProfile id: 0
INFO	2025-10-12T19:38:08,803	5530	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Limiting resource is cpus at 2 tasks per executor
INFO	2025-10-12T19:38:08,795	5522	org.apache.spark.resource.ResourceProfile	[Thread-7]	60	Default ResourceProfile created, executor resources: Map(executorType -> name: executorType, amount: 1, script: , vendor: , cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
INFO	2025-10-12T19:38:08,767	5494	org.apache.spark.SparkContext	[Thread-7]	60	Submitted application: maximo_dq_mrline
INFO	2025-10-12T19:38:08,765	5492	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	No custom resources configured for spark.driver.
INFO	2025-10-12T19:38:08,766	5493	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
INFO	2025-10-12T19:38:08,764	5491	org.apache.spark.resource.ResourceUtils	[Thread-7]	60	==============================================================
INFO	2025-10-12T19:38:08,579	5306	org.apache.spark.SparkContext	[Thread-7]	60	OS info Linux, 5.10.240-238.966.amzn2.x86_64, amd64
INFO	2025-10-12T19:38:08,579	5306	org.apache.spark.SparkContext	[Thread-7]	60	Java version 17.0.16
INFO	2025-10-12T19:38:08,578	5305	org.apache.spark.SparkContext	[Thread-7]	60	Running Spark version 3.5.4-amzn-0
INFO	2025-10-12T19:38:08,566	5293	org.apache.spark.emr.EMRParamSideChannel	[Thread-7]	177	Setting FGAC mode to false
INFO	2025-10-12T19:38:05,634	2361	com.amazonaws.services.glue.SafeLogging	[main]	60	Initializing logging subsystem
INFO	2025-10-12T19:38:05,454	2181	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
INFO	2025-10-12T19:38:05,123	1850	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
Sun Oct 12 19:38:03 UTC 2025
Launching ...
INFO	2025-10-12T19:38:02,843	13866	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	76	shutdownAsyncProcessing has been completed
INFO	2025-10-12T19:38:02,842	13865	com.amazonaws.services.glue.utils.concurrent.GlueConcurrentAsyncProcessingService	[main]	50	shutdownAsyncProcessing has been Started
INFO	2025-10-12T19:38:02,833	13856	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	39	Setting Up Virtual Env and Application Python Modules has been completed in async mode
INFO	2025-10-12T19:38:02,698	13721	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-12535296226656668579/pythonmodules/createvenvzip.sh /tmp/glue_venv /tmp/glue-job-12535296226656668579_glue_venv.zip
INFO	2025-10-12T19:38:00,455	11478	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-12535296226656668579/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-12535296226656668579/python/3CvvA4-AwsGlueMLLibs/amzn_awsgluemlpythonlibs-1.0-py3-none-any.whl
INFO	2025-10-12T19:38:00,450	11473	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-12535296226656668579/python/3CvvA4-AwsGlueMLLibs.py.zip -d /tmp/glue-job-12535296226656668579/python/3CvvA4-AwsGlueMLLibs
INFO	2025-10-12T19:37:59,368	10391	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute /usr/bin/bash /tmp/glue-job-12535296226656668579/pythonmodules/pythonmoduleinstaller.sh /tmp/glue_venv --no-index --no-deps /tmp/glue-job-12535296226656668579/python/ufak9W-AWSGlueDataplanePython-5.0.704/amzn_awsgluelibs-5.0.704-py3-none-any.whl
INFO	2025-10-12T19:37:59,354	10377	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute unzip /tmp/glue-job-12535296226656668579/python/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip -d /tmp/glue-job-12535296226656668579/python/ufak9W-AWSGlueDataplanePython-5.0.704
INFO	2025-10-12T19:37:56,918	7941	com.amazonaws.services.glue.FileDownloader	[sdk-async-response-2-0]	145	Object downloaded. Details: GetObjectResponse(AcceptRanges=bytes, LastModified=2025-10-10T16:51:03Z, ContentLength=453, ETag="3f516bac98ff6f23cf7791a839a72cc0", ContentType=binary/octet-stream, ServerSideEncryption=AES256, Metadata={})
INFO	2025-10-12T19:37:56,918	7941	com.amazonaws.services.glue.launch.helpers.FileManager	[main]	119	Script should be downloaded at /tmp/glue-job-12535296226656668579/raw_dq_load.py 
INFO	2025-10-12T19:37:56,127	7150	com.amazonaws.services.glue.FileDownloader	[main]	138	Download bucket: entergy-govdatacore-dataeng-code-repo-dev key: entergy-gov-data-core-code/scripts/raw_dq_load.py to /tmp/glue-job-12535296226656668579/raw_dq_load.py with usingProxy: false and isProxyDisabled: true
INFO	2025-10-12T19:37:56,116	7139	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	37	Encoded S3 URI to s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
INFO	2025-10-12T19:37:56,116	7139	com.amazonaws.services.glue.utils.AWSS3Utils$	[main]	32	Encoding S3 URI s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py
INFO	2025-10-12T19:37:55,885	6908	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py file to destination location: /tmp/glue-job-12535296226656668579/raw_dq_load.py
INFO	2025-10-12T19:37:55,882	6905	com.amazonaws.services.glue.PrepareLaunch	[main]	194	list of connectors to be added in classpath: List()
INFO	2025-10-12T19:37:55,629	6652	com.amazonaws.services.glue.launch.helpers.ConnectionsManager	[main]	78	GLUE_CONNECTIVITY: attached connection types: ListBuffer()
INFO	2025-10-12T19:37:55,534	6557	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/aws_glue_connectors/selected/native
INFO	2025-10-12T19:37:55,535	6558	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/aws_glue_connectors/marketplace
INFO	2025-10-12T19:37:55,533	6556	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/amazon
INFO	2025-10-12T19:37:55,534	6557	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/amazon/certs
INFO	2025-10-12T19:37:55,532	6555	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/aws_glue_connectors
INFO	2025-10-12T19:37:55,533	6556	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/aws_glue_connectors/selected
INFO	2025-10-12T19:37:55,533	6556	com.amazonaws.services.glue.PrepareLaunch	[main]	264	Creating directory /tmp/glue-job-12535296226656668579/exception_catch
INFO	2025-10-12T19:37:55,517	6540	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	78	setting up the log4j.configurationFile=/tmp/glue-job-12535296226656668579/glue-4433256871168293869log4j2.properties
INFO	2025-10-12T19:37:55,110	6133	com.amazonaws.services.glue.FileDownloader	[main]	95	downloading /tmp/glue-4433256871168293869log4j2.properties file to destination location: /tmp/glue-job-12535296226656668579/glue-4433256871168293869log4j2.properties
WARN	2025-10-12T19:37:55,107	6130	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	60	Logger setup failed for exception analysis: Cannot invoke "java.net.URL.toURI()" because the return value of "java.lang.Class.getResource(String)" is null
INFO	2025-10-12T19:37:55,104	6127	com.amazonaws.services.glue.launch.helpers.LoggerPropsManager	[main]	31	setupLoggerProperties...
INFO	2025-10-12T19:37:55,103	6126	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	59	glue.etl.telemetry.runtimeImproveFeature.autoscaling, jr_4cd19852f74703f225781bc74a7e03820e4015540a2c03c2b0124a9c6384e1d2_attempt_3
INFO	2025-10-12T19:37:55,097	6120	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	113	optimizeParallelismConfigs started 
INFO	2025-10-12T19:37:54,473	5496	com.amazonaws.services.glue.utils.AWSClientUtils$	[main]	98	AWSClientUtils: create aws sts client with conf: proxy hostnull, proxy port 0
INFO	2025-10-12T19:37:54,433	5456	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	90	Endpoints: {credentials_provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain, glue.endpoint=https://glue.us-gov-west-1.amazonaws.com, lakeformation.endpoint=https://lakeformation.us-gov-west-1.amazonaws.com, jes.endpoint=https://glue-jes.us-gov-west-1.amazonaws.com, region=us-gov-west-1}
INFO	2025-10-12T19:37:54,223	5246	com.amazonaws.services.glue.utils.EndpointConfig$	[main]	36	 STAGE is prod
INFO	2025-10-12T19:37:54,218	5241	com.amazonaws.services.glue.launch.helpers.SparkPropsManagerHelper	[main]	99	
proxy {
  host = null
  port = -1
}
INFO	2025-10-12T19:37:54,185	5208	com.amazonaws.services.glue.launch.helpers.PrepareLaunchProperties	[main]	89	Get job script: raw_dq_load.py.
INFO	2025-10-12T19:37:54,178	5201	com.amazonaws.services.glue.PythonModuleInstaller	[pool-5-thread-1]	176	Command to Execute python3.11 -m venv --clear /tmp/glue_venv
INFO	2025-10-12T19:37:54,174	5197	com.amazonaws.services.glue.utils.concurrent.PythonModuleTask	[pool-5-thread-1]	25	Setting Up Virtual Env and Application/Customer Provided Python Modules started in async mode
1760297873206
25/10/12 19:37:53 INFO GlueLibsDownloader: Elapsed time: 1756 millis
25/10/12 19:37:52 INFO GlueLibsDownloader: Elapsed time: 809 millis
25/10/12 19:37:50 WARN VersionInfoUtils: The AWS SDK for Java 1.x entered maintenance mode starting July 31, 2024 and will reach end of support on December 31, 2025. For more information, see https://aws.amazon.com/blogs/developer/the-aws-sdk-for-java-1-x-is-in-maintenance-mode-effective-july-31-2024/
You can print where on the file system the AWS SDK for Java 1.x core runtime is located by setting the AWS_JAVA_V1_PRINT_LOCATION environment variable or aws.java.v1.printLocation system property to 'true'.
This message can be disabled by setting the AWS_JAVA_V1_DISABLE_DEPRECATION_ANNOUNCEMENT environment variable or aws.java.v1.disableDeprecationAnnouncement system property to 'true'.
The AWS SDK for Java 1.x is being used here:
at java.base/java.lang.Thread.getStackTrace(Thread.java:1619)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.printDeprecationAnnouncement(VersionInfoUtils.java:81)
at glue.shaded.com.amazonaws.util.VersionInfoUtils.<clinit>(VersionInfoUtils.java:59)
at glue.shaded.com.amazonaws.internal.EC2ResourceFetcher.<clinit>(EC2ResourceFetcher.java:44)
at glue.shaded.com.amazonaws.auth.InstanceMetadataServiceCredentialsFetcher.<init>(InstanceMetadataServiceCredentialsFetcher.java:38)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:111)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:91)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<init>(InstanceProfileCredentialsProvider.java:75)
at glue.shaded.com.amazonaws.auth.InstanceProfileCredentialsProvider.<clinit>(InstanceProfileCredentialsProvider.java:58)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.initializeProvider(EC2ContainerCredentialsProviderWrapper.java:66)
at glue.shaded.com.amazonaws.auth.EC2ContainerCredentialsProviderWrapper.<init>(EC2ContainerCredentialsProviderWrapper.java:55)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<init>(DefaultAWSCredentialsProviderChain.java:60)
at glue.shaded.com.amazonaws.auth.DefaultAWSCredentialsProviderChain.<clinit>(DefaultAWSCredentialsProviderChain.java:54)
at glue.shaded.com.amazonaws.services.s3.AmazonS3ClientBuilder.standard(AmazonS3ClientBuilder.java:46)
at glue.shaded.com.amazonaws.services.s3.AmazonS3Client.builder(AmazonS3Client.java:740)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.getS3Client(GlueLibsDownloader.java:289)
at com.amazonaws.services.glue.GlueLibsDownloader$Builder.build(GlueLibsDownloader.java:281)
at com.amazonaws.services.glue.GlueBootstrap.downloadGlueLibs(GlueBootstrap.java:373)
at com.amazonaws.services.glue.GlueBootstrap.lambda$setUpGlueAndUserLibs$1(GlueBootstrap.java:124)
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
at java.base/java.lang.Thread.run(Thread.java:840)
25/10/12 19:37:50 INFO GlueBootstrap: Downloading customer supplied extra files...
25/10/12 19:37:50 INFO GlueBootstrap: Downloading Glue libs...
25/10/12 19:37:50 INFO GlueBootstrap: Glue Bootstrapping the driver...
25/10/12 19:37:50 INFO GlueBootstrap: Glue Bootstrapping...
openjdk version "17.0.16" 2025-07-15 LTS
OpenJDK Runtime Environment Corretto-17.0.16.8.1 (build 17.0.16+8-LTS)
OpenJDK 64-Bit Server VM Corretto-17.0.16.8.1 (build 17.0.16+8-LTS, mixed mode, sharing)
/etc/alternatives/jre/bin/java --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=jdk.naming.dns/com.sun.jndi.dns=java.naming --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.math=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util.regex=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/jdk.internal=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/jdk.internal.reflect=ALL-UNNAMED --add-opens=java.base/jdk.internal.util=ALL-UNNAMED --add-opens=java.base/jdk.internal.util.random=ALL-UNNAMED --add-opens=java.sql/java.sql=ALL-UNNAMED --add-opens=jdk.management/com.sun.management.internal=ALL-UNNAMED -XX:+IgnoreUnrecognizedVMOptions -Djavax.net.ssl.trustStore=/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -Djavax.net.ssl.trustStoreType=JKS -Djavax.net.ssl.trustStorePassword=amazon -DRDS_ROOT_CERT_PATH=/opt/amazon/certs/rds-combined-ca-bundle.pem -DREDSHIFT_ROOT_CERT_PATH=/opt/amazon/certs/redshift-ssl-ca-cert.pem -DRDS_TRUSTSTORE_URL=file:/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks -cp /usr/share/aws/aws-glue-shuffle/*:/usr/share/aws/emr-glue-bootstrap/*:/usr/lib/spark/jars/*:/usr/lib/spark/conf:/usr/share/aws/aws-java-sdk-v2/*:/usr/share/aws/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/aws/hmclient/lib/*:/usr/share/aws/iceberg/lib/*:/usr/share/aws/delta/lib/*:/usr/lib/hudi/*:/usr/share/aws/redshift/jdbc/*:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/glue-connectors/lib/*:/usr/share/aws/glue-pii-dependencies/lib/*:/usr/share/aws/datazone-openlineage-spark/lib/*:/usr/lib/hadoop/lib/*::/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar:/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar:/usr/share/aws/emr/cloudwatch-sink/lib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/lib/hadoop/*:/etc/hadoop/conf:/usr/share/java/Hive-JSON-Serde/* -Dlog4j2.configurationFile=/etc/spark/conf.dist/log4j2.properties com.amazonaws.services.glue.GlueBootstrap --conf spark.dynamicAllocation.enabled=true --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.minExecutors=1 --conf spark.dynamicAllocation.maxExecutors=4 --conf spark.executor.memory=10g --conf spark.driver.memory=10g --conf spark.network.timeout=600 --app_name maximo_dq_mrline    --glue-di-packages-correlation-ids 20250828-143656_,20250828-143656_,6376818366,6376818366 --TempDir s3://aws-glue-assets-331875467123-us-gov-west-1/entergy-gov-data-core-code/temporary/ --internal-lib-urls https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/aws-glue-dataplane-python/java17/5.0.704/ufak9W-AWSGlueDataplanePython-5.0.704.py.zip?X-Amz-Security-Token=FwoDYXdzEDIaDC0qAqoIQcW1qNYUJiKuAXpOzs8qwMVrVbc11D3opJklo5Z9pMvg2DQmQybaHKVr9k9sqUULbMIe4LoNTHnV33oC6ivGDB3ZA1n8GF4s9L%2BP9n1ruFGpTBuuUoMn68aVAnxRH2jDX5yKFujnw9tFj66fOa65fbDDdps8FDDxmDL5YnIhn9gX0QOknJoG4PnKktUFFaC%2B%2FFTFbo69AX%2BLJieZ0IFCc9wR2ycOeOe7ssmDWar%2B4AMBVSpsa1bKbCiIh7DHBjIfduz08DZyyrQgN%2BopE3A5rSnwR8e9D0v6Y3YUy8IpLg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T193744Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3GNLTI5BH%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=88acf3058399a43deb632e13458b4c66f07ce15fa9b64f7c9966b45b83acbe7b,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/aws-glue-di-libs/java17/5.0.704/odvJng-aws-glue-di-package-5.0.704.jar?X-Amz-Security-Token=FwoDYXdzEDIaDC0qAqoIQcW1qNYUJiKuAXpOzs8qwMVrVbc11D3opJklo5Z9pMvg2DQmQybaHKVr9k9sqUULbMIe4LoNTHnV33oC6ivGDB3ZA1n8GF4s9L%2BP9n1ruFGpTBuuUoMn68aVAnxRH2jDX5yKFujnw9tFj66fOa65fbDDdps8FDDxmDL5YnIhn9gX0QOknJoG4PnKktUFFaC%2B%2FFTFbo69AX%2BLJieZ0IFCc9wR2ycOeOe7ssmDWar%2B4AMBVSpsa1bKbCiIh7DHBjIfduz08DZyyrQgN%2BopE3A5rSnwR8e9D0v6Y3YUy8IpLg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T193744Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3GNLTI5BH%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=4713c269c5567b3b2d376ff59e0783cc66eed9cf9778463b81ffa738c0ba63cc,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/AwsGlueMLLibsPython/java17/5.0.380/3CvvA4-AwsGlueMLLibs.py.zip?X-Amz-Security-Token=FwoDYXdzEDIaDC0qAqoIQcW1qNYUJiKuAXpOzs8qwMVrVbc11D3opJklo5Z9pMvg2DQmQybaHKVr9k9sqUULbMIe4LoNTHnV33oC6ivGDB3ZA1n8GF4s9L%2BP9n1ruFGpTBuuUoMn68aVAnxRH2jDX5yKFujnw9tFj66fOa65fbDDdps8FDDxmDL5YnIhn9gX0QOknJoG4PnKktUFFaC%2B%2FFTFbo69AX%2BLJieZ0IFCc9wR2ycOeOe7ssmDWar%2B4AMBVSpsa1bKbCiIh7DHBjIfduz08DZyyrQgN%2BopE3A5rSnwR8e9D0v6Y3YUy8IpLg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T193744Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3GNLTI5BH%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=7898c4479b8212184fd5bb261ab3353f964a1c7d876a59aaf2cbc9498e8e9676,https://prod-us-gov-west-1-package-distribution-artifacts-bucket.s3.us-gov-west-1.amazonaws.com/007/Glue5.0/AwsGlueMLLibs/java17/5.0.380/dj5xOe-AwsGlueMLLibs.jar?X-Amz-Security-Token=FwoDYXdzEDIaDC0qAqoIQcW1qNYUJiKuAXpOzs8qwMVrVbc11D3opJklo5Z9pMvg2DQmQybaHKVr9k9sqUULbMIe4LoNTHnV33oC6ivGDB3ZA1n8GF4s9L%2BP9n1ruFGpTBuuUoMn68aVAnxRH2jDX5yKFujnw9tFj66fOa65fbDDdps8FDDxmDL5YnIhn9gX0QOknJoG4PnKktUFFaC%2B%2FFTFbo69AX%2BLJieZ0IFCc9wR2ycOeOe7ssmDWar%2B4AMBVSpsa1bKbCiIh7DHBjIfduz08DZyyrQgN%2BopE3A5rSnwR8e9D0v6Y3YUy8IpLg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251012T193744Z&X-Amz-SignedHeaders=host&X-Amz-Credential=ASIARNA7EHT3GNLTI5BH%2F20251012%2Fus-gov-west-1%2Fs3%2Faws4_request&X-Amz-Expires=1800&X-Amz-Signature=f187de07abaa81f9b5298fc8e28d56542e0ca59c2d673db4ab23b3617f6cb23b --config s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/config/maximo/dq/mrline.yaml  --job_type data_quality --JOB_ID j_68d9e2b2aec606b50ea33ae15a515464d4c4f08c793fb106abbcf2d1ef73367f --extra-py-files s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/mosaic.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/sqlglot.zip,s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/glue_packages/yaml.zip   --JOB_RUN_ID jr_4cd19852f74703f225781bc74a7e03820e4015540a2c03c2b0124a9c6384e1d2_attempt_3 --scriptLocation s3://entergy-govdatacore-dataeng-code-repo-dev/entergy-gov-data-core-code/scripts/raw_dq_load.py  --tenant-internal glue --enable-auto-scaling true --JOB_NAME maximo_dq_mrline
Sun Oct 12 19:37:48 UTC 2025
Preparing ...